<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2018%2F04%2F12%2FGolang%20%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[1. 接口1234567891011121314151617181920212223242526272829303132333435363738394041424344package maintype I interface &#123; foo1() foo2()&#125;type S struct &#123;&#125;func (s S) foo1() &#123;&#125;func (s S) foo2() &#123;&#125;type T struct &#123;&#125;func (t *T) foo1() &#123;&#125;func (t *T) foo2() &#123;&#125;type R struct &#123;&#125;func (r R) foo1() &#123;&#125;func (r *R) foo2() &#123;&#125;func main() &#123; var s S var si I = s si.foo1() si = &amp;s si.foo2() var t T var ti I = &amp;t ti.foo1() //ti = t 编译报错 var r R var ri I = &amp;r ri.foo1()&#125; 若 T 是一个具体类型，并且想在 T 上实现 接口 I： 如果将接口的方法绑定到 T 上，那么可以将 T 或者 *T 类型的变量赋值给 I 类型的变量。 如果将接口的方法绑定到 T 上，那么只能将 T 类型的变量赋值给 I 类型的变量。 如果将接口的一部分方法绑定到 T 上，一部分绑定到 T 上，那么只能将 T 类型的变量赋值给 I 类型的变量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python 基础编程]]></title>
    <url>%2F2018%2F03%2F23%2F%E3%80%8APython%20%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 基础知识 双斜线整除（适用于浮点数）： 1234&gt;&gt;&gt; 5.2 // 2.02.0&gt;&gt;&gt; 5 // 22 乘方运算符： 12&gt;&gt;&gt; 2 ** 38 str：把值转换为字符串；repr：把值变为合法的 Python 表达式 12345678&gt;&gt;&gt; str(10000L)'10000'&gt;&gt;&gt; print str(10000L)10000&gt;&gt;&gt; repr(10000L)'10000L'&gt;&gt;&gt; print repr(10000L)10000L input 和 raw_input：input 假设用户输入的是合法的 Python 表达式（例如字符串需要用引号括起来），而 raw_input 把所有的输入当做字符串处理。 长字符串：使用 &#39;&#39;&#39; 三引号： 1234&gt;&gt;&gt; print '''hello... world'''helloworld 原始字符串： 1234&gt;&gt;&gt; print r'C:\nowhere'C:\nowhere&gt;&gt;&gt; print r"Let's go \n\n"Let's go \n\n 2. 列表和元组 分片 1234567891011121314151617181920212223242526272829&gt;&gt;&gt; nums = range(10)&gt;&gt;&gt; nums[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; nums[2:7][2, 3, 4, 5, 6]&gt;&gt;&gt; nums[:][0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; nums[5:][5, 6, 7, 8, 9]&gt;&gt;&gt; nums[-5:-1][5, 6, 7, 8]&gt;&gt;&gt; nums[:6][0, 1, 2, 3, 4, 5]&gt;&gt;&gt; nums[-3:][7, 8, 9]&gt;&gt;&gt; nums[-3:2][]&gt;&gt;&gt; nums[::3][0, 3, 6, 9]&gt;&gt;&gt; nums[9:2:-2][9, 7, 5, 3]&gt;&gt;&gt; nums[::-3][9, 6, 3, 0]&gt;&gt;&gt; nums[5::-3][5, 2]&gt;&gt;&gt; nums[:5:-3][9, 6]&gt;&gt;&gt; nums[1:5:-1][] 序列相加： 12&gt;&gt;&gt; [1, 2, 3] + [4, 5][1, 2, 3, 4, 5] 序列相乘： 123456&gt;&gt;&gt; [2] * 3[2, 2, 2]&gt;&gt;&gt; [2, 3] * 3[2, 3, 2, 3, 2, 3]&gt;&gt;&gt; [None] * 10[None, None, None, None, None, None, None, None, None, None] list 函数： 1234&gt;&gt;&gt; list('hello')['h', 'e', 'l', 'l', 'o']&gt;&gt;&gt; ''.join(list('hello'))'hello' 分片赋值： 1234567891011121314&gt;&gt;&gt; name = list('Gil')&gt;&gt;&gt; name[3:] = list('gamesh')&gt;&gt;&gt; name['G', 'i', 'l', 'g', 'a', 'm', 'e', 's', 'h']&gt;&gt;&gt; name[5:5] = ['XYZ']&gt;&gt;&gt; NAMETraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'NAME' is not defined&gt;&gt;&gt; name['G', 'i', 'l', 'g', 'a', 'XYZ', 'm', 'e', 's', 'h']&gt;&gt;&gt; name[:] = []&gt;&gt;&gt; name[] append：追加元素 count：统计某个元素出现次数 extend：在列表末尾一次性追加另一个序列中的多个值。 index：查找某个值第一个匹配项的索引位置。 insert：将对象插入到列表指定位置。 pop：移除元素（默认是最后一个）并返回该元素值。 remove：移除某个值的第一个匹配项。方法无返回值。 reverse：反向存放。 sort：原地排序。方法无返回值。可以传入排序函数参数，以及 key 和 reverse 两个关键字参数。参数 key 指定一个排序过程中使用的函数，用该函数为每个列表元素创建一个键，然后所有元素根据键来排序。reverse 提供一个布尔值，用来指明列表是否需要反向排序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&gt;&gt;&gt; x = [4, 1, 3, 6, 5, 2, 8]&gt;&gt;&gt; x.append(7)&gt;&gt;&gt; x[4, 1, 3, 6, 5, 2, 8, 7]&gt;&gt;&gt; y = [7, 9]&gt;&gt;&gt; x.extend(y)&gt;&gt;&gt; x[4, 1, 3, 6, 5, 2, 8, 7, 7, 9]&gt;&gt;&gt; x.count(7)2&gt;&gt;&gt; x.index(6)3&gt;&gt;&gt; x.insert(0, 10)&gt;&gt;&gt; x[10, 4, 1, 3, 6, 5, 2, 8, 7, 7, 9]&gt;&gt;&gt; x.pop()9&gt;&gt;&gt; x[10, 4, 1, 3, 6, 5, 2, 8, 7, 7]&gt;&gt;&gt; x.pop(1)4&gt;&gt;&gt; x[10, 1, 3, 6, 5, 2, 8, 7, 7]&gt;&gt;&gt; x.remove(7)&gt;&gt;&gt; x[10, 1, 3, 6, 5, 2, 8, 7]&gt;&gt;&gt; x.reverse()&gt;&gt;&gt; x[7, 8, 2, 5, 6, 3, 1, 10]&gt;&gt;&gt; y = sorted(x)&gt;&gt;&gt; y[1, 2, 3, 5, 6, 7, 8, 10]&gt;&gt;&gt; y = x[:]&gt;&gt;&gt; y.sort()&gt;&gt;&gt; y[1, 2, 3, 5, 6, 7, 8, 10]&gt;&gt;&gt; y = x[:]&gt;&gt;&gt; y.sort(reverse=True)&gt;&gt;&gt; y[10, 8, 7, 6, 5, 3, 2, 1]&gt;&gt;&gt; def mycmp(a, b):... return -cmp(a, b)...&gt;&gt;&gt; y = x[:]&gt;&gt;&gt; y.sort(mycmp)&gt;&gt;&gt; y[10, 8, 7, 6, 5, 3, 2, 1]&gt;&gt;&gt; x = ['abc', 'd', 'ef']&gt;&gt;&gt; x.sort(key=len)&gt;&gt;&gt; x['d', 'ef', 'abc']&gt;&gt;&gt; x.reverse()&gt;&gt;&gt; x['abc', 'ef', 'd'] 创建元组： 12345678&gt;&gt;&gt; x = 1, 2, 3&gt;&gt;&gt; x(1, 2, 3)&gt;&gt;&gt; x = (1,)&gt;&gt;&gt; x(1,)&gt;&gt;&gt; x[:](1,) 元组的分片还是元组，就像列表的分片还是列表。 tuple 函数以一个序列作为参数并把它转换为元组： 123&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; tuple(x)(1, 2, 3) 元组的存在意义： 在映射中作为键存在（不可变对象） 作为很多内建函数和方法的返回值 3. 字符串 字符串常量： 12345678910111213&gt;&gt;&gt; import string&gt;&gt;&gt; print string.digits0123456789&gt;&gt;&gt; print string.lettersABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz&gt;&gt;&gt; print string.lowercaseabcdefghijklmnopqrstuvwxyz&gt;&gt;&gt; print string.uppercaseABCDEFGHIJKLMNOPQRSTUVWXYZ&gt;&gt;&gt; print string.printable0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\]^_`&#123;|&#125;~&gt;&gt;&gt; print string.punctuation&gt;&gt; !"#$%&amp;'()*+,-./:;&lt;=&gt;?@[]^_`&#123;|&#125;~ find ：查找子串 12&gt;&gt;&gt; "My name is Gil".find('Gil')11 replace：替换 12&gt;&gt;&gt; "My name is Gil".replace('Gil', 'Yamato')'My name is Yamato' join： 12&gt;&gt;&gt; &apos;+&apos;.join([&apos;1&apos;, &apos;2&apos;, &apos;3&apos;])&apos;1+2+3&apos; split: 1234&gt;&gt;&gt; 'hello world'.split()['hello', 'world']&gt;&gt;&gt; '1+2+3'.split('+')['1', '2', '3'] split： 1234&gt;&gt;&gt; 'hello world'.split()['hello', 'world']&gt;&gt;&gt; '1+2+3'.split('+')['1', '2', '3'] strip： 1234&gt;&gt;&gt; ' wait for stripping '.strip()'wait for stripping'&gt;&gt;&gt; ' !!!!another case !!!! '.strip(' !')'another case' 4. 字典 dict 函数通过其他映射或者键值对的序列建立字典： 123456789101112131415161718&gt;&gt;&gt; items = [('k1', 'k2'), ('v1', 'v2')]&gt;&gt;&gt; d = dict(items)&gt;&gt;&gt; d&#123;'v1': 'v2', 'k1': 'k2'&#125;&gt;&gt;&gt; items = [('k1', 'v1'), ('k2', 'v2')]&gt;&gt;&gt; d = dict(items)&gt;&gt;&gt; d&#123;'k2': 'v2', 'k1': 'v1'&#125;&gt;&gt;&gt; d = dict(name = 'Gil', age = 17)&gt;&gt;&gt; d&#123;'age': 17, 'name': 'Gil'&#125;# 字典的格式化字符串&gt;&gt;&gt; "%(name)s is %(age)d years old" % d'Gil is 17 years old'&gt;&gt;&gt; len(d)2 clear 方法清除字典中所有的项。 copy 方法返回一个具有相同键值对的新字典（浅复制，深复制需要使用内置的 deepcopy 函数）。 fromkeys 使用给定的键建立新的字典，每个键都对应一个默认的值 None。 get 方法按键取值。如果键不存在，则得到 None。可以在方法中传入默认值： 123&gt;&gt;&gt; d.get('none')&gt;&gt;&gt; d.get('none', 'N/A')'N/A' items 方法将字典的所有的项以列表方式返回，列表中的每一项都表示为（键，值）对的形式： 12&gt;&gt;&gt; d.items()[('age', 17), ('name', 'Gil')] iteritems 类似于 items，但是会返回一个迭代器对象而不是列表： 12&gt;&gt;&gt; d.iteritems()&lt;dictionary-itemiterator object at 0x10f3ce838&gt; keys 方法将字典中的键以列表形式返回，而 iterkeys 则返回针对键的迭代器。 values 方法以列表的形式返回字典中的值，而 itervalues 返回值的迭代器。与 keys 方法不同的是，values 方法返回的值的列表中可以包含重复的元素。 pop 方法用来获得对应于给定键的值，然后将这个键值对从字典中移除： 12&gt;&gt;&gt; d.pop('name')'Gil' popitem 弹出一个键值对： 12&gt;&gt;&gt; d.popitem()('age', 17) setdefault 某种程度上类似于 get，能够获得与给定键相关联的值。除此之外，setdefault 还能在字典中不含有给定键的情况下设定相应的键值。当键不存在时，setdefault 返回默认值并且响应地更新字典。如果键存在，那么就返回与其相应的值，但不更新字典。默认值是可选的，如果不设定，则默认使用 None： 123456&gt;&gt;&gt; d.setdefault('nobody', 'Adam')'Adam'&gt;&gt;&gt; d.setdefault('nobody', 'Berserker')'Adam'&gt;&gt;&gt; d.setdefault('burning')&gt;&gt;&gt; update 方法可以利用一个字典项更新另一个字典： 1234&gt;&gt;&gt; e = &#123;'another': 'zzz'&#125;&gt;&gt;&gt; d.update(e)&gt;&gt;&gt; d&#123;'nobody': 'Adam', 'another': 'zzz', 'burning': None&#125; 遍历字典： 123456&gt;&gt;&gt; for k, v in d.items():... print k, v...nobody Adamanother zzzburning None 5. 条件、循环和其他语句 序列解包： 123456&gt;&gt;&gt; x, y, z = (1, 2, 3)&gt;&gt;&gt; x1&gt;&gt;&gt; x, y = y, x&gt;&gt;&gt; x, y(2, 1) 解包序列中的元素数量必须和放置在赋值符号左边的变量数量完全一致。 链式赋值： 12345x = y = somefunc()# 相当于y = somefunc()x = y 下列值在作为布尔表达式的时候，会被解释器看做假： 1False, None, 0, "", (), [], &#123;&#125;s bool 函数可以用来转换其他值： 1234&gt;&gt;&gt; bool("I am Gil")True&gt;&gt;&gt; bool(0)False 相等和同一运算符： 12345678910&gt;&gt;&gt; x = y = [1, 2, 3]&gt;&gt;&gt; z = [1, 2, 3]&gt;&gt;&gt; x == yTrue&gt;&gt;&gt; x == zTrue&gt;&gt;&gt; x is yTrue&gt;&gt;&gt; x is zFalse 序列的比较： 123456&gt;&gt;&gt; "alpha" &lt; "beta"True&gt;&gt;&gt; [1, 2] &lt; [2, 1]True&gt;&gt;&gt; [1, [2, 3]] &lt; [1, [2, 4]]True 断言： 123456&gt;&gt;&gt; age = 10&gt;&gt;&gt; assert 0 &lt;= age &lt;= 100&gt;&gt;&gt; assert age &gt; 100Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AssertionError zip 函数：并行迭代 1234567&gt;&gt;&gt; names = ['anne', 'beth', 'claire']&gt;&gt;&gt; ages = [17, 18, 19, 20]&gt;&gt;&gt; zip(names, ages)[('anne', 17), ('beth', 18), ('claire', 19)]&gt;&gt;&gt; zip(range(5), range(10), xrange(100000))[(0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4)] zip 可以处理不等长的序列，当最短的序列用完时就会停止。 enumerage 函数：按索引迭代 123&gt;&gt;&gt; for i, item in enumerage(a_list):... if(item == 'xxx'):... a_list[i] = 'yyy' sorted 和 reversed：排序和翻转可迭代对象 1234567&gt;&gt;&gt; sorted('Hello, world!')[' ', '!', ',', 'H', 'd', 'e', 'l', 'l', 'l', 'o', 'o', 'r', 'w']&gt;&gt;&gt; list(reversed('Hello, world!'))['!', 'd', 'l', 'r', 'o', 'w', ' ', ',', 'o', 'l', 'l', 'e', 'H']&gt;&gt;&gt;&gt;&gt;&gt; ''.join(reversed('Hello, world!'))'!dlrow ,olleH' 循环中的 else 字句：仅当循环没有被 break 时执行 12345&gt;&gt;&gt; for i in range(0, 10):... if(i == 1):... break... else:... print('did not find 1') 列表推导式： 1234&gt;&gt;&gt; [x ** x for x in range(1, 6)][1, 4, 27, 256, 3125]&gt;&gt;&gt; [x ** x for x in range(1, 6) if x &gt; 3][256, 3125] del 函数： 12345678&gt;&gt;&gt; x = y = [1, 2]&gt;&gt;&gt; del x&gt;&gt;&gt; xTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'x' is not defined&gt;&gt;&gt; y[1, 2] del 只删除引用，而不删除对象本身（由垃圾回收清理）。 exec： 12345678910&gt;&gt;&gt; exec "print 'Hello, world!'"Hello, world!&gt;&gt;&gt; from math import sqrt&gt;&gt;&gt; scope = &#123;&#125;&gt;&gt;&gt; exec 'sqrt = 1' in scope&gt;&gt;&gt; sqrt(4)2.0&gt;&gt;&gt; scope['sqrt']1 eval 函数： 12345&gt;&gt;&gt; scope = &#123;&#125;&gt;&gt;&gt; scope['x'] = 2&gt;&gt;&gt; exec 'y = 3' in scope&gt;&gt;&gt; eval('x * y', scope)6 6. 抽象 判断函数是否可调用：callable 12&gt;&gt;&gt; callable(math.sqrt)True 如果在函数的开头写下字符串，它就会作为函数的一部分进行存储，这称为文档字符串，通过 __doc__ 属性访问： 12&gt;&gt;&gt; math.sqrt.__doc__'sqrt(x)\n\nReturn the square root of x.' 通过 help 函数获取对象的信息： 1234567&gt;&gt;&gt;help(math.sqrt)Help on built-in function sqrt in module math:sqrt(...) sqrt(x) Return the square root of x. Python 形式上不支持函数重载。 位置参数与默认参数： 123456789101112131415161718&gt;&gt;&gt; def foo(name="Gil", age=17):... print '%s is %d years old.' % (name, age)...&gt;&gt;&gt; foo()Gil is 17 years old.&gt;&gt;&gt; foo("Lyn")Lyn is 17 years old.&gt;&gt;&gt; foo("Allen", 20)Allen is 20 years old.&gt;&gt;&gt; foo(age=25)Gil is 25 years old.&gt;&gt;&gt; foo(20, "Allen")Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 2, in fooTypeError: %d format: a number is required, not str&gt;&gt;&gt; foo(age=20, name="Allen")Allen is 20 years old. 不定参数： 123456789101112&gt;&gt;&gt; def foo(argv, *params, **kw):... print argv, params, kw...&gt;&gt;&gt; foo(0, 1, 2, 3, k='v', p='q')0 (1, 2, 3) &#123;'p': 'q', 'k': 'v'&#125;&gt;&gt;&gt; foo(0, *(1, 2, 3), **&#123;'k':'v', 'p':'q'&#125;)0 (1, 2, 3) &#123;'p': 'q', 'k': 'v'&#125;&gt;&gt;&gt; foo(*(1, 2, 3), **&#123;'k':'v', 'p':'q'&#125;, argv=0) File "&lt;stdin&gt;", line 1 foo(*(1, 2, 3), **&#123;'k':'v', 'p':'q'&#125;, argv=0) ^SyntaxError: invalid syntax 在和位置参数配合时可能会出问题。 vars 函数：查看局部作用域字典。 globals 函数：查看全局作用域字典。 函数内部使用 global 声明一个变量为全局变量。 闭包： 12345678910&gt;&gt;&gt; def outermulti(factor):... def innermulti(number):... return number * factor... return innermulti...&gt;&gt;&gt; foo = outermulti(10)&gt;&gt;&gt; foo(2.33)23.3&gt;&gt;&gt; outermulti(5)(4)20 函数式编程： 123456&gt;&gt;&gt; map(str, range(10))['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']&gt;&gt;&gt; seq = ["foo", "x41", "?!", "***"]&gt;&gt;&gt; filter(lambda x : x.isalnum(), seq)['foo', 'x41'] 7. 更加抽象 self 参数事实上正是方法和函数的区别。方法（更专业一点可以称为绑定方法）将他们的第一个参数绑定到所属的实例上。 为了让方法或者特性变为私有，只要在它的名字前面加上双下划线。类的内部定义中，所有以双下划线开始的名字都被”翻译“成前面加上单下划线的类名的形式： 123456789101112131415&gt;&gt;&gt; class A:... def __inaccessible(self):... print 'inaccessible'... def accessible(self):... print 'accessible'...&gt;&gt;&gt; a = A()&gt;&gt;&gt; a.accessible()accessible&gt;&gt;&gt; a.__inaccessible()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: A instance has no attribute '__inaccessible'&gt;&gt;&gt; a._A__inaccessible()inaccessible 类的命名空间： 1234567891011121314&gt;&gt;&gt; class Incre:... n = 0... def __init__(self):... Incre.n += 1...&gt;&gt;&gt; m = Incre()&gt;&gt;&gt; m.n1&gt;&gt;&gt; x = Incre()&gt;&gt;&gt; x.n2&gt;&gt;&gt; m.n = 10&gt;&gt;&gt; x.n2 检查继承： 1234567891011121314&gt;&gt;&gt; class SubA(A):... pass...&gt;&gt;&gt; issubclass(SubA, A)True&gt;&gt;&gt; SubA.__bases__(&lt;class __main__.A at 0x10f3b5a78&gt;,)&gt;&gt;&gt; x = SubA()&gt;&gt;&gt; isinstance(x, SubA)True&gt;&gt;&gt; isinstance(x, A)True&gt;&gt;&gt; x.__class__&lt;class __main__.SubA at 0x10f3b5b48&gt; 如果一个方法从多个超类继承（多个具有相同名字的不同方法），那么先继承的类中的方法会重写后继承的类中的方法。 查看对象内所有存储的值，可以使用 __dict__ 属性： 12&gt;&gt;&gt; A.__dict__&#123;'accessible': &lt;function accessible at 0x10f3cf578&gt;, '__module__': '__main__', '_A__inaccessible': &lt;function __inaccessible at 0x10f3cfc80&gt;, '__doc__': None&#125; 8. 异常123456789101112try: doSomething()except ExceptionA, ea: handlerA(ea)except (ExceptionB1, ExceptionB2), eb: handleB(eb)except: handleOthers()else: handleNoException()finally: doDefaultLogic() 9. 魔法方法、属性和迭代器 静态方法和类方法： 12345678910111213&gt;&gt;&gt; class MyClass(object):... class_var = "class var"... @staticmethod... def smeth():... print "This is a static method"... @classmethod... def cmeth(cls):... print "This is a class method", cls, cls.class_var...&gt;&gt;&gt; MyClass.smeth()This is a static method&gt;&gt;&gt; MyClass.cmeth()This is a class method &lt;class '__main__.MyClass'&gt; class var __getattribute__(self, name)：当特性 name 被访问时自动调用。__getattribute__(self, name) 拦截所有特性的访问，也拦截对 __dict__ 的访问。访问 __getattribute__ 中与 self 有关的特性时，使用超类的 __getattribute__ 方法（使用 super 函数）是唯一安全的途径。 __getattr__(self, name)__：当特性 name 被访问且对象没有相应的特性时被自动调用。 __setattr__(self, name, value)：当试图给特性 name 赋值时会被自动调用。 __delattr__(self, name)：当试图删除特性 name 时被自动调用。 一个实现了 __iter__ 方法的对象是可迭代的，一个实现了 next 方法的对象则是迭代器。__iter__ 方法会返回一个迭代器（即自身）。 生成器是一个包含 yield 关键字的函数。当它被调用时，在函数体中的代码不会被执行，而会返回一个迭代器。每次请求一个值，就会执行生成器中的代码，直到遇到一个 yield 或者 return 语句。yield 意味着应该生成一个值，而 return 语句意味着生成器要停止执行。 10. 自带电池 模块在第一次导入到程序中时被执行。 在主程序中，变量 __name__ 的值是 __main__，而在导入的模块中，这个值就被设定为模块的名字。 序列和映射是对象的集合。为了实现它们基本的行为，如果对象是不可变的，那么就需要使用两个魔法方法，如果是可变的则需要 4 个： __len__(self)：这个方法返回集合中所含项目的数量。对于序列来说，这就是元素的个数；对于映射来说，则是键值对的数量。如果返回 0（并且没有实现重写该行为的 __nonzero__），对象会被当做一个布尔变量中的假值进行处理。 __getitem__(self.key)：这个方法返回与所给键对应的值。对于一个序列，键应该是一个 0～n-1的整数，n 是序列的长度；对于映射来说，可以使用任何种类的键。 __setitem__(self, key, value) ：这个方法应该按一定的方式存储和 key 相关的 value，该值随后可使用 __getitem__ 来获取。当然，只能为可以修改的对象定义这个方法。 __delitem__(self, key)：这个方法在对一部分对象使用 del 语句时被调用，同时必须删除和元素相关的键。这个方法也是为可修改的对象定义的（并不是删除全部的对象，而只删除一些需要移除的元素）。 对这些方法的附加要求如下： 对于一个序列来说，如果键是负整数，那么要从末尾开始计数。换句话说，x[-n] 和 [x[len(x) - n]] 是一样的。 如果键是不合适的类型，会引发一个 TypeError 异常。 如果序列的索引是正确的类型，但超出了范围，应该引发一个 IndexError 异常。 当模块存储在文件中时（扩展名 .py），包就是模块所在的目录。它必须包含一个命名为 __init__.py 的文件。假设要建立一个名为 drawing 的包，其中包括名为 shapes 和 colors 的模块。 123import drawingimport drawing.colorsfrom drawing import shapes 第一条语句中， __init__ 模块的内容是可用的，但 shapes 和 colors 模块则不可用。执行第二条语句后，colors 模块可用了，但只能通过全名 drawing.colors 来使用。在执行第三条语句之后，shapes 模块可用，可以通过短名调用。 dir() 函数可以打印对象的所有特性（以及模块的所有函数、类、变量等）： 12&gt;&gt;&gt; dir(math)['__doc__', '__file__', '__name__', '__package__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos', 'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs', 'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'hypot', 'isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'modf', 'pi', 'pow', 'radians', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'trunc'] __all__ 变量定义了模块的公有接口。准确地说，它告诉解释器：从模块导入所有名字代表什么含义。如果没有设定 __all__，用 import * 语句默认将会导入模块中所有不以下划线开头的全局名称。 11. 文件和流 open 函数用来打开文件： open(name[, mode[, buffering]]) 模式参数 模式 描述 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。 w 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 w+ 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 如果缓冲参数是 0（或者 False），I/O 就是无缓冲的；如果是 1 或者 True，I/O 就是有缓冲的。大于 1 的数字代表缓冲区的大小（单位是字节），-1 （或者其他负数）代表使用默认的缓冲区大小。 下表列出了 file 对象常用的函数： 序号 方法及描述 1 file.close() 关闭文件。关闭后文件不能再进行读写操作。 2 file.flush() 刷新文件内部缓冲，直接把内部缓冲区的数据立刻写入文件，而不是被动的等待输出缓冲区写入。 3 file.fileno() 返回一个整型的文件描述符（file descriptor FD 整型），可以用在如 os 模块的 read 方法等一些底层操作上。 4 file.isatty() 如果文件连接到一个终端设备返回 True，否则返回 False。 5 file.next() 返回文件下一行。 6 file.read([size]) 从文件读取指定的字节数，如果未给定或为负则读取所有。 7 file.readline([size]) 读取整行，包括 “\n” 字符。 8 file.readlines([sizehint]) 读取所有行并返回列表，若给定 sizeint&gt;0，则是设置一次读多少字节，这是为了减轻读取压力。 9 [file.seek(offset[, whence]) 设置文件当前位置。 10 file.tell() 返回文件当前位置。 11 [file.truncate([size]) 截取文件，截取的字节通过 size 指定，默认为当前文件位置。 12 file.write(str) 将字符串写入文件，没有返回值。 13 file.writelines(sequence) 向文件写入一个序列字符串列表，如果需要换行则要自己加入每行的换行符。 14. 网络编程 用 socket() 函数来创建套接字，语法格式如下： 1socket.socket([family[, type[, proto]]]) family：套接字家族可以使 AF_UNIX 或者 AF_INET type：套接字类型可以根据是面向连接的还是非连接分为 SOCK_STREAM 或 SOCK_DGRAM protocol：一般不填默认为0 API： 函数 描述 服务器端套接字 s.bind() 绑定地址 (host, port) 到套接字， 在 AF_INET 下，以元组 (host, port) 的形式表示地址。 s.listen() 开始 TCP 监听。backlog 指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为 1，大部分应用程序设为 5 就可以了。 s.accept() 被动接受 TCP 客户端连接，（阻塞式）等待连接的到来 客户端套接字 s.connect() 主动初始化 TCP 服务器连接。一般 address 的格式为元组 (hostname, port)，如果连接出错，返回 socket.error 错误。 s.connect_ex() connect() 函数的扩展版本，出错时返回出错码，而不是抛出异常 公共用途的套接字函数 s.recv() 接收 TCP 数据，数据以字符串形式返回，bufsize指定要接收的最大数据量。flag 提供有关消息的其他信息，通常可以忽略。 s.send() 发送 TCP 数据，将 string 中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于 string 的字节大小。 s.sendall() 完整发送 TCP 数据，完整发送 TCP 数据。将 string 中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回 None，失败则抛出异常。 s.recvfrom() 接收 UDP 数据，与 recv() 类似，但返回值是 (data, address)。其中 data 是包含接收数据的字符串，address 是发送数据的套接字地址。 s.sendto() 发送 UDP 数据，将数据发送到套接字，address 是形式为 (ipaddr, port) 的元组，指定远程地址。返回值是发送的字节数。 s.close() 关闭套接字 s.getpeername() 返回连接套接字的远程地址。返回值通常是元组 (ipaddr, port)。 s.getsockname() 返回套接字自己的地址。通常是一个元组 (ipaddr, port)。 s.setsockopt(level,optname,value) 设置给定套接字选项的值。 s.getsockopt(level,optname[.buflen]) 返回套接字选项的值。 s.settimeout(timeout) 设置套接字操作的超时期，timeout 是一个浮点数，单位是秒。值为 None 表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如 connect()） s.gettimeout() 返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。 s.fileno() 返回套接字的文件描述符。 s.setblocking(flag) 如果 flag 为 0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用 recv() 没有发现任何数据，或 send() 调用无法立即发送数据，那么将引起 socket.error 异常。 s.makefile() 创建一个与该套接字相关连的文件]]></content>
      <categories>
        <category>读书笔记</category>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[想读的书]]></title>
    <url>%2F2018%2F02%2F04%2F%E6%83%B3%E8%AF%BB%E7%9A%84%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[古今数学思想 什么是数学 全球通史 推理的迷宫]]></content>
  </entry>
  <entry>
    <title><![CDATA[大数据算法问题]]></title>
    <url>%2F2018%2F01%2F10%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AE%97%E6%B3%95%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot + Dubbo 试用]]></title>
    <url>%2F2018%2F01%2F02%2FSpring%20Boot%20%2B%20Dubbo%20%E8%AF%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1. 启动 ZooKeeperMac 下启动单机版 ZooKeeper： zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties 2. dubbo-api创建服务接口定义项目。该项目中只定义了一个服务接口 iservice.IUserService： 1234public interface IUserService &#123; public String hello(String s);&#125; 正常情况下应该将这个项目发布成 jar 包供提供方和消费者调用，不过这里为了简便起见，会在 Intellij 中直接让服务提供方和消费者依赖 dubbo-api 项目。 2. dubbo-provider创建服务提供方项目 dubbo-provider，基于 Spring Boot，并设置依赖 dubbo-api。 服务提供方启动类 DubboProviderApplication 12345678@SpringBootApplication@ImportResource("classpath:dubbo-provider.xml")public class DubboProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DubboProviderApplication.class, args); &#125;&#125; 这里 import 了 dubbo 项目的配置 xml。 定义服务实现 serviceimpl.UserServiceImpl 123456public class UserServiceImpl implements IUserService &#123; public String hello(String s) &#123; return "hello " + s + "!"; &#125;&#125; 在 application-properties 里设置服务的 HTTP 端口 server.port=8888。 在 classpath 下创建配置文件 dubbo-provider.xml： 12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="dubbo-provider" /&gt; &lt;dubbo:registry address="zookeeper://localhost:2181"/&gt; &lt;dubbo:provider cluster="failfast"/&gt; &lt;dubbo:protocol name="dubbo" port="12345" /&gt; &lt;bean id="userServiceImpl" class="xyq.serviceimpl.UserServiceImpl"/&gt; &lt;dubbo:service interface="iservice.IUserService" ref="userServiceImpl"/&gt;&lt;/beans&gt; 这个 xml 中定义了： 服务提供方的名称：dubbo-provider 注册中心的协议及地址：运行在本地 2181 端口上的 ZooKeeper dubbo 服务运行的端口：12345 暴露的服务接口及其实现：IUserService 和 UserServiceImpl 启动项目。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354552017-12-28 21:39:54.739 INFO 13377 --- [ main] xyq.DubboProviderApplication : Starting DubboProviderApplication on bogon with PID 13377 (/Users/xyq/workspace/myproject/dubbo-provider/target/classes started by xyq in /Users/xyq/workspace)2017-12-28 21:39:54.743 INFO 13377 --- [ main] xyq.DubboProviderApplication : No active profile set, falling back to default profiles: default2017-12-28 21:39:54.854 INFO 13377 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d127a61: startup date [Thu Dec 28 21:39:54 CST 2017]; root of context hierarchy2017-12-28 21:39:55.323 INFO 13377 --- [ main] o.s.b.f.xml.XmlBeanDefinitionReader : Loading XML bean definitions from class path resource [dubbo-provider.xml]2017-12-28 21:39:55.530 INFO 13377 --- [ main] c.a.dubbo.common.logger.LoggerFactory : using logger: com.alibaba.dubbo.common.logger.log4j.Log4jLoggerAdapter2017-12-28 21:39:56.281 INFO 13377 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8888 (http)2017-12-28 21:39:56.295 INFO 13377 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2017-12-28 21:39:56.296 INFO 13377 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.232017-12-28 21:39:56.402 INFO 13377 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2017-12-28 21:39:56.402 INFO 13377 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1553 ms2017-12-28 21:39:56.549 INFO 13377 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: &apos;dispatcherServlet&apos; to [/]2017-12-28 21:39:56.553 INFO 13377 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;characterEncodingFilter&apos; to: [/*]2017-12-28 21:39:56.554 INFO 13377 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;hiddenHttpMethodFilter&apos; to: [/*]2017-12-28 21:39:56.554 INFO 13377 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;httpPutFormContentFilter&apos; to: [/*]2017-12-28 21:39:56.554 INFO 13377 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;requestContextFilter&apos; to: [/*]2017-12-28 21:39:57.045 INFO 13377 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d127a61: startup date [Thu Dec 28 21:39:54 CST 2017]; root of context hierarchy2017-12-28 21:39:57.114 INFO 13377 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error]&#125;&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)2017-12-28 21:39:57.115 INFO 13377 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error],produces=[text/html]&#125;&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)2017-12-28 21:39:57.159 INFO 13377 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:39:57.159 INFO 13377 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:39:57.189 INFO 13377 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:39:57.318 INFO 13377 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup2017-12-28 21:39:57.330 INFO 13377 --- [ main] com.alibaba.dubbo.config.AbstractConfig : [DUBBO] The service ready on spring started. service: iservice.IUserService, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.417 INFO 13377 --- [ main] com.alibaba.dubbo.config.AbstractConfig : [DUBBO] Export dubbo service iservice.IUserService to local registry, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.417 INFO 13377 --- [ main] com.alibaba.dubbo.config.AbstractConfig : [DUBBO] Export dubbo service iservice.IUserService to url dubbo://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;bind.ip=10.236.19.51&amp;bind.port=12345&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.417 INFO 13377 --- [ main] com.alibaba.dubbo.config.AbstractConfig : [DUBBO] Register dubbo service iservice.IUserService url dubbo://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;bind.ip=10.236.19.51&amp;bind.port=12345&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346 to registry registry://localhost:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-provider&amp;dubbo=2.5.8&amp;pid=13377&amp;registry=zookeeper&amp;timestamp=1514468397338, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.535 INFO 13377 --- [ main] c.a.d.remoting.transport.AbstractServer : [DUBBO] Start NettyServer bind /0.0.0.0:12345, export /10.236.19.51:12345, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.555 INFO 13377 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Load registry store file /Users/xyq/.dubbo/dubbo-registry-dubbo-provider-localhost:2181.cache, data: &#123;xyq.service.UserService=empty://10.236.19.51:12345/xyq.service.UserService?anyhost=true&amp;application=dubbo-provider&amp;category=configurators&amp;check=false&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=xyq.service.UserService&amp;methods=hello&amp;pid=12958&amp;side=provider&amp;timestamp=1514467127634&#125;, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.562 INFO 13377 --- [ main] c.a.d.common.concurrent.ExecutionList : [DUBBO] Executor for listenablefuture is null, will use default executor!, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.571 INFO 13377 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread.2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:zookeeper.version=3.3.3-1073969, built on 02/23/2011 22:27 GMT2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:host.name=bogon2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.version=1.8.0_912017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.vendor=Oracle Corporation2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/tools.jar:/Users/xyq/workspace/myproject/dubbo-provider/target/classes:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.5.9.RELEASE/spring-boot-starter-web-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter/1.5.9.RELEASE/spring-boot-starter-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot/1.5.9.RELEASE/spring-boot-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.5.9.RELEASE/spring-boot-autoconfigure-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.5.9.RELEASE/spring-boot-starter-logging-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/ch/qos/logback/logback-classic/1.1.11/logback-classic-1.1.11.jar:/Users/xyq/.m2/repository/ch/qos/logback/logback-core/1.1.11/logback-core-1.1.11.jar:/Users/xyq/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.25/jcl-over-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.25/log4j-over-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/yaml/snakeyaml/1.17/snakeyaml-1.17.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.5.9.RELEASE/spring-boot-starter-tomcat-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.23/tomcat-embed-core-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.23/tomcat-annotations-api-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.5.23/tomcat-embed-el-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.23/tomcat-embed-websocket-8.5.23.jar:/Users/xyq/.m2/repository/org/hibernate/hibernate-validator/5.3.6.Final/hibernate-validator-5.3.6.Final.jar:/Users/xyq/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/Users/xyq/.m2/repository/org/jboss/logging/jboss-logging/3.3.1.Final/jboss-logging-3.3.1.Final.jar:/Users/xyq/.m2/repository/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.8.10/jackson-databind-2.8.10.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.8.0/jackson-annotations-2.8.0.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.8.10/jackson-core-2.8.10.jar:/Users/xyq/.m2/repository/org/springframework/spring-web/4.3.13.RELEASE/spring-web-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-aop/4.3.13.RELEASE/spring-aop-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-webmvc/4.3.13.RELEASE/spring-webmvc-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-expression/4.3.13.RELEASE/spring-expression-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/Users/xyq/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/xyq/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/xyq/.m2/repository/org/springframework/spring-core/4.3.13.RELEASE/spring-core-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/com/alibaba/dubbo/2.5.8/dubbo-2.5.8.jar:/Users/xyq/.m2/repository/org/springframework/spring-context/4.3.13.RELEASE/spring-context-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-beans/4.3.13.RELEASE/spring-beans-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/xyq/.m2/repository/org/jboss/netty/netty/3.2.5.Final/netty-3.2.5.Final.jar:/Users/xyq/.m2/repository/com/github/sgroschupf/zkclient/0.1/zkclient-0.1.jar:/Users/xyq/.m2/repository/org/apache/zookeeper/zookeeper/3.3.3/zookeeper-3.3.3.jar:/Users/xyq/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/xyq/.m2/repository/log4j/log4j/1.2.14/log4j-1.2.14.jar:/Users/xyq/workspace/myproject/dubbo-api/target/classes:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.library.path=/Users/xyq/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.2017-12-28 21:39:57.577 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.io.tmpdir=/var/folders/yq/d0v9dm456zd_xzc1lhllw19m0000gn/T/2017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.compiler=&lt;NA&gt;2017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.name=Mac OS X2017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.arch=x86_642017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.version=10.13.12017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.name=xyq2017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.home=/Users/xyq2017-12-28 21:39:57.578 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.dir=/Users/xyq/workspace2017-12-28 21:39:57.579 INFO 13377 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@247f74ac2017-12-28 21:39:57.589 INFO 13377 --- [or-SendThread()] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/127.0.0.1:21812017-12-28 21:39:57.600 INFO 13377 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established to localhost/127.0.0.1:2181, initiating session2017-12-28 21:39:57.613 INFO 13377 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1609d33be850005, negotiated timeout = 300002017-12-28 21:39:57.615 INFO 13377 --- [tor-EventThread] org.I0Itec.zkclient.ZkClient : zookeeper state changed (SyncConnected)2017-12-28 21:39:57.618 INFO 13377 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Register: dubbo://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.639 INFO 13377 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Subscribe: provider://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;category=configurators&amp;check=false&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346, dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.647 INFO 13377 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Notify urls for subscribe url provider://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;category=configurators&amp;check=false&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346, urls: [empty://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;category=configurators&amp;check=false&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346], dubbo version: 2.5.8, current host: 127.0.0.12017-12-28 21:39:57.707 INFO 13377 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8888 (http)2017-12-28 21:39:57.712 INFO 13377 --- [ main] xyq.DubboProviderApplication : Started DubboProviderApplication in 3.544 seconds (JVM running for 4.34) 可以看到服务提供方在 ZooKeeper 上注册成功了。 3. dubbo-consumer创建服务提供方项目 dubbo-consumer，基于 Spring Boot，并设置依赖 dubbo-api。 服务消费者启动类 DubboConsumerApplication 12345678@SpringBootApplication@ImportResource("classpath:dubbo-consumer.xml")public class DubboConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DubboConsumerApplication.class, args); &#125;&#125; 创建控制器 UserController 12345678910111213@Controllerpublic class UserController &#123; @Autowired private IUserService userService; @RequestMapping("/hello") @ResponseBody public String sayHello(@RequestParam("name") String name) &#123; String welcome = userService.hello(name); return welcome; &#125;&#125; 在 application-properties 里设置服务的 HTTP 端口 server.port=8889。 在 classpath 下创建配置文件 dubbo-consumer.xml： 12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="dubbo-consumer" /&gt; &lt;dubbo:registry address="zookeeper://localhost:2181"/&gt; &lt;dubbo:provider cluster="failfast"/&gt; &lt;dubbo:protocol name="dubbo" port="12346" /&gt; &lt;!-- 引用服务配置 --&gt; &lt;dubbo:reference id="userService" interface="iservice.IUserService" cluster="failfast" check="false"/&gt;&lt;/beans&gt; 这个 xml 中定义了： 服务消费者的名称：dubbo-consumer 注册中心的协议及地址：运行在本地 2181 端口上的 ZooKeeper dubbo 服务运行的端口：12346 需要注册的 spring bean：userService，并指定它对应了 dubbo 上发布的 IUserService 这个服务接口。 启动项目。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455562017-12-28 21:42:43.113 INFO 13482 --- [ main] xyq.DubboConsumerApplication : Starting DubboConsumerApplication on bogon with PID 13482 (/Users/xyq/workspace/myproject/dubbo-consumer/target/classes started by xyq in /Users/xyq/workspace)2017-12-28 21:42:43.115 INFO 13482 --- [ main] xyq.DubboConsumerApplication : No active profile set, falling back to default profiles: default2017-12-28 21:42:43.177 INFO 13482 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d127a61: startup date [Thu Dec 28 21:42:43 CST 2017]; root of context hierarchy2017-12-28 21:42:43.860 INFO 13482 --- [ main] o.s.b.f.xml.XmlBeanDefinitionReader : Loading XML bean definitions from class path resource [dubbo-consumer.xml]2017-12-28 21:42:44.114 INFO 13482 --- [ main] c.a.dubbo.common.logger.LoggerFactory : using logger: com.alibaba.dubbo.common.logger.log4j.Log4jLoggerAdapter2017-12-28 21:42:44.920 INFO 13482 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean &apos;dubbo-consumer&apos; of type [com.alibaba.dubbo.config.ApplicationConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-12-28 21:42:44.930 INFO 13482 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean &apos;com.alibaba.dubbo.config.RegistryConfig&apos; of type [com.alibaba.dubbo.config.RegistryConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-12-28 21:42:44.931 INFO 13482 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean &apos;userService&apos; of type [com.alibaba.dubbo.config.spring.ReferenceBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-12-28 21:42:45.432 INFO 13482 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8889 (http)2017-12-28 21:42:45.444 INFO 13482 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2017-12-28 21:42:45.446 INFO 13482 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.232017-12-28 21:42:45.541 INFO 13482 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2017-12-28 21:42:45.541 INFO 13482 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2368 ms2017-12-28 21:42:45.658 INFO 13482 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: &apos;dispatcherServlet&apos; to [/]2017-12-28 21:42:45.661 INFO 13482 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;characterEncodingFilter&apos; to: [/*]2017-12-28 21:42:45.662 INFO 13482 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;hiddenHttpMethodFilter&apos; to: [/*]2017-12-28 21:42:45.662 INFO 13482 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;httpPutFormContentFilter&apos; to: [/*]2017-12-28 21:42:45.662 INFO 13482 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;requestContextFilter&apos; to: [/*]2017-12-28 21:42:45.774 INFO 13482 --- [ main] c.a.d.common.concurrent.ExecutionList : [DUBBO] Executor for listenablefuture is null, will use default executor!, dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.780 INFO 13482 --- [-localhost:2181] org.I0Itec.zkclient.ZkEventThread : Starting ZkClient event thread.2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:zookeeper.version=3.3.3-1073969, built on 02/23/2011 22:27 GMT2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:host.name=bogon2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.version=1.8.0_912017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.vendor=Oracle Corporation2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/lib/tools.jar:/Users/xyq/workspace/myproject/dubbo-consumer/target/classes:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.5.9.RELEASE/spring-boot-starter-web-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter/1.5.9.RELEASE/spring-boot-starter-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot/1.5.9.RELEASE/spring-boot-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.5.9.RELEASE/spring-boot-autoconfigure-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.5.9.RELEASE/spring-boot-starter-logging-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/ch/qos/logback/logback-classic/1.1.11/logback-classic-1.1.11.jar:/Users/xyq/.m2/repository/ch/qos/logback/logback-core/1.1.11/logback-core-1.1.11.jar:/Users/xyq/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.25/jcl-over-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.25/log4j-over-slf4j-1.7.25.jar:/Users/xyq/.m2/repository/org/yaml/snakeyaml/1.17/snakeyaml-1.17.jar:/Users/xyq/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.5.9.RELEASE/spring-boot-starter-tomcat-1.5.9.RELEASE.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.23/tomcat-embed-core-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.23/tomcat-annotations-api-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.5.23/tomcat-embed-el-8.5.23.jar:/Users/xyq/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.23/tomcat-embed-websocket-8.5.23.jar:/Users/xyq/.m2/repository/org/hibernate/hibernate-validator/5.3.6.Final/hibernate-validator-5.3.6.Final.jar:/Users/xyq/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/Users/xyq/.m2/repository/org/jboss/logging/jboss-logging/3.3.1.Final/jboss-logging-3.3.1.Final.jar:/Users/xyq/.m2/repository/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.8.10/jackson-databind-2.8.10.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.8.0/jackson-annotations-2.8.0.jar:/Users/xyq/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.8.10/jackson-core-2.8.10.jar:/Users/xyq/.m2/repository/org/springframework/spring-web/4.3.13.RELEASE/spring-web-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-aop/4.3.13.RELEASE/spring-aop-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-webmvc/4.3.13.RELEASE/spring-webmvc-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-expression/4.3.13.RELEASE/spring-expression-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/Users/xyq/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/xyq/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/xyq/.m2/repository/org/springframework/spring-core/4.3.13.RELEASE/spring-core-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/com/alibaba/dubbo/2.5.8/dubbo-2.5.8.jar:/Users/xyq/.m2/repository/org/springframework/spring-context/4.3.13.RELEASE/spring-context-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/springframework/spring-beans/4.3.13.RELEASE/spring-beans-4.3.13.RELEASE.jar:/Users/xyq/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/xyq/.m2/repository/org/jboss/netty/netty/3.2.5.Final/netty-3.2.5.Final.jar:/Users/xyq/.m2/repository/com/github/sgroschupf/zkclient/0.1/zkclient-0.1.jar:/Users/xyq/.m2/repository/org/apache/zookeeper/zookeeper/3.3.3/zookeeper-3.3.3.jar:/Users/xyq/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/xyq/.m2/repository/log4j/log4j/1.2.14/log4j-1.2.14.jar:/Users/xyq/workspace/myproject/dubbo-api/target/classes:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.library.path=/Users/xyq/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.2017-12-28 21:42:45.785 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.io.tmpdir=/var/folders/yq/d0v9dm456zd_xzc1lhllw19m0000gn/T/2017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:java.compiler=&lt;NA&gt;2017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.name=Mac OS X2017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.arch=x86_642017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:os.version=10.13.12017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.name=xyq2017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.home=/Users/xyq2017-12-28 21:42:45.787 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Client environment:user.dir=/Users/xyq/workspace2017-12-28 21:42:45.788 INFO 13482 --- [clientConnector] org.apache.zookeeper.ZooKeeper : Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5cee7de62017-12-28 21:42:45.798 INFO 13482 --- [or-SendThread()] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/0:0:0:0:0:0:0:1:21812017-12-28 21:42:45.818 INFO 13482 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session2017-12-28 21:42:45.825 INFO 13482 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1609d33be850006, negotiated timeout = 300002017-12-28 21:42:45.826 INFO 13482 --- [tor-EventThread] org.I0Itec.zkclient.ZkClient : zookeeper state changed (SyncConnected)2017-12-28 21:42:45.846 INFO 13482 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Register: consumer://10.236.19.51/iservice.IUserService?application=dubbo-consumer&amp;category=consumers&amp;check=false&amp;cluster=failfast&amp;dubbo=2.5.8&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;side=consumer&amp;timestamp=1514468565714, dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.859 INFO 13482 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Subscribe: consumer://10.236.19.51/iservice.IUserService?application=dubbo-consumer&amp;category=providers,configurators,routers&amp;check=false&amp;cluster=failfast&amp;dubbo=2.5.8&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;side=consumer&amp;timestamp=1514468565714, dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.871 INFO 13482 --- [ main] c.a.d.r.zookeeper.ZookeeperRegistry : [DUBBO] Notify urls for subscribe url consumer://10.236.19.51/iservice.IUserService?application=dubbo-consumer&amp;category=providers,configurators,routers&amp;check=false&amp;cluster=failfast&amp;dubbo=2.5.8&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;side=consumer&amp;timestamp=1514468565714, urls: [dubbo://10.236.19.51:12345/iservice.IUserService?anyhost=true&amp;application=dubbo-provider&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13377&amp;side=provider&amp;timestamp=1514468397346, empty://10.236.19.51/iservice.IUserService?application=dubbo-consumer&amp;category=configurators&amp;check=false&amp;cluster=failfast&amp;dubbo=2.5.8&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;side=consumer&amp;timestamp=1514468565714, empty://10.236.19.51/iservice.IUserService?application=dubbo-consumer&amp;category=routers&amp;check=false&amp;cluster=failfast&amp;dubbo=2.5.8&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;side=consumer&amp;timestamp=1514468565714], dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.966 INFO 13482 --- [ main] c.a.d.remoting.transport.AbstractClient : [DUBBO] Successed connect to server /10.236.19.51:12345 from NettyClient 10.236.19.51 using dubbo version 2.5.8, channel is NettyChannel [channel=[id: 0x3f3c966c, /10.236.19.51:61111 =&gt; /10.236.19.51:12345]], dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.966 INFO 13482 --- [ main] c.a.d.remoting.transport.AbstractClient : [DUBBO] Start NettyClient bogon/10.236.19.51 connect to the server /10.236.19.51:12345, dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:45.998 INFO 13482 --- [ main] com.alibaba.dubbo.config.AbstractConfig : [DUBBO] Refer dubbo service iservice.IUserService from url zookeeper://localhost:2181/com.alibaba.dubbo.registry.RegistryService?anyhost=true&amp;application=dubbo-consumer&amp;check=false&amp;cluster=failfast&amp;default.cluster=failfast&amp;dubbo=2.5.8&amp;generic=false&amp;interface=iservice.IUserService&amp;methods=hello&amp;pid=13482&amp;register.ip=10.236.19.51&amp;remote.timestamp=1514468397346&amp;side=consumer&amp;timestamp=1514468565714, dubbo version: 2.5.8, current host: 10.236.19.512017-12-28 21:42:46.218 INFO 13482 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d127a61: startup date [Thu Dec 28 21:42:43 CST 2017]; root of context hierarchy2017-12-28 21:42:46.268 INFO 13482 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/hello]&#125;&quot; onto public java.lang.String xyq.UserController.sayHello(java.lang.String)2017-12-28 21:42:46.270 INFO 13482 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error]&#125;&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)2017-12-28 21:42:46.270 INFO 13482 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error],produces=[text/html]&#125;&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)2017-12-28 21:42:46.294 INFO 13482 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:42:46.294 INFO 13482 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:42:46.323 INFO 13482 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-12-28 21:42:46.430 INFO 13482 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup2017-12-28 21:42:46.472 INFO 13482 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8889 (http)2017-12-28 21:42:46.476 INFO 13482 --- [ main] xyq.DubboConsumerApplication : Started DubboConsumerApplication in 3.634 seconds (JVM running for 3.99) 4. 测试浏览器中打开 http://localhost:8889/hello?name=gilgamesh ，可以看见回复：hello gilgamesh! 5. 注意事项项目中需要添加 ZkClient 的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>RPC</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：集群启动与选举]]></title>
    <url>%2F2017%2F12%2F29%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E4%B8%8E%E9%80%89%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[1. QuorumPeerMainQuorumPeerMain 类的 Main 函数较为简单，直接调用了 initializeAndRun 方法，参数就是 zkServer.sh 转入的参数，这里是 “start”。在 initializeAndRun 方法内部，首先启动的是定时清除镜像任务 DatadirCleanupManager，默认设置为保留 3 份。由于 purgeInterval 这个参数默认设置为 0，所以不会启动镜像定时清除机制。 org.apache.zookeeper.server.DatadirCleanupManager#start 1234567891011121314151617public void start() &#123; if (PurgeTaskStatus.STARTED == purgeTaskStatus) &#123; LOG.warn("Purge task is already running."); return; &#125; // Don't schedule the purge task with zero or negative purge interval. if (purgeInterval &lt;= 0) &#123; LOG.info("Purge task is not scheduled."); return; &#125; timer = new Timer("PurgeTask", true); TimerTask task = new PurgeTask(dataLogDir, snapDir, snapRetainCount); timer.scheduleAtFixedRate(task, 0, TimeUnit.HOURS.toMillis(purgeInterval)); purgeTaskStatus = PurgeTaskStatus.STARTED;&#125; 接下来，如果配置的 ZooKeeper 服务器大于 1 台，调用 runFromConfig 方法进行集群信息配置，并启动 QuorumPeer 线程。 org.apache.zookeeper.server.quorum.QuorumPeerMain#runFromConfig 123456789101112131415161718192021222324252627282930313233343536373839404142// ...ServerCnxnFactory cnxnFactory = ServerCnxnFactory.createFactory();cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns());quorumPeer = getQuorumPeer();quorumPeer.setQuorumPeers(config.getServers());quorumPeer.setTxnFactory(new FileTxnSnapLog( new File(config.getDataDir()), new File(config.getDataLogDir())));quorumPeer.setElectionType(config.getElectionAlg());quorumPeer.setMyid(config.getServerId());quorumPeer.setTickTime(config.getTickTime());quorumPeer.setInitLimit(config.getInitLimit());quorumPeer.setSyncLimit(config.getSyncLimit());quorumPeer.setQuorumListenOnAllIPs(config.getQuorumListenOnAllIPs());quorumPeer.setCnxnFactory(cnxnFactory);quorumPeer.setQuorumVerifier(config.getQuorumVerifier());quorumPeer.setClientPortAddress(config.getClientPortAddress());quorumPeer.setMinSessionTimeout(config.getMinSessionTimeout());quorumPeer.setMaxSessionTimeout(config.getMaxSessionTimeout());quorumPeer.setZKDatabase(new ZKDatabase(quorumPeer.getTxnFactory()));quorumPeer.setLearnerType(config.getPeerType());quorumPeer.setSyncEnabled(config.getSyncEnabled());// sets quorum sasl authentication configurationsquorumPeer.setQuorumSaslEnabled(config.quorumEnableSasl);if(quorumPeer.isQuorumSaslAuthEnabled())&#123; quorumPeer.setQuorumServerSaslRequired(config.quorumServerRequireSasl); quorumPeer.setQuorumLearnerSaslRequired(config.quorumLearnerRequireSasl); quorumPeer.setQuorumServicePrincipal(config.quorumServicePrincipal); quorumPeer.setQuorumServerLoginContext(config.quorumServerLoginContext); quorumPeer.setQuorumLearnerLoginContext(config.quorumLearnerLoginContext);&#125;quorumPeer.setQuorumCnxnThreadsSize(config.quorumCnxnThreadsSize);quorumPeer.initialize();quorumPeer.start();quorumPeer.join();//... 2. ServerCnxnFactory每个 QuorumPeer 线程启动之前都会先启动一个 cnxnFactory 线程，首先初始化 ServerCnxnFactory，这个是用来接收来自客户端的连接的，也就是这里启动的是一个 TCP 服务器。在 ZooKeeper 里提供两种 TCP 服务器的实现，一个是使用 Java 原生 NIO 的方式，另外一个是使用 NETTY。默认是 NIO 的方式，一个典型的 Reactor 模型。 org.apache.zookeeper.server.ServerCnxnFactory#createFactory() 123456789101112131415static public ServerCnxnFactory createFactory() throws IOException &#123; String serverCnxnFactoryName = System.getProperty(ZOOKEEPER_SERVER_CNXN_FACTORY); if (serverCnxnFactoryName == null) &#123; serverCnxnFactoryName = NIOServerCnxnFactory.class.getName(); &#125; try &#123; ServerCnxnFactory serverCnxnFactory = (ServerCnxnFactory) Class.forName(serverCnxnFactoryName).newInstance(); LOG.info("Using &#123;&#125; as server connection factory", serverCnxnFactoryName); return serverCnxnFactory; &#125; catch (Exception e) &#123; IOException ioe = new IOException("Couldn't instantiate " + serverCnxnFactoryName); ioe.initCause(e); throw ioe; &#125;&#125; 3. QuorumPeer接下来会开始针对 QuorumPeer 实例进行参数配置，QuorumPeer 类代表了 ZooKeeper 集群内的一个节点，参数较多，比较关键的是 setQuorumPeers、setMyid（每一个 ZooKeeper 节点对应有一个 MyId）、setCnxnFactory（TCP 服务）、setZKDatabase（ZooKeeper 自带的内存数据库）、setTickTime（ZooKeeper 服务端和客户端的会话控制）等等。注意到 QuorumPeer 在初始化时 ServerState 被设置为 LOOKING。 接下来调用同步方法 start，正式进入 QuorumPeer 类。start 方法主要包括四个方法，即读取内存数据库、启动 TCP 服务、选举 ZooKeeper 的 Leader 角色、启动自己线程。 org.apache.zookeeper.server.quorum.QuorumPeer#start 1234567@Overridepublic synchronized void start() &#123; loadDataBase(); cnxnFactory.start(); startLeaderElection(); super.start();&#125; 3.1 读取内存数据库org.apache.zookeeper.server.quorum.QuorumPeer#loadDataBase 1234567891011121314151617private void loadDataBase() &#123; File updating = new File(getTxnFactory().getSnapDir(), UPDATING_EPOCH_FILENAME); try &#123; zkDb.loadDataBase(); // load the epochs long lastProcessedZxid = zkDb.getDataTree().lastProcessedZxid; long epochOfZxid = ZxidUtils.getEpochFromZxid(lastProcessedZxid); try &#123; currentEpoch = readLongFromFile(CURRENT_EPOCH_FILENAME); if (epochOfZxid &gt; currentEpoch &amp;&amp; updating.exists()) &#123; setCurrentEpoch(epochOfZxid); &#125; // ... &#125; // ...&#125; loadDataBase 方法用于恢复数据，即从磁盘读取数据到内存，调用了 ZKDatabase 实例的 addCommittedProposal 方法，该方法维护了一个提交日志的队列，用于快速同步 follower 角色的节点信息，日志信息默认保存 500 条，所以选用了 LinkedList 队列用于快速删除数据溢出时的第一条信息。 org.apache.zookeeper.server.ZKDatabase#addCommittedProposal 12345678910111213141516171819202122232425262728293031323334public void addCommittedProposal(Request request) &#123; WriteLock wl = logLock.writeLock(); try &#123; wl.lock(); if (committedLog.size() &gt; commitLogCount) &#123; committedLog.removeFirst(); minCommittedLog = committedLog.getFirst().packet.getZxid(); &#125; if (committedLog.size() == 0) &#123; minCommittedLog = request.zxid; maxCommittedLog = request.zxid; &#125; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); try &#123; request.hdr.serialize(boa, "hdr"); if (request.txn != null) &#123; request.txn.serialize(boa, "txn"); &#125; baos.close(); &#125; catch (IOException e) &#123; LOG.error("This really should be impossible", e); &#125; QuorumPacket pp = new QuorumPacket(Leader.PROPOSAL, request.zxid, baos.toByteArray(), null); Proposal p = new Proposal(); p.packet = pp; p.request = request; committedLog.add(p); maxCommittedLog = p.packet.getZxid(); &#125; finally &#123; wl.unlock(); &#125;&#125; 为了保证事务的顺序一致性，ZooKeeper 采用了递增的事务 id 号（ZXID）来标识事务。所有的提议（Proposal）都在被提出的时候加上了 ZXID。实现中 ZXID 是一个 64 位的数字，高 32 位是 EPOCH 用来标识 Leader 节点是否改变，每次一个 Leader 被选出来以后它都会有一个新的 EPOCH 值，标识当前属于哪个 Leader 的统治，低 32 位用于递增计数。 如果当前保存的 EPOCH 和最新获取的不一样，那就说明 Leader 重新选举过了，用最新的值替换。 3.2 选举准备工作startLeaderElection 方法调用了 createElectionAlgorithm 方法进行选举，目前仅用 electionType 为 3，即使用 FastLeaderElection 算法。 org.apache.zookeeper.server.quorum.QuorumPeer#createElectionAlgorithm 12345678910case 3: qcm = createCnxnManager(); QuorumCnxManager.Listener listener = qcm.listener; if(listener != null)&#123; listener.start(); le = new FastLeaderElection(this, qcm); &#125; else &#123; LOG.error("Null listener when initializing cnx manager"); &#125; break; 3.2.1 监听选举端口在 QuorumCnxManager.Listener 中启动 I/O 线程，默认绑定 3888 端口，等待集群其他机器连接： org.apache.zookeeper.server.quorum.QuorumCnxManager.Listener#run 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic void run() &#123; int numRetries = 0; InetSocketAddress addr; while((!shutdown) &amp;&amp; (numRetries &lt; 3))&#123; try &#123; ss = new ServerSocket(); ss.setReuseAddress(true); if (listenOnAllIPs) &#123; int port = view.get(QuorumCnxManager.this.mySid).electionAddr.getPort(); addr = new InetSocketAddress(port); &#125; else &#123; addr = view.get(QuorumCnxManager.this.mySid).electionAddr; &#125; LOG.info("My election bind port: " + addr.toString()); setName(view.get(QuorumCnxManager.this.mySid).electionAddr.toString()); ss.bind(addr); while (!shutdown) &#123; Socket client = ss.accept(); setSockOpts(client); LOG.info("Received connection request " + client.getRemoteSocketAddress()); // Receive and handle the connection request // asynchronously if the quorum sasl authentication is // enabled. This is required because sasl server // authentication process may take few seconds to finish, // this may delay next peer connection requests. if (quorumSaslAuthEnabled) &#123; receiveConnectionAsync(client); &#125; else &#123; receiveConnection(client); &#125; numRetries = 0; &#125; // ... // ...// ... 3.2.2 接收连接请求receiveConnection 会调用 handleConnection 方法，对 Socket 做一次读操作，接收对方发送过来的 sid。为了避免 peer 之间重复建立连接，这里仅允许高 sid 的实例向低 sid 的实例发起连接请求。 对于合法连接请求，QuorumCnxManager 根据 sid 分配独立的 SendWorker 和 RecvWorker，负责读写 Socket。QuorumCnxManager 中以 sid 为 key 保存了来自各个 peer 的连接对应的一些数据结构： 12345final ConcurrentHashMap&lt;Long, SendWorker&gt; senderWorkerMap;final ConcurrentHashMap&lt;Long, ArrayBlockingQueue&lt;ByteBuffer&gt;&gt; queueSendMap;final ConcurrentHashMap&lt;Long, ByteBuffer&gt; lastMessageSent;public final ArrayBlockingQueue&lt;Message&gt; recvQueue; org.apache.zookeeper.server.quorum.QuorumCnxManager#handleConnection 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182private void handleConnection(Socket sock, DataInputStream din) throws IOException &#123; Long sid = null; try &#123; // Read server id sid = din.readLong(); if (sid &lt; 0) &#123; // this is not a server id but a protocol version (see ZOOKEEPER-1633) sid = din.readLong(); // next comes the #bytes in the remainder of the message // note that 0 bytes is fine (old servers) int num_remaining_bytes = din.readInt(); if (num_remaining_bytes &lt; 0 || num_remaining_bytes &gt; maxBuffer) &#123; LOG.error("Unreasonable buffer length: &#123;&#125;", num_remaining_bytes); closeSocket(sock); return; &#125; byte[] b = new byte[num_remaining_bytes]; // remove the remainder of the message from din int num_read = din.read(b); if (num_read != num_remaining_bytes) &#123; LOG.error("Read only " + num_read + " bytes out of " + num_remaining_bytes + " sent by server " + sid); &#125; &#125; if (sid == QuorumPeer.OBSERVER_ID) &#123; /* * Choose identifier at random. We need a value to identify * the connection. */ sid = observerCounter.getAndDecrement(); LOG.info("Setting arbitrary identifier to observer: " + sid); &#125; &#125; catch (IOException e) &#123; closeSocket(sock); LOG.warn("Exception reading or writing challenge: " + e.toString()); return; &#125; // do authenticating learner LOG.debug("Authenticating learner server.id: &#123;&#125;", sid); authServer.authenticate(sock, din); //If wins the challenge, then close the new connection. if (sid &lt; this.mySid) &#123; /* * This replica might still believe that the connection to sid is * up, so we have to shut down the workers before trying to open a * new connection. */ SendWorker sw = senderWorkerMap.get(sid); if (sw != null) &#123; sw.finish(); &#125; /* * Now we start a new connection */ LOG.debug("Create new connection to server: " + sid); closeSocket(sock); connectOne(sid); // Otherwise start worker threads to receive data. &#125; else &#123; SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if(vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); sw.start(); rw.start(); return; &#125; &#125; 3.2.3 主动发起连接请求若收到的连接请求的源服务器的 sid 更小，则关闭连接并调用 connectOne 方法主动向对方发起连接。这里的 connectOne 方法会根据是否已经与目标 peer 建立连接来判断是否需要建立连接。判断方法是检查 senderWorkerMap 里是否有 sid 对应的 SendWorker。若没有，则调用 startConnection 方法发起连接。 这里 startConnection 和前面的 handleConnection 的作用很相似，只不过一个用于主动发起连接请求，一个用于处理收到连接请求。相应地，这里仅允许向更低 sid 的 peer 发起连接。 对应地，在 startConnection 方法中，建立 TCP 连接后会将自己的 sid 发送给对方，供对方的 handleConnection 方法读取。 org.apache.zookeeper.server.quorum.QuorumCnxManager#startConnection 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private boolean startConnection(Socket sock, Long sid) throws IOException &#123; DataOutputStream dout = null; DataInputStream din = null; try &#123; // Sending id and challenge dout = new DataOutputStream(sock.getOutputStream()); dout.writeLong(this.mySid); dout.flush(); din = new DataInputStream(new BufferedInputStream(sock.getInputStream())); &#125; catch (IOException e) &#123; LOG.warn("Ignoring exception reading or writing challenge: ", e); closeSocket(sock); return false; &#125; // authenticate learner authLearner.authenticate(sock, view.get(sid).hostname); // If lost the challenge, then drop the new connection if (sid &gt; this.mySid) &#123; LOG.info("Have smaller server identifier, so dropping the " + "connection: (" + sid + ", " + this.mySid + ")"); closeSocket(sock); // Otherwise proceed with the connection &#125; else &#123; SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if(vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); sw.start(); rw.start(); return true; &#125; return false;&#125; 但在刚启动时，还没有向其他实例发起连接。 RecvWorker 负责从 Socket 中读出数据封装成 Message 放入 recvQueue 中。 SendWorker 负责从 queueSendMap 中取出数据写入 Socket 并放入 lastMessageSent。这里有个细节：一旦 ZK 发现针对当前远程服务器的发送队列为空，会从 lastMessageSent 中取出一个最近发送过的消息再次发送。 总结一下：Listener 启动后，会监听选举端口上的连接请求，对每个连接请求，从其 Socket 中读取对方的 sid，并与自己的 sid 比较，判断连接发起流程是否合法。若不合法，则断开连接，由自己主动向对方的选举端口发起连接，并发送自己的 sid。对于每个合法连接请求，双方都会为其分配单独的 SendWorker 和 RecvWorker。那么这里有一个问题，最初的连接请求是如何发起的？后文可以看到，在 QuorumPeer 主线程启动后，每个 peer 都会根据集群的配置，向所有选举的 PARTICIPANT（非 OBSERVER）发起连接请求，并发送选票。 3.2.2 准备选举算法然后调用基于 TCP 的选举算法 FastLeaderElection。这里已经通过 FastLeaderElection 的构造函数初始化了一个 Messenger 实例，启动了 WorkerSender 和 WorkerReceiver 线程。 org.apache.zookeeper.server.quorum.FastLeaderElection 1234567891011121314151617181920212223242526272829303132333435public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager)&#123; this.stop = false; this.manager = manager; starter(self, manager);&#125;LinkedBlockingQueue&lt;ToSend&gt; sendqueue;LinkedBlockingQueue&lt;Notification&gt; recvqueue;private void starter(QuorumPeer self, QuorumCnxManager manager) &#123; this.self = self; proposedLeader = -1; proposedZxid = -1; sendqueue = new LinkedBlockingQueue&lt;ToSend&gt;(); recvqueue = new LinkedBlockingQueue&lt;Notification&gt;(); this.messenger = new Messenger(manager);&#125;protected class Messenger &#123; Messenger(QuorumCnxManager manager) &#123; this.ws = new WorkerSender(manager); Thread t = new Thread(this.ws, "WorkerSender[myid=" + self.getId() + "]"); t.setDaemon(true); t.start(); this.wr = new WorkerReceiver(manager); t = new Thread(this.wr, "WorkerReceiver[myid=" + self.getId() + "]"); t.setDaemon(true); t.start(); &#125;&#125; WorkerSender：不断从 sendqueue 中获取待发送的选票，并将其传递给 QuorumCnxManager 的 queueSendMap。若还未与选票的目标服务器建立连接，则发起连接请求。 org.apache.zookeeper.server.quorum.FastLeaderElection.Messenger.WorkerSender#run 123456789101112131415161718public void run() &#123; while (!stop) &#123; try &#123; ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS); if(m == null) continue; process(m); &#125; catch (InterruptedException e) &#123; break; &#125; &#125; LOG.info("WorkerSender is down");&#125;void process(ToSend m) &#123; ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), m.leader, m.zxid, m.electionEpoch, m.peerEpoch); manager.toSend(m.sid, requestBuffer);&#125; org.apache.zookeeper.server.quorum.QuorumCnxManager#toSend 12345678910111213141516171819202122232425262728/** * Processes invoke this message to queue a message to send. Currently, * only leader election uses it. */public void toSend(Long sid, ByteBuffer b) &#123; /* * If sending message to myself, then simply enqueue it (loopback). */ if (this.mySid == sid) &#123; b.position(0); addToRecvQueue(new Message(b.duplicate(), sid)); /* * Otherwise send to the corresponding thread to send. */ &#125; else &#123; /* * Start a new connection if doesn't have one already. */ ArrayBlockingQueue&lt;ByteBuffer&gt; bq = new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY); ArrayBlockingQueue&lt;ByteBuffer&gt; bqExisting = queueSendMap.putIfAbsent(sid, bq); if (bqExisting != null) &#123; addToSendQueue(bqExisting, b); &#125; else &#123; addToSendQueue(bq, b); &#125; connectOne(sid); &#125;&#125; WorkerReceiver：不断从 QuorumCnxManager 的 recvQueue 中拉取收到的选票。 在该过程中如果当前服务器是 LOOKING 状态，将选票保存到 recvQueue 队列中。如果发现外部选票的选举轮次（逻辑时钟）小于自己的，则忽略该选票并立即发出自己的内部选票。 如果当前服务器不是 LOOKING 状态，则忽略选票并将 Leader 信息以选票的形式发送出去。 org.apache.zookeeper.server.quorum.FastLeaderElection.Messenger.WorkerReceiver#run 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public void run() &#123; Message response; while (!stop) &#123; // Sleeps on receive try&#123; response = manager.pollRecvQueue(3000, TimeUnit.MILLISECONDS); if(response == null) continue; if(!self.getVotingView().containsKey(response.sid))&#123; Vote current = self.getCurrentVote(); ToSend notmsg = new ToSend(ToSend.mType.notification, current.getId(), current.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, current.getPeerEpoch()); sendqueue.offer(notmsg); &#125; else &#123; // ... // Instantiate Notification and set its attributes Notification n = new Notification(); // State of peer that sent this message QuorumPeer.ServerState ackstate = QuorumPeer.ServerState.LOOKING; switch (response.buffer.getInt()) &#123; case 0: ackstate = QuorumPeer.ServerState.LOOKING; break; case 1: ackstate = QuorumPeer.ServerState.FOLLOWING; break; case 2: ackstate = QuorumPeer.ServerState.LEADING; break; case 3: ackstate = QuorumPeer.ServerState.OBSERVING; break; default: continue; &#125; n.leader = response.buffer.getLong(); n.zxid = response.buffer.getLong(); n.electionEpoch = response.buffer.getLong(); n.state = ackstate; n.sid = response.sid; if(!backCompatibility)&#123; n.peerEpoch = response.buffer.getLong(); &#125; else &#123; n.peerEpoch = ZxidUtils.getEpochFromZxid(n.zxid); &#125; n.version = (response.buffer.remaining() &gt;= 4) ? response.buffer.getInt() : 0x0; // ... if(self.getPeerState() == QuorumPeer.ServerState.LOOKING)&#123; recvqueue.offer(n); if((ackstate == QuorumPeer.ServerState.LOOKING) &amp;&amp; (n.electionEpoch &lt; logicalclock.get()))&#123; Vote v = getVote(); ToSend notmsg = new ToSend(ToSend.mType.notification, v.getId(), v.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, v.getPeerEpoch()); sendqueue.offer(notmsg); &#125; &#125; else &#123; Vote current = self.getCurrentVote(); if(ackstate == QuorumPeer.ServerState.LOOKING)&#123; ToSend notmsg; if(n.version &gt; 0x0) &#123; notmsg = new ToSend(ToSend.mType.notification, current.getId(), current.getZxid(), current.getElectionEpoch(), self.getPeerState(), response.sid, current.getPeerEpoch()); &#125; else &#123; Vote bcVote = self.getBCVote(); notmsg = new ToSend(ToSend.mType.notification, bcVote.getId(), bcVote.getZxid(), bcVote.getElectionEpoch(), self.getPeerState(), response.sid, bcVote.getPeerEpoch()); &#125; sendqueue.offer(notmsg); &#125; &#125; &#125; catch (InterruptedException e) &#123; System.out.println("Interrupted Exception while waiting for new message" + e.toString()); &#125; &#125;&#125; 3.3 启动自己线程在等待其他节点提交自己申请的过程中，进入了 QuorumPeer 的线程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Overridepublic void run() &#123; // ... try &#123; while (running) &#123; switch (getPeerState()) &#123; case LOOKING: LOG.info("LOOKING"); // ... try &#123; setBCVote(null); setCurrentVote(makeLEStrategy().lookForLeader()); &#125; catch (Exception e) &#123; LOG.warn("Unexpected exception", e); setPeerState(ServerState.LOOKING); &#125; break; case OBSERVING: try &#123; LOG.info("OBSERVING"); setObserver(makeObserver(logFactory)); observer.observeLeader(); &#125; // ... break; case FOLLOWING: try &#123; LOG.info("FOLLOWING"); setFollower(makeFollower(logFactory)); follower.followLeader(); &#125; // ... break; case LEADING: LOG.info("LEADING"); try &#123; setLeader(makeLeader(logFactory)); leader.lead(); setLeader(null); &#125; // ... break; &#125; &#125; &#125; // ...&#125; 4. Leader 选举QuorumPeer 是 ZooKeeper 服务器实例的托管者，在运行期间，QuorumPeer 的核心工作就是不断地检测当前服务器的状态，并做出相应的处理。在正常情况下，ZooKeeper 服务器的状态在 LOOKING、LEADING 和 FOLLOWING / OBSERVING 之间进行切换。而在启动阶段，QuorumPeer 的初始状态是 LOOKING，因此开始进行 Leader 选举。 在 LOOKING 状态下，会调用 org.apache.zookeeper.server.quorum.FastLeaderElection#lookForLeader 方法进行 Leader 选举： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135// ...HashMap&lt;Long, Vote&gt; recvset = new HashMap&lt;Long, Vote&gt;();HashMap&lt;Long, Vote&gt; outofelection = new HashMap&lt;Long, Vote&gt;();int notTimeout = finalizeWait;synchronized(this)&#123; logicalclock.incrementAndGet(); updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch());&#125;sendNotifications();/* * Loop in which we exchange notifications until we find a leader */while ((self.getPeerState() == ServerState.LOOKING) &amp;&amp; (!stop))&#123; /* * Remove next notification from queue, times out after 2 times * the termination time */ Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); /* * Sends more notifications if haven't received enough. * Otherwise processes new notification. */ if(n == null)&#123; if(manager.haveDelivered())&#123; sendNotifications(); &#125; else &#123; manager.connectAll(); &#125; /* * Exponential backoff */ int tmpTimeOut = notTimeout*2; notTimeout = (tmpTimeOut &lt; maxNotificationInterval?tmpTimeOut:maxNotificationInterval); LOG.info("Notification time out: " + notTimeout); &#125; else if(self.getVotingView().containsKey(n.sid)) &#123; /* * Only proceed if the vote comes from a replica in the * voting view. */ switch (n.state) &#123; case LOOKING: // If notification &gt; current, replace and send messages out if (n.electionEpoch &gt; logicalclock.get()) &#123; logicalclock.set(n.electionEpoch); recvset.clear(); if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) &#123; updateProposal(n.leader, n.zxid, n.peerEpoch); &#125; else &#123; updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); &#125; sendNotifications(); &#125; else if (n.electionEpoch &lt; logicalclock.get()) &#123; break; &#125; else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &#123; updateProposal(n.leader, n.zxid, n.peerEpoch); sendNotifications(); &#125; recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); if (termPredicate(recvset, new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch))) &#123; // Verify if there is any change in the proposed leader while((n = recvqueue.poll(finalizeWait, TimeUnit.MILLISECONDS)) != null)&#123; if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch))&#123; recvqueue.put(n); break; &#125; &#125; /* * This predicate is true once we don't read any new * relevant message from the reception queue */ if (n == null) &#123; self.setPeerState((proposedLeader == self.getId()) ? ServerState.LEADING: learningState()); Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); leaveInstance(endVote); return endVote; &#125; &#125; break; case OBSERVING: LOG.debug("Notification from observer: " + n.sid); break; case FOLLOWING: case LEADING: /* * Consider all notifications from the same epoch * together. */ if(n.electionEpoch == logicalclock.get())&#123; recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); if(ooePredicate(recvset, outofelection, n)) &#123; self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING: learningState()); Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &#125; &#125; /* * Before joining an established ensemble, verify * a majority is following the same leader. */ outofelection.put(n.sid, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)); if(ooePredicate(outofelection, outofelection, n)) &#123; synchronized(this)&#123; logicalclock.set(n.electionEpoch); self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING: learningState()); &#125; Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote; &#125; break; default: LOG.warn("Notification state unrecognized: &#123;&#125; (n.state), &#123;&#125; (n.sid)", n.state, n.sid); break; &#125; &#125; else &#123; LOG.warn("Ignoring notification from non-cluster member " + n.sid); &#125; &#125; return null;&#125; 4.1 自增选举轮次ZK 在进行新一轮的投票时，会首先对 logicalClock 进行自增操作。 4.2 初始化投票在 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()) 语句中，会设置初始化选票。这里要注意，对于 PARTICIPANT，选票中的 Leader SID 为服务器自己的 SID；而对于 OBSERVER，选票中的 Leader SID 为 Long.MIN_VALUE。类似地，选票中的 ZXID 和 peerEpoch 也为 Long.MIN_VALUE。 1234567891011121314151617181920212223private long getInitId()&#123; if(self.getLearnerType() == LearnerType.PARTICIPANT) return self.getId(); else return Long.MIN_VALUE;&#125;private long getInitLastLoggedZxid()&#123; if(self.getLearnerType() == LearnerType.PARTICIPANT) return self.getLastLoggedZxid(); else return Long.MIN_VALUE;&#125;private long getPeerEpoch()&#123; if(self.getLearnerType() == LearnerType.PARTICIPANT) try &#123; return self.getCurrentEpoch(); &#125; catch(IOException e) &#123; RuntimeException re = new RuntimeException(e.getMessage()); re.setStackTrace(e.getStackTrace()); throw re; &#125; else return Long.MIN_VALUE;&#125; 数据结构 Vote 如下： 12345678class Vote &#123; private int version; private long id; // 当前服务器自身的 SID private long zxid; // 当前服务器的最新 ZXID 值 private long electionEpoch; // 当前服务器的逻辑时钟 private long peerEpoch; // 被推举的服务器的选举轮次 private ServerState state; // LOOKING&#125; 4.3 发送初始化投票在 sendNotifications 方法中，会根据配置信息，向所有其他参与投票的 PARTICIPANT （即非 OBSERVER）发送 LOOKING 状态的投票。 org.apache.zookeeper.server.quorum.FastLeaderElection#sendNotifications 123456789101112131415161718/** * Send notifications to all peers upon a change in our vote */private void sendNotifications() &#123; for (QuorumServer server : self.getVotingView().values()) &#123; long sid = server.id; ToSend notmsg = new ToSend(ToSend.mType.notification, proposedLeader, proposedZxid, logicalclock.get(), QuorumPeer.ServerState.LOOKING, sid, proposedEpoch); &#125; sendqueue.offer(notmsg); &#125;&#125; 回忆前述 WorkerSender 的作用，这里也即是向配置文件中的其他 PARTICIPANT 发起连接的时机（但可能因为 sid 的规则限制被拒绝并由对方再次发起连接，或者该 PARTICIPANT 对应的实例尚未启动）。连接请求是发往其他所有 PARTICIPANT 的，因此服务器的启动顺序不影响整个流程。最终 PARTICIPANT 两两之间会建立连接，Observer 会与所有 PARTICIPANT 建立连接。 4.4 接受外部投票如果发出选票的服务器 sid 不在集群配置的 PARTICIPANT 范围内，则 WorkerReceiver 立即用服务器当前选票作回应，该选票不会被添加到 recvQueue 中。这也就是说，虽然 Observer 也在 LOOKING 状态下向其他 PARTICIPANT 发出了自己的选票，但是会被其他 PARTICIPANT 忽略。 每台服务器会通过 lookForLeader 方法不断从 recvQueue 队列中获取外部投票。如果服务器发现无法获取到任何投票，那么就会立即确认自己是否和集群中其他服务器保持着有效连接。如果发现没有建立连接，那么就会马上建立连接。如果已经建立了连接，那么就再次发送自己当前的内部投票。 4.5 判断选票状态 如果发送选票的服务器状态是 OBSERVING，则忽略该选票。 如果发送选票的服务器状态是 FOLLOWING 或者 LEADING（回忆前面说的 WorkerReceiver 的逻辑，服务器在非 LOOKING 状态下收到了来自 LOOKING 状态服务器的选票，则以内部投票进行响应），说明当前集群中已经完成了选举，则根据选票中的 LEADER 和 EPOCH 等信息更新自身状态。 如果发送选票的服务器状态是 LOOKING，进入下面的流程。 4.6 LOOKING 时选票处理流程4.6.1 比较逻辑时钟在处理外部投票的时候，会根据逻辑时钟来进行不同的处理。 外部投票的逻辑时钟大于内部投票。此时立即更新自己的逻辑时钟，并且清空所有已经收到的投票，然后使用初始化的投票来进行 PK 已确定是否变更内部投票。 外部投票的逻辑时钟小于内部投票。此时忽略该外部投票。 外部投票的逻辑时钟和内部投票一致。此时进行选票 PK。 4.6.2 选票 PK 如果外部投票中被推举的 Leader 服务器的选举轮次（epoch）大于内部投票，那么就需要进行投票变更。 如果选举轮次一致，那么就对比两者的 ZXID，如果外部投票的 ZXID 大于内部投票，那么就需要进行投票变更。 如果两者的 ZXID 一致，那么就对比两者的 SID。如果外部投票的 SID 大于内部投票，那么就需要进行投票变更。 org.apache.zookeeper.server.quorum.FastLeaderElection#totalOrderPredicate 1234567891011121314151617protected boolean totalOrderPredicate(long newId, long newZxid, long newEpoch, long curId, long curZxid, long curEpoch) &#123; if(self.getQuorumVerifier().getWeight(newId) == 0)&#123; return false; &#125; /* * We return true if one of the following three cases hold: * 1- New epoch is higher * 2- New epoch is the same as current epoch, but new zxid is higher * 3- New epoch is the same as current epoch, new zxid is the same * as current zxid, but server id is higher. */ return ((newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId)))));&#125; 4.6.3 变更投票使用外部投票的选票信息来覆盖内部投票，变更完成后，再次将这个变更后的内部投票发送出去。 注意到 OBSERVER 同样会做选票 PK、选票变更等操作，只不过其后续选票也会被忽略。 4.6.4 选票归档无论是否进行了投票变更，都会将刚刚收到的那份外部投票放入 recvset 中进行归档。recvset 用于记录当前服务器再本轮次的 Leader 选举中收到的所有外部投票，并按 SID 分组。 4.6.5 统计投票统计集群中是否有过半的服务器认可了当前的内部投票。如果确定已经有过半的服务器认可了该内部投票，则终止投票。 org.apache.zookeeper.server.quorum.FastLeaderElection#termPredicate 1234567891011121314151617181920212223/** * Termination predicate. Given a set of votes, determines if * have sufficient to declare the end of the election round. * * @param votes Set of votes * @param l Identifier of the vote received last * @param zxid zxid of the the vote received last */ protected boolean termPredicate(HashMap&lt;Long, Vote&gt; votes, Vote vote) &#123; HashSet&lt;Long&gt; set = new HashSet&lt;Long&gt;(); /* * First make the views consistent. Sometimes peers will have * different zxids for a server depending on timing. */ for (Map.Entry&lt;Long,Vote&gt; entry : votes.entrySet()) &#123; if (vote.equals(entry.getValue()))&#123; set.add(entry.getKey()); &#125; &#125; return self.getQuorumVerifier().containsQuorum(set); &#125; 4.6.6 更新服务器状态服务器会首先判断当前被过半服务器认可的投票所对应的 Leader 服务器是否是自己，如果是自己的话，那么就会将自己的服务器状态更新为 LEADING，否则根据具体情况来确定自己是 FOLLOWING（自己是 PARTICIPANT） 或是 OBSERVING（自己不是 PARTICIPANT）。 5. 选举时序图 6. Follower 启动回到 QuorumPeer 的主线程，当服务器状态变为非 LOOKING 时，会根据自己的角色创建相应的服务器实例，并开始进入各自角色的主流程。 org.apache.zookeeper.server.quorum.Follower#followLeader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * the main method called by the follower to follow the leader * * @throws InterruptedException */void followLeader() throws InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); LOG.info("FOLLOWING - LEADER ELECTION TOOK - &#123;&#125;", electionTimeTaken); self.start_fle = 0; self.end_fle = 0; fzk.registerJMX(new FollowerBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); try &#123; connectToLeader(leaderServer.addr, leaderServer.hostname); long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); //check to see if the leader zxid is lower than ours //this should never happen but is just a safety check long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch &lt; self.getAcceptedEpoch()) &#123; LOG.error("Proposed leader epoch " + ZxidUtils.zxidToString(newEpochZxid) + " is less than our accepted epoch " + ZxidUtils.zxidToString(self.getAcceptedEpoch())); throw new IOException("Error: Epoch of leader is lower"); &#125; syncWithLeader(newEpochZxid); QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; readPacket(qp); processPacket(qp); &#125; &#125; catch (Exception e) &#123; LOG.warn("Exception when following the leader", e); try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; // clear pending revalidations pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX((Learner)this); &#125;&#125; 6.1 创建服务器实例创建 Follower 和 FollowerZooKeeperServer 实例。 6.2 和 Leader 建立连接所有的 Learner 服务器在启动完毕后，会从 Leader 选举的投票结果中找到当前集群中的 Leader 服务器，然后与其建立连接。 6.3 向 Leader 注册将 Learner 服务器自己的基本信息发送给 Leader 服务器，即 LearnerInfo，包括 SID 和最新的 ZXID。 6.4 发送 ACK 信息Learner 在收到来自 Leader 的 LEADERINFO 消息后，解析出 epoch 和 ZXID，然后向 Leader 反馈一个 ACKEPOCH 响应。 org.apache.zookeeper.server.quorum.Learner#registerWithLeader 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Once connected to the leader, perform the handshake protocol to * establish a following / observing connection. * @param pktType * @return the zxid the Leader sends for synchronization purposes. * @throws IOException */protected long registerWithLeader(int pktType) throws IOException&#123; /* * Send follower info, including last zxid and sid */ long lastLoggedZxid = self.getLastLoggedZxid(); QuorumPacket qp = new QuorumPacket(); qp.setType(pktType); qp.setZxid(ZxidUtils.makeZxid(self.getAcceptedEpoch(), 0)); /* * Add sid to payload */ LearnerInfo li = new LearnerInfo(self.getId(), 0x10000); ByteArrayOutputStream bsid = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(bsid); boa.writeRecord(li, "LearnerInfo"); qp.setData(bsid.toByteArray()); writePacket(qp, true); readPacket(qp); final long newEpoch = ZxidUtils.getEpochFromZxid(qp.getZxid()); if (qp.getType() == Leader.LEADERINFO) &#123; // we are connected to a 1.0 server so accept the new epoch and read the next packet leaderProtocolVersion = ByteBuffer.wrap(qp.getData()).getInt(); byte epochBytes[] = new byte[4]; final ByteBuffer wrappedEpochBytes = ByteBuffer.wrap(epochBytes); if (newEpoch &gt; self.getAcceptedEpoch()) &#123; wrappedEpochBytes.putInt((int)self.getCurrentEpoch()); self.setAcceptedEpoch(newEpoch); &#125; else if (newEpoch == self.getAcceptedEpoch()) &#123; // since we have already acked an epoch equal to the leaders, we cannot ack // again, but we still need to send our lastZxid to the leader so that we can // sync with it if it does assume leadership of the epoch. // the -1 indicates that this reply should not count as an ack for the new epoch wrappedEpochBytes.putInt(-1); &#125; else &#123; throw new IOException("Leaders epoch, " + newEpoch + " is less than accepted epoch, " + self.getAcceptedEpoch()); &#125; QuorumPacket ackNewEpoch = new QuorumPacket(Leader.ACKEPOCH, lastLoggedZxid, epochBytes, null); writePacket(ackNewEpoch, true); return ZxidUtils.makeZxid(newEpoch, 0); &#125; else &#123; if (newEpoch &gt; self.getAcceptedEpoch()) &#123; self.setAcceptedEpoch(newEpoch); &#125; if (qp.getType() != Leader.NEWLEADER) &#123; LOG.error("First packet should have been NEWLEADER"); throw new IOException("First packet should have been NEWLEADER"); &#125; return qp.getZxid(); &#125;&#125; 6.5 数据同步参见 《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：数据与存储。 这里会将自己持有的 SessionTracker 设置为 LearnerSessionTracker。 6.6 启动 FollowerZooKeeperServer6.7 处理与 Leader 的后续交互7. Leader 启动org.apache.zookeeper.server.quorum.Leader#lead 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139/** * This method is main function that is called to lead * * @throws IOException * @throws InterruptedException */void lead() throws IOException, InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); LOG.info("LEADING - LEADER ELECTION TOOK - &#123;&#125;", electionTimeTaken); self.start_fle = 0; self.end_fle = 0; zk.registerJMX(new LeaderBean(this, zk), self.jmxLocalPeerBean); try &#123; self.tick.set(0); zk.loadData(); leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid()); // Start thread that waits for connection requests from // new followers. cnxAcceptor = new LearnerCnxAcceptor(); cnxAcceptor.start(); readyToStart = true; long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch()); zk.setZxid(ZxidUtils.makeZxid(epoch, 0)); synchronized(this)&#123; lastProposed = zk.getZxid(); &#125; newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null); if ((newLeaderProposal.packet.getZxid() &amp; 0xffffffffL) != 0) &#123; LOG.info("NEWLEADER proposal has Zxid of " + Long.toHexString(newLeaderProposal.packet.getZxid())); &#125; waitForEpochAck(self.getId(), leaderStateSummary); self.setCurrentEpoch(epoch); // We have to get at least a majority of servers in sync with // us. We do this by waiting for the NEWLEADER packet to get // acknowledged try &#123; waitForNewLeaderAck(self.getId(), zk.getZxid(), LearnerType.PARTICIPANT); &#125; catch (InterruptedException e) &#123; shutdown("Waiting for a quorum of followers, only synced with sids: [ " + getSidSetString(newLeaderProposal.ackSet) + " ]"); HashSet&lt;Long&gt; followerSet = new HashSet&lt;Long&gt;(); for (LearnerHandler f : learners) followerSet.add(f.getSid()); if (self.getQuorumVerifier().containsQuorum(followerSet)) &#123; LOG.warn("Enough followers present. " + "Perhaps the initTicks need to be increased."); &#125; Thread.sleep(self.tickTime); self.tick.incrementAndGet(); return; &#125; startZkServer(); /** * WARNING: do not use this for anything other than QA testing * on a real cluster. Specifically to enable verification that quorum * can handle the lower 32bit roll-over issue identified in * ZOOKEEPER-1277. Without this option it would take a very long * time (on order of a month say) to see the 4 billion writes * necessary to cause the roll-over to occur. * * This field allows you to override the zxid of the server. Typically * you'll want to set it to something like 0xfffffff0 and then * start the quorum, run some operations and see the re-election. */ String initialZxid = System.getProperty("zookeeper.testingonly.initialZxid"); if (initialZxid != null) &#123; long zxid = Long.parseLong(initialZxid); zk.setZxid((zk.getZxid() &amp; 0xffffffff00000000L) | zxid); &#125; if (!System.getProperty("zookeeper.leaderServes", "yes").equals("no")) &#123; self.cnxnFactory.setZooKeeperServer(zk); &#125; // Everything is a go, simply start counting the ticks // WARNING: I couldn't find any wait statement on a synchronized // block that would be notified by this notifyAll() call, so // I commented it out //synchronized (this) &#123; // notifyAll(); //&#125; // We ping twice a tick, so we only update the tick every other // iteration boolean tickSkip = true; while (true) &#123; Thread.sleep(self.tickTime / 2); if (!tickSkip) &#123; self.tick.incrementAndGet(); &#125; HashSet&lt;Long&gt; syncedSet = new HashSet&lt;Long&gt;(); // lock on the followers when we use it. syncedSet.add(self.getId()); for (LearnerHandler f : getLearners()) &#123; // Synced set is used to check we have a supporting quorum, so only // PARTICIPANT, not OBSERVER, learners should be used if (f.synced() &amp;&amp; f.getLearnerType() == LearnerType.PARTICIPANT) &#123; syncedSet.add(f.getSid()); &#125; f.ping(); &#125; // check leader running status if (!this.isRunning()) &#123; shutdown("Unexpected internal error"); return; &#125; if (!tickSkip &amp;&amp; !self.getQuorumVerifier().containsQuorum(syncedSet)) &#123; //if (!tickSkip &amp;&amp; syncedCount &lt; self.quorumPeers.size() / 2) &#123; // Lost quorum, shutdown shutdown("Not sufficient followers synced, only synced with sids: [ " + getSidSetString(syncedSet) + " ]"); // make sure the order is the same! // the leader goes to looking return; &#125; tickSkip = !tickSkip; &#125; &#125; finally &#123; zk.unregisterJMX(this); &#125;&#125; 7.1 创建服务器实例创建 Leader 和 LeaderZooKeeperServer 实例。 7.2 启动 LearnerCnxAcceptor创建并启动 Learner 接收器 LearnerCnxAcceptor，负责接收所有非 Leader 服务器的连接请求，创建并启动对应的 LearnerHandler。 org.apache.zookeeper.server.quorum.Leader.LearnerCnxAcceptor#run 123456789101112131415161718192021while (!stop) &#123; try&#123; Socket s = ss.accept(); // start with the initLimit, once the ack is processed // in LearnerHandler switch to the syncLimit s.setSoTimeout(self.tickTime * self.initLimit); s.setTcpNoDelay(nodelay); BufferedInputStream is = new BufferedInputStream(s.getInputStream()); LearnerHandler fh = new LearnerHandler(s, is, Leader.this); fh.start(); &#125; catch (SocketException e) &#123; if (stop) &#123; stop = true; &#125; else &#123; throw e; &#125; &#125; catch (SaslException e)&#123; LOG.error("Exception while connecting to quorum learner", e); &#125;&#125; 7.3 创建 LearnerHandlerLeader 接收到来自其他机器的连接创建请求后，会为每一个 Learner 创建一个 LearnerHandler 实例，以 TCP 长连接的形式负责 Leader 和 Learner 之间几乎所有的消息通信和数据同步。 7.4 解析 Learner 信息，计算新的 epochorg.apache.zookeeper.server.quorum.Leader#getEpochToPropose 12345678910111213141516171819202122232425262728293031private HashSet&lt;Long&gt; connectingFollowers = new HashSet&lt;Long&gt;();public long getEpochToPropose(long sid, long lastAcceptedEpoch) throws InterruptedException, IOException &#123; synchronized(connectingFollowers) &#123; if (!waitingForNewEpoch) &#123; return epoch; &#125; if (lastAcceptedEpoch &gt;= epoch) &#123; epoch = lastAcceptedEpoch+1; &#125; connectingFollowers.add(sid); QuorumVerifier verifier = self.getQuorumVerifier(); if (connectingFollowers.contains(self.getId()) &amp;&amp; verifier.containsQuorum(connectingFollowers)) &#123; waitingForNewEpoch = false; self.setAcceptedEpoch(epoch); connectingFollowers.notifyAll(); &#125; else &#123; long start = Time.currentElapsedTime(); long cur = start; long end = start + self.getInitLimit()*self.getTickTime(); while(waitingForNewEpoch &amp;&amp; cur &lt; end) &#123; connectingFollowers.wait(end - cur); cur = Time.currentElapsedTime(); &#125; if (waitingForNewEpoch) &#123; throw new InterruptedException("Timeout while waiting for epoch from quorum"); &#125; &#125; return epoch; &#125;&#125; Leader 服务器在接收到 Learner 的基本信息后，会解析出该 Learner 的 SID 和 ZXID，然后根据该 Learner 的 ZXID 解析出其对应的 epoch_of_learner，和当前 Leader 的 epoch_of_leader 进行比较，如果 epoch_of_learner 更大，则更新 epoch_of_learner： $$epoch_of_learner = epoch_of_learner + 1$$Leader 的 lead 方法和各个 LearnerHandler 线程会阻塞在 getEpochToPropose 方法处，直到过半的 Quorum 已经向 Leader 进行了注册，Leader 就可以确定当前集群的 epoch 了，并将 waitingForEpoch 标记设置为 false。 7.5 发送 Leader 状态12345678910111213141516171819202122232425262728293031private HashSet&lt;Long&gt; electingFollowers = new HashSet&lt;Long&gt;();private boolean electionFinished = false;public void waitForEpochAck(long id, StateSummary ss) throws IOException, InterruptedException &#123; synchronized(electingFollowers) &#123; if (electionFinished) &#123; return; &#125; if (ss.getCurrentEpoch() != -1) &#123; if (ss.isMoreRecentThan(leaderStateSummary)) &#123; throw new IOException("Follower is ahead of the leader, leader summary: " + leaderStateSummary.getCurrentEpoch() + " (current epoch), " + leaderStateSummary.getLastZxid() + " (last zxid)"); &#125; electingFollowers.add(id); &#125; QuorumVerifier verifier = self.getQuorumVerifier(); if (electingFollowers.contains(self.getId()) &amp;&amp; verifier.containsQuorum(electingFollowers)) &#123; electionFinished = true; electingFollowers.notifyAll(); &#125; else &#123; long start = Time.currentElapsedTime(); long cur = start; long end = start + self.getInitLimit()*self.getTickTime(); while(!electionFinished &amp;&amp; cur &lt; end) &#123; electingFollowers.wait(end - cur); cur = Time.currentElapsedTime(); &#125; if (!electionFinished) &#123; throw new InterruptedException("Timeout while waiting for epoch to be acked by quorum"); &#125; &#125; &#125;&#125; 计算出新的 epoch 之后，各个 LearnerHandler 会将该信息以一个 LEADERINFO 消息的形式发送给 Learner，同时等待 Learner 以 ACKEPOCH 消息进行响应。此时，Leader 的 lead 方法和各个 LearnerHandler 线程会阻塞在 waitForEpochAck 方法处，直到有过半的 Learner 确认了新的 epoch，然后将 electionFinished 标记设置为 true。 这里存在和计算 epoch 时一样的问题。 7.8 数据同步Leader 服务器收到 Learner 的 ACKEPOCH 消息后，就可以开始与 Learner 进行数据同步了。同步完成后根据 Learn 的类型将 LearnerHandler 添加到 forwardingFollowers 或 observingLearners 集合中。 参见 《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：数据与存储 7.9 启动 LeaderZooKeeperServer7.10 处理与 Learner 的后续交互8. Observer 启动当服务器状态变为 OBSERVING 时，服务器创建 Observer 和 ObserverZooKeeperServer 实例，并调用 org.apache.zookeeper.server.quorum.Observer#observeLeader 方法处理与 Leader 的后续流程。 123456789101112131415161718192021222324252627282930313233343536/** * the main method called by the observer to observe the leader * * @throws InterruptedException */void observeLeader() throws InterruptedException &#123; zk.registerJMX(new ObserverBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); LOG.info("Observing " + leaderServer.addr); try &#123; connectToLeader(leaderServer.addr, leaderServer.hostname); long newLeaderZxid = registerWithLeader(Leader.OBSERVERINFO); syncWithLeader(newLeaderZxid); QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; readPacket(qp); processPacket(qp); &#125; &#125; catch (Exception e) &#123; LOG.warn("Exception when observing the leader", e); try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; // clear pending revalidations pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX(this); &#125;&#125; 9. ZooKeeperServer 的启动与请求链初始化 org.apache.zookeeper.server.ZooKeeperServer#startup 123456789101112public synchronized void startup() &#123; if (sessionTracker == null) &#123; createSessionTracker(); &#125; startSessionTracker(); setupRequestProcessors(); registerJMX(); setState(State.RUNNING); notifyAll();&#125; 创建并启动会话管理器。 初始化 ZooKeeper 的请求处理链。 org.apache.zookeeper.server.quorum.LeaderZooKeeperServer#setupRequestProcessors 123456789101112131415@Overrideprotected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor toBeAppliedProcessor = new Leader.ToBeAppliedRequestProcessor( finalProcessor, getLeader().toBeApplied); commitProcessor = new CommitProcessor(toBeAppliedProcessor, Long.toString(getServerId()), false, getZooKeeperServerListener()); commitProcessor.start(); ProposalRequestProcessor proposalProcessor = new ProposalRequestProcessor(this, commitProcessor); proposalProcessor.initialize(); firstProcessor = new PrepRequestProcessor(this, proposalProcessor); ((PrepRequestProcessor)firstProcessor).start();&#125; org.apache.zookeeper.server.quorum.FollowerZooKeeperServer#setupRequestProcessors 12345678910111213@Overrideprotected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); commitProcessor = new CommitProcessor(finalProcessor, Long.toString(getServerId()), true, getZooKeeperServerListener()); commitProcessor.start(); firstProcessor = new FollowerRequestProcessor(this, commitProcessor); ((FollowerRequestProcessor) firstProcessor).start(); syncProcessor = new SyncRequestProcessor(this, new SendAckRequestProcessor((Learner)getFollower())); syncProcessor.start();&#125; org.apache.zookeeper.server.quorum.ObserverZooKeeperServer#setupRequestProcessors 1234567891011121314151617181920212223242526@Overrideprotected void setupRequestProcessors() &#123; // We might consider changing the processor behaviour of // Observers to, for example, remove the disk sync requirements. // Currently, they behave almost exactly the same as followers. RequestProcessor finalProcessor = new FinalRequestProcessor(this); commitProcessor = new CommitProcessor(finalProcessor, Long.toString(getServerId()), true, getZooKeeperServerListener()); commitProcessor.start(); firstProcessor = new ObserverRequestProcessor(this, commitProcessor); ((ObserverRequestProcessor) firstProcessor).start(); /* * Observer should write to disk, so that the it won't request * too old txn from the leader which may lead to getting an entire * snapshot. * * However, this may degrade performance as it has to write to disk * and do periodic snapshot which may double the memory requirements */ if (syncRequestProcessorEnabled) &#123; syncProcessor = new SyncRequestProcessor(this, null); syncProcessor.start(); &#125;&#125; 注册 JMX 服务。 10. 自问自答10.1 Observer 如何获知选举结果？Observer 在启动时向 PARTICIPANT 发送的初始选票会被 PARTICIPANT 忽略，且 PARTICIPANT 不会在选举过程中向 Observer 发送选票。此时，根据 org.apache.zookeeper.server.quorum.FastLeaderElection#lookForLeader，Observer 将不断向 PARTICIPANT 发送初始选票，直到集群选举完毕，某一个变更为 LEADING 或 FOLLOWING 状态的服务器收到了它的选票并且向它回复了选举结果。 10.2 QuorumVerifier 如何检查一个集合是否包含 Quorum？QuorumPeerConfig 在读取配置文件时，会将各服务器以 SID 为 key，对应的 QuorumPeer 实例为 value 放入对应的哈希表中。其中，PARTICIPANT 放入 servers，Observer 放入 observers。然后以 servers 的大小初始化 QuorumVerifier，其默认实现是 QuorumMaj。 org.apache.zookeeper.server.quorum.flexible.QuorumMaj#containsQuorum 123456/** * Verifies if a set is a majority. */public boolean containsQuorum(HashSet&lt;Long&gt; set)&#123; return (set.size() &gt; half);&#125; 该方法会将入参集合的大小与 PARTICIPANT 数量的一半做比较，但不会检查入参集合中的元素是否属于某一个 PARTICIPANT。 最后，observers 中的元素会被移入 servers。 10.3 选举完成后的新 epoch 计算过程存在什么问题？这里存在两个问题： connectingFollowers 名称与作用不符。它至少应包含 Leader 的 SID，除 Follower 以外，还可能包含 Observer 的 SID。 在这里，由于 connectingFollowers 集合可能包含了 Observer 的 SID，以它为参数作 Quorum 检查是不合适的（没有 PARTIPANT 检查）。 假定集群当前由一个 Leader、两个 Follower 和一个 Observer 组成。这里，PARTICIPANT 总数为 3，则 Quorum 的一半是 2。即使只有 Leader 和 Observer 提交了 epoch 并且 SID 被添加到 connectingFollowers 中，条件也被满足了。 在这个地方，要么应该忽略来自 Observer 提交的 epoch，要么应当要求已提交 epoch 的成员总数（Leader + Learner）超过集群所有成员数的一半（而不是 PARTICIPANT 的一半），逻辑才是一致的。 新 epoch 发送给集群后，Leader 对 ACK 消息的确认逻辑存在类似的问题。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：会话]]></title>
    <url>%2F2017%2F12%2F26%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E4%BC%9A%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[1. 会话状态在 ZooKeeper 客户端与服务端成功完成连接创建后，就创建了一个会话。ZooKeeper 会话在整个运行期间的生命周期中，会在不同的会话状态之间进行切换，这些状态可以一般可以分为 CONNECTING、CONNECTED、RECONNECTING、RECONNECTED、CLOSE 等。 一旦客户端开始创建 ZooKeeper 对象，那么客户端状态就会变成 CONNECTING，同时客户端开始从服务器地址列表中逐个选取 IP 地址来尝试进行网络连接，直到成功连接上服务器，然后将客户端状态变更为 CONNECTED。 通常情况下，伴随着网络闪断或是其他原因，客户端与服务端之间的连接会出现断开情况，一旦碰到这种情况，ZooKeeper 客户端会自动进行重连操作，同时客户端的状态再次变为 CONNCTING，直到重新连接上服务器后，客户端状态又会再次转变成 CONNECTED。因此，通常情况下，在 ZooKeeper 运行期间，客户端的状态总是介于 CONNECTING 和 CONNECTED 两者之一。 另外，如果出现诸如会话超时、权限检查失败或是客户端主动退出程序等情况，那么客户端的状态就会直接变更为 CLOSE。 2. 会话创建2.1 SessionSession 是ZooKeeper 中会话的实体，代表了一个客户端会话。其包含以下 4 个基本属性： sessionlD：会话 ID，用来唯一标识一个会话，每次客户端创建新会话的时候，ZooKeeper 都会为其分配一个全局唯一的 sessionID。 TimeOut：会话超时时间。客户端在构造 ZooKeeper 实例的时候，会配置一个 sessionTimeout 参数用于指定会话的超时时间。ZooKeeper 客户端向服务器发送这个超时时间后，服务器会根据自己的超时时间限制最终确定会话的超时时间。 TickTime：下次会话超时时间点。为了便于 ZooKeeper 对会话实行 “分桶策略” 管理，同时也是为了高效低耗地实现会话的超时检测与清理，ZooKeeper 会为每个会话标记一个下次会话超时时间点。TickTime 是一个 13 位的 long 型数据，其值接近于当前时间加上 TimeOut，但不完全相等。 isClosing：该属性用于标记一个会话是否已经被关闭。通常当服务端检测到一个会话巳经超时失效的时候，会将该会话的 isClosing 属性标记为 “已关闭”，这样就能确保不再处理来自该会话的新请求了。 2.2 生成 sessionIdorg.apache.zookeeper.server.SessionTrackerImpl#initializeNextSession 123456public static long initializeNextSession(long id) &#123; long nextSid; nextSid = (Time.currentElapsedTime() &lt;&lt; 24) &gt;&gt;&gt; 8; nextSid = nextSid | (id &lt;&lt;56); return nextSid; &#125; 2.3 SessionTrackerSessionTracker 是 ZooKeeper 服务端的会话管理器。Leader 的 SessionTracker 会保存整个集群中的所有会话信息，负责会话的创建、管理和清理工作，其实现是 SessionTrackerImpl。Learner 的 SessionTracker 的实现是 LearnerSessionTracker，仅做记录客户端会话激活信息用。 每一个会话在 SessionTrackerImpl 内部都保留了三份： sessionById：这是一个 HashMap&lt;Long, SessionImpl&gt; 类型的数据结构，用于根据 sessionid 来管理 Session 实体。 sessionWithTimeout：这是一个 ConcurrentHashMap&lt;Long, Integer&gt; 类型的数据结构，用于根据 sessionId 来管理会话的超时时间。该数据结构和 ZooKeeper 内存数据库相连通，会被定期持久化到快照文件中去。 sessionSets：这是一个 HashMap&lt;Long, SessionSet&gt; 类型的数据结构，用于根据下次会话超时时间点来归档会话，便于进行会话管理和超时检查。 3. 会话管理ZooKeeper 集群的会话管理由 Leader 统一处理。 3.1 分桶策略ZooKeeper 采用了一种特殊的会话管理方式，我们称之为 “分桶策略”。所谓分桶策略，是指将类似的会话放在同一区块中进行管理，以便于 ZooKeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。 ZooKeeper 将所有的会话都分配在了不同的区块之中，分配的原则是每个会话的 “下次超时时间点”（ExpirationTime)。ExpirationTime 是指该会话最近一次可能超时的时间点，对于一个新创建的会话而言，其会话创建完毕后， ZooKeeper 就会为其计算 ExpirationTime，计算方式如下：$$ExpirationTime = CurrentTime + SessionTimeout$$在 ZooKeeper 的实际实现中，还做了一个处理。ZooKeeper 的 Leader 服务器在运行期间会定时地进行会话超时检査，其时间间隔是 ExpirationInterval，单位是毫秒，默认值是 tickTime 的值，即默认情况下，每隔 2000 毫秒进行一次会话超时检查。为了方便对多个会话同时进行超时检査，完整的 ExpirationTime 的计算方式如下：$$\begin{equation}ExpirationTime_ = CurrentTime + SessionTimeout \ExpirationTime = (ExpirationTime_ /Expirationlnterval +1)*Expirationlnterval\end{equation}$$最终计算出的 ExpirationTime 即为客户端会话下次超时时间所对应的 ”桶“（即，大于会话下次超时时间的最小 ExpirationInterval 整数倍）。同时，会话的 tickTime 属性被设置为 ExpirationTime，SessionTracker 以这个 ExpirationTime 为 key 将会话保存到 sessionSets 中。 org.apache.zookeeper.server.SessionTrackerImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354synchronized public boolean touchSession(long sessionId, int timeout) &#123; SessionImpl s = sessionsById.get(sessionId); // Return false, if the session doesn't exists or marked as closing if (s == null || s.isClosing()) &#123; return false; &#125; long expireTime = roundToInterval(Time.currentElapsedTime() + timeout); if (s.tickTime &gt;= expireTime) &#123; // Nothing needs to be done return true; &#125; SessionSet set = sessionSets.get(s.tickTime); if (set != null) &#123; set.sessions.remove(s); &#125; s.tickTime = expireTime; set = sessionSets.get(s.tickTime); if (set == null) &#123; set = new SessionSet(); sessionSets.put(expireTime, set); &#125; set.sessions.add(s); return true;&#125;private long roundToInterval(long time) &#123; // We give a one interval grace period return (time / expirationInterval + 1) * expirationInterval;&#125;@Overridesynchronized public void run() &#123; try &#123; while (running) &#123; currentTime = Time.currentElapsedTime(); if (nextExpirationTime &gt; currentTime) &#123; this.wait(nextExpirationTime - currentTime); continue; &#125; SessionSet set; set = sessionSets.remove(nextExpirationTime); if (set != null) &#123; for (SessionImpl s : set.sessions) &#123; setSessionClosing(s.sessionId); expirer.expire(s); &#125; &#125; nextExpirationTime += expirationInterval; &#125; &#125; catch (InterruptedException e) &#123; handleException(this.getName(), e); &#125; LOG.info("SessionTrackerImpl exited loop!");&#125; 3.2 会话激活在 ZooKeeper 的实际设计中，只要客户端有请求发送到服务端，那么就会触发一次会话激活。会话激活大体分为以下两种情况： 客户端向服务端发送请求，包括读写请求，就么就会触发一次会话激活。 这是通过在 org.apache.zookeeper.server.ZooKeeperServer#submitRequest(org.apache.zookeeper.server.Request) 中调用 touchSession 来实现的。 客户端发现在 sessionTimeout/3 时间内尚未和服务端进行过任何通信，那么就会主动发起一个 PING 请求，服务端收到该请求后，就会触发第一种情况下的会话激活，俗称 “心跳检测”。 会话激活的过程，不仅能够使服务端检测到对应客户端的存活性，同时也能让客户端自己保持连接状态。 如果客户端连接的是 Leader，那么由 Leader 的 SessionTrackerImpl 直接处理会话激活操作。 如果客户端连接的是 Learner，那么 Learner 将客户端的激活信息保存在 touchTable 中： org.apache.zookeeper.server.quorum.LearnerSessionTracker#touchSession 12345HashMap&lt;Long, Integer&gt; touchTable = new HashMap&lt;Long, Integer&gt;();synchronized public boolean touchSession(long sessionId, int sessionTimeout) &#123; touchTable.put(sessionId, sessionTimeout); return true;&#125; Leader 会定时通过 PING 消息从 Learner 那儿获取客户端激活信息，这个时候，Learner 会将 touchTable 的内容发送给 Leader，同时清空 touchTable。 org.apache.zookeeper.server.quorum.Learner#ping 12345678910111213protected void ping(QuorumPacket qp) throws IOException &#123; // Send back the ping with our session data ByteArrayOutputStream bos = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(bos); HashMap&lt;Long, Integer&gt; touchTable = zk .getTouchSnapshot(); for (Entry&lt;Long, Integer&gt; entry : touchTable.entrySet()) &#123; dos.writeLong(entry.getKey()); dos.writeInt(entry.getValue()); &#125; qp.setData(bos.toByteArray()); writePacket(qp, true);&#125; org.apache.zookeeper.server.quorum.LearnerZooKeeperServer#getTouchSnapshot 123456protected HashMap&lt;Long, Integer&gt; getTouchSnapshot() &#123; if (sessionTracker != null) &#123; return ((LearnerSessionTracker) sessionTracker).snapshot(); &#125; return new HashMap&lt;Long, Integer&gt;();&#125; org.apache.zookeeper.server.quorum.LearnerSessionTracker#snapshot 12345synchronized HashMap&lt;Long, Integer&gt; snapshot() &#123; HashMap&lt;Long, Integer&gt; oldTouchTable = touchTable; touchTable = new HashMap&lt;Long, Integer&gt;(); return oldTouchTable;&#125; Leader 会从 PING 消息的回复中，逐个取出 sessionId 及其 sessionTimeout 时间，做激活操作。 org.apache.zookeeper.server.quorum.LearnerHandler#run 123456789101112131415161718@Overridepublic void run() &#123; // ... while (true) &#123; switch (qp.getType()) &#123; case Leader.PING: // Process the touches ByteArrayInputStream bis = new ByteArrayInputStream(qp.getData()); DataInputStream dis = new DataInputStream(bis); while (dis.available() &gt; 0) &#123; long sess = dis.readLong(); int to = dis.readInt(); leader.zk.touch(sess, to); &#125; break; &#125; &#125; &#125; Leader 的会话激活操作分为以下几个步骤： 检验该会话是否已经被关闭。 计算该会话新的超时时间 ExpirationTime_New。 获取该会话上次超时时间 ExpirationTime_Old。 迁移会话。将该会话从老的区块中取出，放入 ExpirationTime_New 对应的新区块中。 3.3 会话超时检查在 ZooKeeper 中，会话超时检査由 Leader 的 SessionTrackerImpl 负责。SessionTrackerImpl 中有一个单独的线程专门进行会话超时检査，其工作机制的核心思路非常简单：逐个依次地对会话桶中剩下的会话进行清理。 ZooKeeperServer 实现了 SessionExpirer 接口： org.apache.zookeeper.server.ZooKeeperServer 12345678910public void expire(Session session) &#123; long sessionId = session.getSessionId(); LOG.info("Expiring session 0x" + Long.toHexString(sessionId) + ", timeout of " + session.getTimeout() + "ms exceeded"); close(sessionId);&#125;private void close(long sessionId) &#123; submitRequest(null, sessionId, OpCode.closeSession, 0, null, null);&#125; 可见，会话超时是通过提交一条 closeSession 的情求来实现的。 4. 会话清理当 SessionTrackerImpl 的会话超时检查线程整理出一些已经过期的会话后，就要开始进行会话清理了。会话清理的步骤大致可以分为以下 7 步。 4.1 标记会话状态为已关闭由于整个会话清理过程需要一段时间，为了保证在此期间不再处理来自该客户端的新请求，SessionTrackerImpl 会首先将该会话的 isClosing 属性标记为 true，这样，即使在会话清理期间接收到该客户端的新请求（虽然目前只是在 Leader 上标记了，但客户端的事务请求会被提交到 Leader），也无法继续处理了。 4.2 发起会话关闭请求为了使对该会话的清理和关闭操作在整个服务端集群中都生效，ZooKeeper 使用了提交会话关闭请求的方式，将其作为一个事务处理。事务被提交到 Leader 的 PreRequestProcessor。 4.3 收集需要清理的临时节点一旦某个会话失效后，那么和该会话相关的临时节点都需要被一并清除掉。因此，在清理临时节点之前，首先需要将服务器上所有和该会话相关的临时节点都整理出来。 在 ZooKeeper 的内存数据库中，为每个会话都单独保存了一份由该会话维护的所有临时节点集合，因此在会话清理阶段，只需要根据当前即将关闭的会话的 sessionId 从内存数据库中获取到这份临时节点列表即可。 在 Leader 处理会话关闭请求之前，可能正好有以下两类请求到达了服务端并正在处理中。 节点删除请求，删除的目标节点正好是上述临时节点中的一个。 临时节点创建请求，创建的目标节点正好是上述临时节点中的一个。 假定当前获取到的临时节点列表是 ephemerals。对于第一类请求，需要将所有这些请求对应的数据节点路径从 ephemerals 中移除，以避免重复删除。对于第二类请求，需要将所有这些请求对应的数据节点路径添加到 ephemerals 中去，以删除这些即将被创建但是尚未保存到内存数据库中去的临时节点。 org.apache.zookeeper.server.PrepRequestProcessor#pRequest2Txn 1234567891011121314151617181920212223242526272829303132// ... request.hdr = new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), type); switch (type) &#123; // ... case OpCode.closeSession: // We don't want to do this check since the session expiration thread // queues up this operation without being the session owner. // this request is the last of the session so it should be ok // zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); HashSet&lt;String&gt; es = zks.getZKDatabase().getEphemerals(request.sessionId); synchronized (zks.outstandingChanges) &#123; for (ChangeRecord c : zks.outstandingChanges) &#123; if (c.stat == null) &#123; // Doing a delete es.remove(c.path); &#125; else if (c.stat.getEphemeralOwner() == request.sessionId) &#123; es.add(c.path); &#125; &#125; for (String path2Delete : es) &#123; addChangeRecord(new ChangeRecord(request.hdr.getZxid(), path2Delete, null, 0, null)); &#125; zks.sessionTracker.setSessionClosing(request.sessionId); &#125; LOG.info("Processed session termination for sessionid: 0x" + Long.toHexString(request.sessionId)); break; // ...&#125;// ... 4.4 添加节点删除事务变更完成该会话相关的临时节点收集后，Leader 会逐个将对这些临时节点创建变更记录，并放入事务变更队列 outstandingChanges 中。 4.5 删除临时节点节点删除事务被提交到整个集群后，各服务器的 FinalRequestProcessor 会触发内存数据库，删除该会话对应的所有临时节点。 4.6 移除会话各服务器的 FinalRequestProcessor 在处理会话关闭事务请求时，会将会话从 SessionTracker 中移除。 4.7 关闭 NIOServerCnxn最后，客户端所连接的那个服务器会向 ServerCnxnFactory 发送一个关闭连接的请求数据，从 NIOServerCnxnFactory 找到该会话对应的 NIOServerCnxn，将其关闭。 5. 重连当客户端与服务端之间的网络连接断开时，ZooKeeper 客户端会自动进行反复的重连，直到最终成功连接上 ZooKeeper 集群中的一台机器。在这种情况下，再次连接上服务端的客户端有可能处于以下两种状态之一。 CONNECTED。如果在会话超时时间内重新连接上了集群中任意一台机器，那么被视为重连成功。 EXPIRED。如果在会话超时时间以外重新连接上，那么服务端其实已经对该会话进行了会话清理操作，因此再次连接上的会话将被视为非法会话。 在客户端与服务端之间维持的是一个长连接，在 sessionTimeout 时间内，服务端会不断地检测该客户端是否还处于正常连接——服务端会将客户端的每次操作视为一次有效的心跳检测来反复地进行会话激活。因此，在正常情况下，客户端会话是一直有效的。然而，当客户端与服务端之间的连接断开后，用户在客户端可能主要会看到两类异常：CONNECTION_LOSS（连接断开）和 SESSION_EXPIRED（会话过期）。 5.1 连接断开 CONNECTION_LOSS有时会因为网络闪断导致客户端与服务器断开连接，或是因为客户端当前连接的服务器出现问题导致连接断开，我们统称这类问题为 “客户端与服务器连接断开” 现象，即 CONNECTION_LOSS。在这种情况下，ZooKeeper 客户端会自动从地址列表中重新逐个选取新的地址并尝试进行重新连接，直到最终成功连接上服务器。 举个例子，假设某应用在使用 ZooKeeper 客户端进行 setData 操作的时候，正好出现了 CONNECTION_LOSS 现象，那么客户端会立即接收到事件 None-Disconnected 通知，同时会抛出异常：org.apache.zookeeper.KeeperException.Code#CONNECTIONLOSS。在这种情况下，应用需要做的事情就是捕获住 ConnectionLossException，然后等待 ZooKeeper 的客户端自动完成重连。一旦客户端成功连接上一台 ZooKeeper 机器后，那么客户端就会收到事件 None-SyncConnected 通知，之后就可以重试刚刚出错的 setData 操作。 5.2 会话失效 SESSION_EXPIRED客户端与服务端断开连接后，如果重连期间耗时过长，超过了会话超时时间限制后还没有成功连接上服务器，那么服务器认为这个会话已经结束了，就会开始进行会话清理。但是另一方面，该客户端本身不知道会话已经失效，并且其客户端状态还是 DISCONNECTED。之后，如果客户端重新连上了服务器，服务器会告诉客户端该会话已经失效（SESSION_EXPIRED）。在这种情况下，用户就需要重新实例化一个 ZooKeeper 对象，并且看应用的复杂情况，重新恢复临时数据。 5.3 会话转移 SESSION_MOVEDZooKeeper 明确提出了会话转移的概念，同时封装了 SessionMovedException 异常。之后，在处理客户端请求的时候，会首先检查会话的所有者（Owner)：如果客户端请求的会话 Owner 不是当前服务器的话，那么就会直接抛出 SessionMovedException 异常。当然，由于客户端已经和这个服务器断开了连接，因此无法收到这个异常的响应。只有多个客户端使用相同的 sessionld/sessionPasswd 创建会话时，才会收到这样的异常。因为一旦有一个客户端会话创建成功，那么 ZooKeeper 服务器就会认为该 sessionld 对应的那个会话已经发生了转移，于是，等到第二个客户端连接上服务器后，就被认为是 “会话转移” 的情况了。 6. 自问自答6.1 会话重连如何实现？ 客户端的会话创建请求作为一个事务，会被同步到整个 ZooKeeper 集群中，各个服务器的 SessionTracker 中记录了整个集群中的会话信息。 客户端会与所连接的服务器保持会话存活（通过读写请求或 PING 请求）。 Leader 会定时地向 Learner 服务器发送 PING 消息，Learner 服务器在接收到 PING 消息后，会将这段时间内保持心跳检测的客户端列表，同样以 PING 消息的形式反馈给 Leader 服务器，由 Leader 服务器来负责逐个对这些客户端进行会话激活。 当客户端重连到另一台服务器上时，org.apache.zookeeper.server.NIOServerCnxn#readConnectRequest 调用 org.apache.zookeeper.server.ZooKeeperServer#processConnectRequest。这里会做一个判断，如果请求中附带了 sessionId，就不执行创建会话操作，而是重新打开会话。 服务器首先执行密码校验工作，如果校验通过，则调用 org.apache.zookeeper.server.ZooKeeperServer#revalidateSession 验证会话有效性。 如果客户端重连上的是 Leader，会话的有效性验证在本地即可操作。 如果客户端重连上的是 Learner，LearnerZooKeeperServer 中重写了 revalidateSession 方法： org.apache.zookeeper.server.quorum.LearnerZooKeeperServer#revalidateSession 12345@Overrideprotected void revalidateSession(ServerCnxn cnxn, long sessionId, int sessionTimeout) throws IOException &#123; getLearner().validateSession(cnxn, sessionId, sessionTimeout);&#125; org.apache.zookeeper.server.quorum.Learner#validateSession 123456789101112void validateSession(ServerCnxn cnxn, long clientId, int timeout) throws IOException &#123; LOG.info("Revalidating client: 0x" + Long.toHexString(clientId)); ByteArrayOutputStream baos = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(baos); dos.writeLong(clientId); dos.writeInt(timeout); dos.close(); QuorumPacket qp = new QuorumPacket(Leader.REVALIDATE, -1, baos.toByteArray(), null); pendingRevalidations.put(clientId, cnxn); writePacket(qp, true);&#125; Learner 会向 Leader 发送 REVALIDATE 消息，由 Leader 来完成客户端会话有效性的验证工作，并向 Learner 返回验证结果。 注意到 SessionTracker 的 sessionWithTimeout 是和 ZooKeeper 的内存数据库相连通的。这样，即使在 ZooKeeper 集群运行过程中发生了重新选举，新的 Leader 也可以在从快照文件和事务日志中恢复出内存数据库后，执行会话有效性验证工作。 Learner 在接收到 Leader 的会话验证结果后，即使会话有效，也不会做一次 addSession 或 touchSession 操作。这是因为如果 Leader 判定该会话有效，那么该会话一定存在于重连上的 Learner 的 LearnerSessionTracker 中，不需要重新添加。同时，这样的会话验证过程会在 Leader 上对该会话进行一次激活。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：角色与消息]]></title>
    <url>%2F2017%2F12%2F25%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E8%A7%92%E8%89%B2%E4%B8%8E%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[1. LeaderLeader服务器是 ZooKeeper 集群工作的核心，其主要工作如下： 事务请求的唯一调度和处理者，保证集群事务处理的顺序性。 集群内部各服务器的调度者。 ZooKeeper 使用责任链模式来处理每一个客户端的请求。 1.1 PrepRequestProcessorLeader 服务器的请求预处理器。在 ZooKeeper 中，那些会改变服务器状态的请求被称为事务请求（创建节点、更新数据、删除节点、创建会话等）。PrepRequestProcessor 能够识别出当前客户端请求是否是事务请求。对于事务请求，PrepRequestProcessor 处理器会对其进行一系列预处理，如创建请求事务头、事务体、会话检查、ACL 检查和版本检查等。 1.2 ProposalRequestProcessorLeader 服务器的事务投票处理器。Leader 服务器事务处理流程的发起者，对于非事务请求，ProposalRequestProcessor 会直接将请求转发到 CommitProcessor 处理器，不再做其他处理；而对于事务请求，除了将请求转发到 CommitProcessor 外，还会根据请求类型创建对应的 Proposal 提议，并发送给所有的 Follower 服务器来发起一次集群内的事务投票。同时，ProposalRequestProcessor 还会将事务请求交付给 SyncRequestProcessor 进行事务日志的记录。 1.3 SyncRequestProcessor事务日志记录处理器，用来将事务请求记录到事务日志文件中，同时还会触发 ZooKeeper 进行数据快照。 1.4 AckRequestProcessorLeader 特有的处理器，负责在 SyncRequestProcessor 完成事务日志记录后，向 Proposal 的投票收集器发送 ACK 反馈，以通知投票收集器当前服务器已经完成了对该 Proposal 的事务日志记录。 1.5 CommitProcessor事务提交处理器。对于非事务请求，该处理器会直接将其交付给下一级处理器处理；对于事务请求，其会等待集群内针对 Proposal 的投票直到该 Proposal 可被提交。利用 CommitProcessor，每个服务器都可以很好地控制对事务请求的顺序处理。 1.6 ToBeAppliedRequestProcessor该处理器中有一个 toBeApplied 队列，用来存储那些已经被 CommitProcessor 处理过的可被提交的 Proposal。ToBeAppliedRequestProcessor 处理器将这些请求逐个交付给 FinalRequestProcessor 处理器进行处理 —— 等到 FinalRequestProcessor 处理器处理完之后，再将其从 toBeApplied队列 中移除。 1.7 FinalRequestProcessor用来进行客户端请求返回之前的收尾工作，包括创建客户端请求的响应；针对事务请求，该处理还会负责将事务应用到内存数据库中去。 2. FollowerFollower 是 ZooKeeper 集群的跟随者，其主要工作如下： 处理客户端非事务请求，转发事务请求给 Leader 服务器。 参与事务请求 Proposal 的投票。 参与 Leader 选举投票。 Follower 也采用了责任链模式组装的请求处理链来处理每一个客户端请求。 2.1 FollowerRequestProcessorFollower 服务器的第一个请求处理器，其主要工作就是识别出当前请求是否是事务请求。如果是事务请求，那么 Follower 就会将该请求转发给 Leader 服务器，Leader 服务器在接收到这个事务请求后，就会将其提交到请求处理链，按照正常事务请求进行处理。 2.2 SendAckRequestProcessor该处理器承担了事务日志记录反馈的角色，在完成事务日志记录后，会向 Leader 服务器发送 ACK 消息以表明自身完成了事务日志的记录工作。它与 AckRequestProcessor 的区别在于，AckRequestProcessor 处理器和 Leader 在同一个服务器上，因此它的 ACK 仅仅是一个本地的方法调用；而 SendAckRequestProcessor 处理器由于在 Follower 服务器上，因此需要通过以 ACK 消息的形式来向 Leader 服务器进行反馈。 3. ObserverObserver 充当观察者角色，观察 ZooKeeper 集群的最新状态变化并将这些状态同步过来。Observer 服务器再工作原理上和 Follower 是基本一致的，对于非事务请求，都可以进行独立的处理，而对于事务请求，则会转发给 Leader 服务器进行处理。区别在于，Observer 不参与任何形式的投票，包括事务请求 Proposal 的投票和 Leader 选举投票。简单地讲，Observer 服务器只提供非事务服务，通常用于在不影响集群事务处理能力的前提下提升集群的非事务处理能力。 需要注意的一点是，Observer 服务器再初始化阶段会将 SyncRequestProcessor 处理器也组装上去，但是在实际运行过程中，Leader 服务器不会将事务请求的投票发送给 Observer 服务器。 4. 集群间消息通信ZooKeeper 的消息类型大体分为数据同步型、服务器初始化型、请求处理型和会话管理型。 4.1 数据同步型数据同步型消息是指在 Learner 和 Leader 服务器进行数据同步时，网络通信所用到的消息，通常有DIFF、TRUNC、SNAP 和 UPTODATE 四种。 消息类型 发送方 → 接收方 说 明 DIFF，13 Leader→Learner 用于通知 Learner 服务器，Leader 即将与其进行 DIFF 方式的数据同步 TRUNC，14 Leader→Learner 用于触发 Learner 服务器进行内存数据库的回滚操作 SNAP，15 Leader→Learner 用于通知 Learner 服务器，Leader 即将与其进行 “全量” 方式的数据同步 UPTODATE，12 Leader→Learner 用来告诉 Learner 服务器，已经完成了数据同步，可以开始对外提供服务了 4.2 服务器初始化型服务器初始化型消息是指在整个集群或是某些新机器初始化的时候，Leader 和 Learner 之间相互通信所使用的消息类型，常见的有 OBSERVERINFO、FOLLOWERINFO、 LEADERINFO、ACKEPOCH 和 NEWLEADER 五种。 消悤类型 发送方一接收方 说 明 OBSERVERINFO，16 Observer→Leader 该信息通常是由 Observer 服务器在启动的时候发送给 Leader 的，用于向 Leader 服务器注册自己，同时向 Leader 服务器表明当前 Learner 服务器的角色是 Observer。消息中包含了当前 Observer 服务器的 SID 和已经处理的最新 ZXID FOLLOWERINFO，11 Follower→Leader 该信息通常是由 Follower 服务器在启动的时候发送 给 Leader 的，用于向 Leader 服务器注册自己，同时向 Leader 服务器表明当前 Learner 服务器的角色是 Follower。消息中包含了当前 Follower 服务器的 SID 和已经处理的最新 ZXID LEADERINFO，17 Leader→Learner 在上面已经提到，在 Learner 连接上 Leader 后， 会向 Leader 发送 LearnerInfo 消息（包含了 OBSERVERINFO 和 FOLLOWERINFO 两类消息），Leader 服务器在接收到该消息后，也会将 Leader 服务器的基本信息发送给这些 Learner，这个消息就是 LEADERINFO， 通常包含了当前 Leader 服务器的最新 EPOCH 值 ACKEPOCH，18 Learner→Leader Learner 在接收到 Leader 发来的 LEADERINFO 消息后，会将自已更新后的 ZXID 和 EPOCH 以 ACKEPOCH 消息的形式发送给 Leader NEWLEADER，10 Leader→Learner 该消息通常用于 Leader 服务器向 Learner 发送一个阶段性的标识消息 —— Leader 会在和 Learner 完成一个交互流程后，向 Learner 发送 NEWLEADER 消息， 同时带上当前 Leader 服务器处理的最新 ZXID。这一系列交互流程包括：足够多的 Follower 服务器连接上 Leader 或是完成数据同步 4.3 请求处理型请求处理型消息是指在进行请求处理的过程中，Leader 和 Learner 服务器之间互相通信所使用的消息，常见的有 REQUEST、PROPOSAL、ACK、COMMIT、INFORM 和 SYNC 六种。 消息类型 发送方—接收方 说 明 REQUEST，1 Learner→Leader 该消息是 ZooKeeper 的请求转发消息。在 ZooKeeper 中，所有的事务请求必由 Leader 服务器来处理。当 Learner 服务器接收到客户端的事务请求后，就会将请求以 REQUEST 消息的形式转发给 Leader 服务器来处理 PROPOSAL，2 Leader→Follower 该消息是 ZooKeeper 实现 ZAB 算法的核心所在，即 ZAB 协议中的提议。在处理事务请求的时候，Leader 服务器会将事务请求以 PROPOSAL 消息的形式创建投票发送给集群中所有的 Follower 服务器来进行事务日志的记录 ACK,3 Follower→Leader Follower 服务器在接收到来自 Leader 的 PROPOSAL 消息后，会进行事务日志的记录。如果完成了事务日志的记录，那么就会以 ACK 消息的形式反馈给 Leader COMMITS Leader→Follower 该消息用于通知集群中所有的 Follower 服务器，可以进行事务请求的提交了。Leader 服务器在接收到过半的 Follower 服务器发来的 ACK 消息后，就进入事务请求的最终提交流程 —— 生成 COMMIT 消息，告知所有的 Follower 服务器进行事务请求的提交 INFORM，8 Leade→Observer 在事务请求提交阶段，针对 Follower 服务器，Leader 仅仅只需要发送一个 COMMIT 消息，Follower 服务器就可以完成事务请求的提交了，因为在这之前的事务请求投票阶段，Follower 已经接收过 PROPOSAL 消息，该消息中包含了事务请求的内容，因此 Follower 可以从之前的 Proposal 缓存中再次获取到事务请求。而对于 Observer 来说，由于之前没有参与事务请求的投票，因此没有该事务请求的上下文，显然， 如果 Leader 同样对其发送一个简单的 COMMIT 消息， Observer 服务器是无法完成事务请求的提交的。为了解决这个问題，ZooKeeper 特别设计了 INFORM 消息，该消息不仅能够通知 Observer 已经可以提交事务请求，同时还会在消息中携带事务请求的内容 SYNC，7 Leader→Learner 该消息用于通知 Learner 服务器已经完成了 Sync 操作 4.4 会话管理型会话管理型消息是指 ZooKeeper 在进行会话管理的过程中，和 Learner 服务器之间互相通信所使用的消息，常见的有 PING 和 REVALIDATE 两种。 消息类型 发送方一接收方 说 明 PING，5 Leader→Learner 该消息用于 Leader 同步 Learner 服务器上的客户端心跳检测，用以激活存活的客户端。ZooKeeper 的客户端往往会随机地和任意一个 ZooKeeper 服务器保持连接，因此Leader 服务器无法直接接收到所有客户端的心跳检测，需要委托给 Learner 来保存这些客户端的心跳检测记录。Leader 会定时地向 Learner 服务器发送 PING 消息，Learner 服务器在接收到 PING 消息后，会将这段时间内保持心跳检测的客户端列表，同样以 PING 消息的形式反馈给 Leader 服务器，由 Leader 服务器来负责逐个对这些客户端进行会话激活。 REVALIDATE，6 Learner→Leader 该消息用于 Learner 校验会话是否有效，同时也会激活会话，这通常发生在客户端重连的过程中，新的服务器需要向 Leader 发送 REVALIDATE 消息以确定该会话是否已经超时。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：数据与存储]]></title>
    <url>%2F2017%2F12%2F25%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[1. 内存数据ZooKeeper 的数据模型是一棵树，而从使用角度看， Zookeeper 就像一个内存数据库一样。在这个内存数据库中，存储了整棵树的内容，包括所有的节点路径、节点数据及其 ACL 信息等，Zookeeper 会定时将这个数据存储到磁盘上。 1.1 DataTreeDataTree 是内存数据存储的核心，是一个树结构，代表了内存中一份完整的数据。DataTree 不包含任何与网络、客户端连接及请求处理相关的业务逻辑，是一个独立的组件。 1.2 DataNodeDataNode 是数据存储的最小单元，其内部除了保存了节点的数据内容、ACL 列表、节点状态之外，还记录了父节点的引用和子节点列表两个属性。同时，DataNode 也提供了对子节点列表进行操作的接口。 1.3 nodesDataTree 用于存储所有 ZooKeeper 节点的路径、数据内容及其 ACL 信息等，底层的数据结构其实是一个典型的 ConcurrentHashMap 键值对结构： 1private final ConcurrentHashMap&lt;String, DataNode&gt; nodes = new ConcurrentHashMap&lt;String, DataNode&gt;(); 在 nodes 这个 Map 中，存放了 ZooKeeper 服务器上所有的数据节点，可以说，对于 ZooKeeper 数据的所有操作，底层都是对这个 Map 结构的操作。nodes 以数据节点的路径（path）为 key，value 则是节点的数据内容：DataNode。 另外，对于所有的临时节点，为了便于实时访问和及时清理，DataTree 中还单独将临时节点保存起来： 1private final Map&lt;Long, HashSet&lt;String&gt;&gt; ephemerals = new ConcurrentHashMap&lt;Long, HashSet&lt;String&gt;&gt;(); 1.4 ZKDatabaseZooKeeper 的内存数据库，负责管理 ZooKeeper 的所有会话、DataTree 存储和事务日志。ZKDatabase 会定时向磁盘 dump 快照数据，同时在 ZooKeeper 启动时，会通过磁盘的事务日志和快照文件恢复成一个完整的内存数据库。 2. 事务日志2.1 日志格式可以使用 org.apache.zookeeper.server.LogFormatter 将事务日志文件转换成可视化的事务操作日志。在转换结果中，每个事务日志第一行为文件头信息： 1ZooKeeper Transactional Log File with dbid 0 txnlog format version 2 之后每一行记录一次事务操作。 116-11-19 下午01时12分48秒 session 0x15554779e59002c cxid 0x0 zxid 0x600000075 createSession 40000 这一行就是一次客户端会话创建的事务操作日志，其中我们不难看出，从左向右分别记录事物操作时间、客户端会话 ID、CXID (客户端的操作序列号）、ZXID、操作类型和会话超时时间。 116-11-19 下午12时04分00秒 session 0x15554779e59000f cxid 0x1 zxid 0x600000027 create &apos;/zookeeper/test,#2f7a6f6f6b65657065722f74657374,v&#123;s&#123;31,s&#123;&apos;digest,&apos;foo:Jfg7TYUBs/6KEtdDWd5OB6bdD2Q=&#125;&#125;&#125;,F,2 这一行是节点创建操作的事务操作日志，从左向右分別记录了事物操作时间、客户端会话 ID、CXID、ZXID、操作类型、节点路径、节点数据内容（#2f7a6f6f6b65657065722f74657374，在 LogFormatter 中使用如下格式输出节点内容：#+内容的 ASCII 码值）、节点的 ACL 信息、是否是临时节点（F 代表持久节点，T 代表临时节点）和父节点的子节点版本号。 注意，转换结果中没有显示每条事务操作记录的 Checksum 信息。 2.2 日志写入FileTxnLog 负责维护事务日志对外的接口，包括事务日志的写入和读取等。将事务操作写入事务日志的工作主要由 append 方法来负责： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * append an entry to the transaction log * @param hdr the header of the transaction * @param txn the transaction part of the entry * returns true iff something appended, otw false */public synchronized boolean append(TxnHeader hdr, Record txn) throws IOException&#123; if (hdr == null) &#123; return false; &#125; if (hdr.getZxid() &lt;= lastZxidSeen) &#123; LOG.warn("Current zxid " + hdr.getZxid() + " is &lt;= " + lastZxidSeen + " for " + hdr.getType()); &#125; else &#123; lastZxidSeen = hdr.getZxid(); &#125; if (logStream==null) &#123; logFileWrite = new File(logDir, ("log." + Long.toHexString(hdr.getZxid()))); fos = new FileOutputStream(logFileWrite); logStream=new BufferedOutputStream(fos); oa = BinaryOutputArchive.getArchive(logStream); FileHeader fhdr = new FileHeader(TXNLOG_MAGIC,VERSION, dbId); fhdr.serialize(oa, "fileheader"); // Make sure that the magic number is written before padding. logStream.flush(); currentSize = fos.getChannel().position(); streamsToFlush.add(fos); &#125; padFile(fos); byte[] buf = Util.marshallTxnEntry(hdr, txn); if (buf == null || buf.length == 0) &#123; throw new IOException("Faulty serialization for header and txn"); &#125; Checksum crc = makeChecksumAlgorithm(); crc.update(buf, 0, buf.length); oa.writeLong(crc.getValue(), "txnEntryCRC"); Util.writeTxnBytes(oa, buf); return true;&#125; 从方法定义中可以看到，ZooKeeper 在进行事务日志写入的过程中，会将事务头和事务体传给该方法。事务日志的写入过程大体可以分为如下 6 个步骤。 2.2.1 确定是否有事务日志可写当 ZooKeeper 服务器启动完成需要进行第一次事务日志的写入，或是上一个事务日志文件写满时，都会处于与事务日志文件断开的状态，即 ZooKeeper 服务器没有和任意一个日志文件相关联。因此在进行事务日志写入前，ZooKeeper 首先会判断 FileTxnLog 组件是否已经关联上一个可写的事务日志文件。若没有，则会使用该事务操作关联的 ZXID 作为后缀创建一个事务日志文件，同时构建事务日志的文件头信息，并立即写入这个事务日志文件中去。同时，将该文件的文件流放入 streamToFlush 集合，该集合用来记录当前需要强制进行数据落盘（将数据强制刷入磁盘上）的文件流。 2.2.2 确定事务日志文件是否需要扩容（预分配）当检测到当前务日志文件剩余空间不足 4096 字节（4KB）时，就会开始进行文件空间扩容，即，在现有文件大小的基础上，将文件大小增加 65536KB （64MB），然后使用 “0”（\0）填充这些被扩容的文件空间。 那么 ZooKeeper 为什么要进行事务日志文件的磁盘空间预分配呢？对客户端的每一次事务操作，ZooKeeper 都会将其写入事务日志文件中。因此，事物日志的写入性能直接决定了 ZooKeeper 服务器对事务请求的响应，也就是说，事务写入近似可以被看作是一个磁盘 I/O 的过程。严格地讲，文件的不断追加写入操作会触发底层磁盘 I/O 为文件开辟新的磁盘块，即磁盘 Seek。因此，为了避免磁盘 Seek 的频率，提高磁盘 I/O 的效率，ZooKeeper 在创建事物日志的时候就会进行文件空间 “预分配” —— 在文件创建之初就向操作系统预分配一个很大的磁盘块，默认是 64MB，而一旦已分配的文件空间不足 4KB 时，将会再次 “预分配”，以避免随着每次事务的写入过程中文件大小增长带来的 Seek 开销，直至创建新的事务日志。事务日志预分配的大小可以通过系统属性 zookeeper.preAllocSize 来进行设置。 2.2.3 事务序列化事务序列化包括对事务头和事务体的序列化，分别是对 TxnHeader （事务头）和 Record （事务体）的序列化。其中事务体又可分为会话创建事务（CreateSessionTxn）、节点创建事务（CreateTxn）、节点删除事务（DeleteTxn）和节点数据更新事务 （SetDataTxn）等。 2.2.4 生成 Checksum为了保证事务日志文件的完整性和数据的准确性，ZooKeeper 在将事务日志写入文件前，会根据事务序列化产生的字节数组来计算 Checksum。ZooKeeper 默认使用 Adler32 算法来计算 Checksum 值。 2.2.5 写入事务日志文件流将序列化后的事务头、事务体及 Checksum 值写入到文件流中去。此时由于 ZooKeeper 使用的是 BufferedOutputStream，因此写入的数据并非真正被写入到磁盘文件上。 2.2.6 事务日志刷入磁盘到此，已经将事务操作写入文件流中，但是由于缓存的原因，无法实时地写入磁盘文件中，因此我们需要将缓存数据强制刷入磁盘中。这里会从 streamsToFlush 中提取出文件流，并调用 FileChannel.force(boolean metaData) 接口来强制将数据刷入磁盘文件中去。force 接口对应的其实是底层的 fsync 接口，是一个比较耗费磁盘 I/O 资源的接口，因此 ZooKeeper 允许用户控制是否需要主动调用该接口，可以通过系统属性 zookeeper.forceSync 来设置。 2.3 日志截断在 ZooKeeper 运行过程中，可能出现非 Leader 机器上记录的事务 ID（peerLastZxid） 比 Leader 服务器大的情况，这是一个非法的运行时状态。 一旦某台机器碰到这样的情况，Leader 会发送 TRUNC 命令给这个机器，要求进行日志截断。Learner 服务器在接收到该命令后，就会删除所有包含或大于 peerLastZxid 的事务日志文件。 3. snapshot——数据快照数据快照用来记录 ZooKeeper 服务器上某一时刻的全量内存数据内容，并将其写入指定的磁盘文件中。快照文件也是使用 ZXID 的十六进制表示来作为文件名后缀，该后缀标识了本次数据快照开始时刻的服务器最新 ZXID。 可以使用 org.apache.zookeeper.server.SnapshotFormatter 将快照数据文件转换成可视化的数据内容。 3.1 数据快照FileSnap 负责维护快照数据对外的接口，包括快照数据的写入和读取等。针对客户端的每一次事务操作，ZooKeeper 都会将它们记录到事务日志中，同时也会将数据变更应用到内存数据库中。ZooKeeper 在进行若干次事务日志记录之后，将内存数据库的全量数据 Dump 到本地文件中，这个过程就是数据快照。 3.1.1 确定是否需要进行数据快照每进行一次事务日志记录之后，ZooKeeper 都会检测当前是否需要进行数据快照。理论上进行 snapCount 次事务操作后就会开始数据快照，但是考虑到数据快照对 ZooKeeper 所在机器的整体性能的影响，需要尽量避免 ZooKeeper 集群中的所有机器在同一时刻进行数据快照。因此 ZooKeeper 在具体的实现中，并不是严格地按照这个策略执行的，而是采取 “过半随机” 策略，即符合如下条件就进行数据快照：$$logCount&gt; (snapCount / 2 + randRoll)$$其中 logCount 代表了当前已经记录的事务日志数量，randRoll 为 1~snapCount/2 之间的随机数，因此上面的条件就相当于：如果我们配置的 snapCount 值为默认的 100000，那么 ZooKeeper 会在 50000~100000 次事务日志记录后进行一次数据快照。 3.1.2 切换事务日志文件满足上述条件之后，ZooKeeper 就要开始进行数据快照了。首先是进行事务日志文件的切换。所谓的事务日志文件切换是指当前的事务日志已经 “写满”（已经写入了 snapCount 个事务日志），需要重新创建一个新的事务日志。 3.1.3 创建数据快照异步线程为了保证数据快照过程不影响 ZooKeeper 的主流程，这里需要创建一个单独的异步线程来进行数据快照。 3.1.4 获取全最数据和会话信息数据快照本质上就是将内存中的所有数据节点信息（DataTree）和会话信息保存到本地磁盘中去。因此这里会先从 ZKDatabase 中获取到 DataTree 和会话信息。 3.1.5 生成快照数据文件名在这一步中， ZooKeeper 会根据当前已提交的最大 ZXID 来生成数据快照文件名。 3.1.6 数椐序列化接下来就开始真正的数据序列化了。在序列化时，首先会序列化文件头信息，这里的文件头和事务日志中的一致，同样也包含了魔数、版本号和 dbid 信息。然后再对会话信息和 DataTree 分別进行序列化，同时生成一个 Checksum，—并写入快照数据文件中去。 4. 初始化4.1 初始化流程4.1.1 初始化FileTxnSnapLogFileTxnSnapLog 是 ZooKeeper 事务日志和快照数据访问层，用于衔接上层业务与底层数据存储。底层数据包含了事务日志和快照数据两部分，因此 FileTxnSnapLog 内部又分为 FileTxnLog 和 FileSnap 的初始化，分别代表事务日志管理器和快找数据管理器的初始化。 4.1.2 初始化 ZKDatabase在初始化过程中，首先会构建一个初始化的 DataTree，同时将 FileTxnSnapLog 交付 ZKDatabase，以便内存数据库能够对事务日志和快照数据进行访问。在 ZKDatabase 初始化的时候，DataTree 也会进行相应的初始化工作，如创建一些 ZooKeeper 的默认节点，包括 /、/zookeeper、/zookeeper/quota 三个节点的创建。 除了 ZooKeeper 的数据节点，在 ZKDatabase 的初始化阶段还会创建一个用于保存所有客户端会话超时时间的记录器：sessionWithTimeouts。 4.1.3 创建 PlayBackListenerPlayBackListener 监听器主要用来接收事务应用过程中的回调。在 ZooKeeper 数据恢复后期，会有一个事务订正的过程，在这个过程中，会回调 PlayBackListener 来进行对应的数据订正。 4.1.4 处理快照文件此时，ZooKeeper 可以开始从磁盘中恢复数据了，首先从快照文件开始加载。 4.1.5 获取最新的 100 个快照文件获取最新的至多 100 个快照文件。 4.1.6 解析快照文件ZooKeeper 逐个对快照文件进行解析，此时需要对其进行反序列化，生成 DataTree 和 sessionsWithTimeouts，同时还会进行文件的 checksum 校验以确定快照文件的正确性。 虽然获取到的是至多 100 个快照文件，但其实在这里的逐个解析过程中，如果正确性校验通过的话，那么通常只会解析最新的那个快照文件。换句话说，只有当最新的快照文件不可用的时候，才会逐个进行解析，直到将这 100 个文件全部解析完。如果将获取到的所有快照文件都解析完后还是无法成功恢复一个完整的 DataTree 和 sessionWithTimeouts，则认为无法从磁盘中加载数据，服务器启动失败。 4.1.7 获取最新的 ZXID此时根据快照文件的文件名就可以解析出一个最新的 ZXID：zxid_for_snap，该 ZXID 代表了 ZooKeeper 开始进行数据快照的时刻。 4.1.8 处理事务日志此时 ZooKeeper 服务器内存中已经有了一份近似全量的数据，现在开始通过事务日志来更新增量数据。 4.1.9 获取所有 zxid_for_snap 之后提交的事务从事务日志中获取所有 ZXID 比 zxid_for_snap 大的事务操作。 4.1.10 事务应用获取到所有 ZXID 大于 zxid_for_snap 的事务后，将其逐个应用到之前基于快照数据文件恢复出来的 DataTree 和 sessionsWithTimeouts 中去。每当有一个事务被应用到内存数据库中去后，ZooKeeper 同时会回调 PlayBackListener，将这一事务操作记录转换成 Proposal，并保存到 ZKDatabase 的 committedLog 中，以便 Follower 进行快速同步。 4.1.11 再次获取最新的 ZXID待所有的事务都被完整地应用到内存数据库中之后，基本上也就完成了数据的初始化过程，此时再次获取一个 ZXID，用来标识上次服务器正常运行时提交的最大事务 ID。 4.1.12 校验 epoch完成数据加载后，ZooKeeper 会从最新 ZXID 中解析出事务处理的 Leader 周期：epochOfZxid。同时也会从磁盘的 currentEpoch 和 acceptedEpoch 文件中读取上次记录的最新的 epoch 值，进行校验。 4.2 PlayBackListenerPlayBackListener 是一个事务应用监听器，用于在事务应用过程中的回调：每当成功将一条事务日志应用到内存数据库中后，就会调用这个监听器。其接口定义非常简单，只有一个方法： 123public interface PlayBackListener &#123; void onTxnLoaded(TxnHeader hdr, Record rec);&#125; 用于对单条事务进行处理。在完成 ZKDatabase 的初始化后，ZooKeeper 会立即创建一个 PlayBackListener 监听器，并将其置于 FileTxnSnapLog 。 5. 数据同步5.1 获取 Learner 状态在注册 Learner 的最后阶段，Learner 服务器会发送给 Leader 服务器一个 ACKEPOCH 数据包，Leader 会从这个数据包中解析出该 Learner 的 currentEpoch 和 lastZxid。然后 Learner 调用 org.apache.zookeeper.server.quorum.Learner#syncWithLeader 等待同步开始。 5.2 数据同步初始化在开始数据同步之前，Leader 服务器会进行数据同步初始化，首先会从 ZooKeeper 的内存数据库中提取出事务请求对应的提议缓存队列，同时完成对以下三个 ZXID 值的初始化。 peerLastZxid：该 Learner 服务器最后处理的 ZXID。 minCommittedLog：Leader 服务器提议缓存队列 commitedLog 中的最小 ZXID。 maxCommittedLog：Leader 服务器提议缓存队列 commitedLog 中的最大 ZXID。 ZooKeeper 集群数据同步通常分为四类，分别是直接差异化同步（DIFF 同步）、先回滚再差异化同步（TRUNC + DIFF 同步）、仅回滚同步（TRUNC 同步）、全量同步（SNAP 同步）。在初始化阶段，Leader 服务器会优先以全量同步方式来同步数据。同时，会根据 Leader 和 Learner 之间的数据差异情况来决定最终的数据同步方式。 5.3 同步模式5.3.1 直接差异化同步（DIFF 同步）场景：peerLastZxid 介于 minCommittedLog 和 maxCommittedLog 之间。 Leader 服务器会首先向这个 Learner 发送一个 DIFF 指令，用于通知 Learner “进入差异化数据同步阶段，Leader 服务器即将把一些 Proposal 同步给自己”。在实际 Proposal 同步过程中，针对每个 Proposal，Leader 服务器都会通过发送两个数据包来完成，分别是 PROPOSAL 内容数据包和 COMMIT 指令数据包——这和 ZooKeeper 运行时 Leader 和 Follower 之间的事务提交过程是一致的。Leader 会将 PROPOSAL 数据包和 COMMIT 指令包暂时先放入 queuedPackets 队列中。 5.3.2 先回滚再差异化同步（TRUNC + DIFF 同步）场景：peerLastZxid 介于 minCommittedLog 和 maxCommittedLog 之间，但 Leader 发现某个 Learner 包含了一条自己没有的事务记录。 对于这个特殊场景，就使用先回滚再差异化同步（TRUNC + DIFF 同步）的方式。Leader 通过 TRUNC 指令让该 Learner 进行事务回滚，回滚到 Leader 服务器上存在的，同时也是最接近于 peerLastzxid 的 ZXID ，随后发送余下的差异数据。 5.3.3 仅回滚同步（TRUNC 同步）场景：peerLastzxid 大于 maxCommittedLog。 这种场景其实就是上述先回滚再差异化同步的简化模式，Leader 会要求 Learner 回滚到 ZXID 值为 maxCommittedLog 对应的事务操作。 5.3.4 全量同步（SNAP 同步） 场景1：peerLastZxid 小于 minCommittedLog。 场景2：Leader 服务器上没有提议缓存队列，peerLastZxid 不等于 lastProcessedZxid（Leader 服务器数据恢复后得到的最大 ZXID） 上述这两个场景非常类似，在这两种场景下, Leader服务器都无法直接使用提议缓存队列和 Learner进行数据同步，因此只能进行全量同步（SNAP 同步）。 所谓全量同步就是 Leader 服务器将本机上的全量内存数据都同步给 Learner。Leader 服务器将会向 Learner发送一个 SNAP 指令，通知 Learner 即将进行全量数据同步。随后， Leader 会从内存数据库中获取到全量的数据节点和会话超时时间记录器，将它们序列化后传输给 Learner 。Learner 服务器接收到该全最数据后，会对其反序列化后载入到内存数据库中。 5.4 后续处理在上面的步骤之后，Leader 已经完成了同步模式的选择。接下来： Leader 将 Learner 加入到 forwardingFollowers 或 observingLearners 队列中。 Leader 将 NEWLEADER 指令添加到 queuedPackets 队列中。 Leader 将选出的同步模式发送给 Learner，其中包含了一个标志 ZXID： 对于 DIFF 同步，该 ZXID 为 maxCommittedLog。 对于 TRUNC 同步，该 ZXID 为 Learner 需要回滚到的那个 ZXID。 对于 SNAP 同步，该 ZXID 为 DataTree 的最新事务 ZXID（这里不能设置为 maxCommittedLog，因为 commitedLog 队列可能为空）。此时，Leader 还会马上将全量数据序列化后发送给 Learner。 然后，在一个新线程中，发送 queuedPackets 队列中的数据，包括 DIFF 和 DIFF + TRUNC 模式下要用到的差异化数据，以及最后的 NEWLEADER 指令。 Leader 和各个 LearnerHandler 在 org.apache.zookeeper.server.quorum.Leader#waitForNewLeaderAck 方法处同步等待半数以上 PARTICIPANT 对 NEWLEADER 指令做出响应。 对于 Learner 而言，在同步数据之后，还会接收到来自 Leader 的 NEWLEADER 指令，此时 Learner 就会反馈给 Leader —个 ACK 消息，表明自己确实完成了对提议缓存队列中 Proposal 的同步。 Leader 在接收到来 Learner 的这个 ACK 消息以后，就认为当前 Learner 已经完成数据同步，同时进入 “过半策略” 等待阶段 —— Leader 会和其他 Learner 服务器进行上述同样的数据同步流程，直到集群中有过半的 PARTICIPANT 机器响应了 Leader 这个 NEWLEADER 消息。注意这里不考虑 Observer。 一但满足 “过半策略” 后，Leader 服务器就会向所有已经完成数据同步的 Learner 发送一个 UPTODATE 指令，用来通知 Learner 已经完成了数据同步，同时集群中已经有过半机器完成了数据同步，集群已经具备了对外服务的能力了。 Learner 在接收到这个来自 Leader 的 UPTODATE 指令后，会终止数据同步流程，然后向 Leader 再次反馈一个 ACK 消息。 org.apache.zookeeper.server.quorum.Leader#waitForNewLeaderAck 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Process NEWLEADER ack of a given sid and wait until the leader receives * sufficient acks. * * @param sid * @param learnerType * @throws InterruptedException */public void waitForNewLeaderAck(long sid, long zxid, LearnerType learnerType) throws InterruptedException &#123; synchronized (newLeaderProposal.ackSet) &#123; if (quorumFormed) &#123; return; &#125; long currentZxid = newLeaderProposal.packet.getZxid(); if (zxid != currentZxid) &#123; LOG.error("NEWLEADER ACK from sid: " + sid + " is from a different epoch - current 0x" + Long.toHexString(currentZxid) + " receieved 0x" + Long.toHexString(zxid)); return; &#125; if (learnerType == LearnerType.PARTICIPANT) &#123; newLeaderProposal.ackSet.add(sid); &#125; if (self.getQuorumVerifier().containsQuorum( newLeaderProposal.ackSet)) &#123; quorumFormed = true; newLeaderProposal.ackSet.notifyAll(); &#125; else &#123; long start = Time.currentElapsedTime(); long cur = start; long end = start + self.getInitLimit() * self.getTickTime(); while (!quorumFormed &amp;&amp; cur &lt; end) &#123; newLeaderProposal.ackSet.wait(end - cur); cur = Time.currentElapsedTime(); &#125; if (!quorumFormed) &#123; throw new InterruptedException("Timeout while waiting for NEWLEADER to be acked by quorum"); &#125; &#125; &#125;&#125; 6. 自问自答6.1 Observer 是否不接收 PROPOSAL 和 COMMIT 消息？在同步阶段，如果 Learner 适用于 DIFF 同步，则 Leader 会把差量数据以 PROPOSAL 和 COMMIT 消息对的形式发送给 Learner，无论该 Learner 是 Follower 还是 Observer。 6.2 每个事务日志文件一定是 64M 大吗？不一定。ZooKeeper 只会在需要进行数据快照时切换事务日志文件。假定 snapCount 为默认的 100000，且 randRoll 为50000，平均每条事务记录大小为 1KB。那么，在新的一次数据快照之前，事务日志文件已经记录了 $1KB * (100000 / 2 + 50000)=100MB$ 的数据，当前事务日志文件扩展到了 128MB。那么当执行数据快照、创建新的事务日志文件后，上一个事务日志文件大小就为 128MB。可见，事务日志文件的大小，归根结底取决于平均事务记录的大小与 randRoll 的值。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：请求处理]]></title>
    <url>%2F2017%2F12%2F19%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. 会话创建请求ZooKeeper 服务端对于会话创建的处理，大体可以分为请求接收、会话创建、预处理、事务处理、事务应用和会话响应 6 大环节，其大体流程如图。 1.1 请求接收1.1.1 I/O 层接收来自客户端的请求在 ZooKeeper 中，NIOServerCnxnFactory 会在运行过程中为客户端连接创建对应的 NIOServerCnxn 实例，客户端与服务端的所有通信都是由NIOServerCnxn 负责的 —— 其负责统一接收来自客户端的所有请求，并将请求内容从底层网络 I/O 中完整地读取出来，一个客户端连接就对应了一个 NIOServerCnxn 的实例。注意刚创建时 NIOServerCnxn 实例的 initialized 字段为 false。 org.apache.zookeeper.server.NIOServerCnxnFactory#run 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public void run() &#123; while (!ss.socket().isClosed()) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; selected; synchronized (this) &#123; selected = selector.selectedKeys(); &#125; ArrayList&lt;SelectionKey&gt; selectedList = new ArrayList&lt;SelectionKey&gt;( selected); Collections.shuffle(selectedList); for (SelectionKey k : selectedList) &#123; if ((k.readyOps() &amp; SelectionKey.OP_ACCEPT) != 0) &#123; SocketChannel sc = ((ServerSocketChannel) k .channel()).accept(); InetAddress ia = sc.socket().getInetAddress(); int cnxncount = getClientCnxnCount(ia); if (maxClientCnxns &gt; 0 &amp;&amp; cnxncount &gt;= maxClientCnxns)&#123; LOG.warn("Too many connections from " + ia + " - max is " + maxClientCnxns ); sc.close(); &#125; else &#123; LOG.info("Accepted socket connection from " + sc.socket().getRemoteSocketAddress()); sc.configureBlocking(false); SelectionKey sk = sc.register(selector, SelectionKey.OP_READ); NIOServerCnxn cnxn = createConnection(sc, sk); sk.attach(cnxn); addCnxn(cnxn); &#125; &#125; else if ((k.readyOps() &amp; (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) &#123; NIOServerCnxn c = (NIOServerCnxn) k.attachment(); c.doIO(k); &#125; else &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug("Unexpected ops in select " + k.readyOps()); &#125; &#125; &#125; selected.clear(); &#125; catch (RuntimeException e) &#123; LOG.warn("Ignoring unexpected runtime exception", e); &#125; catch (Exception e) &#123; LOG.warn("Ignoring exception", e); &#125; &#125; closeAll(); LOG.info("NIOServerCnxn factory exited run method");&#125; 1.1.2 判断是否是客户端会话创建请求当底层 I/O 有数据可读时，NIOServerCnxnFactory 找到绑定的 NIOServerCnxn 实例，调用其 doIO 方法。这里会做一个判断，若 initialized 字段为 false，则这一定是客户端的第一个请求会话创建请求。 org.apache.zookeeper.server.NIOServerCnxn#readPayload 123456789101112131415161718192021222324/** Read the request payload (everything following the length prefix) */private void readPayload() throws IOException, InterruptedException &#123; if (incomingBuffer.remaining() != 0) &#123; // have we read length bytes? int rc = sock.read(incomingBuffer); // sock is non-blocking, so ok if (rc &lt; 0) &#123; throw new EndOfStreamException( "Unable to read additional data from client sessionid 0x" + Long.toHexString(sessionId) + ", likely client has closed socket"); &#125; &#125; if (incomingBuffer.remaining() == 0) &#123; // have we read length bytes? packetReceived(); incomingBuffer.flip(); if (!initialized) &#123; readConnectRequest(); &#125; else &#123; readRequest(); &#125; lenBuffer.clear(); incomingBuffer = lenBuffer; &#125;&#125; 1.1.3 反序列化 ConnectRequest 请求一旦确定客户端请求是会话创建请求，那么服务端就可以对其进行反序列化，并生成一个 ConnectRequest 请求实体。 org.apache.zookeeper.server.NIOServerCnxn#readConnectRequest 1234567private void readConnectRequest() throws IOException, InterruptedException &#123; if (!isZKServerRunning()) &#123; throw new IOException("ZooKeeperServer not running"); &#125; zkServer.processConnectRequest(this, incomingBuffer); initialized = true;&#125; org.apache.zookeeper.server.ZooKeeperServer#processConnectRequest 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public void processConnectRequest(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException &#123; BinaryInputArchive bia = BinaryInputArchive.getArchive(new ByteBufferInputStream(incomingBuffer)); ConnectRequest connReq = new ConnectRequest(); connReq.deserialize(bia, "connect"); boolean readOnly = false; try &#123; readOnly = bia.readBool("readOnly"); cnxn.isOldClient = false; &#125; catch (IOException e) &#123; // this is ok -- just a packet from an old client which // doesn't contain readOnly field LOG.warn("Connection request from old client " + cnxn.getRemoteSocketAddress() + "; will be dropped if server is in r-o mode"); &#125; if (readOnly == false &amp;&amp; this instanceof ReadOnlyZooKeeperServer) &#123; String msg = "Refusing session request for not-read-only client " + cnxn.getRemoteSocketAddress(); LOG.info(msg); throw new CloseRequestException(msg); &#125; if (connReq.getLastZxidSeen() &gt; zkDb.dataTree.lastProcessedZxid) &#123; String msg = "Refusing session request for client " + cnxn.getRemoteSocketAddress() + " as it has seen zxid 0x" + Long.toHexString(connReq.getLastZxidSeen()) + " our last zxid is 0x" + Long.toHexString(getZKDatabase().getDataTreeLastProcessedZxid()) + " client must try another server"; LOG.info(msg); throw new CloseRequestException(msg); &#125; int sessionTimeout = connReq.getTimeOut(); byte passwd[] = connReq.getPasswd(); int minSessionTimeout = getMinSessionTimeout(); if (sessionTimeout &lt; minSessionTimeout) &#123; sessionTimeout = minSessionTimeout; &#125; int maxSessionTimeout = getMaxSessionTimeout(); if (sessionTimeout &gt; maxSessionTimeout) &#123; sessionTimeout = maxSessionTimeout; &#125; cnxn.setSessionTimeout(sessionTimeout); // We don't want to receive any packets until we are sure that the // session is setup cnxn.disableRecv(); long sessionId = connReq.getSessionId(); if (sessionId != 0) &#123; long clientSessionId = connReq.getSessionId(); serverCnxnFactory.closeSession(sessionId); cnxn.setSessionId(sessionId); reopenSession(cnxn, sessionId, passwd, sessionTimeout); &#125; else &#123; createSession(cnxn, passwd, sessionTimeout); &#125;&#125; 1.1.4 判断是否 ReadOnly 客户端如果当前 ZooKeeper 客户端是以 ReadOnly 模式启动的，那么所有来自非 ReadOnly 客户端的请求将无法被处理。因此，服务端需要先检查其是否是 ReadOnly 客户端，并以此来决定是否接受该会话创建请求。 1.1.5 检查客户端 ZXID在正常情况下，同一个 ZooKeeper 集群中，服务端的 ZXID 必定大于客户端的 ZXID，因此如果发现客户端的 ZXID 大于服务端的 ZXID，那么服务端不接受该客户端的会话创建请求。 1.1.6 协商 sessionTimeout客户端在构造 ZooKeeper 实例时，会有一个 sessionTimeout 参数用于指定会话的超时时间。客户端向服务器发送这个超时时间后，服务器会根据自己的超时时间限制最终确定该会话的超时时间。 默认情况下，ZooKeeper 服务器对超时时间的限制介于 2 个 tickTime 到 20 个 tickTime 之间。 1.1.7 判断是否需要重新创建会话服务端根据客户端请求中是否包含 sessionID 来判断该客户端是否需要重新创建会话。如果客户端请求中已经包含了 sessionID，那么就认为该客户端正在进行会话重连。这种情况下，服务端只需要重新打开这个会话，否则需要重新创建。 1.2 会话创建org.apache.zookeeper.server.ZooKeeperServer#createSession 12345678910long createSession(ServerCnxn cnxn, byte passwd[], int timeout) &#123; long sessionId = sessionTracker.createSession(timeout); Random r = new Random(sessionId ^ superSecret); r.nextBytes(passwd); ByteBuffer to = ByteBuffer.allocate(4); to.putInt(timeout); cnxn.setSessionId(sessionId); submitRequest(cnxn, sessionId, OpCode.createSession, 0, to, null); return sessionId;&#125; org.apache.zookeeper.server.SessionTrackerImpl#createSession 1234synchronized public long createSession(int sessionTimeout) &#123; addSession(nextSessionId, sessionTimeout); return nextSessionId++;&#125; 1.2.1 为客户端生成 sessionId在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionId。 分配方式是通过 SessionTracker 对基准 sessionId 做自增操作。无论客户端连的是哪台服务器，生成的 sessionId 都是全局唯一的。 1.2.2 注册会话在会话创建初期，会将客户端会话的相关信息保存到 SessionTracker 的 sessionWithTimeout 和 sessionById 中。 org.apache.zookeeper.server.SessionTrackerImpl#addSession 12345678synchronized public void addSession(long id, int sessionTimeout) &#123; sessionsWithTimeout.put(id, sessionTimeout); if (sessionsById.get(id) == null) &#123; SessionImpl s = new SessionImpl(id, sessionTimeout, 0); sessionsById.put(id, s); &#125; touchSession(id, sessionTimeout);&#125; 1.2.3 激活会话为会话安排一个区块，方便会话清理程序能够快速高效地进行会话清理。 org.apache.zookeeper.server.SessionTrackerImpl#touchSession 123456789101112131415161718192021222324synchronized public boolean touchSession(long sessionId, int timeout) &#123; SessionImpl s = sessionsById.get(sessionId); // Return false, if the session doesn't exists or marked as closing if (s == null || s.isClosing()) &#123; return false; &#125; long expireTime = roundToInterval(Time.currentElapsedTime() + timeout); if (s.tickTime &gt;= expireTime) &#123; // Nothing needs to be done return true; &#125; SessionSet set = sessionSets.get(s.tickTime); if (set != null) &#123; set.sessions.remove(s); &#125; s.tickTime = expireTime; set = sessionSets.get(s.tickTime); if (set == null) &#123; set = new SessionSet(); sessionSets.put(expireTime, set); &#125; set.sessions.add(s); return true;&#125; 1.2.4 生成会话密钥服务端在创建一个客户端会话时，会同时为客户端生成一个会话密码，连同 sessionId 一起发送给客户端，作为会话在集群中不同机器间转移的凭证。 1.2.5 将请求交给 firstProcessororg.apache.zookeeper.server.ZooKeeperServer#submitRequest(org.apache.zookeeper.server.ServerCnxn, long, int, int, java.nio.ByteBuffer, java.util.List&lt;org.apache.zookeeper.data.Id&gt;) 12345private void submitRequest(ServerCnxn cnxn, long sessionId, int type, int xid, ByteBuffer bb, List&lt;Id&gt; authInfo) &#123; Request si = new Request(cnxn, sessionId, xid, type, bb, authInfo); submitRequest(si);&#125; 这里的 type 为 createSession。 org.apache.zookeeper.server.ZooKeeperServer#submitRequest(org.apache.zookeeper.server.Request) 12345678910111213141516171819202122232425262728293031323334public void submitRequest(Request si) &#123; if (firstProcessor == null) &#123; synchronized (this) &#123; try &#123; // Since all requests are passed to the request // processor it should wait for setting up the request // processor chain. The state will be updated to RUNNING // after the setup. while (state == State.INITIAL) &#123; wait(1000); &#125; &#125; catch (InterruptedException e) &#123; LOG.warn("Unexpected interruption", e); &#125; if (firstProcessor == null || state != State.RUNNING) &#123; throw new RuntimeException("Not started"); &#125; &#125; &#125; try &#123; touch(si.cnxn); boolean validpacket = Request.isValid(si.type); if (validpacket) &#123; firstProcessor.processRequest(si); if (si.cnxn != null) &#123; incInProcess(); &#125; &#125; else &#123; LOG.warn("Received packet at server of unknown type " + si.type); new UnimplementedRequestProcessor().processRequest(si); &#125; &#125; // ...&#125; firstProcessor 是一个 RequestProcessor 类型的变量。在提交给 firstProcessor 处理器之前，Zookeeper 会根据该请求所属的会话，进行一次激活会话操作，以确保当前会话处于激活状态，完成会话激活后，则提交请求至 firstProcessor 处理器，放入待处理请求队列中。 到这里 createSession 方法结束，后续流程由 firstProcessor 线程异步处理。 在会话创建请求的处理中，无论客户端连接的是 Leader 还是 Learner，到目前为止的处理流程都是相同的。接下来的差别在于： 对于 Leader 服务器，其 firstProcessor 的实现为 PrepRequestProcessor。 对于 Follower 服务器，其 firstProcessor 的实现为 FollowerRequestProcessor。 对于 Observer 服务器，其 firstProcessor 的实现为 ObserverRequestProcessor。 FollowerRequestProcessor 和 ObserverRequestProcessor会将事务请求以 REQUEST 消息的形式转发给 Leader 处理。Leader 的 LearnerHandler 在接收到这个消息后，会解析出客户端的原始请求，然后提交到自己的请求处理链中开始进行事务请求的处理。 1.3 事务预处理1.3.1 异步处理请求org.apache.zookeeper.server.PrepRequestProcessor#run 1234567891011121314151617@Overridepublic void run() &#123; try &#123; while (true) &#123; Request request = submittedRequests.take(); long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &#123; traceMask = ZooTrace.CLIENT_PING_TRACE_MASK; &#125; if (Request.requestOfDeath == request) &#123; break; &#125; pRequest(request); &#125; &#125; // ...&#125; org.apache.zookeeper.server.PrepRequestProcessor#pRequest 方法根据请求的类型，将事务类请求交由 org.apache.zookeeper.server.PrepRequestProcessor#pRequest2Txn 方法处理。对一些类型的事务请求，还要生成变更记录放入 outstandingChanges 队列中。 123456789101112131415// ... request.hdr = new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), type); switch (type) &#123; // ... case OpCode.createSession: request.request.rewind(); int to = request.request.getInt(); request.txn = new CreateSessionTxn(to); request.request.rewind(); zks.sessionTracker.addSession(request.sessionId, to); zks.setOwner(request.sessionId, request.getOwner()); break; // ...&#125;// ... 1.3.2 创建请求事务头对于事务请求，ZooKeeper 首先会为其创建请求事务头。请求事务头包含了一个事务请求最基本的一些信息，包括 sessionId、ZXID、CXID（客户端的操作序列号） 和请求类型等。 1234567public class TxnHeader implements Record &#123; private long clientId; private int cxid; private long zxid; private long time; private int type;&#125; 1.3.3 创建请求事务体对于事务请求，ZooKeeper 还会为其创建请求事务体。对应到会话创建请求，对应的事务体实现为 CreateSessionTxn。 1.3.4 注册与激活会话此处进行会话注册与激活的目的是处理由非 Leader 服务器转发过来的会话创建请求，在这种情况下，其尚未在 Leader 的 SessionTracker 中进行会话的注册，因此需要在此处进行一次注册与激活。 1.4 事务处理在 pRequest 方法最后，会将请求提交给 RequestProcessor 类型变量 nextProcessor 处理。对于 Leader，这个变量的实现类为 ProposalRequestProcessor。 ProposalRequestProcessor 顾名思义是一个与提案相关的处理器。所谓的提案，是 ZooKeeper 中针对事务请求所展开的一个投票流程中对事务操作的包装。从 ProposalRequestProcessor 处理器开始，请求的处理将会同时进入三个子处理流程，分别是 Sync 流程、Proposal 流程和 Commit 流程。 org.apache.zookeeper.server.quorum.ProposalRequestProcessor#processRequest 123456789101112131415161718192021222324public void processRequest(Request request) throws RequestProcessorException &#123; /* In the following IF-THEN-ELSE block, we process syncs on the leader. * If the sync is coming from a follower, then the follower * handler adds it to syncHandler. Otherwise, if it is a client of * the leader that issued the sync command, then syncHandler won't * contain the handler. In this case, we add it to syncHandler, and * call processRequest on the next processor. */ if(request instanceof LearnerSyncRequest)&#123; zks.getLeader().processSync((LearnerSyncRequest)request); &#125; else &#123; nextProcessor.processRequest(request); if (request.hdr != null) &#123; // We need to sync and get consensus on any transactions try &#123; zks.getLeader().propose(request); &#125; catch (XidRolloverException e) &#123; throw new RequestProcessorException(e.getMessage(), e); &#125; syncProcessor.processRequest(request); &#125; &#125;&#125; 对 Leader 而言： ProposalRequestProcessor 会首先将请求提交给 nextProcessor，其具体实现是 CommitProcessor。请求被放入 CommitProcessor 的 队列 queuedRequests，等待 CommitProcessor 的线程异步处理（即等待投票完成），此即 Commit 流程。 调用 Leader 的 propose 方法，生成 Proposal 并广播给 Follower，统计 Follower 返回的投票结果并通知各个 Learner 最终提交事务，此即 Proposal 流程。这个流程会在完成后唤醒 Commit 流程。 由 SyncRequestProcessor 进行事务日志的记录，并调用 AckRequestProcessor 处理 Leader 自己的投票，此即 Sync 流程。这个流程会流向 Proposal 流程。 当 Leader 对非事务请求的处理流程到达此处时，由于不包含请求事务头，因此仅仅只是把请求提交给 CommitProcessor。 1.4.1 Proposal 流程org.apache.zookeeper.server.quorum.Leader#propose 12345678910111213141516171819202122232425262728293031323334353637383940/** * create a proposal and send it out to all the members * * @param request * @return the proposal that is queued to send to all the members */public Proposal propose(Request request) throws XidRolloverException &#123; /** * Address the rollover issue. All lower 32bits set indicate a new leader * election. Force a re-election instead. See ZOOKEEPER-1277 */ if ((request.zxid &amp; 0xffffffffL) == 0xffffffffL) &#123; String msg = "zxid lower 32 bits have rolled over, forcing re-election, and therefore new epoch start"; shutdown(msg); throw new XidRolloverException(msg); &#125; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); try &#123; request.hdr.serialize(boa, "hdr"); if (request.txn != null) &#123; request.txn.serialize(boa, "txn"); &#125; baos.close(); &#125; catch (IOException e) &#123; LOG.warn("This really should be impossible", e); &#125; QuorumPacket pp = new QuorumPacket(Leader.PROPOSAL, request.zxid, baos.toByteArray(), null); Proposal p = new Proposal(); p.packet = pp; p.request = request; synchronized (this) &#123; lastProposed = p.packet.getZxid(); outstandingProposals.put(lastProposed, p); sendPacket(pp); &#125; return p;&#125; 1.4.1.1 发起投票如果当前请求是事务请求，那么 Leader 服务器就会发起一轮事务投票。在发起事务投票之前，会首先检查当前服务器的 ZXID 是否可用。 1.4.1.2 生成提案 Proposal若 ZXID 可用，ZooKeeper 会将之前创建的请求头和事务体，以及 ZXID 和请求本身序列化到 Proposal 对象中 —— 此 Proposal 对象就是一个提案，即针对 ZooKeeper 服务器状态的一次变更申请。 1.4.1.3 广播提案更新 lastProposed，以 ZXID 作为 key 将该提案放入投票箱 outstandingProposals 中，同时将该提案广播给所有 Follower。 org.apache.zookeeper.server.quorum.Leader#sendPacket 1234567void sendPacket(QuorumPacket qp) &#123; synchronized (forwardingFollowers) &#123; for (LearnerHandler f : forwardingFollowers) &#123; f.queuePacket(qp); &#125; &#125;&#125; 1.4.1.4 Follower 接收提案（Follower Sync 流程）Follower 启动后，会通过 followLeader 方法不断从与 Leader 之间的连接中读取数据并作相应处理。 org.apache.zookeeper.server.quorum.Follower#processPacket 1234567891011121314151617181920212223242526272829303132333435363738/** * Examine the packet received in qp and dispatch based on its contents. * @param qp * @throws IOException */protected void processPacket(QuorumPacket qp) throws IOException&#123; switch (qp.getType()) &#123; case Leader.PING: ping(qp); break; case Leader.PROPOSAL: TxnHeader hdr = new TxnHeader(); Record txn = SerializeUtils.deserializeTxn(qp.getData(), hdr); if (hdr.getZxid() != lastQueued + 1) &#123; LOG.warn("Got zxid 0x" + Long.toHexString(hdr.getZxid()) + " expected 0x" + Long.toHexString(lastQueued + 1)); &#125; lastQueued = hdr.getZxid(); fzk.logRequest(hdr, txn); break; case Leader.COMMIT: fzk.commit(qp.getZxid()); break; case Leader.UPTODATE: LOG.error("Received an UPTODATE message after Follower started"); break; case Leader.REVALIDATE: revalidate(qp); break; case Leader.SYNC: fzk.sync(); break; default: LOG.error("Invalid packet type: &#123;&#125; received by Observer", qp.getType()); &#125;&#125; org.apache.zookeeper.server.quorum.FollowerZooKeeperServer#logRequest 1234567891011public void logRequest(TxnHeader hdr, Record txn) &#123; Request request = new Request(null, hdr.getClientId(), hdr.getCxid(), hdr.getType(), null, null); request.hdr = hdr; request.txn = txn; request.zxid = hdr.getZxid(); if ((request.zxid &amp; 0xffffffffL) != 0) &#123; pendingTxns.add(request); &#125; syncProcessor.processRequest(request);&#125; 到这里，Follower 将这个事务记录到 pendingTxns 中，并将事务请求提交给 syncProcessor 作异步处理，在 Follower 的 Sync 流程中对提案做响应并向 Leader 提交 ACK 信息。 1.4.1.5 Leader 统计投票Leader 的 LearnerHandler 会接收来自各个 Follower 的 ACK 信息，并调用 Leader 的 org.apache.zookeeper.server.quorum.Leader#processAck 对投票做处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Keep a count of acks that are received by the leader for a particular proposal * * @param zxid the zxid of the proposal sent out * @param followerAddr */synchronized public void processAck(long sid, long zxid, SocketAddress followerAddr) &#123; if ((zxid &amp; 0xffffffffL) == 0) &#123; return; &#125; if (outstandingProposals.size() == 0) &#123; return; &#125; if (lastCommitted &gt;= zxid) &#123; // The proposal has already been committed return; &#125; Proposal p = outstandingProposals.get(zxid); if (p == null) &#123; LOG.warn("Trying to commit future proposal: zxid 0x&#123;&#125; from &#123;&#125;", Long.toHexString(zxid), followerAddr); return; &#125; p.ackSet.add(sid); if (self.getQuorumVerifier().containsQuorum(p.ackSet))&#123; if (zxid != lastCommitted+1) &#123; LOG.warn("Commiting zxid 0x&#123;&#125; from &#123;&#125; not first!", Long.toHexString(zxid), followerAddr); LOG.warn("First is 0x&#123;&#125;", Long.toHexString(lastCommitted + 1)); &#125; outstandingProposals.remove(zxid); if (p.request != null) &#123; toBeApplied.add(p); &#125; if (p.request == null) &#123; LOG.warn("Going to commmit null request for proposal: &#123;&#125;", p); &#125; commit(zxid); inform(p); zk.commitProcessor.commit(p.request); if(pendingSyncs.containsKey(zxid))&#123; for(LearnerSyncRequest r: pendingSyncs.remove(zxid)) &#123; sendSync(r); &#125; &#125; &#125;&#125; 当提案获得了集群中过半 PARTICIPANT 的投票，那么就认为该提案通过。 1.4.1.6 处理通过的提案 将提案的 ZXID 从 outstandingProposals 中移除。 将提案添加到 toBeApplied 队列。 向所有 Follower 发送 COMMIT 消息。由于 Follower 已经保存了所有关于该提案的信息，这里只需向其发送 ZXID 即可。 向所有 Observer 发送 INFORM 消息。由于 Observer 并未参与之前的投票阶段，因此 Observer 服务器并未保存任何关于该提案的信息。INFORM 消息中会包含当前提案的内容。 向 CommitProcessor 提交这个被通过的事务，进入 Leader 的 Commit 流程。 1.4.2 Sync 流程Leader 在生成事务提案和 Follower 接收到事务提案时，都会将提案放入 SyncRequestProcessor 的提案队列 queuedRequests，等待 SyncRequestProcessor 线程异步处理。 SyncRequestProcessor 处理器会记录事务日志，并提交给 nextProcessor 做后续处理。但是，Leader 和 Follower 的 SyncRequestProcessor 具有不同的 nextProcessor 实现。 1.4.2.1 Leader 的 Sync 流程对于 Leader，其 SyncRequestProcessor 的 nextProcessor 是 AckRequestProcessor。由于 Leader 自己也需要对事务进行投票，AckRequestProcessor 会用事务请求本身作为 ACK，并调用 Leader 的方法处理该 ACK。因此，Leader 的 Sync 流程最终会流向 Proposal 流程。 org.apache.zookeeper.server.quorum.AckRequestProcessor#processRequest 12345678910/** * Forward the request as an ACK to the leader */public void processRequest(Request request) &#123; QuorumPeer self = leader.self; if(self != null) leader.processAck(self.getId(), request.zxid, null); else LOG.error("Null QuorumPeer");&#125; 1.4.2.2 Follower 的 Sync 流程对于 Follower，其 SyncRequestProcessor 的 nextProcessor 是 SendAckRequestProcessor。syncProcessor 进行事务日志的记录后，由 SendAckRequestProcessor 向 Leader 回复一个 ACK 消息。 org.apache.zookeeper.server.quorum.SendAckRequestProcessor#processRequest 12345678910111213141516171819public void processRequest(Request si) &#123; if(si.type != OpCode.sync)&#123; QuorumPacket qp = new QuorumPacket(Leader.ACK, si.hdr.getZxid(), null, null); try &#123; learner.writePacket(qp, false); &#125; catch (IOException e) &#123; LOG.warn("Closing connection to leader, exception during packet send", e); try &#123; if (!learner.sock.isClosed()) &#123; learner.sock.close(); &#125; &#125; catch (IOException e1) &#123; // Nothing to do, we are shutting things down, so an exception here is irrelevant LOG.debug("Ignoring error closing the connection", e1); &#125; &#125; &#125;&#125; 1.4.2.3 Observer 的 Sync 流程虽然 Observer 会初始化 SyncRequestProcessor，但由于 Leader 不会向 Observer 转发事务提案，因此 Observer 不存在 Sync 流程。 1.4.3 Commit 流程org.apache.zookeeper.server.quorum.CommitProcessor#run 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Overridepublic void run() &#123; try &#123; Request nextPending = null; while (!finished) &#123; int len = toProcess.size(); for (int i = 0; i &lt; len; i++) &#123; nextProcessor.processRequest(toProcess.get(i)); &#125; toProcess.clear(); synchronized (this) &#123; if ((queuedRequests.size() == 0 || nextPending != null) &amp;&amp; committedRequests.size() == 0) &#123; wait(); continue; &#125; if ((queuedRequests.size() == 0 || nextPending != null) &amp;&amp; committedRequests.size() &gt; 0) &#123; Request r = committedRequests.remove(); if (nextPending != null &amp;&amp; nextPending.sessionId == r.sessionId &amp;&amp; nextPending.cxid == r.cxid) &#123; nextPending.hdr = r.hdr; nextPending.txn = r.txn; nextPending.zxid = r.zxid; toProcess.add(nextPending); nextPending = null; &#125; else &#123; toProcess.add(r); &#125; &#125; &#125; if (nextPending != null) &#123; continue; &#125; synchronized (this) &#123; while (nextPending == null &amp;&amp; queuedRequests.size() &gt; 0) &#123; Request request = queuedRequests.remove(); switch (request.type) &#123; case OpCode.create: case OpCode.delete: case OpCode.setData: case OpCode.multi: case OpCode.setACL: case OpCode.createSession: case OpCode.closeSession: nextPending = request; break; case OpCode.sync: if (matchSyncs) &#123; nextPending = request; &#125; else &#123; toProcess.add(request); &#125; break; default: toProcess.add(request); &#125; &#125; &#125; &#125; &#125; catch (InterruptedException e) &#123; LOG.warn("Interrupted exception while waiting", e); &#125; catch (Throwable e) &#123; LOG.error("Unexpected exception causing CommitProcessor to exit", e); &#125; LOG.info("CommitProcessor exited loop!");&#125; 1.4.3.1 Leader 的 Commit 流程 将请求交付给 CommitProcessor 处理器。 如前所述，Leader 在生成提案之前，会首先将生成的提案放到 CommitProcessor 的 queuedRequests 队列中。 处理 queuedRequests 队列请求。 CommitProcessor 会有一个单独的线程来处理 queuedRequests 队列中的请求。 标记 nextPending。 若从 queuedRequests 中取出的请求是一个事务请求，则需要在集群中进行投票处理，同时将nextPending 标记为当前请求。 等待 Proposal 投票。 在进行 Commit 流程的同时，Leader 会生成 Proposal 并广播给所有 Follower 服务器，此时，Commit 流程等待，直到投票结束。 投票通过。 若提案获得过半 PARTICIPANT 认可，那么进入请求提交阶段。Leader 会将该请求放入 commitedRequests 队列中，同时唤醒 Commit 流程。 提交请求。 若 commitedRequests 队列中存在可以提交的请求，那么 Commit 流程将请求放入 toProcess 队列中。在这个过程中为了保证事务请求的顺序执行，Commit 流程还会对比之前标记的 nextPending 和 commitedRequests 队列中的第一个请求是否一致。在下一次循环中，toProcess 队列中的请求将被取出交付下一个请求处理器。对于 Leader 而言，下一个请求处理器是 ToBeAppliedRequestProcessor。 1.4.3.2 Follower 的 Commit 流程org.apache.zookeeper.server.quorum.FollowerZooKeeperServer#commit 1234567891011121314public void commit(long zxid) &#123; if (pendingTxns.size() == 0) &#123; LOG.warn("Committing " + Long.toHexString(zxid) + " without seeing txn"); return; &#125; long firstElementZxid = pendingTxns.element().zxid; if (firstElementZxid != zxid) &#123; LOG.error("Committing zxid 0x" + Long.toHexString(zxid) + " but next pending txn 0x" + Long.toHexString(firstElementZxid)); System.exit(12); &#125; Request request = pendingTxns.remove(); commitProcessor.commit(request);&#125; Follower 在收到 COMMIT 消息时，会首先将该事务的 ZXID 与 pendingTxns 队列中缓存的事务对比，然后放入 CommitProcessor 的 committedRequests 队列。 Follower 的 CommitProcessor 将在两个队列中整理事务信息，在后续循环中提交给下一个请求处理器，即 FinalRequestProcessor。 1.4.3.3 Observer 的 Commit 流程org.apache.zookeeper.server.quorum.Observer#processPacket 12345678910111213141516171819202122232425262728293031323334353637383940/** * Controls the response of an observer to the receipt of a quorumpacket * @param qp * @throws IOException */protected void processPacket(QuorumPacket qp) throws IOException&#123; switch (qp.getType()) &#123; case Leader.PING: ping(qp); break; case Leader.PROPOSAL: LOG.warn("Ignoring proposal"); break; case Leader.COMMIT: LOG.warn("Ignoring commit"); break; case Leader.UPTODATE: LOG.error("Received an UPTODATE message after Observer started"); break; case Leader.REVALIDATE: revalidate(qp); break; case Leader.SYNC: ((ObserverZooKeeperServer)zk).sync(); break; case Leader.INFORM: TxnHeader hdr = new TxnHeader(); Record txn = SerializeUtils.deserializeTxn(qp.getData(), hdr); Request request = new Request (null, hdr.getClientId(), hdr.getCxid(), hdr.getType(), null, null); request.txn = txn; request.hdr = hdr; ObserverZooKeeperServer obs = (ObserverZooKeeperServer)zk; obs.commitRequest(request); break; default: LOG.error("Invalid packet type: &#123;&#125; received by Observer", qp.getType()); &#125;&#125; Observer 收到来自 Leader 的 INFORM 消息后的处理过程类似于 Follower。 1.5 事务应用对于 Leader，事务由 CommitProcessor 提交给 ToBeAppliedRequestProcessor，再由 ToBeAppliedRequestProcessor 提交给 FinalRequestProcessor；对于 Follower 和 Observer，事务由 CommitProcessor 提交给 FinalRequestProcessor。 有效性检查 FinalRequestProcessor 处理器检查 outstandingChanges 队列中请求的有效性，如果发现这些请求已经落后于当前正在处理的请求，那么直接从 outstandingChanges 队列中移除。 事务应用 之前的请求处理仅仅是将事务请求记录到了事务日志中去，而内存数据库中的状态尚未变更。因此，在这个环节，需要将事务变更应用到内存数据库中。 org.apache.zookeeper.server.ZooKeeperServer#processTxn 1234567891011121314151617public ProcessTxnResult processTxn(TxnHeader hdr, Record txn) &#123; ProcessTxnResult rc; int opCode = hdr.getType(); long sessionId = hdr.getClientId(); rc = getZKDatabase().processTxn(hdr, txn); if (opCode == OpCode.createSession) &#123; if (txn instanceof CreateSessionTxn) &#123; CreateSessionTxn cst = (CreateSessionTxn) txn; sessionTracker.addSession(sessionId, cst.getTimeOut()); &#125; else &#123; LOG.warn("*****&gt;&gt;&gt;&gt;&gt; Got " + txn.getClass() + " " + txn.toString()); &#125; &#125; else if (opCode == OpCode.closeSession) &#123; sessionTracker.removeSession(sessionId); &#125; return rc;&#125; 对于会话创建这类事务请求，需要向 SessionTracker 进行会话注册。此时，一个客户端的会话被保存到了集群中的所有服务器上（但是注意，Leader 和 Learner 的 SessionTracker 具有不同实现）。 将事务放入 commitProposal 队列 一旦完成事务请求的内存数据库应用，就可以将该请求放入 commitProposal 队列中。 commitProposal 队列用来保存最近被提交的事务请求，以便集群间机器进行数据的快速同步。 1.6 会话响应FinalRequestProcessor 继续处理对会话请求的响应。 统计处理 ZooKeeper 计算请求在服务端处理所花费的时间，统计客户端连接的基本信息，如 lastZxid（最新的 ZXID）、lastOp（最后一次和服务端的操作）和 lastLatency（最后一次请求处理所花费的时间）等。 创建响应 ConnectResponse ConnectResponse 就是一个会话创建成功后的响应，包含了当前客户端与服务端之间的通信协议版本号 protocolVersion、会话超时时间、sessionId 和会话密码。 序列化 ConnectResponse I/O 层发送响应给客户端 1.7 客户端处理请求响应对于会话创建请求，客户端会调用 org.apache.zookeeper.ClientCnxn.SendThread#onConnected 方法，生成一个 None-SyncConnected 事件，交由 EventThread 处理： 123456789101112131415161718192021222324252627282930313233void onConnected(int _negotiatedSessionTimeout, long _sessionId, byte[] _sessionPasswd, boolean isRO) throws IOException &#123; negotiatedSessionTimeout = _negotiatedSessionTimeout; if (negotiatedSessionTimeout &lt;= 0) &#123; state = States.CLOSED; eventThread.queueEvent(new WatchedEvent( Watcher.Event.EventType.None, Watcher.Event.KeeperState.Expired, null)); eventThread.queueEventOfDeath(); String warnInfo; warnInfo = "Unable to reconnect to ZooKeeper service, session 0x" + Long.toHexString(sessionId) + " has expired"; LOG.warn(warnInfo); throw new SessionExpiredException(warnInfo); &#125; if (!readOnly &amp;&amp; isRO) &#123; LOG.error("Read/write client got connected to read-only server"); &#125; readTimeout = negotiatedSessionTimeout * 2 / 3; connectTimeout = negotiatedSessionTimeout / hostProvider.size(); hostProvider.onConnected(); sessionId = _sessionId; sessionPasswd = _sessionPasswd; state = (isRO) ? States.CONNECTEDREADONLY : States.CONNECTED; seenRwServerBefore |= !isRO; KeeperState eventState = (isRO) ? KeeperState.ConnectedReadOnly : KeeperState.SyncConnected; eventThread.queueEvent(new WatchedEvent( Watcher.Event.EventType.None, eventState, null));&#125; 2. SetData 请求服务端对于 SetData 请求的处理大致可以分为 4 步，分别是请求的预处理、事务处理、事务应用和请求响应。 2.1 预处理 I/O 层接收来自客户端的请求。 判断是否是客户端会话创建请求。对于 SetData 请求，由于已经完成了会话创建，因此按照正常事务请求进行处理。 将请求交给 PrepRequestProcessor 处理器进行处理。 org.apache.zookeeper.server.PrepRequestProcessor#pRequest2Txn 12345678910111213141516171819202122232425262728// ... request.hdr = new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), type); switch (type) &#123; // ... case OpCode.setData: zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); SetDataRequest setDataRequest = (SetDataRequest)record; if(deserialize) ByteBufferInputStream.byteBuffer2Record(request.request, setDataRequest); path = setDataRequest.getPath(); validatePath(path, request.sessionId); nodeRecord = getRecordForPath(path); checkACL(zks, nodeRecord.acl, ZooDefs.Perms.WRITE, request.authInfo); version = setDataRequest.getVersion(); int currentVersion = nodeRecord.stat.getVersion(); if (version != -1 &amp;&amp; version != currentVersion) &#123; throw new KeeperException.BadVersionException(path); &#125; version = currentVersion + 1; request.txn = new SetDataTxn(path, setDataRequest.getData(), version); nodeRecord = nodeRecord.duplicate(request.hdr.getZxid()); nodeRecord.stat.setVersion(version); addChangeRecord(nodeRecord); break; // ...&#125;// ... 创建请求事务头。 会话检查。 检查该会话是否有效，即是否已经超时。 反序列化请求，并创建 ChangeRecord 记录。 ZooKeeper 首先会对请求反序列化并生成特定的 SetDataRequest 请求，请求中包含了数据节点路径 path、更新的内容 data 和期望的数据节点版本 version。同时根据请求对应的 path，Zookeeper 会生成一个 ChangeRecord 记录。 ACL检查。检查客户端是否具有数据更新的权限。 数据版本检查。 ZooKeeper 通过 version 属性来实现乐观锁机制的写入校验。 创建请求事务体 SetDataTxn。 保存 ChangeRecord 记录到 outstandingChanges 队列中。 2.2 事务处理参见会话创建的事务处理阶段。 2.3 事务应用 交付给 FinalRequestProcessor 处理器。 事务应用。 将请求事务头和事务体直接交给内存数据库 ZKDatabase 进行事务应用，同时返回 ProcessTxnResult 对象，包含了数据节点内容更新后的 stat。 将事务请求放入 commitProposal 队列。 2.4 请求响应 统计处理。 创建响应体 SetDataResponse。 其包含了当前数据节点的最新状态 stat。 创建响应头。 包含当前响应对应的事务 ZXID 和请求处理是否成功的标识。 序列化响应。 I/O层发送响应给客户端。 3. GetData 请求服务端对于 GetData 请求的处理，大致分为 3 步，分别是请求的预处理、非事务处理和请求响应。 3.1 预处理 I/O 层接收来自客户端的请求。 判断是否是客户端会话创建请求。 会话检查。 将请求提交给 firstProcessor。 对于 Leader，PreRequestProcessor 再次检查会话，然后交给 ProposalRequestProcessor。由于这种情况下请求事务头为 null，Leader 将提交请求给 CommitProcessor 并忽略 Proposal 和 Sync 阶段。 对于 Learner，提交请求给 CommitProcessor。 3.2 非事务处理 反序列化 GetDataRequest 请求。 获取数据节点。 ACL检查。 获取数据内容和 stat，注册 Watcher。 3.3 请求响应 创建响应体 GetDataResponse。响应体包含当前数据节点的内容和状态 stat。 创建响应头。 统计处理。 序列化响应。 I/O层发送响应给客户端。 4. 自问自答4.1 Learner 如何处理事务请求？当一个 Learner 收到客户端的事务请求时，会通过 REQUEST 消息转发给 Leader。Leader 的 LearnerHandler 收到消息后，会提交给 PreRequestProcessor，进入预处理阶段。由于该请求不是来自于与 Leader 相连的客户端的，因此相比于完整流程，跳过了前面的会话创建阶段。 4.2 在事务处理的过程中，Follower 会收到哪些消息？如何客户端连接的是一个 Follower，整个流程中该 Follower 会收到： 来自客户端的事务请求。由 FollowerRequestProcessor 处理，发送 REQUEST 消息给 Leader，并添加到 CommitProcessor 的 queuedRequests 队列。 不论客户端是向哪台服务器提交的事务请求，所有 Follower 都会收到： 来自 Leader 的事务提案。由 FollowerZooKeeperServer 交给 SyncRequestProcessor 处理，提交到 SendAckRequestProcessor，向 Leader 回复 ACK。 来自 Leader 的 COMMIT 消息。由 FollowerZooKeeperServer 添加事务请求到 CommitProcesser 的 committedRequests 队列，并在接下来提交到 FinalRequestProcessor。 4.2 在事务处理的过程中，Observer 会收到哪些消息？如何客户端连接的是一个 Observer，整个流程中该 Observer 会收到： 来自客户端的事务请求。由 ObserverRequestProcessor 处理，发送 REQUEST 消息给 Leader，并记录到 CommitProcessor 的 queuedRequests 队列。 不论客户端是向哪台服务器提交的事务请求，所有 Observer 都会收到： 来自 Leader 的 INFORM 消息。由 ObserverZooKeeperServer 添加事务请求到 CommitProcesser 的 committedRequests 队列，并在接下来提交到 FinalRequestProcessor。 4.3 Leader 是否回复来自 Learner 的 REQUEST 消息？Leader 不会对 Learner 的 REQUEST 消息做回复。请求处理结果由 Leader 向所有 Learner 发送确认信息（COMMIT 或 INFORM）传达。 4.4 如何保证只由接收客户端事务请求的那台服务器来对客户端发送响应？ 对于接收客户端事务请求的服务器，在流程中流转时，会创建一个 Request 对象，其 cnxn 属性被设置为处理该客户端请求的 NIOServerCnxn 实例。这个对象最终被添加到 CommitProcessor 的 queuedRequests 队列中，等待 Leader 确认事务处理结果。其他服务器不会执行这一个步骤。 对于 Leader： 如果客户端请求是直接发送给 Leader 的，如前所述，Leader 会创建一个 Request 对象，其 cnxn 属性被设置为处理该客户端请求的 NIOServerCnxn 实例，然后调用 org.apache.zookeeper.server.ZooKeeperServer#submitRequest(org.apache.zookeeper.server.Request)。 如果客户端请求不是直接发送给 Leader 的，那么 Leader 会收到来自某一个 Learner 的 REQUEST 请求。Leader 会创建一个 Request 对象，其 cnxn 属性为 null，然后调用 org.apache.zookeeper.server.ZooKeeperServer#submitRequest(org.apache.zookeeper.server.Request)。 org.apache.zookeeper.server.quorum.LearnerHandler#run 1234567891011121314151617181920212223@Overridepublic void run() &#123; // ... while (true) &#123; switch (qp.getType()) &#123; case Leader.REQUEST: bb = ByteBuffer.wrap(qp.getData()); sessionId = bb.getLong(); cxid = bb.getInt(); type = bb.getInt(); bb = bb.slice(); Request si; if(type == OpCode.sync)&#123; si = new LearnerSyncRequest(this, sessionId, cxid, type, bb, qp.getAuthinfo()); &#125; else &#123; si = new Request(null, sessionId, cxid, type, bb, qp.getAuthinfo()); &#125; si.setOwner(this); leader.zk.submitRequest(si); break; &#125; &#125; &#125; 无论哪种情况，这个 Request 将在 Leader 的 Commit 流程中被 Leader 添加到 CommitProcessor 的 queuedRequests 队列中，等待集群投票结果。 无论哪种情况，这个 Request 将在 Leader 的 Proposal 流程中被 Leader 添加到 CommitProcessor 的 committedRequests 队列中，等待事务应用。 对于 Follower： 在 Leader 向 Follower 提交事务提案后，也会创建一个 Request 对象，但其 cnxn 属性被设置为 null，然后将其添加到 FollowerZooKeeperServer 的 pendingTxn 队列中。 在 Leader 向 Follower 正式提交事务（COMMIT）后，会从 pendingTxn 队列取出该 Request 对象，放入 CommitProcesser 的 committedRequests 队列中。 对于 Observer： 在 Leader 向 Follower 正式提交事务（INFORM）后，会创建一个 Request 对象，但其 cnxn 属性被设置为 null，放入 CommitProcesser 的 committedRequests 队列中。 综上所述，对于服务器： 如果自己是收到客户端请求的那个服务器，那么自己的 CommitProcesser 的 queuedRequests 队列中都会包含一个待提交的事务请求，其 cnxn 属性为客户端连接对应的 NIOServerCnxn 实例。 如果自己不是收到客户端请求的那个服务器，那么自己的 CommitProcesser 的 committedRequests 队列中都会包含一个待提交的事务请求，其 cnxn 属性为 null。 在 CommitProcesser 整理请求信息的过程中，会优先考虑 queuedRequests 队列中的 Request 对象。因此，如果自己是收到客户端请求的那个服务器，那么提交给 FinalRequestProcessor 的 Requet 对象的 cnxn 属性不为 null；反之则为 null。 在 FinalRequestProcessor 的处理过程中，各服务器首先完成事务应用。这是将做一次判断，只有当传入的 Request 对象的 cnxn 参数不为 null 时，才会继续进行后续的会话响应操作。 最终，集群中的所有服务器都提交并应用了事务，但只有客户端所连接的那个服务器才会对客户端进行响应。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：客户端]]></title>
    <url>%2F2017%2F12%2F13%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[ZooKeeper 客户端主要由以下几个核心组件组成： ZooKeeper 实例：客户端的入口 ClientWatchManager：客户端Watcher管理器 HostProvider：客户端地址列表管理器 ClientCnxn：客户端核心线程 ZooKeeper 客户端的构造方法有以下几种： 1234public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd)public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) 这些构造方法的最终根据是否重用 session 有两种实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private final ZKWatchManager watchManager = new ZKWatchManager(); //不重用session public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly) throws IOException &#123; LOG.info("Initiating client connection, connectString=" + connectString + " sessionTimeout=" + sessionTimeout + " watcher=" + watcher); watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser( connectString); HostProvider hostProvider = new StaticHostProvider( connectStringParser.getServerAddresses()); cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); cnxn.start(); &#125; //重用session public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) throws IOException &#123; watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser( connectString); HostProvider hostProvider = new StaticHostProvider( connectStringParser.getServerAddresses()); cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), sessionId, sessionPasswd, canBeReadOnly); cnxn.seenRwServerBefore = true; // since user has provided sessionId cnxn.start(); &#125; //ClientCnxnSocket 的默认实现是 ClientCnxnSocketNIO private static ClientCnxnSocket getClientCnxnSocket() throws IOException &#123; String clientCnxnSocketName = System .getProperty(ZOOKEEPER_CLIENT_CNXN_SOCKET); if (clientCnxnSocketName == null) &#123; clientCnxnSocketName = ClientCnxnSocketNIO.class.getName(); &#125; try &#123; return (ClientCnxnSocket) Class.forName(clientCnxnSocketName).getDeclaredConstructor() .newInstance(); &#125; catch (Exception e) &#123; IOException ioe = new IOException("Couldn't instantiate " + clientCnxnSocketName); ioe.initCause(e); throw ioe; &#125; &#125; 1. 一次会话的创建过程1.1 初始化阶段客户端的初始化过程分为以下几个步骤： 初始化 ZooKeeper 对象。 通过调用 ZooKeeper 的构造方法来实例化一个 ZooKeeper 对象，在初始化过程中，会创建一个客户端的 Watcher 管理器：ClientWatchManager。 设置会话默认 Watcher。 如果在构造方法中传入了一个 Watcher 对象，那么客户端会将这个对象作为默认 Watcher 保存在 ClientWatchManager 中。 构造 ZooKeeper 服务器地址列表管理器：HostProvider。 对于构造方法中传入的服务器地址，客户端会将其存放在服务器地址列表管理器 HostProvider 中。 创建并初始化客户端网络连接器：ClientCnxn。 ZooKeeper 客户端首先会创建一个网络连接器 ClientCnxn，用来管理客户端与服务器的网络交互。另外，客户端在创建 ClientCnxn 的同时，还会初始化两个核心队列 outgoingQueue 和 pendingQueue，分别作为客户端请求的发送队列和服务端响应的等待队列。 ClientCnxn 的构造和启动方法如下： 123456789101112131415161718192021222324252627private final LinkedList&lt;Packet&gt; pendingQueue = new LinkedList&lt;Packet&gt;();private final LinkedList&lt;Packet&gt; outgoingQueue = new LinkedList&lt;Packet&gt;(); public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) &#123; this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; connectTimeout = sessionTimeout / hostProvider.size(); readTimeout = sessionTimeout * 2 / 3; readOnly = canBeReadOnly; sendThread = new SendThread(clientCnxnSocket); eventThread = new EventThread();&#125;//启动 SendThread 和 EventThreadpublic void start() &#123; sendThread.start(); eventThread.start();&#125; 初始化 SendThread 和 EventThread。 ClientCnxn 还会创建两个核心网络线程 SendThread 和 EventThread，前者用于管理客户端和服务端之间的所有网络 I/O，后者则用于进行客户端的事件处理。同时，客户端还会将 ClientCnxnSocket 分配给 SendThread 作为底层网络 I/O 处理器，并初始化 EventThread 的待处理事件队列 waitingEvents，用于存放所有等待被客户端处理的事件。 SendThread： 1234567SendThread(ClientCnxnSocket clientCnxnSocket) &#123; super(makeThreadName("-SendThread()")); //设置当前状态为 CONNECTING state = States.CONNECTING; this.clientCnxnSocket = clientCnxnSocket; setDaemon(true);&#125; EventThread： 12345private final LinkedBlockingQueue&lt;Object&gt; waitingEvents = new LinkedBlockingQueue&lt;Object&gt;();EventThread() &#123; super(makeThreadName("-EventThread")); setDaemon(true);&#125; 1.2 会话创建阶段 启动 SendThread 和 EventThread。 SendThread 首先会判断当前客户端的状态，进行一系列请理性工作。 获取一个服务器地址。 在开始创建 TCP之前，SendThread 首先需要获取一个 ZooKeeper 服务器的目标地址，这通常是从 HostProvider 中随机获取出一个地址，然后委托给 ClientCnxnSocket 去创建与 ZooKeeper 服务器之间的 TCP 连接。 创建TCP连接。 获取一个服务器地址后，ClientCnxnSocket 负责和服务器创建一个 TCP 长连接。 构造 ConnectRequest 请求。 以上步骤后，ClientCnxnSocket 和服务器之间创建了一个 TCP 长连接，但和 ZooKeeper 服务器之间的会话创建尚未完成。ClientCnxnSocket 会进一步调用 SendThread 的 primeConnection() 方法，构造一个 ConnectRequest 请求。该请求代表了客户端试图和服务端之间创建一个会话。同时，将该请求包装成 Packet 对象，放入请求发送队列 outgoingQueue 中去。 发送请求。 ClientCnxnSocket 负责从 outgoingQueue 中取出一个待发送的 Packet 对象，将其序列化成 ByteBuffer 后，向服务端进行发送。 1.3 响应处理阶段 接受服务器端响应。 ClientCnxnSocket 接受到服务端响应后，会首先判断当前的客户端状态是否是 “已初始化”，如果尚未完成初始化，那么就认为该响应一定是会话创建请求的响应，直接交由 readConnectResult 方法来处理该响应。 处理 Response。 ClientCnxnSocket 会对接受到的服务端响应进行反序列化，得到 ConnectResponse 对象，并从中获取到 ZooKeeper 服务端分配的会话 sessionId。 连接成功。 连接成功后，一方面需要通知 SendThread 线程，进一步对客户端进行会话参数的设置，包括 readTimeout 和 connectTimeout 等，并更新客户端状态，另一方面，需要通知地址管理器 HostProvider 当前成功连接的服务器地址。 生成事件：SyncConnected-None。 为了能够让上层应用感知到会话的成功创建，SendThread 会生成一个事件 SyncConnected-None，代表客户端与服务器会话创建成功，并将该事件传递给 EventThread 线程。 查询 Watcher。 EventThread 线程收到事件后，会从 ClientWatchManager 管理器中查询出对应的 Watcher，针对 SyncConnected-None 事件，那么就直接找出存储的默认 Watcher，然后将其放到 EventThread 的 watingEvents 队列中去。 处理事件。 EventThread 不断的从 watingEvents 队列中取出待处理的 Watcher 对象，然后直接调用该对象的 process 接口方法，以达到触发 Watcher 的目的。 2. 服务器地址列表2.1 Chroot：客户端隔离命名空间在 3.2.0 之后版本的 ZooKeeper 中，添加了 “Chroot” 特性，该特性允许每个客户端为自己设置一个命名空间。如果一个 ZooKeeper 客户端设置了 Chroot，那么该客户端对服务器的任何操作，都将会被限制在自己的命名空间下。 客户端可以通过在 connectString 中添加后缀的方式来设置 Chroot，如下所示： 1192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181/apps/X 将这样一个 connectString 传入客户端的 ConnectStringParser 后就能够解析出 Chroot 并保存在 chrootPath 属性中。 2.2 HostProvider：地址列表管理器HostProvider 的默认实现是 StaticHostProvider。通过调用 staticHostProvider 的 next() 方法，能够从 StaticHostProvider 中获取一个可用的服务器地址。这个 next() 方法并非简单地从 serverAddresses 中一次获取一个服务器地址，而是先将随机打散后的服务器地址列表拼装成一个环形的循环队列。注意这个随机过程是一次性的，也就是说，之后的使用过程中一直是按照这样的顺利来获取服务器地址的。 3. ClientCnxn：网络 I/O3.1 PacketPacket 是 ClientCnxn 内部定义的一个堆协议层的封装，用作 ZooKeeper 中请求和响应的载体。Packet 包含了请求头（requestHeader）、响应头（replyHeader）、请求体（request）、响应体（response）、节点路径（clientPath/serverPath）、注册的 Watcher（watchRegistration）等信息，然而，并非 Packet 中所有的属性都在客户端与服务端之间进行网络传输，只会将 requestHeader、request、readOnly 三个属性序列化，并生成可用于底层网络传输的 ByteBuffer，其他属性都保存在客户端的上下文中，不会进行与服务端之间的网络传输。 org.apache.zookeeper.ClientCnxn.Packet#createBB 1234567891011121314151617181920212223public void createBB() &#123; try &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); boa.writeInt(-1, "len"); // We'll fill this in later if (requestHeader != null) &#123; requestHeader.serialize(boa, "header"); &#125; if (request instanceof ConnectRequest) &#123; request.serialize(boa, "connect"); // append "am-I-allowed-to-be-readonly" flag boa.writeBool(readOnly, "readOnly"); &#125; else if (request != null) &#123; request.serialize(boa, "request"); &#125; baos.close(); this.bb = ByteBuffer.wrap(baos.toByteArray()); this.bb.putInt(this.bb.capacity() - 4); this.bb.rewind(); &#125; catch (IOException e) &#123; LOG.warn("Ignoring unexpected exception", e); &#125;&#125; 3.2 outgoingQueue 和 pendingQueueClientCnxn 维护着 outgoingQueue（客户端的请求发送队列）和 pendingQueue（服务端响应的等待队列），outgoingQueue 专门用于存储那些需要发送到服务端的 Packet 集合，pendingQueue 用于存储那些已经从客户端发送到服务端的，但是需要等待服务端响应的 Packet 集合。 3.3 ClientCnxnSocket：底层 Socket 通信层在 ZooKeeper 中，ClientCnxnSocket 的默认实现是 ClientCnxnSocketNIO，该实现类使用 Java 原生的 NIO 接口，其核心是 doIO 逻辑，主要负责对请求的发送和响应接收过程。 SendThread 线程中会循环调用 org.apache.zookeeper.ClientCnxnSocketNIO#doTransport 12345678910111213141516171819202122232425262728293031@Overridevoid doTransport(int waitTimeOut, List&lt;Packet&gt; pendingQueue, LinkedList&lt;Packet&gt; outgoingQueue, ClientCnxn cnxn) throws IOException, InterruptedException &#123; selector.select(waitTimeOut); Set&lt;SelectionKey&gt; selected; synchronized (this) &#123; selected = selector.selectedKeys(); &#125; // Everything below and until we get back to the select is // non blocking, so time is effectively a constant. That is // Why we just have to do this once, here updateNow(); for (SelectionKey k : selected) &#123; SocketChannel sc = ((SocketChannel) k.channel()); if ((k.readyOps() &amp; SelectionKey.OP_CONNECT) != 0) &#123; if (sc.finishConnect()) &#123; updateLastSendAndHeard(); sendThread.primeConnection(); &#125; &#125; else if ((k.readyOps() &amp; (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) &#123; doIO(pendingQueue, outgoingQueue, cnxn); &#125; &#125; if (sendThread.getZkState().isConnected()) &#123; synchronized(outgoingQueue) &#123; if (findSendablePacket(outgoingQueue, cnxn.sendThread.clientTunneledAuthenticationInProgress()) != null) &#123; enableWrite(); &#125; &#125; &#125; selected.clear();&#125; org.apache.zookeeper.ClientCnxnSocketNIO#doIO 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192void doIO(List&lt;Packet&gt; pendingQueue, LinkedList&lt;Packet&gt; outgoingQueue, ClientCnxn cnxn) throws InterruptedException, IOException &#123; SocketChannel sock = (SocketChannel) sockKey.channel(); if (sock == null) &#123; throw new IOException("Socket is null!"); &#125; if (sockKey.isReadable()) &#123; int rc = sock.read(incomingBuffer); if (rc &lt; 0) &#123; throw new EndOfStreamException( "Unable to read additional data from server sessionid 0x" + Long.toHexString(sessionId) + ", likely server has closed socket"); &#125; if (!incomingBuffer.hasRemaining()) &#123; incomingBuffer.flip(); if (incomingBuffer == lenBuffer) &#123; recvCount++; readLength(); &#125; else if (!initialized) &#123; readConnectResult(); enableRead(); if (findSendablePacket(outgoingQueue, cnxn.sendThread.clientTunneledAuthenticationInProgress()) != null) &#123; // Since SASL authentication has completed (if client is configured to do so), // outgoing packets waiting in the outgoingQueue can now be sent. enableWrite(); &#125; lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); initialized = true; &#125; else &#123; sendThread.readResponse(incomingBuffer); lenBuffer.clear(); incomingBuffer = lenBuffer; updateLastHeard(); &#125; &#125; &#125; if (sockKey.isWritable()) &#123; synchronized(outgoingQueue) &#123; Packet p = findSendablePacket(outgoingQueue, cnxn.sendThread.clientTunneledAuthenticationInProgress()); if (p != null) &#123; updateLastSend(); // If we already started writing p, p.bb will already exist if (p.bb == null) &#123; if ((p.requestHeader != null) &amp;&amp; (p.requestHeader.getType() != OpCode.ping) &amp;&amp; (p.requestHeader.getType() != OpCode.auth)) &#123; p.requestHeader.setXid(cnxn.getXid()); &#125; p.createBB(); &#125; sock.write(p.bb); if (!p.bb.hasRemaining()) &#123; sentCount++; outgoingQueue.removeFirstOccurrence(p); if (p.requestHeader != null &amp;&amp; p.requestHeader.getType() != OpCode.ping &amp;&amp; p.requestHeader.getType() != OpCode.auth) &#123; synchronized (pendingQueue) &#123; pendingQueue.add(p); &#125; &#125; &#125; &#125; if (outgoingQueue.isEmpty()) &#123; // No more packets to send: turn off write interest flag. // Will be turned on later by a later call to enableWrite(), // from within ZooKeeperSaslClient (if client is configured // to attempt SASL authentication), or in either doIO() or // in doTransport() if not. disableWrite(); &#125; else if (!initialized &amp;&amp; p != null &amp;&amp; !p.bb.hasRemaining()) &#123; // On initial connection, write the complete connect request // packet, but then disable further writes until after // receiving a successful connection response. If the // session is expired, then the server sends the expiration // response and immediately closes its end of the socket. If // the client is simultaneously writing on its end, then the // TCP stack may choose to abort with RST, in which case the // client would never receive the session expired event. See // http://docs.oracle.com/javase/6/docs/technotes/guides/net/articles/connection_release.html disableWrite(); &#125; else &#123; // Just in case enableWrite(); &#125; &#125; &#125;&#125; 3.3.1 请求发送客户端提交请求： org.apache.zookeeper.ClientCnxn#submitRequest 12345678910111213public ReplyHeader submitRequest(RequestHeader h, Record request, Record response, WatchRegistration watchRegistration) throws InterruptedException &#123; ReplyHeader r = new ReplyHeader(); Packet packet = queuePacket(h, r, request, response, null, null, null, null, watchRegistration); synchronized (packet) &#123; while (!packet.finished) &#123; packet.wait(); &#125; &#125; return r;&#125; org.apache.zookeeper.ClientCnxn#queuePacket 1234567891011121314151617181920212223242526272829Packet queuePacket(RequestHeader h, ReplyHeader r, Record request, Record response, AsyncCallback cb, String clientPath, String serverPath, Object ctx, WatchRegistration watchRegistration)&#123; Packet packet = null; // Note that we do not generate the Xid for the packet yet. It is // generated later at send-time, by an implementation of ClientCnxnSocket::doIO(), // where the packet is actually sent. synchronized (outgoingQueue) &#123; packet = new Packet(h, r, request, response, watchRegistration); packet.cb = cb; packet.ctx = ctx; packet.clientPath = clientPath; packet.serverPath = serverPath; if (!state.isAlive() || closing) &#123; conLossPacket(packet); &#125; else &#123; // If the client is asking to close the session then // mark as closing if (h.getType() == OpCode.closeSession) &#123; closing = true; &#125; outgoingQueue.add(packet); &#125; &#125; sendThread.getClientCnxnSocket().wakeupCnxn(); return packet;&#125; 在正常情况下，ClientCnxnSocket 会从 outgoingQueue 中取出一个可发送的 Packet 对象，同时生成一个客户端请求序号 XID 并将其设置到 Packet 请求头中去，然后将其序列化后进行发送。 请求发送完毕后，会立即将该 Packet 保存到 pendingQueue 中，以便等待服务端响应返回后进行相应的处理。 3.3.2 响应接收客户端获取到来自服务端的完整响应数据后，根据不同的客户端请求类型，会进行不同的处理。 如果检测到当前客户端尚未进行初始化，那么说明当前客户端与服务端之间正在进行会话创建，那么就直接将接收到的 ByteBuffer（incomingBuffer）序列化成 ConnectResponse 对象。 如果当前客户端已经处于正常的会话周期，并且接收到的服务端响应是一个事件，那么客户端将接收到的 ByteBuffer 序列化成 WatcherEvent 对象，并将该事件放入待处理队列中。 如果是一个常规的请求响应（Create、GetData、Exist 等），那么会从 pendingQueue 队列中取出一个 Packet 来进行相应的处理。客户端首先会通过检验服务端响应中的 XID 来确保请求处理的顺序性，然后再将接收到的 ByteBuffer 序列化成 Response 对象。 最后，会在 finishPacket 方法中处理 Watcher 注册等逻辑。 3.4 SendThreadSendThread 是客户端 ClientCnxn 内部一个核心的 I/O 调度线程，用于管理客户端和服务端之间的所有网络 I/O 操作。在 ZooKeeper 客户端的实际运行过程中，一方面，SendThread 维护了客户端与服务端之间的会话生命周期，其通过在—定的周期频率内向服务端发送一个 PING 包来实现心跳检测。同时，在会话周期内，如果客户端与服务端之间出现 TCP 连接断开的怙况，那么就会自动且透明化地完成重连操作。 另一方面，SendThread 管理了客户端所有的请求发送和响应接收操作，其将上层客户端 API 操作转换成相应的请求协议并发送到服务端，并完成对同步调用的返回和异步调用的回调。同时，SendThread 还负责将来自服务端的事件传递给 EventThread 去处理。 3.5 EventThreadEventThread 是客户端 ClientCnxn 内部的另一个核心线程，负责客户端的事件处理，并触发客户端注册的 Watcher 监听。EventThread 中有一个 waitingEvents 队列，用于临时存放那些需要被触发的 Object，包括那些客户端注册的 Watcher 和异步接口中注册的回调器 AsyncCallback。同时，EventThread 会不断地从 waitingEvents 这个队列中取出 Object，识别出具体类型（Watcher 或者 AsyncCallback），并分别调用 process 和 processResult 接口方法来实现对事件的触发和回调。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：四字命令]]></title>
    <url>%2F2017%2F12%2F09%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E5%9B%9B%E5%AD%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[使用方式： telnet 1234567891011121314$ telnet localhost 2181Trying ::1...Connected to localhost.Escape character is '^]'.confclientPort=2181dataDir=/usr/local/var/lib/zookeeper/version-2dataLogDir=/usr/local/var/lib/zookeeper/version-2tickTime=3000maxClientCnxns=0minSessionTimeout=6000maxSessionTimeout=60000serverId=0Connection closed by foreign host. nc 123456789$ echo conf | nc localhost 2181clientPort=2181dataDir=/usr/local/var/lib/zookeeper/version-2dataLogDir=/usr/local/var/lib/zookeeper/version-2tickTime=3000maxClientCnxns=0minSessionTimeout=6000maxSessionTimeout=60000serverId=0 以下示例基于在本地以默认配置起单实例ZooKeeper和Kafka，Kafka连接到ZooKeeper。Mac系统下ZooKeeper配置文件目录为/usr/local/etc/zookeeper。 1. confconf命令用于输出ZooKeeper服务器运行时使用的基本配置信息，包括clientPort，dataDir和tickTime等。 conf会根据当前的运行模式来决定打印输出的服务器配置信息，如果是单机模式(standalone)，不会输出 initLimit、syncLimit、electionAlg以及electionPort等集群配置信息。 123456789$ echo conf | nc localhost 2181clientPort=2181dataDir=/usr/local/var/lib/zookeeper/version-2dataLogDir=/usr/local/var/lib/zookeeper/version-2tickTime=3000maxClientCnxns=0minSessionTimeout=6000maxSessionTimeout=60000serverId=0 2. conscons命令用于输出当前这台服务器上所有客户端连接的详细信息，包括每个客户端的客户端IP、会话ID和最后一次与服务器交互的操作类型等。 123$ echo cons | nc localhost 2181 /127.0.0.1:51436[1](queued=0,recved=493,sent=495,sid=0x15e983124a00000,lop=PING,est=1505792940222,to=6000,lcxid=0x17c,lzxid=0x478,lresp=1505793166428,llat=0,minlat=0,avglat=0,maxlat=129) /0:0:0:0:0:0:0:1:51550[0](queued=0,recved=1,sent=0) 3. crstcrst命令用于重置所有客户端的连接统计信息。 12$ echo crst | nc localhost 2181Connection stats reset. 4. dumpdump命令用于输出当前集群的所有会话信息，包括这些会话的会话ID，以及每个会话创建的临时节点等信息。另外，如果在Leader服务器上执行该命令的话，还能够看到每个会话的超时时间。 123456789101112$ echo dump | nc localhost 2181SessionTracker dump:Session Sets (3):0 expire at Tue Sep 19 11:55:51 CST 2017:0 expire at Tue Sep 19 11:55:54 CST 2017:1 expire at Tue Sep 19 11:55:57 CST 2017: 0x15e983124a00000ephemeral nodes dump:Sessions with Ephemerals (1):0x15e983124a00000: /controller /brokers/ids/0 5. envienvi命令用于输出ZooKeeper所在服务器运行时的环境信息，包括os.version，java.version和user.home等。 1234567891011121314151617$ echo envi | nc localhost 2181Environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMThost.name=bogonjava.version=1.8.0_91java.vendor=Oracle Corporationjava.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/jrejava.class.path=java.library.path=/Users/xyq/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.java.io.tmpdir=/var/folders/yq/d0v9dm456zd_xzc1lhllw19m0000gn/T/java.compiler=&lt;NA&gt;os.name=Mac OS Xos.arch=x86_64os.version=10.12.6user.name=xyquser.home=/Users/xyquser.dir=/Users/xyq 6. ruokruok命令即“are you ok”，用于输出当前ZooKeeper服务器是否正在运行。执行该命令后，如果当前ZooKeeper服务器正在运行，那么返回“imok”，否则没有任何响应输出。 ruok命令的输出仅仅只能表明当前服务器是否正在运行，准确地讲，只能说明2181端口打开着，同时四字命令执行流程正常，但是不能代表ZooKeeper服务器是否运行正常。在很多时候，如果当前服务器无法正常处理客户端的读写请求，甚至已经无法和集群中的其他机器通信，ruok命令依然返回“imok”。 12$ echo ruok | nc localhost 2181imok 7. statstat命令用于获取ZooKeeper服务器的运行时状态信息，包括基本的ZooKeeper版本，打包信息，运行时角色，集群数据节点个数等信息，另外还会将当前服务器的客户端连接信息打印出来。 12345678910111213$ echo stat | nc localhost 2181Zookeeper version: 3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMTClients: /0:0:0:0:0:0:0:1:51369[0](queued=0,recved=1,sent=0) Latency min/avg/max: 0/0/0Received: 4Sent: 3Connections: 1Outstanding: 0Zxid: 0x43cMode: standaloneNode count: 140 8. srvrsrvr命令和stat命令的功能一致，唯一的区别是srvr不会将客户端的连接情况输出，仅仅输出服务器的自身信息。 12345678910$ echo srvr | nc localhost 2181Zookeeper version: 3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMTLatency min/avg/max: 0/0/129Received: 1979Sent: 1980Connections: 2Outstanding: 0Zxid: 0x478Mode: standaloneNode count: 142 9. wchswchs命令用于输出当前服务器上管理的Watchers的概要信息。 123$ echo wchs | nc localhost 21811 connections watching 11 pathsTotal watches:11 10. wchcwchc命令用于输出当前服务器上管理的Watchers的详细信息，以会话为单位进行归组，同时列出被该会话注册了Watcher的节点路径。 12345678910111213$ echo wchc | nc localhost 21810x15e9aac69320000 /controller /isr_change_notification /admin/preferred_replica_election /admin/reassign_partitions /brokers/ids /admin/delete_topics /brokers/topics/springCloudBus /config/changes /brokers/topics/sleuth /brokers/topics/__consumer_offsets /brokers/topics 10. wchpwchp命令和wchc命令非常类似，也是用于输出当前服务器上管理的Watchers的详细信息，不同点在于wchp命令的输出信息以节点路径为单位进行归组。 1234567891011121314151617181920212223$ echo wchp | nc localhost 2181/controller 0x15e9aac69320000/isr_change_notification 0x15e9aac69320000/admin/preferred_replica_election 0x15e9aac69320000/admin/reassign_partitions 0x15e9aac69320000/brokers/ids 0x15e9aac69320000/admin/delete_topics 0x15e9aac69320000/brokers/topics/springCloudBus 0x15e9aac69320000/config/changes 0x15e9aac69320000/brokers/topics/sleuth 0x15e9aac69320000/brokers/topics/__consumer_offsets 0x15e9aac69320000/brokers/topics 0x15e9aac69320000 11. mntrmntr命令用于输出比stat命令更为详尽的服务器统计信息，包括请求处理的延迟情况、服务器内存数据库大小和集群的数据同步情况。 12345678910111213141516$ echo mntr | nc localhost 2181zk_version 3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMTzk_avg_latency 0zk_max_latency 129zk_min_latency 0zk_packets_received 2060zk_packets_sent 2061zk_num_alive_connections 2zk_outstanding_requests 0zk_server_state standalonezk_znode_count 142zk_watch_count 16zk_ephemerals_count 2zk_approximate_data_size 10973zk_open_file_descriptor_count 97zk_max_file_descriptor_count 10240 12. isroNew in 3.4.0: Tests if server is running in read-only mode. The server will respond with “ro” if in read-only mode or “rw” if not in read-only mode. 12$ echo isro | nc localhost 2181rw 13. gtmkGets the current trace mask as a 64-bit signed long value in decimal format. 12$ echo gtmk | nc localhost 2181306]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：Watcher]]></title>
    <url>%2F2017%2F12%2F07%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9AWatcher%2F</url>
    <content type="text"><![CDATA[ZooKeeper 允许客户端向服务端注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher，那么就会向指定客户端发送一个事件通知来实现分布式的通知功能。 ZooKeeper 的 Watcher 机制主要包括客户端线程、客户端 WatchManager 和 ZooKeeper 服务器三部分。在具体工作流程上，简单地讲，客户端在向 ZooKeeper 服务器注册 Watcher 的同时，会将 Watcher 对象存储在客户端的 WatchManager 中。当 ZooKeeper 服务器端触发 Watcher 事件后，会向客户端发送通知，客户端线程从 WatchManager 中取出对应的 Watcher 对象来执行回调逻辑。 1. Watcher 接口在 ZooKeeper 中，接口类 Watcher 用于表示一个标准的事件处理器，其定义了事件通知相关的逻辑，包含 KeeperState 和 EventType 两个枚举类，分别代表了通知状态和事件类型，同时定义了事件的回调方法：process(WatchedEvent event)。 1.1 Watcher 事件 KeeperState EventType 触发条件 说明 None（-1） 客户端与服务端成功建立连接 NodeCreated（1） Watcher 监听的对应数据节点被创建 SyncConnected（0） NodeDeleted（2） Watcher 监听的对应数据节点被删除 此时客户端和服务器处于连接状态 NodeDataChanged（3） Watcher 监听的对应数据节点的数据内容发生变更 NodeChildChanged（4） Wather 监听的对应数据节点的子节点列表发生变更 Disconnected（0） None（-1） 客户端与 ZooKeeper 服务器断开连接 此时客户端和服务器处于断开连接状态 Expired（-112） Node（-1） 会话超时 此时客户端会话失效，通常同时也会受到 SessionExpiredException 异常 AuthFailed（4） None（-1） 通常有两种情况。（1）使用错误的 schema 进行权限检查 （2）SASL 权限检查失败 通常同时也会收到 AuthFailedException 异常 1.2 回调方法 process()process 方法是 Watcher 接口中的一个回调方法，当 ZooKeeper 向客户端发送一个 Watcher 事件通知时，客户端就会对相应的 process 方法进行回调，从而实现对事件的处理。 org.apache.zookeeper.Watcher#process 1abstract public void process(WatchedEvent event); WatchedEvent 包含了每一个事件的三个基本属性：通知状态（keeperState），事件类型（EventType）和节点路径（path）。 在这里提一下 WathcerEvent 实体。笼统地讲，两者表示的是同一个事物，都是对一个服务端事件的封装。不同的是，WatchedEvent 是一个逻辑事件，用于服务端和客户端程序执行过程中所需的逻辑对象，而 WatcherEvent 因为实现了序列化接口，因此可以用于网络传输。 org.apache.zookeeper.proto.WatcherEvent 12345public class WatcherEvent implements Record &#123; private int type; private int state; private String path;&#125; 服务端在生成 WatchedEvent 事件之后，会调用 getWrapper 方法将自己包装成一个可序列化的 WatcherEvent 事件，以便通过网络传输到客户端。客户端在接收到服务端的这个事件对象后，首先会将 WatcherEvent 还原成一个 WatchedEvent 事件，并传递给 process 方法处理，回调方法 process 根据入参就能够解析出完整的服务端事件了。 2. 工作机制2.1 客户端注册 Watcher在创建一个 ZooKeeper 客户端的实例时可以向构造方法中传入一个默认的 Watcher： 1public ZooKeeper(String connectString，int sessionTimeout,Watcher watcher); 这个 Watcher 将作为整个 ZooKeeper 会话期间的默认 Watcher，会一直被保存在客户端 ZKWatchManager 的 defaultWatcher 中。另外，ZooKeeper 客户端也可以通过 getData，getChildren 和 exist 三个接口来向 ZooKeeper 服务器注册 Watcher，无论使用哪种方式，注册 Watcher 的工作原理都是一致的。 以 org.apache.zookeeper.ZooKeeper#getData(java.lang.String, org.apache.zookeeper.Watcher, org.apache.zookeeper.data.Stat) 为例： 123456789101112131415161718192021222324252627282930public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException &#123; final String clientPath = path; PathUtils.validatePath(clientPath); // the watch contains the un-chroot path WatchRegistration wcb = null; if (watcher != null) &#123; wcb = new DataWatchRegistration(watcher, clientPath); &#125; final String serverPath = prependChroot(clientPath); RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.getData); GetDataRequest request = new GetDataRequest(); request.setPath(serverPath); request.setWatch(watcher != null); GetDataResponse response = new GetDataResponse(); ReplyHeader r = cnxn.submitRequest(h, request, response, wcb); if (r.getErr() != 0) &#123; throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); &#125; if (stat != null) &#123; DataTree.copyStat(response.getStat(), stat); &#125; return response.getData();&#125; 在向 getData 接口注册 Watcher 后，客户端首先会对当前客户端请求 request 进行标记，将其设置为 “使用 Watcher 监听”，同时会封装一个 Watcher 的注册信息 WatchRegistration 对象，用于暂时保存数据节点的路径和 Watcher 的对应关系。 在 ZooKeeper 中，Packet 可以被看作一个最小的通信协议单元，用于进行客户端与服务端之间的网络传输，任何需要传输的对象都需要包装成一个 Packet 对象。因此，在 ClientCnxn 中 WatchRegistration 又会被封装到 Packet 中，然后放入发送队列中等待客户端发送： org.apache.zookeeper.ClientCnxn#submitRequest 12345678910111213public ReplyHeader submitRequest(RequestHeader h, Record request, Record response, WatchRegistration watchRegistration) throws InterruptedException &#123; ReplyHeader r = new ReplyHeader(); Packet packet = queuePacket(h, r, request, response, null, null, null, null, watchRegistration); synchronized (packet) &#123; while (!packet.finished) &#123; packet.wait(); &#125; &#125; return r;&#125; 随后，ZooKeeper 客户端就会向服务端发送这个请求，同时等待请求的返回。完成请求发送后，会由客户端 SendThread 线程的 readResponse 方法负责接收来自服务端的响应，finishPacket 方法会从 Packet 中取出对应的 Watcher 并注册到 ZkWatchManager 中去： org.apache.zookeeper.ClientCnxn#finishPacket 123456789101112131415private void finishPacket(Packet p) &#123; if (p.watchRegistration != null) &#123; p.watchRegistration.register(p.replyHeader.getErr()); &#125; if (p.cb == null) &#123; synchronized (p) &#123; p.finished = true; p.notifyAll(); &#125; &#125; else &#123; p.finished = true; eventThread.queuePacket(p); &#125;&#125; 从上面的内容中，我们已经了解到客户端已经将 Watcher 暂时封装在了 WatchRegistration 对象中，现在就需要从这个封装对象中再次提取出 Watcher 来： org.apache.zookeeper.ZooKeeper.WatchRegistration#register 1234567891011121314abstract protected Map&lt;String, Set&lt;Watcher&gt;&gt; getWatches(int rc);public void register(int rc) &#123; if (shouldAddWatch(rc)) &#123; Map&lt;String, Set&lt;Watcher&gt;&gt; watches = getWatches(rc); synchronized(watches) &#123; Set&lt;Watcher&gt; watchers = watches.get(clientPath); if (watchers == null) &#123; watchers = new HashSet&lt;Watcher&gt;(); watches.put(clientPath, watchers); &#125; watchers.add(watcher); &#125; &#125;&#125; org.apache.zookeeper.ZooKeeper.ZKWatchManager 12345678910private static class ZKWatchManager implements ClientWatchManager &#123; private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); private volatile Watcher defaultWatcher;&#125; 在 register 方法中，客户端会将之前暂时保存的 Watcher 对象转交给 ZKWatchManager，并最终保存到 dataWatches 中去。ZKWatchManager.dataWatches 是一个 Map&lt;String, Set&lt;Watcher&gt;&gt; 类型的数据结构，用于将数据节点的路径和 Watcher 对象进行一一映射后管理起来。 在 Packet.createBB() 中，ZooKeeper 只会将 requestHeader 和 reqeust 两个属性进行序列化，也就是说，尽管 WatchResgistration 被封装在了 Packet 中，但是并没有被序列化到底层字节数组中去，因此也就不会进行网络传输了。 2.2 服务端处理 Watcher2.2.1 服务端注册 Watcher服务端收到来自客户端的请求后，在 org.apache.zookeeper.server.FinalRequestProcessor#processRequest 中会判断当前请求是否需要注册 Watcher： 1234567891011121314case OpCode.getData: &#123; lastOp = "GETD"; GetDataRequest getDataRequest = new GetDataRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, getDataRequest); DataNode n = zks.getZKDatabase().getNode(getDataRequest.getPath()); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n), ZooDefs.Perms.READ, request.authInfo); Stat stat = new Stat(); byte b[] = zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); rsp = new GetDataResponse(b, stat); break;&#125; 从 getData 请求的处理逻辑中，我们可以看到，当 getDataRequest.getWatch() 为 true 的时候，ZooKeeper 就认为当前客户端请求需要进行 Watcher 注册，于是就会将当前的 ServerCnxn 对象作为一个 Watcher 连同数据节点路径传入 getData 方法中去。注意到，抽象类 ServerCnxn 实现了 Watcher 接口。 数据节点的节点路径和 ServerCnxn 最终会被存储在 WatcherManager 的 watchTable 和 watch2Paths 中。WatchManager 是 ZooKeeper 服务端 Watcher 的管理者，其内部管理的 watchTable 和 watch2Pashs 两个存储结构，分别从两个维度对 Watcher 进行存储。 watchTable 是从数据节点路径的粒度来托管 Watcher。 watch2Paths 是从 Watcher 的粒度来控制事件触发需要触发的数据节点。 org.apache.zookeeper.server.WatchManager#addWatch 12345678910111213141516171819public synchronized void addWatch(String path, Watcher watcher) &#123; HashSet&lt;Watcher&gt; list = watchTable.get(path); if (list == null) &#123; // don't waste memory if there are few watches on a node // rehash when the 4th entry is added, doubling size thereafter // seems like a good compromise list = new HashSet&lt;Watcher&gt;(4); watchTable.put(path, list); &#125; list.add(watcher); HashSet&lt;String&gt; paths = watch2Paths.get(watcher); if (paths == null) &#123; // cnxns typically have many watches, so use default cap here paths = new HashSet&lt;String&gt;(); watch2Paths.put(watcher, paths); &#125; paths.add(path);&#125; 2.2.2 Watcher 触发org.apache.zookeeper.server.DataTree#setData 12345678910111213141516171819202122232425public Stat setData(String path, byte data[], int version, long zxid, long time) throws KeeperException.NoNodeException &#123; Stat s = new Stat(); DataNode n = nodes.get(path); if (n == null) &#123; throw new KeeperException.NoNodeException(); &#125; byte lastdata[] = null; synchronized (n) &#123; lastdata = n.data; n.data = data; n.stat.setMtime(time); n.stat.setMzxid(zxid); n.stat.setVersion(version); n.copyStat(s); &#125; // now update if the path is in a quota subtree. String lastPrefix; if((lastPrefix = getMaxPrefixWithQuota(path)) != null) &#123; this.updateBytes(lastPrefix, (data == null ? 0 : data.length) - (lastdata == null ? 0 : lastdata.length)); &#125; dataWatches.triggerWatch(path, EventType.NodeDataChanged); return s;&#125; 在对指定节点进行数据更新后，通过调用 org.apache.zookeeper.server.WatchManager#triggerWatch方法来触发相关的事件： 1234567891011121314151617181920212223public Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) &#123; WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); HashSet&lt;Watcher&gt; watchers; synchronized (this) &#123; watchers = watchTable.remove(path); if (watchers == null || watchers.isEmpty()) &#123; return null; &#125; for (Watcher w : watchers) &#123; HashSet&lt;String&gt; paths = watch2Paths.get(w); if (paths != null) &#123; paths.remove(path); &#125; &#125; &#125; for (Watcher w : watchers) &#123; if (supress != null &amp;&amp; supress.contains(w)) &#123; continue; &#125; w.process(e); &#125; return watchers;&#125; 无论是 dataWatches 还是 childWatches 管理器，Watcher 的触发逻辑都是一致的，基本步骤如下。 封装 WatchedEvent。 首先将通知状态（KeeperState）、事件类型（EventType）以及节点路径（Path）封装成一个 WatchedEvent 对象。 查询 Watcher。 根据数据节点的节点路径从 watchTable 中取出对应的 Watcher。如果没有找到 Watcher，说明没有任何客户端在该数据节点上注册过 Watcher，直接退出。而如果找到了这个 Watcher，会将其提取出来，同时会直接从 watchTable 和 watch2Paths 中将其删除——从这里我们也可以看出，Watcher 在服务端是一次性的，即触发一次就失效了。 调用 process 方法来触发 Watcher。 在这一步中，会逐个依次地调用从步骤2中找出的所有 Watcher 的 process 方法。这里的 process 方法，事实上就是 ServerCnxn 的对应方法： org.apache.zookeeper.server.NIOServerCnxn#process 12345678@Overridesynchronized public void process(WatchedEvent event) &#123; ReplyHeader h = new ReplyHeader(-1, -1L, 0); // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); sendResponse(h, e, "notification");&#125; 在 process 方法中，主要逻辑如下。 在请求头中标记 “-1”，表明当前是一个通知。 将 WawtchedEvent 包装成 WatcherEvent，以便进行网络传输序列化。 向客户端发送该通知。 3. 客户端回调 Watcher3.1 SendThread 接收事件通知对于一个来自服务端的响应，客户端都是由 org.apache.zookeeper.ClientCnxn.SendThread#readResponse 方法来统一进行处理的，如果响应头 replyHdr 中标识了 XID 为 -1，表明这是一个通知类型的响应。 12345678910111213141516171819202122if (replyHdr.getXid() == -1) &#123; // -1 means notification WatcherEvent event = new WatcherEvent(); event.deserialize(bbia, "response"); // convert from a server path to a client path if (chrootPath != null) &#123; String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath("/"); else if (serverPath.length() &gt; chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else &#123; LOG.warn("Got server path " + event.getPath() + " which is too short for chroot path " + chrootPath); &#125; &#125; WatchedEvent we = new WatchedEvent(event); eventThread.queueEvent( we ); return;&#125; 处理过程大体上分为以下 4 个主要步骤： 反序列化。 将字节流转换成 WatcherEvent 对象。 处理 chrootPath。 如果客户端设置了 chrootPath 属性，那么需要对服务端传过来的完整的节点路径进行 chrootPath 处理，生成客户端的一个相对节点路径。 还原 WatchedEvent。 将 WatcherEvent 对象转换成 WatchedEvent。 回调 Watcher。 将 WatchedEvent 对象交给 EventThread 线程，在下一个轮询周期中进行 Watcher 回调。 3.2 EventThread 处理事件通知SendThread 接收到服务端的通知事件后，会通过调用 EventThread.queueEvent 方法将事件传给 EventThread 线程，其逻辑如下： org.apache.zookeeper.ClientCnxn.EventThread#queueEvent 12345678910111213public void queueEvent(WatchedEvent event) &#123; if (event.getType() == EventType.None &amp;&amp; sessionState == event.getState()) &#123; return; &#125; sessionState = event.getState(); // materialize the watchers based on the event WatcherSetEventPair pair = new WatcherSetEventPair( watcher.materialize(event.getState(), event.getType(),event.getPath()), event); // queue the pair (watch set &amp; event) for later processing waitingEvents.add(pair);&#125; queueEvent 方法首先会根据该通知事件，从 ZKWatchManager 中取出所有相关的 Watcher： 123456789101112131415161718192021 @Override public Set&lt;Watcher&gt; materialize(Watcher.Event.KeeperState state, Watcher.Event.EventType type, String clientPath) &#123; Set&lt;Watcher&gt; result = new HashSet&lt;Watcher&gt;(); switch (type) &#123; // ... case NodeDataChanged: case NodeCreated: synchronized (dataWatches) &#123; addTo(dataWatches.remove(clientPath), result); &#125; synchronized (existWatches) &#123; addTo(existWatches.remove(clientPath), result); &#125; break; // ... &#125; return result; &#125;&#125; 客户端在识别出事件类型 EventType 后，会从相应的 Watcher 存储（即 dataWatches，existWatches 或 childWatches 中的一个或多个）中去除对应的 Watcher。注意，此处使用的是 remove 接口，因此也表明了客户端的 Watcher 机制同样也是一次性的，即一旦被触发后，该 Watcher 就失效了。 获取到相关的所有 Watcher 后，会将其放入 waitingEvents 这个队列中去。WaitingEvents 是一个待处理 Watcher 队列，EventThread 的 run 方法会不断对该队列进行处理。EventThread 线程每次都会从 waitingEvents 队列中取出一个 Watcher，并进行串行同步处理。注意，此处 processEvent 方法中的 Watcher 才是之前客户端真正注册的 Watcher，调用其 process 方法就可以实现 Watcher 的回调了。 4. 自问自答4.1 连接中断时，客户端如何处理？ 客户端抛出 EndOfStreamException 异常，此时客户端状态还是 CONNECTED。 SendThread 处理异常，清理连接，将当前所有请求置为失败，错误码是 CONNECTIONLOSS。 org.apache.zookeeper.ClientCnxn.SendThread#cleanup 123456789101112131415private void cleanup() &#123; clientCnxnSocket.cleanup(); synchronized (pendingQueue) &#123; for (Packet p : pendingQueue) &#123; conLossPacket(p); &#125; pendingQueue.clear(); &#125; synchronized (outgoingQueue) &#123; for (Packet p : outgoingQueue) &#123; conLossPacket(p); &#125; outgoingQueue.clear(); &#125;&#125; org.apache.zookeeper.ClientCnxn#conLossPacket 12345678910111213141516private void conLossPacket(Packet p) &#123; if (p.replyHeader == null) &#123; return; &#125; switch (state) &#123; case AUTH_FAILED: p.replyHeader.setErr(KeeperException.Code.AUTHFAILED.intValue()); break; case CLOSED: p.replyHeader.setErr(KeeperException.Code.SESSIONEXPIRED.intValue()); break; default: p.replyHeader.setErr(KeeperException.Code.CONNECTIONLOSS.intValue()); &#125; finishPacket(p);&#125; 创建 None-Disconnected 事件，发送给 EventThread。此时 ZooKeeper 客户端仍持有之前注册的所有 Watcher。 4.2 客户端如何在重连后重新向服务器注册 Watcher？ SendThread 选下一个服务器地址请求 TCP 连接。 连上之后发送 ConnectRequest，其中 sessionid 和 password是当前会话的数据。 假设客户端重试比较快，session 还没超时，则服务端返回连接成功的 ConnectResponse 。（反之若 session 过期，则校验失败，客户端会抛出 SessionExpired 异常并退出。 客户端收到相应，发送 SyncConnected 事件。 客户端发送 SetWatches 请求，重建 Watcher。这个包实际上是在 SendThread 调用 org.apache.zookeeper.ClientCnxn.SendThread#primeConnection 方法时，和 ConnectRequest 请求先后添加到发送队列中的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void primeConnection() throws IOException &#123; isFirstConnect = false; long sessId = (seenRwServerBefore) ? sessionId : 0; ConnectRequest conReq = new ConnectRequest(0, lastZxid, sessionTimeout, sessId, sessionPasswd); synchronized (outgoingQueue) &#123; // We add backwards since we are pushing into the front // Only send if there's a pending watch // TODO: here we have the only remaining use of zooKeeper in // this class. It's to be eliminated! if (!disableAutoWatchReset) &#123; List&lt;String&gt; dataWatches = zooKeeper.getDataWatches(); List&lt;String&gt; existWatches = zooKeeper.getExistWatches(); List&lt;String&gt; childWatches = zooKeeper.getChildWatches(); if (!dataWatches.isEmpty() || !existWatches.isEmpty() || !childWatches.isEmpty()) &#123; Iterator&lt;String&gt; dataWatchesIter = prependChroot(dataWatches).iterator(); Iterator&lt;String&gt; existWatchesIter = prependChroot(existWatches).iterator(); Iterator&lt;String&gt; childWatchesIter = prependChroot(childWatches).iterator(); long setWatchesLastZxid = lastZxid; while (dataWatchesIter.hasNext() || existWatchesIter.hasNext() || childWatchesIter.hasNext()) &#123; List&lt;String&gt; dataWatchesBatch = new ArrayList&lt;String&gt;(); List&lt;String&gt; existWatchesBatch = new ArrayList&lt;String&gt;(); List&lt;String&gt; childWatchesBatch = new ArrayList&lt;String&gt;(); int batchLength = 0; // Note, we may exceed our max length by a bit when we add the last // watch in the batch. This isn't ideal, but it makes the code simpler. while (batchLength &lt; SET_WATCHES_MAX_LENGTH) &#123; final String watch; if (dataWatchesIter.hasNext()) &#123; watch = dataWatchesIter.next(); dataWatchesBatch.add(watch); &#125; else if (existWatchesIter.hasNext()) &#123; watch = existWatchesIter.next(); existWatchesBatch.add(watch); &#125; else if (childWatchesIter.hasNext()) &#123; watch = childWatchesIter.next(); childWatchesBatch.add(watch); &#125; else &#123; break; &#125; batchLength += watch.length(); &#125; SetWatches sw = new SetWatches(setWatchesLastZxid, dataWatchesBatch, existWatchesBatch, childWatchesBatch); RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.setWatches); h.setXid(-8); Packet packet = new Packet(h, new ReplyHeader(), sw, null, null); outgoingQueue.addFirst(packet); &#125; &#125; &#125; for (AuthData id : authInfo) &#123; outgoingQueue.addFirst(new Packet(new RequestHeader(-4, OpCode.auth), null, new AuthPacket(0, id.scheme, id.data), null, null)); &#125; outgoingQueue.addFirst(new Packet(null, null, conReq, null, null, readOnly)); &#125; clientCnxnSocket.enableReadWriteOnly();&#125; 服务端处理 SetWatches 请求。]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《从 Paxos 到 ZooKeeper：分布式一致性原理与实践》：序列化与协议]]></title>
    <url>%2F2017%2F12%2F06%2F%E3%80%8A%E4%BB%8E%20Paxos%20%E5%88%B0%20ZooKeeper%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[1. 使用 Jute 进行序列化使用 Jute 来对对象进行序列化和反序列化，大体可以分为 4 步： 实体类需要实现 Record 接口的 serialize 和 deserialize 方法。 构建一个序列化器 ByteOutputArchive。 调用实体类的 serialize 方法，将对象序列化到指定 tag 中去。 调用实体类的 deserialize 方法，从指定的 tag 中反序列化出数据内容。 2. 深入 Jute2.1 Record 接口Jute 定义了自己独特的序列化格式 Record。 org.apache.jute.Record 123456public interface Record &#123; public void serialize(OutputArchive archive, String tag) throws IOException; public void deserialize(InputArchive archive, String tag) throws IOException;&#125; 所有实体类通过实现 Record 接口的这两个方法，来定义自己将如何被序列化和反序列化。其中 archive 是底层真正的序列化器和反序列化器，并且每个 archive 中可以包含对多个对象的序列化和反序列化，因此两个接口方法中都标记了参数 tag，用于向序列化器和反序列化器标识对象自己的标记。 OutputArchive 和 InputArchive 分别是 Jute 底层的序列化器和反序列化器接口定义。在最新版本的 Jute 中，分别有 BinaryOutputArchive/BinaryInputArchive、CsvoutputArchive/CsvInputArchive 和 XmlOutputArchive/XmlInputArchive 三种实现。无论哪种实现，都是基于 OutputStream 和 InputStream 进行操作。 3. 通信协议基于 TCP/IP 协议，ZooKeeper 实现了自己的通信协议来完成客户端与服务端、服务端与服务端之间的网络通信。ZooKeeper 通信协议整体上的设计非常简单，对于请求，主要包含请求头和请求体，而对于响应，则主要包含响应头和响应体。 3.1 协议解析：请求部分3.1.1 请求头：RequestHeaderorg.apache.zookeeper.proto.RequestHeader 1234public class RequestHeader implements Record &#123; private int xid; private int type; &#125; xid 用于记录客户端请求发起的先后序号，用来确保单个客户端请求的响应顺序。type 代表请求的操作类型，所有操作类型都被定义在类 org.apache.zookeeper.ZooDefs.OpCode 中。根据协议规定，除非是会话创建请求，其他所有的客户端请求中都会带上请求头。 3.1.2 请求体：Request协议的请求体部分是指请求的主体内容部分，包含了请求的所有操作内容。不同的请求类型，其请求体部分的结构是不同的。 org.apache.zookeeper.proto.GetDataRequest 1234public class GetDataRequest implements Record &#123; private String path; private boolean watch; &#125; 3.2 协议解析：响应部分3.2.1 响应头：ReplyHeaderorg.apache.zookeeper.proto.ReplyHeader 12345class ReplyHeader implements Record &#123; int xid; long zxid; int err; &#125; xid 与请求头中的xid一致，zxid 表示 ZooKeeper 服务器上当前最新的事务 ID，err 则是一个错误码，当请求处理过程中出现异常情况时，会在这个错误码中标识出来， 3.2.2 响应体：Response协议的响应体部分包含了响应的所有返回数据，不同的响应类型，其响应体部分的结构是不同的。 org.apache.zookeeper.proto.GetDataResponse 1234class GetDataResponse implements Record &#123; private byte[] data; private org.apache.zookeeper.data.Stat stat;&#125;]]></content>
      <categories>
        <category>ZooKeeper</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：慢查询日志和监视器》]]></title>
    <url>%2F2017%2F10%2F22%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E5%92%8C%E7%9B%91%E8%A7%86%E5%99%A8%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 慢查询日志Redis 的慢查询日志功能用于记录执行时间超过给定时长的命令请求，用户可以通过这个功能产生的日志来监视和优化查询速度。 服务器配置有两个和慢查询日志相关的选项： slowlog-log-slower-than 选项指定执行时间超过多少微秒（1 秒等于 1,000,000 微秒）的命令请求会被记录到日志上。 slowlog-max-len 选项指定服务器最多保存多少条慢查询日志。 服务器使用先进先出的方式保存多条慢查询日志：当服务器储存的慢查询日志数量等于 slowlog-max-len 选项的值时，服务器在添加一条新的慢查询日志之前，会先将最旧的一条慢查询日志删除。 1.1 慢查询记录的保存服务器状态中包含了几个和慢查询日志功能有关的属性： 12345678910111213141516171819struct redisServer &#123; // ... // 下一条慢查询日志的 ID long long slowlog_entry_id; // 保存了所有慢查询日志的链表 list *slowlog; // 服务器配置 slowlog-log-slower-than 选项的值 long long slowlog_log_slower_than; // 服务器配置 slowlog-max-len 选项的值 unsigned long slowlog_max_len; // ...&#125;; slowlog_entry_id 属性的初始值为 0 ，每当创建一条新的慢查询日志时，这个属性的值就会用作新日志的 id 值，之后程序会对这个属性的值增一。 slowlog 链表保存了服务器中的所有慢查询日志， 链表中的每个节点都保存了一个 slowlogEntry 结构， 每个 slowlogEntry 结构代表一条慢查询日志： 123456789101112131415161718typedef struct slowlogEntry &#123; // 唯一标识符 long long id; // 命令执行时的时间，格式为 UNIX 时间戳 time_t time; // 执行命令消耗的时间，以微秒为单位 long long duration; // 命令与命令参数 robj **argv; // 命令与命令参数的数量 int argc;&#125; slowlogEntry; 1.2 慢查询日志的阅览和删除可以使用 SLOWLOG GET 命令查看服务器所保存的慢查询日志，伪代码如下： 12345678910111213141516171819def SLOWLOG_GET(number=None): # 用户没有给定 number 参数 # 那么打印服务器包含的全部慢查询日志 if number is None: number = SLOWLOG_LEN() # 遍历服务器中的慢查询日志 for log in redisServer.slowlog: if number &lt;= 0: # 打印的日志数量已经足够，跳出循环 break else: # 继续打印，将计数器的值减一 number -= 1 # 打印日志 printLog(log) 查看日志数量的 SLOWLOG LEN 命令可以用以下伪代码来定义： 1234def SLOWLOG_LEN(): # slowlog 链表的长度就是慢查询日志的条目数量 return len(redisServer.slowlog) 另外，用于清除所有慢查询日志的 SLOWLOG RESET 命令可以用以下伪代码来定义： 1234567def SLOWLOG_RESET(): # 遍历服务器中的所有慢查询日志 for log in redisServer.slowlog: # 删除日志 deleteLog(log) 1.3 添加新日志在每次执行命令的之前和之后，程序都会记录微秒格式的当前 UNIX 时间戳，这两个时间戳之间的差就是服务器执行命令所耗费的时长，服务器会将这个时长作为参数之一传给 slowlogPushEntryIfNeeded 函数，而 slowlogPushEntryIfNeeded 函数则负责检查是否需要为这次执行的命令创建慢查询日志，以下伪代码展示了这一过程： 1234567891011# 记录执行命令前的时间before = unixtime_now_in_us()# 执行命令execute_command(argv, argc, client)# 记录执行命令后的时间after = unixtime_now_in_us()# 检查是否需要创建新的慢查询日志slowlogPushEntryIfNeeded(argv, argc, before-after) slowlogPushEntryIfNeeded 函数的作用有两个： 检查命令的执行时长是否超过 slowlog-log-slower-than 选项所设置的时间，如果是的话，就为命令创建一个新的日志，并将新日志添加到 slowlog 链表的表头。 检查慢查询日志的长度是否超过 slowlog-max-len 选项所设置的长度，如果是的话，那么将多出来的日志从 slowlog 链表中删除掉。 以下是 slowlogPushEntryIfNeeded 函数的实现代码： 1234567891011121314void slowlogPushEntryIfNeeded(robj **argv, int argc, long long duration) &#123; // 慢查询功能未开启，直接返回 if (server.slowlog_log_slower_than &lt; 0) return; // 如果执行时间超过服务器设置的上限，那么将命令添加到慢查询日志 if (duration &gt;= server.slowlog_log_slower_than) // 新日志添加到链表表头 listAddNodeHead(server.slowlog,slowlogCreateEntry(argv,argc,duration)); // 如果日志数量过多，那么进行删除 while (listLength(server.slowlog) &gt; server.slowlog_max_len) listDelNode(server.slowlog,listLast(server.slowlog));&#125; slowlogCreateEntry 函数根据传入的参数，创建一个新的慢查询日志，并将 redisServer.slowlog_entry_id 的值增一。 2. 监视器通过执行 MONITOR 命令，客户端可以将自己变为一个监视器，实时地接收并打印出服务器当前处理的命令请求的相关信息： 123456789redis&gt; MONITOROK1378822099.421623 [0 127.0.0.1:56604] &quot;PING&quot;1378822105.089572 [0 127.0.0.1:56604] &quot;SET&quot; &quot;msg&quot; &quot;hello world&quot;1378822109.036925 [0 127.0.0.1:56604] &quot;SET&quot; &quot;number&quot; &quot;123&quot;1378822140.649496 [0 127.0.0.1:56604] &quot;SADD&quot; &quot;fruits&quot; &quot;Apple&quot; &quot;Banana&quot; &quot;Cherry&quot;1378822154.117160 [0 127.0.0.1:56604] &quot;EXPIRE&quot; &quot;msg&quot; &quot;10086&quot;1378822257.329412 [0 127.0.0.1:56604] &quot;KEYS&quot; &quot;*&quot;1378822258.690131 [0 127.0.0.1:56604] &quot;DBSIZE&quot; 每当一个客户端向服务器发送一条命令请求时，服务器除了会处理这条命令请求之外，还会将关于这条命令请求的信息发送给所有监视器。 2.1 成为监视器发送 MONITOR 命令可以让一个普通客户端变为一个监视器，该命令的实现原理可以用以下伪代码来实现： 12345678910def MONITOR(): # 打开客户端的监视器标志 client.flags |= REDIS_MONITOR # 将客户端添加到服务器状态的 monitors 链表的末尾 server.monitors.append(client) # 向客户端返回 OK send_reply(&quot;OK&quot;) 2.2 向监视器发送命令信息服务器在每次处理命令请求之前，都会调用 replicationFeedMonitors 函数，由这个函数将被处理命令请求的相关信息发送给各个监视器。 以下是 replicationFeedMonitors 函数的伪代码定义，函数首先根据传入的参数创建信息，然后将信息发送给所有监视器： 1234567891011def replicationFeedMonitors(client, monitors, dbid, argv, argc): # 根据执行命令的客户端、当前数据库的号码、命令参数、命令参数个数等参数 # 创建要发送给各个监视器的信息 msg = create_message(client, dbid, argv, argc) # 遍历所有监视器 for monitor in monitors: # 将信息发送给监视器 send_message(monitor, msg)]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：客户端》]]></title>
    <url>%2F2017%2F10%2F21%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%8B%2F</url>
    <content type="text"><![CDATA[Redis 服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令请求，而服务器则接收并处理客户端发送的命令请求，并向客户端返回命令回复。 通过使用由 I/O 多路复用技术实现的文件事件处理器，Redis 服务器使用单线程单进程的方式来处理命令请求，并与多个客户端进行网络通信。 对于每个与服务器进行连接的客户端，服务器都为这些客户端建立了相应的 redis.h/redisClient 结构（客户端状态），这个结构保存了客户端当前的状态信息，以及执行相关功能时需要用到的数据结构： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* With multiplexing we need to take per-client state. * Clients are taken in a linked list. */typedef struct redisClient &#123; uint64_t id; /* Client incremental unique ID. */ int fd; redisDb *db; int dictid; robj *name; /* As set by CLIENT SETNAME */ sds querybuf; size_t querybuf_peak; /* Recent (100ms or more) peak of querybuf size */ int argc; robj **argv; struct redisCommand *cmd, *lastcmd; int reqtype; int multibulklen; /* number of multi bulk arguments left to read */ long bulklen; /* length of bulk argument in multi bulk request */ list *reply; unsigned long reply_bytes; /* Tot bytes of objects in reply list */ int sentlen; /* Amount of bytes already sent in the current buffer or object being sent. */ time_t ctime; /* Client creation time */ time_t lastinteraction; /* time of the last interaction, used for timeout */ time_t obuf_soft_limit_reached_time; int flags; /* REDIS_SLAVE | REDIS_MONITOR | REDIS_MULTI ... */ int authenticated; /* when requirepass is non-NULL */ int replstate; /* replication state if this is a slave */ int repl_put_online_on_ack; /* Install slave write handler on ACK. */ int repldbfd; /* replication DB file descriptor */ off_t repldboff; /* replication DB file offset */ off_t repldbsize; /* replication DB file size */ sds replpreamble; /* replication DB preamble. */ long long reploff; /* replication offset if this is our master */ long long repl_ack_off; /* replication ack offset, if this is a slave */ long long repl_ack_time;/* replication ack time, if this is a slave */ long long psync_initial_offset; /* FULLRESYNC reply offset other slaves copying this slave output buffer should use. */ char replrunid[REDIS_RUN_ID_SIZE+1]; /* master run id if this is a master */ int slave_listening_port; /* As configured with: SLAVECONF listening-port */ int slave_capa; /* Slave capabilities: SLAVE_CAPA_* bitwise OR. */ multiState mstate; /* MULTI/EXEC state */ blockingState bpop; /* blocking state */ list *watched_keys; /* Keys WATCHED for MULTI/EXEC CAS */ dict *pubsub_channels; /* channels a client is interested in (SUBSCRIBE) */ list *pubsub_patterns; /* patterns a client is interested in (SUBSCRIBE) */ sds peerid; /* Cached peer ID. */ /* Response buffer */ int bufpos; char buf[REDIS_REPLY_CHUNK_BYTES];&#125; redisClient; Redis 服务器状态结构的 clients 属性是一个链表，这个链表保存了所有与服务器连接的客户端的状态结构，对客户端执行批量操作，或者查找某个指定的客户端，都可以通过遍历 clients 链表来完成： 12345678910struct redisServer &#123; // ... // 一个链表，保存了所有客户端状态 list *clients; // ... &#125; 1. 客户端属性1.1 套接字描述符客户端状态的 fd 属性记录了客户端正在使用的套接字描述符： 123456789typedef struct redisClient &#123; // ... int fd; // ...&#125; redisClient; 根据客户端类型的不同，fd 属性的值可以是 -1 或者是大于 -1 的整数： 伪客户端（fake client）的 fd 属性的值为 -1 ：伪客户端处理的命令请求来源于 AOF 文件或者 Lua 脚本，而不是网络，所以这种客户端不需要套接字连接，自然也不需要记录套接字描述符。目前 Redis 服务器会在两个地方用到伪客户端，一个用于载入 AOF 文件并还原数据库状态，而另一个则用于执行 Lua 脚本中包含的 Redis 命令。 普通客户端的 fd 属性的值为大于 -1 的整数：普通客户端使用套接字来与服务器进行通讯，所以服务器会用 fd 属性来记录客户端套接字的描述符。因为合法的套接字描述符不能是 -1 ，所以普通客户端的套接字描述符的值必然是大于 -1 的整数。 执行 CLIENT_LIST 命令可以列出目前所有连接到服务器的普通客户端，命令输出中的 fd 域显示了服务器连接客户端所使用的套接字描述符： 1234redis&gt; CLIENT listaddr=127.0.0.1:53428 fd=6 name= age=1242 idle=0 ...addr=127.0.0.1:53469 fd=7 name= age=4 idle=4 ... 1.2 名字在默认情况下，一个连接到服务器的客户端是没有名字的。使用 CLIENT_SETNAME 命令可以为客户端设置一个名字，让客户端的身份变得更清晰。 客户端的名字记录在客户端状态的 name 属性里面： 123456789typedef struct redisClient &#123; // ... robj *name; // ...&#125; redisClient; 如果客户端没有为自己设置名字，那么相应客户端状态的 name 属性指向 NULL 指针；相反地，如果客户端为自己设置了名字，那么 name 属性将指向一个字符串对象，而该对象就保存着客户端的名字。 1.3 标志客户端的标志属性 flags 记录了客户端的角色（role），以及客户端目前所处的状态： 123456789typedef struct redisClient &#123; // ... int flags; // ...&#125; redisClient; flags 属性的值可以是单个标志： 1flags = &lt;flag&gt; 也可以是多个标志的二进制或，比如： 1flags = &lt;flag1&gt; | &lt;flag2&gt; | ... 每个标志使用一个常量表示，一部分标志记录了客户端的角色： 在主从服务器进行复制操作时，主服务器会成为从服务器的客户端，而从服务器也会成为主服务器的客户端。REDIS_MASTER 标志表示客户端代表的是一个主服务器，REDIS_SLAVE 标志表示客户端代表的是一个从服务器。 REDIS_PRE_PSYNC 标志表示客户端代表的是一个版本低于 Redis 2.8 的从服务器，主服务器不能使用 PSYNC 命令与这个从服务器进行同步。这个标志只能在 REDIS_SLAVE 标志处于打开状态时使用。 REDIS_LUA_CLIENT 标识表示客户端是专门用于处理 Lua 脚本里面包含的 Redis 命令的伪客户端。 而另外一部分标志则记录了客户端目前所处的状态： REDIS_MONITOR 标志表示客户端正在执行 MONITOR 命令。 REDIS_UNIX_SOCKET 标志表示服务器使用 UNIX 套接字来连接客户端。 REDIS_BLOCKED 标志表示客户端正在被 BRPOP 、BLPOP 等命令阻塞。 REDIS_UNBLOCKED 标志表示客户端已经从 REDIS_BLOCKED 标志所表示的阻塞状态中脱离出来， 不再阻塞。 REDIS_UNBLOCKED 标志只能在 REDIS_BLOCKED 标志已经打开的情况下使用。 REDIS_MULTI 标志表示客户端正在执行事务。 REDIS_DIRTY_CAS 标志表示事务使用 WATCH 命令监视的数据库键已经被修改， REDIS_DIRTY_EXEC 标志表示事务在命令入队时出现了错误，以上两个标志都表示事务的安全性已经被破坏，只要这两个标记中的任意一个被打开，EXEC 命令必然会执行失败。这两个标志只能在客户端打开了 REDIS_MULTI 标志的情况下使用。 REDIS_CLOSE_ASAP 标志表示客户端的输出缓冲区大小超出了服务器允许的范围，服务器会在下一次执行 serverCron 函数时关闭这个客户端，以免服务器的稳定性受到这个客户端影响。积存在输出缓冲区中的所有内容会直接被释放，不会返回给客户端。 REDIS_CLOSE_AFTER_REPLY 标志表示有用户对这个客户端执行了 CLIENT_KILL 命令，或者客户端发送给服务器的命令请求中包含了错误的协议内容。服务器会将客户端积存在输出缓冲区中的所有内容发送给客户端，然后关闭客户端。 REDIS_ASKING 标志表示客户端向集群节点（运行在集群模式下的服务器）发送了 ASKING 命令。 REDIS_FORCE_AOF 标志强制服务器将当前执行的命令写入到 AOF 文件里面，REDIS_FORCE_REPL 标志强制主服务器将当前执行的命令复制给所有从服务器。执行 PUBSUB 命令会使客户端打开 REDIS_FORCE_AOF 标志，执行 SCRIPT_LOAD 命令会使客户端打开 REDIS_FORCE_AOF 标志和 REDIS_FORCE_REPL 标志。 在主从服务器进行命令传播期间，从服务器需要向主服务器发送 REPLICATION ACK 命令，在发送这个命令之前，从服务器必须打开主服务器对应的客户端的 REDIS_MASTER_FORCE_REPLY 标志，否则发送操作会被拒绝执行。 以上提到的所有标志都定义在 redis.h 文件里面。 通常情况下，Redis 只会将那些对数据库进行了修改的命令写入到 AOF 文件，并复制到各个从服务器：如果一个命令没有对数据库进行任何修改，那么它就会被认为是只读命令，这个命令不会被写入到 AOF 文件，也不会被复制到从服务器。 以上规则适用于绝大部分 Redis 命令，但 PUBSUB 命令和 SCRIPT_LOAD 命令是其中的例外。 PUBSUB 命令虽然没有修改数据库，但 PUBSUB 命令向频道的所有订阅者发送消息这一行为带有副作用，接收到消息的所有客户端的状态都会因为这个命令而改变。因此，服务器需要使用 REDIS_FORCE_AOF 标志，强制将这个命令写入 AOF 文件，这样在将来载入 AOF 文件时，服务器就可以再次执行相同的 PUBSUB 命令，并产生相同的副作用。 SCRIPT_LOAD 命令的情况与 PUBSUB 命令类似：虽然 SCRIPT_LOAD 命令没有修改数据库，但它修改了服务器状态，所以它是一个带有副作用的命令，服务器需要使用 REDIS_FORCE_AOF 标志，强制将这个命令写入 AOF 文件，使得将来在载入 AOF 文件时，服务器可以产生相同的副作用。 另外，为了让主服务器和从服务器都可以正确地载入 SCRIPT_LOAD 命令指定的脚本，服务器需要使用 REDIS_FORCE_REPL 标志，强制将 SCRIPT_LOAD 命令复制给所有从服务器。 1.4 输入缓冲区客户端状态的输入缓冲区用于保存客户端发送的命令请求： 123456789typedef struct redisClient &#123; // ... sds querybuf; // ...&#125; redisClient; 输入缓冲区的大小会根据输入内容动态地缩小或者扩大，但它的最大大小不能超过 1 GB ，否则服务器将关闭这个客户端。 1.5 命令与命令参数在服务器将客户端发送的命令请求保存到客户端状态的 querybuf 属性之后， 服务器将对命令请求的内容进行分析，并将得出的命令参数以及命令参数的个数分别保存到客户端状态的 argv 属性和 argc 属性： 1234567891011typedef struct redisClient &#123; // ... robj **argv; int argc; // ...&#125; redisClient; argv 属性是一个数组，数组中的每个项都是一个字符串对象：其中 argv[0] 是要执行的命令，而之后的其他项则是传给命令的参数。 argc 属性则负责记录 argv 数组的长度。 1.6 命令的实现函数当服务器从协议内容中分析并得出 argv 属性和 argc 属性的值之后，服务器将根据项 argv[0] 的值， 在命令表中查找命令所对应的命令实现函数。 命令表是一个字典，字典的键是一个 SDS 结构，保存了命令的名字，字典的值是命令所对应的 redisCommand 结构，这个结构保存了命令的实现函数、命令的标志、命令应该给定的参数个数、命令的总执行次数和总消耗时长等统计信息。 当程序在命令表中成功找到 argv[0] 所对应的 redisCommand 结构时，它会将客户端状态的 cmd 指针指向这个结构： 123456789typedef struct redisClient &#123; // ... struct redisCommand *cmd; // ...&#125; redisClient; 之后，服务器就可以使用 cmd 属性所指向的 redisCommand 结构，以及 argv 、argc 属性中保存的命令参数信息，调用命令实现函数，执行客户端指定的命令。 针对命令表的查找操作不区分输入字母的大小写。 1.7 输出缓冲区执行命令所得的命令回复会被保存在客户端状态的输出缓冲区里面，每个客户端都有两个输出缓冲区可用，一个缓冲区的大小是固定的，另一个缓冲区的大小是可变的： 固定大小的缓冲区用于保存那些长度比较小的回复，比如 OK 、简短的字符串值、整数值、错误回复，等等。 可变大小的缓冲区用于保存那些长度比较大的回复，比如一个非常长的字符串值，一个由很多项组成的列表，一个包含了很多元素的集合，等等。 客户端的固定大小缓冲区由 buf 和 bufpos 两个属性组成： 1234567891011typedef struct redisClient &#123; // ... char buf[REDIS_REPLY_CHUNK_BYTES]; int bufpos; // ...&#125; redisClient; buf 是一个大小为 REDIS_REPLY_CHUNK_BYTES 字节的字节数组，而 bufpos 属性则记录了 buf 数组目前已使用的字节数量。 REDIS_REPLY_CHUNK_BYTES 常量目前的默认值为 16*1024 ，也即是说，buf 数组的默认大小为 16 KB 。 当 buf 数组的空间已经用完，或者回复因为太大而没办法放进 buf 数组里面时，服务器就会开始使用可变大小缓冲区。 可变大小缓冲区由 reply 链表和一个或多个字符串对象组成： 123456789typedef struct redisClient &#123; // ... list *reply; // ...&#125; redisClient; 通过使用链表来连接多个字符串对象，服务器可以为客户端保存一个非常长的命令回复，而不必受到固定大小缓冲区 16 KB 大小的限制。 1.8 身份验证客户端状态的 authenticated 属性用于记录客户端是否通过了身份验证： 123456789typedef struct redisClient &#123; // ... int authenticated; // ...&#125; redisClient; 如果 authenticated 的值为 0 ，那么表示客户端未通过身份验证；如果 authenticated 的值为 1， 那么表示客户端已经通过了身份验证。 当客户端 authenticated 属性的值为 0 时，除了 AUTH 命令之外，客户端发送的所有其他命令都会被服务器拒绝执行： 12345redis&gt; PING(error) NOAUTH Authentication required.redis&gt; SET msg &quot;hello world&quot;(error) NOAUTH Authentication required. 当客户端通过 AUTH 命令成功进行身份验证之后， 客户端状态 authenticated 属性的值就会从 0 变为 1，这时客户端就可以像往常一样向服务器发送命令请求了。 authenticated 属性仅在服务器启用了身份验证功能时使用：如果服务器没有启用身份验证功能的话， 那么即使 authenticated 属性的值为 0 （这是默认值），服务器也不会拒绝执行客户端发送的命令请求。 1.9 时间最后，客户端还有几个和时间有关的属性： 12345678910111213typedef struct redisClient &#123; // ... time_t ctime; time_t lastinteraction; time_t obuf_soft_limit_reached_time; // ...&#125; redisClient; ctime 属性记录了创建客户端的时间，这个时间可以用来计算客户端与服务器已经连接了多少秒—— CLIENT_LIST 命令的 age 域记录了这个秒数： 123redis&gt; CLIENT listaddr=127.0.0.1:53428 ... age=1242 ... lastinteraction 属性记录了客户端与服务器最后一次进行互动（interaction）的时间，这里的互动可以是客户端向服务器发送命令请求，也可以是服务器向客户端发送命令回复。 lastinteraction 属性可以用来计算客户端的空转（idle）时间，也即是，距离客户端与服务器最后一次进行互动以来，已经过去了多少秒—— CLIENT_LIST 命令的 idle 域记录了这个秒数： 123redis&gt; CLIENT listaddr=127.0.0.1:53428 ... idle=12 ... obuf_soft_limit_reached_time 属性记录了输出缓冲区第一次到达软性限制（soft limit）的时间。 2. 客户端的创建与关闭2.1 创建普通客户端如果客户端是通过网络连接与服务器进行连接的普通客户端，那么在客户端使用 connect 函数连接到服务器时，服务器就会调用连接事件处理器，为客户端创建相应的客户端状态，并将这个新的客户端状态添加到服务器状态结构的 clients 链表的末尾。 2.2 关闭普通客户端一个普通客户端可以因为多种原因而被关闭： 如果客户端进程退出或者被杀死，那么客户端与服务器之间的网络连接将被关闭，从而造成客户端被关闭。 如果客户端向服务器发送了带有不符合协议格式的命令请求，那么这个客户端也会被服务器关闭。 如果客户端成为了 CLIENTKILL 命令的目标，那么它也会被关闭。 如果用户为服务器设置了 timeout 配置选项，那么当客户端的空转时间超过 timeout 选项设置的值时，客户端将被关闭。不过 timeout 选项有一些例外情况：如果客户端是主服务器（打开了 REDIS_MASTER标志），从服务器（打开了 REDIS_SLAVE标志），正在被 BLPOP 等命令阻塞（打开了 REDIS_BLOCKED 标志），或者正在执行 SUBSCRIBE，PSUBSCRIBE 等订阅命令，那么即使客户端的空转时间超过了 timeout 选项的值，客户端也不会被服务器关闭。 如果客户端发送的命令请求的大小超过了输入缓冲区的限制大小（默认为 1 GB），那么这个客户端会被服务器关闭。 如果要发送给客户端的命令回复的大小超过了输出缓冲区的限制大小，那么这个客户端会被服务器关闭。 为了避免客户端的回复过大，占用过多的服务器资源，服务器会时刻检查客户端的输出缓存区的大小，并在缓存区的大小超出范围时，执行相应的限制操作。 服务器使用两种模式来限制客户端的输出缓冲区的大小： 硬性限制（hard limit）：如果输出缓冲区的大小超过了硬性限制所设置的大小，那么服务器立即关闭客户端。 软性限制（soft limit）：如果输出缓冲区的大小超过了软性限制所设置的大小，但还没超过硬性限制，那么服务器将使用客户端状态结构的 obuf_soft_limit_reached_time 属性记录下客户端到达软性限制的起始时间；之后服务器会继续监视客户端，如果输出缓冲区的大小一直超出软性限制，并且持续时间超过服务器设定的时长，那么服务器将关闭客户端；相反地，如果输出缓冲区的大小在指定时间之内，不再超出软性限制，那么客户端就不会被关闭，并且 obuf_soft_limit_reached_time 属性的值也会被清零。 使用 client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;，可以为普通客户端、从服务器客户端、发布/订阅客户端分别设置不同的软性限制和硬性限制。 2.3 Lua 脚本的伪客户端服务器会在初始化时创建负责执行 Lua 脚本中包含的 Redis 命令的伪客户端，并将这个伪客户端关联在服务器状态结构的 lua_client 属性中： 123456789struct redisServer &#123; // ... redisClient *lua_client; // ... &#125; lua_client 伪客户端在服务器运行的整个生命期中会一直存在，只有服务器被关闭时，这个客户端才会被关闭。 2.4 AOF 文件的伪客户端服务器在载入 AOF 文件时，会创建用于执行 AOF 文件包含的 Redis 命令的伪客户端，并在载入完成之后，关闭这个伪客户端。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：Sentinel》]]></title>
    <url>%2F2017%2F10%2F20%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9ASentinel%E3%80%8B%2F</url>
    <content type="text"><![CDATA[Sentinel 是 Redis 的高可用性解决方案：由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。 1. 启动并初始化 Sentinel启动一个 Sentinel 可以使用命令： 1$ redis-sentinel /path/to/your/sentinel.conf 或者命令： 1$ redis-server /path/to/your/sentinel.conf --sentinel 这两个命令的效果完全相同。 当一个 Sentinel 启动时，它需要执行以下步骤： 初始化服务器。 将普通 Redis 服务器使用的代码替换成 Sentinel 专用代码。 初始化 Sentinel 状态。 根据给定的配置文件，初始化 Sentinel 的监视主服务器列表。 创建连向主服务器的网络连接。 1.1 初始化服务器Sentinel 模式下 Redis 服务器主要功能的使用情况 功能 使用情况 数据库和键值对方面的命令，比如 SET、DEL、FLUSHDB。 不使用。 事务命令，比如 MULTI 和 WATCH。 不使用。 脚本命令，比如 EVAL。 不使用。 RDB 持久化命令，比如 SAVE 和 BGSAVE。 不使用。 AOF 持久化命令，比如 BGREWRITEAOF。 不使用。 复制命令，比如 SLAVEOF。 Sentinel 内部可以使用，但客户端不可以使用。 发布与订阅命令，比如 PUBLISH 和 SUBSCRIBE。 SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE 四个命令在 Sentinel 内部和客户端都可以使用，但 PUBLISH 命令只能在 Sentinel 内部使用。 文件事件处理器（负责发送命令请求、处理命令回复）。 Sentinel 内部使用，但关联的文件事件处理器和普通 Redis 服务器不同。 时间事件处理器（负责执行 serverCron 函数）。 Sentinel 内部使用，时间事件的处理器仍然是 serverCron 函数，serverCron 函数会调用 sentinel.c/sentinelTimer 函数，后者包含了 Sentinel 要执行的所有操作。 1.2 使用 Sentinel 专用代码启动 Sentinel 的第二个步骤就是将一部分普通 Redis 服务器使用的代码替换成 Sentinel 专用代码。 比如说， 普通 Redis 服务器使用 redis.h/REDIS_SERVERPORT 常量的值作为服务器端口： 1#define REDIS_SERVERPORT 6379 而 Sentinel 则使用 sentinel.c/REDIS_SENTINEL_PORT 常量的值作为服务器端口： 1#define REDIS_SENTINEL_PORT 26379 除此之外， 普通 Redis 服务器使用 redis.c/redisCommandTable 作为服务器的命令表，而 Sentinel 则使用 sentinel.c/sentinelcmds 作为服务器的命令表，并且其中的 INFO 命令会使用 Sentinel 模式下的专用实现 sentinel.c/sentinelInfoCommand 函数， 而不是普通 Redis 服务器使用的实现 redis.c/infoCommand 函数。 sentinelcmds 命令表也解释了为什么在 Sentinel 模式下， Redis 服务器不能执行诸如 SET、 DBSIZE、 EVAL 等等这些命 ——因为服务器根本没有在命令表中载入这些命令：PING、 SENTINEL 、INFO、SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE 和 PUNSUBSCRIBE 这七个命令就是客户端可以对 Sentinel 执行的全部命令了。 1.3 初始化 Sentinel 状态在应用了 Sentinel 的专用代码之后，接下来，服务器会初始化一个 sentinel.c/sentinelState 结构（后面简称 “Sentinel 状态”），这个结构保存了服务器中所有和 Sentinel 功能有关的状态 （服务器的一般状态仍然由 redis.h/redisServer 结构保存）： 1234567891011121314151617181920212223242526struct sentinelState &#123; // 当前纪元，用于实现故障转移 uint64_t current_epoch; // 保存了所有被这个 sentinel 监视的主服务器 // 字典的键是主服务器的名字 // 字典的值则是一个指向 sentinelRedisInstance 结构的指针 dict *masters; // 是否进入了 TILT 模式？ int tilt; // 目前正在执行的脚本的数量 int running_scripts; // 进入 TILT 模式的时间 mstime_t tilt_start_time; // 最后一次执行时间处理器的时间 mstime_t previous_time; // 一个 FIFO 队列，包含了所有需要执行的用户脚本 list *scripts_queue;&#125; sentinel; 1.4 初始化 Sentinel 状态的 masters 属性Sentinel 状态中的 masters 字典记录了所有被 Sentinel 监视的主服务器的相关信息，其中： 字典的键是被监视主服务器的名字。 而字典的值则是被监视主服务器对应的 sentinel.c/sentinelRedisInstance 结构。 每个 sentinelRedisInstance 结构（后面简称 “实例结构”）代表一个被 Sentinel 监视的 Redis 服务器实例（instance），这个实例可以是主服务器、从服务器、或者另外一个 Sentinel 。 实例结构包含的属性非常多，以下代码展示了实例结构在表示主服务器时使用的其中一部分属性： 12345678910111213141516171819202122232425262728293031323334353637383940414243typedef struct sentinelRedisInstance &#123; // 标识值，记录了实例的类型，以及该实例的当前状态 int flags; // 实例的名字 // 主服务器的名字由用户在配置文件中设置 // 从服务器以及 Sentinel 的名字由 Sentinel 自动设置 // 格式为 ip:port ，例如 &quot;127.0.0.1:26379&quot; char *name; // 实例的运行 ID char *runid; // 配置纪元，用于实现故障转移 uint64_t config_epoch; // 实例的地址 sentinelAddr *addr; // SENTINEL down-after-milliseconds 选项设定的值 // 实例无响应多少毫秒之后才会被判断为主观下线（subjectively down） mstime_t down_after_period; /* Master specific. */ dict *sentinels; /* Other sentinels monitoring the same master. */ dict *slaves; /* Slaves for this master instance. */ // SENTINEL monitor &lt;master-name&gt; &lt;IP&gt; &lt;port&gt; &lt;quorum&gt; 选项中的 quorum 参数 // 判断这个实例为客观下线（objectively down）所需的支持投票数量 int quorum; // SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt; 选项的值 // 在执行故障转移操作时，可以同时对新的主服务器进行同步的从服务器数量 int parallel_syncs; // SENTINEL failover-timeout &lt;master-name&gt; &lt;ms&gt; 选项的值 // 刷新故障迁移状态的最大时限 mstime_t failover_timeout; // ...&#125; sentinelRedisInstance; sentinelRedisInstance.addr 属性是一个指向 sentinel.c/sentinelAddr 结构的指针，这个结构保存着实例的 IP 地址和端口号： 1234567typedef struct sentinelAddr &#123; char *ip; int port;&#125; sentinelAddr; 对 Sentinel 状态的初始化将引发对 masters 字典的初始化，而 masters 字典的初始化是根据被载入的 Sentinel 配置文件来进行的。 配置文件的一个例子： 1234567891011121314151617181920212223###################### master1 configure ######################sentinel monitor master1 127.0.0.1 6379 2sentinel down-after-milliseconds master1 30000sentinel parallel-syncs master1 1sentinel failover-timeout master1 900000###################### master2 configure ######################sentinel monitor master2 127.0.0.1 12345 5sentinel down-after-milliseconds master2 50000sentinel parallel-syncs master2 5sentinel failover-timeout master2 450000 1.5 创建连向主服务器的网络连接初始化 Sentinel 的最后一步是创建连向被监视主服务器的网络连接：Sentinel 将成为主服务器的客户端，它可以向主服务器发送命令，并从命令回复中获取相关的信息。 对于每个被 Sentinel 监视的主服务器来说，Sentinel 会创建两个连向主服务器的异步网络连接： 一个是命令连接，这个连接专门用于向主服务器发送命令，并接收命令回复。 另一个是订阅连接，这个连接专门用于订阅主服务器的 __sentinel__:hello 频道。 在 Redis 目前的发布与订阅功能中， 被发送的信息都不会保存在 Redis 服务器里面，如果在信息发送时，想要接收信息的客户端不在线或者断线，那么这个客户端就会丢失这条信息。因此，为了不丢失 __sentinel__:hello 频道的任何信息，Sentinel 必须专门用一个订阅连接来接收该频道的信息。 而另一方面，除了订阅频道之外，Sentinel 还又必须向主服务器发送命令，以此来与主服务器进行通讯，所以 Sentinel 还必须向主服务器创建命令连接。 并且因为 Sentinel 需要与多个实例创建多个网络连接，所以 Sentinel 使用的是异步连接。 2. 获取主服务器信息Sentinel 默认会以每十秒一次的频率，通过命令连接向被监视的主服务器发送 INFO 命令，并通过分析 INFO 命令的回复来获取主服务器的当前信息。 举个例子，假设主服务器 mater 有三个从服务器 slave0、slave1 和 slave2，并且一个 Sentinel 正在连接主服务器，那么 Sentinel 将持续地向主服务器发送 INFO 命令，并获得类似于以下内容的回复： 123456789101112131415# Server...run_id: // 略...# Replicationrole:masterconnected_slaves:3slave0:ip=127.0.0.1,port=11111,state=online,offset=43,lag=0slave1:ip=127.0.0.1,port=22222,state=online,offset=43,lag=0slave2:ip=127.0.0.1,port=33333,state=online,offset=43,lag=0...# Other sections... 通过分析主服务器返回的 INFO 命令回复，Sentinel 可以获取以下两方面的信息： 主服务器本身的信息，包括服务器运行 ID run_id，服务器角色 role 等； 主服务器属下的所有从服务器信息。包括从服务器的 IP 地址、端口号等，根据这些信息，Sentinel 无须用户提供从服务器的地址信息，就可以自动发现从服务器。 根据 run_id 域和 role 域记录的信息，Sentinel 将对主服务器的实例结构进行更新。至于主服务返回的从服务器信息，则会被用于更新主服务器实例结构的 slaves 字典，这个字典记录了主服务器属下的从服务器名单： 字典的键是由 Sentinel 自动设置的从服务器名字，格式为 ip:port。 字典的值是从服务器对应的实例结构。 Sentinel 在分析 INFO 命令中包含的从服务器信息时，会检查从服务器对应的实例结构是否已经存在于 slaves 字典： 如果已存在，进行更新； 否则创建一个新的实例结构。 主服务器实例结构和从服务器实例结构之间的区别： 主服务器实例结构的 flags 属性的值为 SRI_MASTER，而从服务器实例结构的 flags 属性的值为 SRI SLAVE。 主服务器实例结构的 name 属性的值是用户使用 Sentinel 配置文件设置的，而从服务器实例结构的 name 属性的值则是 Sentinel 根据从服务器的 IP 地址和端口号自动设置的。 3. 获取从服务器信息当 Sentinel 发现主服务器有新的从服务器时，Sentinel 除了会创建相应的从服务器实例结构外，还会创建从服务器的命令连接和订阅连接。 同样，Sentinel也会以以每 10 秒一次的频率，通过命令连接向从服务器发送 INFO 命令，并获得类似于以下内容的回复： 1234567891011121314# Server...run_id: // 略...# Replicationrole:slavemaster_host:127.0.0.1master_port:6379master_link_status:upslave_repl_offset:11887slave_priority:100# Other sections... 根据 INFO 命令的回复，Sentinel 会提取出以下信息： 从服务器的运行 ID run_id。 从服务器的角色 role。 主服务器的 IP 地址 master_host，以及主服务器的端口号 master_port。 主从服务器的连接状态 master_link_status。 从服务器的优先级 slave_priority。 从服务器的复制偏移量 slave_repl_offset。 根据这些信息，Sentinel 会对从服务器的实例结构进行更新。 4. 向主服务器和从服务器发送消息在默认情况下，Sentinel 会以每两秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器发送以下格式的命令： 1PUBLISH __sentinel__:hello &quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot; 这条命令向服务器的 __sentinel__:hello 频道发送了一条消息，信息的内容由多个参数组成： 其中以 s_ 开头的参数记录的是 Sentinel 本身的信息。 而以 m_ 开头的参数记录的则是主服务器的信息。如果 Sentinel 正在监视的是主服务器，那么这些参数记录的就是主服务器的信息；如果 Sentinel 正在监视的是从服务器，那么这些参数记录的就是从服务器正在复制的主服务器的信息。 5. 接收来自主服务器和从服务器的频道信息当 Sentinel 与一个主服务器或者从服务器建立起订阅连接之后，Sentinel 就会通过订阅连接，向服务器发送以下命令： 1SUBSCRIBE __sentinel__:hello Sentinel 对 __sentinel__:hello 频道的订阅会一直持续到 Sentinel 与服务器的连接断开为止。这也就是说，对于每个与 Sentinel 连接的服务器，Sentinel 既通过命令连接向服务器的 __sentinel__:hello 频道发送消息，又通过订阅连接从服务器的 __sentinel__:hello 频道接收消息。 对于监视同一个服务器的多个 Sentinel 来说，一个 Sentinel 发送的消息会被其他 Sentinel 接收到，这些消息会被用于更新其他 Sentinel 对发送消息 Sentinel 的认知，也会被用于更新其他 Sentinel 对被监视服务器的认知。 当一个 Sentinel 从 __sentinel__:hello 频道收到一条消息时，Sentinel 会对这条消息进行分析，提取出消息中的 Sentinel IP 地址、Sentinel 端口号、Sentinel 运行 ID等八个参数，并进行以下检查： 如果信息中记录的 Sentinel 运行 ID 和接收信息的 Sentinel 运行 ID 相同，那么说明这条消息是 Sentinel 自己发送的，Sentinel 将丢弃这条消息，不做进一步处理。 相反地，如果信息中记录的 Sentinel 运行 ID 和接收信息的 Sentinel 运行 ID 不相同，那么说明这条消息是监视同一个服务器的其他 Sentinel 发来的，接收消息的 Sentinel 将根据信息中的各个参数，对相应主服务器的实例结构进行更新。 （如果某个 Sentinel 发现自己的配置纪元低于接收到的配置纪元，则会用新的配置更新自己的配置？） 5.1 更新 sentinels 字典Sentinel 为主服务器创建的实例结构中的 sentinels 字典保存了除 Sentinel 本身之外，所有同样监视这个主服务器的其他 Sentinel 的资料： sentinels 字典的键是其中一个 Sentinel 的名字，格式为 ip:port。 sentinels 字典的值则是键所对应 Sentinel 的实例结构。 当一个 Sentinel 接收到其他 Sentinel 发来的消息时（称发送消息的 Sentinel 为源 Sentinel，接收消息的 Sentinel 为目标 Sentinel），目标 Sentinel 会从信息中分析并提取出以下两方面的参数： 与 Sentinel 有关的参数：源 Sentinel 的 IP 地址、端口号、运行 ID 和配置纪元。 与主服务器有关的参数：源 Sentinel 正在监视的主服务器的名字、IP 地址、端口号和配置纪元。 根据信息中提取出的主服务器参数，目标 Sentinel 会在自己的 Sentinel 状态的 masters 字典中查找相应的主服务器实例结构，然后根据提取出的 Sentinel 参数，检查主服务器实例结构的 sentinels 字典，源 Sentinel 的实例结构是否存在： 如果源 Sentinel 的实例结构已经存在，那么对源 Sentinel 的实力结构进行更新。 如果源 Sentinel 的实例结构不存在，那么说明源 Sentinel 是刚刚开始监视主服务器的新 Sentinel，目标 Sentinel 会为源 Sentinel 创建一个新的实例结构，并将这个结构添加到 sentinels 字典里面。 5.3 创建连向其他 Sentinel 的命令连接当 Sentinel 通过频道信息发现一个新的 Sentinel 时，它不仅会为新 Sentinel 在 sentinels 字典中创建相应的实例结构，还会创建一个连向新 Sentinel 的命令连接，而新 Sentinel 也同样会创建连向这个 Sentinel 的命令连接，最终监视同一主服务器的多个 Sentinel 将形成相互连接的网络：Sentinel A 有连向 Sentinel B 的命令连接，而 Sentinel B 也有连向 Sentinel A 的命令连接。 使用命令连接相连的各个 Sentinel 可以通过向其他 Sentinel 发送命令请求来进行信息交换。 Sentinel 之间只会创建命令连接，不会创建订阅连接。 6. 检测主观下线状态在默认情况下，Sentinel 会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他 Sentinel 在内）发送 PING 命令，并通过实例返回的 PING 命令回复来判断实例是否在线。 实例对 PING 命令的回复可以分为以下两种情况： 有效回复：实例返回 +PONG、-LOADING、-MASTERDOWN 三种回复的其中一种。 无效回复：实例返回除 +PONG、-LOADING、-MASTERDOWN 三种回复之外的其他回复，或者在指定时限内没有返回任何回复。 Sentinel 配置文件中的 down-after-milliseconds 选项指定了 Sentinel 判断实例进入主观下线所需的时间长度：如果一个实例在 down-after-milliseconds 毫秒内，连续向 Sentinel 返回无效回复，那么 Sentinel 会修改这个实例所对应的实例结构，在结构的 flags 属性中打开 SRI_S_DOWN 标识，以此来表示这个实例已经进入主观下线状态。 用户设置的 down-after-milliseconds 选项的值，不仅会被 Sentinel 用来判断主服务器的主观下线状态，还会被用于判断主服务器属下的所有从服务器，以及所有同样监视这个主服务器的其他 Sentinel 的主观下线状态。需要注意的是，对于监视同一个主服务器的多个 Sentinel 来说，这些 Sentinel 所设置的 down-after-milliseconds 选项的值也可能不同，因此，当一个 Sentinel 将主服务器判断为主观下线时，其他 Sentinel 可能仍然会认为主服务器处于在线状态。 7. 检查客观下线状态当 Sentinel 将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他 Sentinel 进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。当 Sentinel 从其他 Sentinel 那里接收到足够数量的已下线判断之后，Sentinel 就会将主服务器判定为客观下线，并对从服务器执行故障转移操作。 7.1 发送 SENTINEL is-master-down-by-addr 命令Sentinel 使用 1SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt; 命令询问其他 Sentinel 是否同意主服务器已下线。 参数 意义 ip 被 Sentinel 判断为主观下线的主服务器的 IP 地址 port 被 Sentinel 判断为主观下线的主服务器的端口号 current_epoch Sentinel 当前的配置纪元，用于选举领头 Sentinel runid 可以是 * 符号或者 Sentinel 的运行 ID：* 符号代表命令仅仅用于检测主服务器的客观下线状态，而 Sentinel 的运行 ID 则用于选举领头 Sentinel 7.2 接收 SENTINEL is-master-down-by-addr 命令当一个 Sentinl（目标 Sentinel）接收到另一个 Sentinel（源 Sentinel）发来的 SENTINEL is-master-down-by-addr 命令时，目标 Sentinel 会分析并取出命令请求中包含的各个参数，并根据其中的主服务器 IP 和端口号，检查主服务器是否已下线，然后向源 Sentinel 返回一条包含三个参数的 Multi Bulk 回复作为回复： &lt;down_state&gt; leader_runid leader_epoch 参数 意义 donw_state 目标 Sentinel 对主服务器的检查结果，1 代表主服务器已下线，0 代表主服务器未下线 leader_runid 可以是 * 符号或者目标 Sentinel 的局部领头 Sentinel 的运行 ID：* 符号代表命令仅仅用于检测主服务器的客观下线状态，而局部领头 Sentinel 的运行 ID 则用于选举领头 Sentinel leader_epoch 目标 Sentinel 的局部领头 Sentinel 的配置纪元，用于选举领头 Sentinel。仅在 leader_runid 的值不为 * 时有效，如果 leader_epoch 的值为 *，那么 leader_epoch 总为 0 7.2 接收 SENTINEL is-master-down-by-addr 命令的回复根据其他 Sentinel 发回的 SENTINEL is-master-down-by-addr 命令回复，Sentinel 将统计其他 Sentinel 同意主服务器已下线的数量，当这一数量达到配置指定的判断客观下线所需的数量时，Sentinel 会将主服务器实例结构 flags 属性的 SRI_O_DOWN 标识打开，表示主服务器已经进入客观下线状态。 当认为主服务器已经进入下线状态的 Sentinel 的数量，超过 Sentinel 配置中设置的 quorum 参数的值，那么该 Sentinel 就会认为主服务器已经进入了客观下线状态。根据配置，对于监视同一个主服务器的多个 Sentinel 来说，它们将主服务器判断为客观下线的条件可能也不同。 8. 选举领头 Sentinel当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个 Sentinel 会进行协商，选举出一个领头 Sentinel，并由领头 Sentinel 对下线主服务器执行故障转移操作。 以下是 Redis 选举领头 Sentinel 的规则和方法： 所有在线的监视同一个主服务器的多个 Sentinel 都有被选为领头 Sentinel 的资格。 每次进行领头 Sentinel 选举之后，不论选举是否成功，所有 Sentinel 的配置纪元（configration epoch）的值都会自增一次。 在一个配置纪元里面，所有 Sentinel 都有一次将某个 Sentinel 设置为局部领头 Sentinel 的机会，并且局部领头一旦设置，在这配置纪元里面就不能再更改了。 每个发现主服务器进入客观下线的 Sentinel 都会要求其他 Sentinel 将自己设置为局部领头 Sentinel。 当一个 Sentinel（源 Sentinel）向另一个 Sentinel（目标 Sentinel）发送 SENTINEL is-master-down-by-addr 命令，并且命令中的 runid 参数不是 * 符号而是源 Sentinel 的运行 ID 时，这表示源 Sentinel 要求目标 Sentinel 将前者设置为后者的局部领头 Sentinel。 Sentinel 设置局部领头 Sentinel 的规则是先到先得：最先向目标 Sentinel 发送设置要求的源 Sentinel 将成为目标 Sentinel 的局部领头 Sentinel，而之后接收到的所有设置要求都会被目标 Sentinel拒绝。 目标 Sentinel 在接收到 SENTINEL is-master-down-by-addr 命令之后，将向源 Sentinel 返回一条命令回复，回复中的 leader_runid 参数和 leader_epoch 参数分别记录了目标 Sentinel 的局部领头 Sentinel 的运行 ID 和配置纪元。 源 Sentinel 在接收到目标 Sentinel 返回的命令回复之后，会检查回复中的 leader_epoch 参数的值和自己的配置纪元是否相同，如果相同的话，那么源 Sentinel 继续取出回复中的 leader_runid 参数，如果 leader_runid 参数的值和源 Sentinel 的运行 ID 一致，那么表示目标 Sentinel 将源 Sentinel 设置成了局部领头 Sentinel。 如果有某个 Sentinel 被半数以上的 Sentinel 设置成了局部领头 Sentinel，那么这个 Sentinel 成为领头 Sentinel。 因为领头 Sentinel 的产生需要半数以上的 Sentinel 支持，并且每个 Sentinel 在每个配置纪元里面只能设置一次局部领头 Sentinel，所以在一个配置纪元里面，只会出现一个领头 Sentinel。 如果在给定时限内，没有一个 Sentinel 被选举为领头 Sentinel，那么各个 Sentinel 将在一段时间之后再次进行选举，直到选举出领头 Sentinel 为止。 9. 故障转移在选举产生出领头 Sentinel 之后，领头 Sentinel 将对已下线的主服务器执行故障转移操作，该操作包含以下三个步骤： 在已下线主服务器属下的所有从服务器里面，挑选出一个从服务器，并将其转换为主服务器。 让已下线主服务器属下的所有从服务器改为复制新的主服务器。 将已下线主服务器设置为新的主服务器的从服务器，当这个旧的主服务器重新上线时，他就会成为新的主服务器的从服务器。 9.1 选出新的主服务器故障转移操作的第一步要做的就是在已下线主服务器属下的所有从服务器中，挑选出一个状态良好、数据完整的从服务器，然后向这个从服务器发送 SLAVEOF no one 命令，将这个从服务器转换为主服务器。 在发送 SLAVEOF no one 命令之后，领头 Sentinel 会以每秒一次的频率（平时是每十秒一次），向被升级的从服务器发送 INFO 命令，并观察命令回复中的角色（role）信息，当被升级服务器的 role 从原来的 slave 变为 master 时，领头 Sentinel 就知道被选中的从服务器已经顺利升级为主服务器了。 领头 Sentinel 将已下线的主服务器的所有从服务器保存到一个列表中，然后按下面进行过滤： 删除列表中所有处于下线或断线转发太的从服务器； 删除列表中所有最近 5s 内没有回复过领头 Sentinel 的 INFO 命令的从服务器； 删除所有与已下线的主服务器连接断开超过 down-after-millisecondes * 10 毫秒的从服务器； 之后，领头 Sentinel将根据从服务器的优先级排序（选出优先级最高的）；如果具有多个相同最高优先级的从服务器，那么再按照从服务器的复制偏移量排序（选出偏移量最大的）；如果还有相同的从服务器，那么按照 runid 进行排序，选出其中 runid 最小的。 9.2 修改从服务器的复制目标当新的主服务器出现之后，领头 Sentinel 下一步要做的就是，让已下线主服务器属下的所有从服务器去复制新的主服务器，这一动作可以通过向从服务器发送 SLAVEOF 命令来实现。 9.3 将旧的主服务器变为从服务器故障转移操作最后要做的是，将已下线的主服务器设置为新的主服务器的从服务器。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：发布与订阅》]]></title>
    <url>%2F2017%2F10%2F16%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85%E3%80%8B%2F</url>
    <content type="text"><![CDATA[Redis 的发布与订阅功能由 PUBLISH、SUBSCRIBE、PSUBSCRIBE 等命令组成。 通过执行 SUBSCRIBE 命令，客户端可以订阅一个或多个频道从而成为这些频道的订阅者（subscriber）：每当有其它客户端向被订阅的频道发送消息（message）时，频道的所有订阅者都会收到这条消息。 除了订阅频道之外，客户端还可以通过执行 PSUBSCRIBE 命令订阅一个或多个模式，从而成为这些模式的订阅者：每当有其他客户端向某个频道发送消息时，消息不仅会被发送给这个频道的所有订阅者，它还会被发送给所有与这个频道相匹配的模式的订阅者。 1. 频道的订阅与退订当一个客户端执行 SUBSCRIBE 命令订阅某个或某些频道的时候，这个客户端与被订阅频道之间就建立起了一种订阅关系。 Redis 将所有频道的订阅关系都保存在服务器状态的 pubsub_channels 字典里面，这个字典的键是某个被订阅的频道，而键的值是一个链表，链表里面记录了所有订阅这个频道的客户端。 12345678910struct redisServer &#123; // ... // 保存所有频道的订阅关系 dict *pubsub_channels; /* Map channels to list of subscribed clients */ // ... &#125;; 1.1 订阅频道每当客户端执行 SUBSCRIBE 命令订阅某个或某些频道的时候，服务器都会将客户端与被订阅的频道在 pubsub_channels 字典中进行关联。 根据频道是否已经有其他订阅者，关联操作分为两种情况执行： 如果频道已经有其他订阅者，那么它在 pubsub_channels 字典中必然有相应的订阅者链表，程序唯一要做的就是将客户端添加到订阅者链表的末尾。 如果频道还未有任何订阅者，那么它必然不存在于 pubsub_channels 字典，程序首先要在 pubsub_channels 字典中为频道创建一个键，并将这个键的值设置为空链表，然后再将客户端添加到链表，成为链表的第一个元素。 SUBSCRIBE 命令的实现可以⽤以下伪代码来描述： 123456789101112def subscribe(*all_input_channels): # 遍历输⼊的所有频道 for channel in all_input_channels: # 如果 channel 不存在于 pubsub_channels 字典（没有任何订阅者） # 那么在字典中添加 channel 键，并设置它的值为空链表 if channel not in server.pubsub_channels: server.pubsub_channels[channel] = [] # 将订阅者添加到频道所对应的链表的末尾 server.pubsub_channels[channel].append(client) 1.2 退订频道UNSUBSCRIBE 命令的⾏为和 SUBSCRIBE 命令的⾏为正好相反 —— 当⼀个客户端退订某个或某些频道的时候，服务器将从 pubsub_channels 中解除客户端与被退订频道之间的关联： 程序会根据被退订频道的名字，在 pubsub_channels 字典中找到频道对应的订阅者链表，然后从订阅者链表中删除退订客户端的信息。 如果删除退订客户端之后，频道的订阅者链表变成了空链表，那么说明这个频道已经没有任何订阅者了，程序将从 pubsub_channels 字典中删除频道对应的键。 UNSUBSCRIBE 命令的实现可以⽤以下伪代码来描述： 12345678910111213def unsubscribe(*all_input_channels): # 遍历要退订的所有频道 for channel in all_input_channels: # 在订阅者链表中删除退订的客户端 server.pubsub_channels[channel].remove(client) # 如果频道已经没有任何订阅者了（订阅者链表为空） # 那么将频道从字典中删除 if len(server.pubsub_channels[channel]) == 0: server.pubsub_channels.remove(channel) 2. 模式的订阅与退订服务器也将所有模式的订阅关系都保存在服务器状态的 pubsub_patterns 属性里面： 12345678910struct redisServer &#123; // ... // 保存所有模式订阅关系 list *pubsub_patterns; // ... &#125; pubsub_patterns 属性是一个链表，链表中的每个节点都包含着一个 pubsubPattern 结构，这个结构的 pattern 属性记录了被订阅的模式，而 client属性则记录了订阅模式的客户端： 123456789typedef struct pubsubPattern &#123; // 订阅模式的客户端 redisClient *client; // 被订阅的模式 robj * pattern; &#125; pubsubPattern; 2.1 订阅模式每当客户端执行 PSUBSCRIBE 命令订阅某个或某些模式的时候，服务器会对每个被订阅的模式执行以下两个操作： 新建一个 pubsubPattern 结构，将结构的 pattern 属性设置为被订阅的模式，client 属性设置为订阅模式的客户端。 将 pubsubPattern 结构添加到 pubsub_patterns 链表的表尾。 PSBUSCRIBE 命令的实现原理可以用以下的伪代码来描述： 12345678910111213def psubscribe(*all_input_patterns): # 遍历输入的所有模式 for pattern in all_input_patterns: # 创建新的 pubsubPattern 结构 # 记录被订阅的模式，以及订阅模式的客户端 pubsubPattern = create_new_pubsubPattern() pubsubPattern.client = client pubsubPattern.pattern = pattern # 将新的 pubsubPattern 追加到 pubsub_patterns 链表末尾 server.pubsub_patterns.append(pubsubPattern) 2.2 退订模式模式的退订命令 PUNSUBSCRIBE 是 PSUBSCRIBE 命令的反操作。当一个客户端退订某个或某些模式的时候，服务器将在 pubsub_patterns 链表中查找并删除那些 pattern 属性为退订模式并且 client 属性为执行退订命令的客户端的 pubsubPattern 结构。 PUNSUBSCRIBE 命令的实现原理可以用以下伪代码来描述： 1234567891011121314def punsubscribe(*all_input_patterns): # 遍历所有要退订的模式 for pattern in all_input_patterns: # 遍历 pubsub_patterns 链表中的所有 pubsubPattern 结构 for pubsubPattern in server.pubsub_patterns: # 如果当前客户端和 pubsubPattern 记录的客户端相同 # 并且要退订的模式也和 pubsubPattern 记录的模式相同 if client == pubsubPattern.client and pattern == pubsubPattern.pattern # 那么将这个 pubsubPattern 从链表中删除 server.pubsub_patterns.remove(pubsubPattern) 3. 发送消息当一个 Redis 客户端执行 PUBLISH &lt;channel&gt; &lt;message&gt; 命令将消息 message 发送给频道 channel的时候，服务器需要执行以下两个操作： 将消息 message 发送给频道 channel 的所有订阅者。 如果有一个或多个模式 pattern 与频道 channel 相匹配。那么将消息 message 发送给 pattern 模式的订阅者。 3.1 将消息发送给频道订阅者因为服务器状态中的 pubsub_channels 字典记录了所有频道的订阅关系，所以为了将消息发送给 channel 频道的所有订阅者，PUBLISH 命令要做的就是在 pubsub_channels 字典里找到频道 channel 的订阅者名单（一个链表），然后将消息发送给名单上的所有客户端。 PUBLISH 命令将消息发送给频道订阅者的方法可以用以下伪代码来描述： 12345678910111213def channel_publish(channel,message): # 如果 channel 键不存在于 pubsub_channels 字典中 # 那么说明 channel 频道没有任何订阅者 # 程序不做发送动作，直接返回 if channel not in server.pubsub_channels: return # 运行到这里，说明 channel 频道至少有一个订阅者 # 程序遍历 channel 频道的订阅者列表 # 将消息发送给所有订阅者 for subscriber in server.pubsub_channels[channel]: send_message(subscriber, message) 3.2 将消息发送给模式订阅者因为服务器状态中的 pubsub_patterns链表记录了所有模式的订阅关系，所以为了将消息发送给所有与 channel 频道相匹配的模式的订阅者，PUBLISH 命令要做的就是遍历整个 pubsub_patterns 链表，查找那些与 channel 频道相匹配的模式，并将消息发送给订阅了这些模式的客户端。 PUBLISH 命令将消息发送给模式订阅者的方法可以用以下伪代码来描述： 12345678910def pattern_publish(channel, message): # 遍历所有模式订阅消息 for pubsubPattern in server.pubsub_patterns: # 如果频道和模式相匹配 if(match(channel, pubsubPatter.pattern)): # 那么将消息发送给订阅该模式的客户端 send_message(pubsubPattern.client, message) 最后，PUBLISH 命令的实现可以用以下伪代码来描述： 1234567def publish(channel, message): # 将消息发送给 channel 频道的所有订阅者 channel_publish(channel, message) # 将消息发送给所有和 channel 频道相匹配的模式的订阅者 pattern_publish(channel, message) 4. 查看订阅信息4.1 PUBSUB CHANNELSPUBSUB CHANNELS [pattern] 子命令用于返回服务器当前被订阅的频道。其中 pattern 参数是可选的： 如果不给定 pattern 参数，那么命令返回服务器当前被订阅的所有频道。 如果给定 pattern 参数，那么命令返回服务器当前被订阅的频道中那些与 pattern 模式相匹配的频道。 这个子命令是通过遍历服务器 pubsub_channels 字典中的所有键（每个键都是一个被订阅的频道），然后记录并返回所有符合条件的频道来实现的，这个过程可以用以下伪代码来描述： 1234567891011121314151617def pubsub_channels(pattern=None): # 一个列表，用于记录所有符合条件的频道 channel_list = [] # 遍历服务器中的所有频道 # (也即是 pubsub_channels 字典的所有键) for channel in server.pubsub_channels: # 当以下两个条件的任意一个满足时，将频道添加到链表里面： # 1）用户没有指定 pattern 参数 # 2）用户指定了 pattern 参数，并且 channel 和 pattern 匹配 if (pattern is None) or match(channel, pattern): channel_list.append(channel) # 向客户端返回频道列表 return channel_list 4.2 PUBSUB NUMSUBPUBSUB NUMSUB [channel1-1 channel-2 ... channel-n] 子命令接受任意多个频道作为输入参数，并返回这些频道的订阅者数量。这个命令是通过在 pubsub_channels 字典中找到频道对应的订阅者链表，这个过程可以用以下伪代码来描述： 1234567891011121314151617181920def pubsub_numsub(*all_input_channels): # 遍历输入的所有频道 for channel in all_input_channels: # 如果 pubsub_channels 字典中没有 channel 这个键 # 那么说明 channel 频道没有任何订阅者 if channel not in server.pubsub_channels: # 返回频道名 reply_channel_name(channel) # 订阅者数量为 0 reply_subscribe_count(0) # 如果 pubsub_channels 字典中存在 channel 键 # 那么说明 channel 频道至少有一个订阅者 else: # 返回频道名 reply_channel_name(channel) # 订阅者数量为0 reply_subscribe_count(len(server.pubsub_channels[channel])) 4.3 PUBSUB NUMPATPUBSUB NUMPAT 命令用于返回服务器当前被订阅模式的数量。 这个命令是通过返回 pubsub_patterns 链表的长度来实现的，因为这个链表的长度就是服务器被订阅模式的数量，这个过程可以用以下伪代码来描述： 1234def pubsub_numpat(): # pubsub_patterns 链表的长度就是被订阅模式的数量 reply_pattern_count(len(server.pubsub_patterns))]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：AOF 持久化》]]></title>
    <url>%2F2017%2F10%2F14%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9AAOF-%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%8B%2F</url>
    <content type="text"><![CDATA[AOF 持久化保存数据库状态的方法是将服务器执行的命令保存到文件中。被写入 AOF 文件的所有命令都是以 Redis 的命令请求协议格式保存的。 服务器在启动时，可以通过载入和执行 AOF 文件中保存的命令来还原服务器关闭之前的数据库状态，以下就是服务器载入 AOF 文件并还原数据库状态时打印的日志： 123[8321] 05 Sep 11:58:50.448 # Server started, Redisversion 2.9.11[8321] 05 Sep 11:58:50.449 * DB loaded from append only file: 0.000 seconds[8321] 05 Sep 11:58:50.449 * The server is now ready to accept connections on port 6379 1. AOF 持久化的实现1.1 命令追加当 AOF 持久化功能处于打开状态时， 服务器在执行完一个写命令之后， 会以协议格式将被执行的写命令追加到服务器状态的 aof_buf 缓冲区的末尾： 123456789struct redisServer &#123; // ... // AOF 缓冲区 sds aof_buf; // ...&#125;; 1.2 AOF 文件的写入与同步Redis 的服务器进程就是一个事件循环（loop）， 这个循环中的文件事件负责接收客户端的命令请求， 以及向客户端发送命令回复， 而时间事件则负责执行像 serverCron 函数这样需要定时运行的函数。 因为服务器在处理文件事件时可能会执行写命令， 使得一些内容被追加到 aof_buf 缓冲区里面， 所以在服务器每次结束一个事件循环之前， 它都会调用 flushAppendOnlyFile 函数， 考虑是否需要将 aof_buf 缓冲区中的内容写入和保存到 AOF 文件里面， 这个过程可以用以下伪代码表示： 12345678910111213def eventLoop(): while True: # 处理文件事件，接收命令请求以及发送命令回复 # 处理命令请求时可能会有新内容被追加到 aof_buf 缓冲区中 processFileEvents() # 处理时间事件 processTimeEvents() # 考虑是否要将 aof_buf 中的内容写入和保存到 AOF 文件里面 flushAppendOnlyFile() flushAppendOnlyFile 函数的行为由服务器配置的 appendfsync 选项的值来决定， 各个不同值产生的行为如下表所示： appendfsync 选项的值 flushAppendOnlyFile 函数的行为 always 将 aof_buf 缓冲区中的所有内容写入并同步到 AOF 文件。 everysec 将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是由一个线程专门负责执行的。 no 将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。 如果用户没有主动为 appendfsync 选项设置值， 那么 appendfsync 选项的默认值为 everysec。 1.3 AOF 持久化的效率和安全性服务器配置 appendfsync 选项的值直接决定 AOF 持久化功能的效率和安全性。 当 appendfsync 的值为 always 时， 服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 并且同步 AOF 文件， 所以 always 的效率是 appendfsync 选项三个值当中最慢的一个， 但从安全性来说， always 也是最安全的， 因为即使出现故障停机， AOF 持久化也只会丢失一个事件循环中所产生的命令数据。 当 appendfsync 的值为 everysec 时， 服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 并且每隔超过一秒就要在子线程中对 AOF 文件进行一次同步： 从效率上来讲， everysec 模式足够快， 并且就算出现故障停机， 数据库也只丢失一秒钟的命令数据。 当 appendfsync 的值为 no 时， 服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 至于何时对 AOF 文件进行同步， 则由操作系统控制。因为处于 no 模式下的 flushAppendOnlyFile 调用无须执行同步操作， 所以该模式下的 AOF 文件写入速度总是最快的， 不过因为这种模式会在系统缓存中积累一段时间的写入数据， 所以该模式的单次同步时长通常是三种模式中时间最长的： 从平摊操作的角度来看， no 模式和 everysec 模式的效率类似， 当出现故障停机时， 使用 no 模式的服务器将丢失上次同步 AOF 文件之后的所有写命令数据。 2. AOF 文件的载入与数据还原因为 AOF 文件里面包含了重建数据库状态所需的所有写命令，所以服务器只要读入并重新执行一遍 AOF 文件里面保存的写命令，就可以还原服务器关闭之前的数据库状态。 Redis 读取 AOF 文件并还原数据库状态的详细步骤如下： 创建一个不带网络连接的伪客户端（fake client）：因为 Redis 的命令只能在客户端上下文中执行，而载入 AOF 文件时所使用的命令直接来源于 AOF 文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行 AOF 文件保存的写命令，伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样。 从 AOF 文件中分析并读取出一条写命令。 使用伪客户端执行被读出的写命令。 一直执行步骤 2 和 步骤 3，直到 AOF 文件中的所有写命令都被处理完毕为止。 3. AOF重写为了解决 AOF 文件体积膨胀的问题，Redis 提供了 AOF 重写功能：Redis 服务器可以创建一个新的 AOF 文件来替代现有的 AOF 文件，新旧两个文件所保存的数据库状态是相同的，但是新的 AOF 文件不会包含任何浪费空间的冗余命令，通常体积会较旧 AOF 文件小很多。 3.1 AOF 文件重写的实现AOF 重写并不需要对原有 AOF 文件进行任何的读取、写入、分析等操作，这个功能是通过读取服务器当前的数据库状态来实现的。首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录该键值对的多个命令。整个重写过程可以用以下的伪代码表示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374def AOF_REWRITE(tmp_tile_name): f = create(tmp_tile_name) # 遍历所有数据库 for db in redisServer.db: # 如果数据库为空，那么跳过这个数据库 if db.is_empty(): continue # 写入 SELECT 命令，用于切换数据库 f.write_command(&quot;SELECT &quot; + db.number) # 遍历所有键 for key in db: # 如果键带有过期时间，并且已经过期，那么跳过这个键 if key.have_expire_time() and key.is_expired(): continue if key.type == String: # 用 SET key value 命令来保存字符串键 value = get_value_from_string(key) f.write_command(&quot;SET &quot; + key + value) elif key.type == List: # 用 RPUSH key item1 item2 ... itemN 命令来保存列表键 item1, item2, ..., itemN = get_item_from_list(key) f.write_command(&quot;RPUSH &quot; + key + item1 + item2 + ... + itemN) elif key.type == Set: # 用 SADD key member1 member2 ... memberN 命令来保存集合键 member1, member2, ..., memberN = get_member_from_set(key) f.write_command(&quot;SADD &quot; + key + member1 + member2 + ... + memberN) elif key.type == Hash: # 用 HMSET key field1 value1 field2 value2 ... fieldN valueN 命令来保存哈希键 field1, value1, field2, value2, ..., fieldN, valueN =\ get_field_and_value_from_hash(key) f.write_command(&quot;HMSET &quot; + key + field1 + value1 + field2 + value2 +\ ... + fieldN + valueN) elif key.type == SortedSet: # 用 ZADD key score1 member1 score2 member2 ... scoreN memberN # 命令来保存有序集键 score1, member1, score2, member2, ..., scoreN, memberN = \ get_score_and_member_from_sorted_set(key) f.write_command(&quot;ZADD &quot; + key + score1 + member1 + score2 + member2 +\ ... + scoreN + memberN) else: raise_type_error() # 如果键带有过期时间，那么用 EXPIREAT key time 命令来保存键的过期时间 if key.have_expire_time(): f.write_command(&quot;EXPIREAT &quot; + key + key.expire_time_in_unix_timestamp()) # 关闭文件 f.close() 在实际中，为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果元素的数量超过了redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD 常量的值，那么重写程序将使用多条命令来记录键的值，而不单单使用一条命令。 在目前版本中，REDIS_AOF_REWRITE_ITEMS_PER_CMD 常量的值为 64，这也就是说，如果一个集合键包含了超过 64 个元素，那么重写程序会用多条SADD命令来记录这个集合，并且每条命令设置的元素数量也为 64 个： 123SADD &lt;set-key&gt; &lt;elem1&gt; &lt;elem2&gt; ... &lt;elem64&gt;SADD &lt;set-key&gt; &lt;elem65&gt; &lt;elem66&gt; ... &lt;elem128&gt;SADD &lt;set-key&gt; &lt;elem129&gt; &lt;elem130&gt; ... &lt;elem192&gt; 另一方面如果一个列表键包含了超过 64 个项，那么重写程序会用多条 RPUSH 命令来保存这个列表，并且每条命令设置的项数量也为 64 个： 123SADD &lt;list-key&gt; &lt;item1&gt; &lt;item2&gt; ... &lt;item64&gt;SADD &lt;list-key&gt; &lt;item65&gt; &lt;item66&gt; ... &lt;item128&gt;SADD &lt;list-key&gt; &lt;item129&gt; &lt;item130&gt; ... &lt;item192&gt; 3.2 AOF 后台重写Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样做可以同时达到两个目的： 子进程进行 AOF 重写期间，服务器进程（父进程）可以继续处理命令请求。 子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。 子进程在进行 AOF 重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而使得服务器当前的数据库状态和重写后的 AOF 文件所保存的数据库状态不一致。 为了解决这种数据不一致问题，Redis 服务器设置了一个 AOF 重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令发送给 AOF 缓冲区和 AOF 重写缓冲区。这也就是说，在子进程执行 AOF 重写期间，服务器进程需要执行以下三个工作： 执行客户端发来的命令。 将执行后的写命令追加到 AOF 缓冲区。 将执行后的写命令追加到 AOF 重写缓冲区。 这样一来，可以保证: AOF 缓冲区的内容会定期被写入和同步到 AOF 文件，对现有 AOF 文件的处理工作会如常进行。 从创建子进程开始，服务器执行的所有写命令都会被记录到 AOF 重写缓冲区里面。 当子进程完成 AOF 重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作： 将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。 对新的 AOF 文件进行改名，原子地（atomic）覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。 信号处理函数执行完毕之后，父进程就可以继续像往常一样接受命令请求了。 在整个 AOF 后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，其他时候，AOF 后台重写都不会阻塞父进程，这将 AOF 重写对服务器性能造成的影响降到了最低。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：RDB 持久化》]]></title>
    <url>%2F2017%2F10%2F10%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9ARDB-%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%8B%2F</url>
    <content type="text"><![CDATA[RDB 持久化功能所生成的 RDB 文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。 1. RDB 文件的创建与载入有两个 Redis 命令可以用于生成 RDB 文件，一个是 SAVE，另一个是 BGSAVE。 SAVE 命令会阻塞 Redis 服务器进程，直到 RDB 文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求。 和 SAVE 命令直接阻塞服务器进程的做法不同，BGSAVE 命令会派生出一个子进程，然后由子进程负责创建 RDB 文件，服务器进程（父进程）继续处理命令请求。 创建 RDB 文件的实际工作由 rdb.c/rdbSave 函数完成，SAVE 命令和 BGSAVE 命令会以不同的方式调用这个函数，通过以下伪代码可以明显地看出这两个命令之间的区别： 1234567891011121314151617181920212223242526def SAVE(): #创建RDB文件 rdbSave() def BGSAVE(): #创建子进程 pid = fork() if pid == 0: #子进程负责创建RDB文件 rdbSave() #完成之后向父进程发送信号 signal_parent() elif pid ＞ 0: #父进程继续处理命令请求，并通过轮询等待子进程的信号 handle_request_and_wait_signal() else: #处理出错情况 handle_fork_error() 和使用 SAVE 命令或者 BGSAVE 命令创建 RDB 文件不同，RDB 文件的载入工作是在服务器启动时自动执行的，所以 Redis 并没有专门用于载入 RDB 文件的命令，只要 Redis 服务器在启动时检测到 RDB 文件存在，它就会自动载入 RDB 文件。 以下是 Redis 服务器启动时打印的日志记录，其中第二条日志 DB loaded from disk:… 就是服务器在成功载入 RDB 文件之后打印的： 1234$ redis-server[7379] 30 Aug 21:07:01.270 # Server started, Redis version 2.9.11[7379] 30 Aug 21:07:01.289 * DB loaded from disk: 0.018 seconds[7379] 30 Aug 21:07:01.289 * The server is now ready to accept connections on port 6379 因为 AOF 文件的更新频率通常比RDB文件的更新频率高，所以： 如果服务器开启了 AOF 持久化功能，那么服务器会优先使用 AOF 文件来还原数据库状态。 只有在 AOF 持久化功能处于关闭状态时，服务器才会使用 RDB 文件来还原数据库状态。 载入 RDB 文件的实际工作由 rdb.c/rdbLoad 函数完成。 1.1 SAVE 命令执行时的服务器状态当 SAVE 命令执行时，Redis 服务器会被阻塞，所以当 SAVE 命令正在执行时，客户端发送的所有命令请求都会被拒绝。只有在服务器执行完 SAVE 命令、重新开始接受命令请求之后，客户端发送的命令才会被处理。 1.2 BGSAVE 命令执行时的服务器状态因为 BGSAVE 命令的保存工作是由子进程执行的，所以在子进程创建 RDB 文件的过程中，Redis 服务器仍然可以继续处理客户端的命令请求，但是，在 BGSAVE 命令执行期间，服务器处理 SAVE、BGSAVE、BGREWRITEAOF 三个命令的方式会和平时有所不同。 首先，在 BGSAVE 命令执行期间，客户端发送的 SAVE 命令会被服务器拒绝，服务器禁止 SAVE 命令和 BGSAVE 命令同时执行是为了避免父进程（服务器进程）和子进程同时执行两个 rdbSave 调用，防止产生竞争条件。 其次，在 BGSAVE 命令执行期间，客户端发送的 BGSAVE 命令会被服务器拒绝，因为同时执行两个 BGSAVE 命令也会产生竞争条件。 最后，BGREWRITEAOF 和 BGSAVE 两个命令不能同时执行： 如果 BGSAVE 命令正在执行，那么客户端发送的 BGREWRITEAOF 命令会被延迟到 BGSAVE 命令执行完毕之后执行。 如果 BGREWRITEAOF 命令正在执行，那么客户端发送的 BGSAVE 命令会被服务器拒绝。 因为 BGREWRITEAOF 和 BGSAVE 两个命令的实际工作都由子进程执行，所以这两个命令在操作方面并没有什么冲突的地方，不能同时执行它们只是一个性能方面的考虑——并发出两个子进程，并且这两个子进程都同时执行大量的磁盘写入操作，这怎么想都不会是一个好主意。 1.3 RDB 文件载入时的服务器状态服务器在载入 RDB 文件期间，会一直处于阻塞状态，直到载入工作完成为止。 2. 自动间隔性保存Redis 允许用户通过设置服务器配置的 save 选项，让服务器每隔一段时间自动执行一次 BGSAVE 命令。用户可以通过 save 选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行 BGSAVE 命令。 举个例子，如果我们向服务器提供以下配置： 123save 900 1save 300 10save 60 10000 那么只要满足以下三个条件中的任意一个，BGSAVE 命令就会被执行： 服务器在 900 秒之内，对数据库进行了至少 1 次修改。 服务器在 300 秒之内，对数据库进行了至少 10 次修改。 服务器在 60 秒之内，对数据库进行了至少 10000 次修改。 举个例子，以下是 Redis 服务器在 60 秒之内，对数据库进行了至少 10000 次修改之后，服务器自动执行 BGSAVE 命令时打印出来的日志： 12345[5085] 03 Sep 17:09:49.463 * 10000 changes in 60 seconds. Saving...[5085] 03 Sep 17:09:49.463 * Background saving started by pid 5189[5189] 03 Sep 17:09:49.522 * DB saved on disk[5189] 03 Sep 17:09:49.522 * RDB: 0 MB of memory used by copy-on-write[5085] 03 Sep 17:09:49.563 * Background saving terminated with success 2.1 设置保存条件当 Redis 服务器启动时，用户可以通过指定配置文件或者传入启动参数的方式设置 save 选项，如果用户没有主动设置 save 选项，那么服务器会为 save 选项设置默认条件： 123save 900 1save 300 10save 60 10000 接着，服务器程序会根据 save 选项所设置的保存条件，设置服务器状态 redisServer 结构的 saveparams 属性： 123456struct redisServer &#123; // ... //记录了保存条件的数组 struct saveparam *saveparams; // ...&#125;; saveparams 属性是一个数组，数组中的每个元素都是一个 saveparam 结构，每个 saveparam 结构都保存了一个 save 选项设置的保存条件： 123456struct saveparam &#123; //秒数 time_t seconds; //修改数 int changes;&#125;; 2.2 dirty 计数器和 lastsave 属性除了 saveparams 数组之外，服务器状态还维持着一个 dirty 计数器，以及一个 lastsave 属性： dirty 计数器记录距离上一次成功执行 SAVE 命令或者 BGSAVE 命令之后，服务器对数据库状态（服务器中的所有数据库）进行了多少次修改（包括写入、删除、更新等操作）。 lastsave 属性是一个 UNIX 时间戳，记录了服务器上一次成功执行 SAVE 命令或者 BGSAVE 命令的时间。 12345678struct redisServer &#123; // ... //修改计数器 long long dirty; //上一次执行保存的时间 time_t lastsave; // ...&#125;; 当服务器成功执行一个数据库修改命令之后，程序就会对 dirty 计数器进行更新：命令修改了多少次数据库，dirty 计数器的值就增加多少。 2.3 检查保存条件是否满足Redis 的服务器周期性操作函数 serverCron 默认每隔 100 毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，它的其中一项工作就是检查 save 选项所设置的保存条件是否已经满足，如果满足的话，就执行 BGSAVE 命令。 以下伪代码展示了 serverCron 函数检查保存条件的过程： 12345678910111213141516171819def serverCron(): # ... #遍历所有保存条件 for saveparam in server.saveparams: #计算距离上次执行保存操作有多少秒 save_interval = unixtime_now()-server.lastsave #如果数据库状态的修改次数超过条件所设置的次数 #并且距离上次保存的时间超过条件所设置的时间 #那么执行保存操作 if server.dirty ＞= saveparam.changes and \ save_interval ＞ saveparam.seconds: BGSAVE() # ... 程序会遍历并检查 saveparams 数组中的所有保存条件，只要有任意一个条件被满足，那么服务器就会执行 BGSAVE 命令。 3. RDB文件结构一个完整 RDB 文件包含： 12345+-----+----------+---------+---+---------+| | | | | ||REDIS|db_version|databases|EOF|check_sum|| | | | | |+-----+----------+---------+---+---------+ RDB 文件的最开头是 REDIS 部分，这个部分的长度为 5 字节，保存着 “REDIS” 五个字符。通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否 RDB 文件。 db_version 长度为 4 字节，它的值是一个字符串表示的整数，这个整数记录了 RDB 文件的版本号，比如 “0006” 就代表 RDB 文件的版本为第六版。 databases 部分包含着零个或任意多个数据库，以及各个数据库中的键值对数据： 如果服务器的数据库状态为空（所有数据库都是空的），那么这个部分也为空，长度为 0 字节。 如果服务器的数据库状态为非空（有至少一个数据库非空），那么这个部分也为非空，根据数据库所保存键值对的数量、类型和内容不同，这个部分的长度也会有所不同。 EOF 常量的长度为 1 字节，这个常量标志着 RDB 文件正文内容的结束，当读入程序遇到这个值的时候，它知道所有数据库的所有键值对都已经载入完毕了。 check_sum 是一个 8 字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对 REDIS、db_version、databases、EOF 四个部分的内容进行计算得出的。服务器在载入 RDB 文件时，会将载入数据所计算出的校验和与 check_sum 所记录的校验和进行对比，以此来检查 RDB 文件是否有出错或者损坏的情况出现。 3.1 databases 部分一个 RDB 文件的 databases 部分可以保存任意多个非空数据库。每个非空数据库在 RDB 文件中都可以保存为 SELECTDB、db_number、key_value_pairs 三个部分。 SELECTDB 常量的长度为 1 字节，当读入程序遇到这个值的时候，它知道接下来要读入的将是一个数据库号码。 db_number 保存着一个数据库号码，根据号码的大小不同，这个部分的长度可以是 1 字节、2 字节或者 5 字节。当程序读入 db_number 部分之后，服务器会调用 SELECT 命令，根据读入的数据库号码进行数据库切换，使得之后读入的键值对可以载入到正确的数据库中。 key_value_pairs 部分保存了数据库中的所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对保存在一起。根据键值对的数量、类型、内容以及是否有过期时间等条件的不同，key_value_pairs 部分的长度也会有所不同。 3.2 key_value_pairs 部分RDB 文件中的每个 key_value_pairs 部分都保存了一个或以上数量的键值对，如果键值对带有过期时间的话，那么键值对的过期时间也会被保存在内。 不带过期时间的键值对在 RDB 文件中由 TYPE、key、value 三部分组成。 1TYPE | key | value TYPE 记录了 value 的类型，长度为1字节，值可以是以下常量的其中一个： REDIS_RDB_TYPE_STRING REDIS_RDB_TYPE_LIST REDIS_RDB_TYPE_SET REDIS_RDB_TYPE_ZSET REDIS_RDB_TYPE_HASH REDIS_RDB_TYPE_LIST_ZIPLIST REDIS_RDB_TYPE_SET_INTSET REDIS_RDB_TYPE_ZSET_ZIPLIST REDIS_RDB_TYPE_HASH_ZIPLIST 以上列出的每个 TYPE 常量都代表了一种对象类型或者底层编码，当服务器读入 RDB 文件中的键值对数据时，程序会根据 TYPE 的值来决定如何读入和解释 value 的数据。key 和 value 分别保存了键值对的键对象和值对象： 其中 key 总是一个字符串对象，它的编码方式和 REDIS_RDB_TYPE_STRING 类型的 value 一样。根据内容长度的不同，key 的长度也会有所不同。 根据 TYPE 类型的不同，以及保存内容长度的不同，保存 value 的结构和长度也会有所不同。 带有过期时间的键值对在 RDB 文件中的结构： 1EXPIRETIME_MS | ms | TYPE | key | value 带有过期时间的键值对中的 TYPE、key、value 三个部分的意义，和前面介绍的不带过期时间的键值对的 TYPE、key、value 三个部分的意义完全相同，至于新增的 EXPIRETIME_MS 和 ms，它们的意义如下： EXPIRETIME_MS 常量的长度为 1 字节，它告知读入程序，接下来要读入的将是一个以毫秒为单位的过期时间。 ms 是一个 8 字节长的带符号整数，记录着一个以毫秒为单位的 UNIX 时间戳，这个时间戳就是键值对的过期时间。 3.3 value 的编码RDB 文件中的每个 value 部分都保存了一个值对象，每个值对象的类型都由与之对应的 TYPE 记录，根据类型的不同，value 部分的结构、长度也会有所不同。 3.3.1 字符串对象如果 TYPE 的值为 REDIS_RDB_TYPE_STRING，那么 value 保存的就是一个字符串对象，字符串对象的编码可以是 REDIS_ENCODING_INT 或者 REDIS_ENCODING_RAW。 如果字符串对象的编码为 REDIS_ENCODING_INT，那么说明对象中保存的是长度不超过 32 位的整数，这种编码的对象将以下面的结构保存： 1ENCODING | integer 其中，ENCODING 的值可以是 REDIS_RDB_ENC_INT8、REDIS_RDB_ENC_INT16 或者 REDIS_RDB_ENC_INT32 三个常量的其中一个，它们分别代表 RDB 文件使用 8 位（bit）、16 位或者 32 位来保存整数值 integer。 如果字符串对象的编码为 REDIS_ENCODING_RAW，那么说明对象所保存的是一个字符串值，根据字符串长度的不同，有压缩和不压缩两种方法来保存这个字符串： 如果字符串的长度小于等于 20 字节，那么这个字符串会直接被原样保存。 如果字符串的长度大于 20 字节，那么这个字符串会被压缩之后再保存。 如果服务器关闭了 RDB 文件压缩功能，那么 RDB 程序总以无压缩的方式保存字符串值。 对于没有被压缩的字符串，RDB 程序会以下面的结构来保存该字符串： 1len | string 其中，string 部分保存了字符串值本身，而 len 保存了字符串值的长度。 对于压缩后的字符串，RDB 程序会以下面的结构来保存该字符串： 1REDIS_RDB_ENC_LZF | compressed_len | origin_len | compressed_string 其中，REDIS_RDB_ENC_LZF 常量标志着字符串已经被 LZF 算法（http://liblzf.plan9.de）压缩过了，读入程序在碰到这个常量时，会根据之后的 compressed_len、origin_len 和 compressed_string 三部分，对字符串进行解压缩：其中 compressed_len 记录的是字符串被压缩之后的长度，而 origin_len 记录的是字符串原来的长度，compressed_string 记录的则是被压缩之后的字符串。 3.3.2 列表对象如果 TYPE 的值为 REDIS_RDB_TYPE_LIST，那么 value 保存的就是一个 REDIS_ENCODING_LINKEDLIST 编码的列表对象，RDB 文件保存这种对象的结构如下： 1list_length | item1 | item2 | ... | itemN list_length 记录了列表的长度，它记录列表保存了多少个项（item），读入程序可以通过这个长度知道自己应该读入多少个列表项。 3.3.3 集合对象如果 TYPE 的值为 REDIS_RDB_TYPE_SET，那么 value 保存的就是一个 REDIS_ENCODING_HT 编码的集合对象，RDB 文件保存这种对象的结构如下： 1set_size | elem1 | elem2 | ... | elemN 其中，set_size 是集合的大小，它记录集合保存了多少个元素，读入程序可以通过这个大小知道自己应该读入多少个集合元素。 3.3.4 哈希表对象如果 TYPE 的值为 REDIS_RDB_TYPE_HASH，那么 value 保存的就是一个 REDIS_ENCODING_HT 编码的集合对象，RDB 文件保存这种对象的结构如下： 1hash_size | key1 | value1 | key2 | value2 | ... | keyN | valueN hash_size 记录了哈希表的大小，也即是这个哈希表保存了多少键值对，读入程序可以通过这个大小知道自己应该读入多少个键值对。 键值对的键和值都是字符串对象，所以程序会以处理字符串对象的方式来保存和读入键值对。 3.3.5 有序集合对象如果 TYPE 的值为 REDIS_RDB_TYPE_ZSET，那么 value 保存的就是一个 REDIS_ENCODING_SKIPLIST 编码的有序集合对象，RDB 文件保存这种对象的结构如下： 1sorted_set_size | member1 | score1 | member2 | score2 | ... | memberN | scoreN 以 element 开头的部分代表有序集合中的元素，每个元素又分为成员（member）和分值（score）两部分，成员是一个字符串对象，分值则是一个 double 类型的浮点数，程序在保存 RDB 文件时会先将分值转换成字符串对象，然后再用保存字符串对象的方法将分值保存起来。 3.3.6 INTSET 编码的集合如果 TYPE 的值为 REDIS_RDB_TYPE_SET_INTSET，那么 value 保存的就是一个整数集合对象，RDB 文件保存这种对象的方法是，先将整数集合转换为字符串对象，然后将这个字符串对象保存到 RDB 文件里面。 如果程序在读入 RDB 文件的过程中，碰到由整数集合对象转换成的字符串对象，那么程序会根据 TYPE 值的指示，先读入字符串对象，再将这个字符串对象转换成原来的整数集合对象。 3.3.7 ZIPLIST 编码的列表、哈希表或者有序集合如果 TYPE 的值为 REDIS_RDB_TYPE_LIST_ZIPLIST、REDIS_RDB_TYPE_HASH_ZIPLIST 或者 REDIS_RDB_TYPE_ZSET_ZIPLIST，那么 value 保存的就是一个压缩列表对象，RDB 文件保存这种对象的方法是： 将压缩列表转换成一个字符串对象。 将转换所得的字符串对象保存到RDB文件。 如果程序在读入 RDB 文件的过程中，碰到由压缩列表对象转换成的字符串对象，那么程序会根据 TYPE 值的指示，执行以下操作： 读入字符串对象，并将它转换成原来的压缩列表对象。 根据 TYPE 的值，设置压缩列表对象的类型：如果 TYPE 的值为 REDIS_RDB_TYPE_LIST_ZIPLIST，那么压缩列表对象的类型为列表；如果 TYPE 的值为 REDIS_RDB_TYPE_HASH_ZIPLIST，那么压缩列表对象的类型为哈希表；如果 TYPE 的值为 REDIS_RDB_TYPE_ZSET_ZIPLIST，那么压缩列表对象的类型为有序集合。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：复制》]]></title>
    <url>%2F2017%2F10%2F08%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E5%A4%8D%E5%88%B6%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 旧版复制功能的实现Redis 的复制功能分为同步（sync）和命令传播（command propagate）两个操作： 其中，同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 而命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器的数据库重新回到一致状态。 1.1 同步当客户端向从服务器发送 SLAVEOF 命令，要求从服务器复制主服务器时，从服务器首先需要执行同步操作，也即是，将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 从服务器对主服务器的同步操作需要通过向主服务器发送 SYNC 命令来完成，以下是 SYNC 命令的执行步骤： 从服务器向主服务器发送 SYNC 命令。 收到 SYNC 命令的主服务器执行 BGSAVE 命令，在后台生成一个 RDB 文件，并使用一个缓冲区记录从现在开始执行的所有写命令。 当主服务器的 BGSAVE 命令执行完毕时，主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器，从服务器接收并载入这个 RDB 文件，将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态。 主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。 1.2 命令传播在同步操作执行完毕之后，主从服务器两者的数据库将达到一致状态，但这种一致并不是一成不变的——每当主服务器执行客户端发送的写命令时，主服务器的数据库就有可能会被修改，并导致主从服务器状态不再一致。 为了让主从服务器再次回到一致状态，主服务器需要对从服务器执行命令传播操作：主服务器会将自己执行的写命令——也即是造成主从服务器不一致的那条写命令——发送给从服务器执行，当从服务器执行了相同的写命令之后，主从服务器将再次回到一致状态。 2. 旧版复制功能的缺陷在 Redis 2.8 以前，从服务器对主服务器的复制可以分为以下两种情况： 初次复制：从服务器以前没有复制过任何主服务器，或者从服务器当前要复制的主服务器和上一次复制的主服务器不同。 断线后重复制：处于命令传播阶段的主从服务器因为网络原因而中断了复制，但从服务器通过自动重连接重新连上了主服务器，并继续复制主服务器。 对于初次复制来说，旧版复制功能能够很好地完成任务，但对于断线后重复制来说，旧版复制功能虽然也能让主从服务器重新回到一致状态，但效率却非常低。 SYNC 命令是一个非常耗费资源的操作，因为每次执行 SYNC 命令，主从服务器需要执行以下操作： 主服务器需要执行 BGSAVE 命令来生成 RDB 文件，这个生成操作会耗费主服务器大量的 CPU、内存和磁盘 I/O 资源。 主服务器需要将自己生成的 RDB 文件发送给从服务器，这个发送操作会耗费主从服务器大量的网络资源（带宽和流量），并对主服务器响应命令请求的时间产生影响。 接收到 RDB 文件的从服务器需要载入主服务器发来的 RDB 文件，并且在载入期间，从服务器会因为阻塞而没办法处理命令请求。 3. 新版复制功能的实现为了解决旧版复制功能在处理断线重复制情况时的低效问题，Redis 从 2.8 版本开始，使用 PSYNC 命令代替 SYNC 命令来执行复制时的同步操作。 PSYNC 命令具有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式： 其中完整重同步用于处理初次复制情况：完整重同步的执行步骤和 SYNC 命令的执行步骤基本一样，它们都是通过让主服务器创建并发送 RDB 文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步。 而部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态。 4. 部分重同步的实现部分重同步功能由以下三个部分构成： 主服务器的复制偏移量（replication offset）和从服务器的复制偏移量。 主服务器的复制积压缓冲区（replication backlog）。 服务器的运行 ID（run ID）。 4.1 复制偏移量执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量： 主服务器每次向从服务器传播 N 个字节的数据时，就将自己的复制偏移量的值加上 N。 从服务器每次收到主服务器传播来的 N 个字节的数据时，就将自己的复制偏移量的值加上N。 通过对比主从服务器的复制偏移量，程序可以很容易地知道主从服务器是否处于一致状态： 如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同的。 相反，如果主从服务器两者的偏移量并不相同，那么说明主从服务器并未处于一致状态。 4.2 复制积压缓冲区复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为 1 MB。 当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面。因此，主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量。 当从服务器重新连上主服务器时，从服务器会通过 PSYNC 命令将自己的复制偏移量 offset 发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作： 如果 offset 偏移量之后的数据（也即是偏移量 offset+1 开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作。主服务器向从服务器发送 +CONTINUE 回复，表示数据同步将以部分重同步模式来进行。 相反，如果 offset 偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作。 Redis 为复制积压缓冲区设置的默认大小为 1 MB，如果主服务器需要执行大量写命令，又或者主从服务器断线后重连接所需的时间比较长，那么这个大小也许并不合适。如果复制积压缓冲区的大小设置得不恰当，那么 PSYNC 命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要。 复制积压缓冲区的最小大小可以根据公式 second*write_size_per_second 来估算： 其中 second 为从服务器断线后重新连接上主服务器所需的平均时间（以秒计算）； 而 write_size_per_second 则是主服务器平均每秒产生的写命令数据量（协议格式的写命令的长度总和）； 为了安全起见，可以将复制积压缓冲区的大小设为 2\*second*write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理。 4.3 服务器运行 ID除了复制偏移量和复制积压缓冲区之外，实现部分重同步还需要用到服务器运行 ID（run ID）： 每个 Redis 服务器，不论主服务器还是从服务，都会有自己的运行 ID。 运行 ID 在服务器启动时自动生成，由 40 个随机的十六进制字符组成。 当从服务器对主服务器进行初次复制时，主服务器会将自己的运行 ID 传送给从服务器，而从服务器则会将这个运行 ID 保存起来。 当从服务器断线并重新连上一个主服务器时，从服务器将向当前连接的主服务器发送之前保存的运行 ID： 如果从服务器保存的运行 ID 和当前连接的主服务器的运行 ID 相同，那么说明从服务器断线之前复制的就是当前连接的这个主服务器，主服务器可以继续尝试执行部分重同步操作。 相反地，如果从服务器保存的运行 ID 和当前连接的主服务器的运行 ID 并不相同，那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器，主服务器将对从服务器执行完整重同步操作。 5. PSYNC 命令的实现PSYNC 命令的调用方法有两种： 如果从服务器以前没有复制过任何主服务器，或者之前执行过 SLAVEOF no one 命令，那么从服务器在开始一次新的复制时将向主服务器发送 PSYNC ? -1命令，主动请求主服务器进行完整重同步（因为这时不可能执行部分重同步）； 相反地，如果从服务器已经复制过某个主服务器，那么从服务器在开始一次新的复制时将向主服务器发送 PSYNC &lt;runid&gt; &lt;offset&gt; 命令：其中 runid 是上一次复制的主服务器的运行 ID，而 offset 则是从服务器当前的复制偏移量，接收到这个命令的主服务器会通过这两个参数来判断应该对从服务器执行哪种同步操作。 根据情况，接收到 PSYNC 命令的主服务器会向从服务器返回以下三种回复的其中一种： 如果主服务器返回 +FULLRESYNC &lt;runid&gt; &lt;offset&gt; 回复，那么表示主服务器将与从服务器执行完整重同步操作：其中 runid 是这个主服务器的运行 ID，从服务器会将这个 ID 保存起来，在下一次发送 PSYNC 命令时使用；而 offset 则是主服务器当前的复制偏移量，从服务器会将这个值作为自己的初始化偏移量. 如果主服务器返回 +CONTINUE 回复，那么表示主服务器将与从服务器执行部分重同步操作，从服务器只要等着主服务器将自己缺少的那部分数据发送过来就可以了。 如果主服务器返回 -ERR 回复，那么表示主服务器的版本低于 Redis 2.8，它识别不了 PSYNC 命令，从服务器将向主服务器发送 SYNC 命令，并与主服务器执行完整同步操作。 6. 复制的实现6.1 步骤 1：设置主服务器的地址和端口当客户端向从服务器发送以下命令时： 12127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379OK 从服务器首先要做的就是将客户端给定的主服务器 IP 地址 127.0.0.1 以及端口 6379 保存到服务器状态的 masterhost 属性和 masterport 属性里面： 1234567891011struct redisServer &#123; // ... // 主服务器的地址 char *masterhost; // 主服务器的端口 int masterport; // ...&#125;; SLAVEOF 命令是一个异步命令，在完成 masterhost 属性和 masterport 属性的设置工作之后，从服务器将向发送 SLAVEOF 命令的客户端返回 OK，表示复制指令已经被接收，而实际的复制工作将在OK 返回之后才真正开始执行。 6.2 步骤 2：建立套接字连接在 SLAVEOF 命令执行之后，从服务器将根据命令所设置的 IP 地址和端口，创建连向主服务器的套接字连接。 如果从服务器创建的套接字能成功连接（connect）到主服务器，那么从服务器将为这个套接字关联一个专门用于处理复制工作的文件事件处理器，这个处理器将负责执行后续的复制工作，比如接收 RDB 文件，以及接收主服务器传播来的写命令，诸如此类。 而主服务器在接受（accept）从服务器的套接字连接之后，将为该套接字创建相应的客户端状态，并将从服务器看作是一个连接到主服务器的客户端来对待，这时从服务器将同时具有服务器（server）和客户端（client）两个身份：从服务器可以向主服务器发送命令请求，而主服务器则会向从服务器返回命令回复。 6.3 步骤3：发送 PING 命令从服务器成为主服务器的客户端之后，做的第一件事就是向主服务器发送一个 PING 命令。 这个 PING 命令有两个作用： 虽然主从服务器成功建立起了套接字连接，但双方并未使用该套接字进行过任何通信，通过发送 PING 命令可以检查套接字的读写状态是否正常。 因为复制工作接下来的几个步骤都必须在主服务器可以正常处理命令请求的状态下才能进行，通过发送 PING 命令可以检查主服务器能否正常处理命令请求。 从服务器在发送 PING 命令之后将遇到以下三种情况的其中一种： 主服务器向从服务器返回了一个命令回复，但从服务器却不能在规定的时限内读取命令回复的内容（timeout），那么表示主从服务器之间的网络连接状态不佳，不能继续执行复制工作的后续步骤。当出现这种情况时，从服务器断开并重新创建连向主服务器的套接字。 如果主服务器返回一个错误，那么表示主服务器暂时没有办法处理从服务器的命令请求，不能继续执行复制工作的后续步骤。当出现这种情况时，从服务器将断开并重新创建连向主服务器的套接字。 如果从服务器读取到 “PONG” 回复，那么表示主从服务器之间的网络连接状态正常，并且主服务器可以正常处理从服务器（客户端）发送的命令请求，在这种情况下，从服务器可以继续执行复制工作的后续步骤。 6.4 步骤 4：身份验证从服务器在收到主服务器返回的 “PONG” 回复之后，下一步要做的就是决定是否进行身份验证： 如果从服务器设置了 masterauth 选项，那么进行身份验证。 如果从服务器没有设置 masterauth 选项，那么不进行身份验证。 在需要进行身份验证的情况下，从服务器将向主服务器发送一条 AUTH 命令，命令的参数为从服务器 masterauth 选项的值。 从服务器在身份验证阶段可能遇到的情况有以下几种： 如果主服务器没有设置 requirepass 选项，并且从服务器也没有设置 masterauth 选项，那么主服务器将继续执行从服务器发送的命令，复制工作可以继续进行。 如果从服务器通过 AUTH 命令发送的密码和主服务器 requirepass 选项所设置的密码相同，那么主服务器将继续执行从服务器发送的命令。否则主服务器将返回一个 invaild password 错误。 如果主服务器设置了 requireoass 选项，但从服务器却没有设置 masterauth 选项，那么主服务器将返回一个 NOAUTH 错误。另一方面，如果主服务器没有设置 requirepass 选项，但是从服务器却设置了 materauth 选项，那么主服务器将返回一个 no password is set 错误。 所有错误情况都会令从服务器中止目前的复制工作，并从创建套接字开始重新执行复制，直到身份验证通过，或者从服务器放弃执行复制为止。 6.5 步骤 5：发送端口信息身份验证步骤之后，从服务器将执行命令 REPLCONF listening-port &lt;port-number&gt;**，向主服务器发送从服务器的监听端口号。 主服务器在接收到这个命令之后，会将端口号记录在从服务器所对应的客户端状态的 slave_listening_port 属性中： 1234567891011typedef struct redisClient &#123; // ... // 从服务器的监听端口号 int slave_listening_port; // ...｝redisClient; slave_listening_port 属性目前唯一的作用就是在主服务器执行 INFO replication 命令时打印出从服务器的端口号。 6.6 步骤 6：同步在这一步，从服务器将向主服务器发送 PSYNC 命令，执行同步操作，并将自己的数据库更新至主服务器数据库当前所处的状态。 值得一提的是，在同步操作执行之前，只有从服务器是主服务器的客户端，但在执行同步操作之后，主服务器也会成为从服务器的客户端： 如果 PSYNC 命令执行的是完整重同步操作，那么主服务器需要成为从服务器的客户端，才能将保存在缓冲区里面的写命令发送给从服务器执行。 如果 PSYNC 命令执行的是部分重同步操作，那么主服务器需要成为从服务器的客户端，才能将保存在复制积压缓冲区中的写命令发送给从服务器执行。 因此，在同步操作执行之后，主从服务器双方都是对方的客户端，它们可以互相向对方发送命令请求，或者互相向对方返回命令回复。 6.6 步骤 7：命令传播当完成了同步之后，主从服务器就会进入命令传播阶段，这时主服务器只要一直将自己执行的写命令发送给从服务器，而从服务器只要一直接收并执行主服务器发来的写命令，就可以保证主从服务器一直保持一致了。 7. 心跳检测在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令：REPLCONF ACK &lt;replication_offset&gt; ，其中 replication_offset 是从服务器当前的复制偏移量。 发送 REPLCONF ACK 命令对于主从服务器有三个作用： 检测主从服务器的网络连接状态。 辅助实现 min-slaves 选项。 检测命令丢失。 7.1 检测主从服务器的网络连接状态主从服务器可以通过发送和接收 REPLCONF ACK 命令来检查两者之间的网络连接是否正常：如果主服务器超过一秒钟没有收到从服务器发来的 REPLCONF ACK 命令，那么主服务器就知道主从服务器之间的连接出现问题了。 通过向主服务器发送 INFO replication 命令，在列出的从服务器列表的 lag 一栏中，我们可以看到相应从服务器最后一次向主服务器发送 REPLCONF ACK 命令距离现在过了多少秒。在一般情况下，lag 的值应该在 0 秒或者 1 秒之间跳动，如果超过 1 秒的话，那么说明主从服务器之间的连接出现了故障。 7.2 辅助实现 min-slaves 配置选项Redis 的 min-slaves-to-write 和 min-slaves-max-lag 两个选项可以防止主服务器在不安全的情况下执行写命令。举个例子，如果我们向主服务器提供以下设置： 12min-slaves-to-write 3min-slaves-max-lag 10 那么在从服务器的数量少于 3 个，或者三个从服务器的延迟（lag）值都大于或等于 10 秒时，主服务器将拒绝执行写命令，这里的延迟值就是上面提到的 INFO replication 命令的 lag 值。 7.3 检测命令丢失如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发送 REPLCONF ACK 命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量，然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。 主服务器向从服务器补发缺失数据这一操作的原理和部分重同步操作的原理非常相似，它们的区别在于：补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：集群》]]></title>
    <url>%2F2017%2F10%2F07%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E9%9B%86%E7%BE%A4%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 节点一个 Redis 集群通常由多个节点（node）组成，在刚开始的时候，每个节点都是相互独立的，它们都处于一个只包含自己的集群当中，要组建一个真正可工作的集群，我们必须将各个独立的节点连接起来，构成一个包含多个节点的集群。 连接各个节点的工作可以使用 CLUSTER MEET 命令来完成，该命令的格式如下：CLUSTER MEET &lt;ip&gt; &lt;port&gt;。 向一个节点 node 发送 CLUSTER MEET 命令，可以让 node 节点与 ip 和 port 所指定的节点进行握手（handshake），当握手成功时，node 节点就会将 ip 和 port 所指定的节点添加到 node 节点当前所在的集群中。 1.1 启动节点一个节点就是一个运行在集群模式下的 Redis 服务器， Redis 服务器在启动时会根据 cluster-enabled 配置选项的是否为 yes 来决定是否开启服务器的集群模式。 节点（运行在集群模式下的 Redis 服务器）会继续使用所有在单机模式中使用的服务器组件。除此之外， 节点会继续使用 redisServer 结构来保存服务器的状态， 使用 redisClient 结构来保存客户端的状态， 至于那些只有在集群模式下才会用到的数据， 节点将它们保存到了 cluster.h/clusterNode 结构， cluster.h/clusterLink 结构， 以及 cluster.h/clusterState 结构里面。 1.2 集群数据结构clusterNode 结构保存了一个节点的当前状态，比如节点的创建时间，节点的名字，节点当前的配置纪元，节点的 IP 和地址，等等。 每个节点都会使用一个 clusterNode 结构来记录自己的状态，并为集群中的所有其他节点（包括主节点和从节点）都创建一个相应的 clusterNode 结构，以此来记录其他节点的状态： 12345678910111213141516171819202122232425typedef struct clusterNode &#123; mstime_t ctime; /* Node object creation time. */ char name[CLUSTER_NAMELEN]; /* Node name, hex string, sha1-size */ int flags; /* CLUSTER_NODE_... */ uint64_t configEpoch; /* Last configEpoch observed for this node */ unsigned char slots[CLUSTER_SLOTS/8]; /* slots handled by this node */ int numslots; /* Number of slots handled by this node */ int numslaves; /* Number of slave nodes, if this is a master */ struct clusterNode **slaves; /* pointers to slave nodes */ struct clusterNode *slaveof; /* pointer to the master node. Note that it may be NULL even if the node is a slave if we don&apos;t have the master node in our tables. */ mstime_t ping_sent; /* Unix time we sent latest ping */ mstime_t pong_received; /* Unix time we received the pong */ mstime_t fail_time; /* Unix time when FAIL flag was set */ mstime_t voted_time; /* Last time we voted for a slave of this master */ mstime_t repl_offset_time; /* Unix time we received offset for this node */ mstime_t orphaned_time; /* Starting time of orphaned master condition */ long long repl_offset; /* Last known repl offset for this node. */ char ip[NET_IP_STR_LEN]; /* Latest known IP address of this node */ int port; /* Latest known port of this node */ clusterLink *link; /* TCP/IP link with this node */ list *fail_reports; /* List of nodes signaling this as failing */&#125; clusterNode; clusterNode 结构的 link 属性是一个 clusterLink 结构，该结构保存了连接节点所需的有关信息，比如套接字描述符，输入缓冲区和输出缓冲区： 12345678/* clusterLink encapsulates everything needed to talk with a remote node. */typedef struct clusterLink &#123; mstime_t ctime; /* Link creation time */ int fd; /* TCP socket file descriptor */ sds sndbuf; /* Packet send buffer */ sds rcvbuf; /* Packet reception buffer */ struct clusterNode *node; /* Node related to this link if any, or NULL */&#125; clusterLink; redisClient 结构和 clusterLink 结构都有自己的套接字描述符和输入、输出缓冲区，这两个结构的区别在于，redisClient 结构中的套接字和缓冲区是用于连接客户端的，而 clusterLink 结构中的套接字和缓冲区则是用于连接节点的。 最后，每个节点都保存着一个 clusterState 结构，这个结构记录了在当前节点的视角下，集群目前所处的状态——比如集群是在线还是下线，集群包含多少个节点，集群当前的配置纪元，诸如此类： 1234567891011121314151617181920212223242526272829303132333435typedef struct clusterState &#123; clusterNode *myself; /* This node */ uint64_t currentEpoch; int state; /* CLUSTER_OK, CLUSTER_FAIL, ... */ int size; /* Num of master nodes with at least one slot */ dict *nodes; /* Hash table of name -&gt; clusterNode structures */ dict *nodes_black_list; /* Nodes we don&apos;t re-add for a few seconds. */ clusterNode *migrating_slots_to[CLUSTER_SLOTS]; clusterNode *importing_slots_from[CLUSTER_SLOTS]; clusterNode *slots[CLUSTER_SLOTS]; zskiplist *slots_to_keys; /* The following fields are used to take the slave state on elections. */ mstime_t failover_auth_time; /* Time of previous or next election. */ int failover_auth_count; /* Number of votes received so far. */ int failover_auth_sent; /* True if we already asked for votes. */ int failover_auth_rank; /* This slave rank for current auth request. */ uint64_t failover_auth_epoch; /* Epoch of the current election. */ int cant_failover_reason; /* Why a slave is currently not able to failover. See the CANT_FAILOVER_* macros. */ /* Manual failover state in common. */ mstime_t mf_end; /* Manual failover time limit (ms unixtime). It is zero if there is no MF in progress. */ /* Manual failover state of master. */ clusterNode *mf_slave; /* Slave performing the manual failover. */ /* Manual failover state of slave. */ long long mf_master_offset; /* Master offset the slave needs to start MF or zero if stil not received. */ int mf_can_start; /* If non-zero signal that the manual failover can start requesting masters vote. */ /* The followign fields are used by masters to take state on elections. */ uint64_t lastVoteEpoch; /* Epoch of the last vote granted. */ int todo_before_sleep; /* Things to do in clusterBeforeSleep(). */ long long stats_bus_messages_sent; /* Num of msg sent via cluster bus. */ long long stats_bus_messages_received; /* Num of msg rcvd via cluster bus.*/&#125; clusterState; 1.3 CLUSTER MEET 命令的实现通过向节点 A 发送 CLUSTER MEET 命令，客户端可以让接收命令的节点 A 将另一个节点 B 添加到节点 A 当前所在的集群里面：CLUSTER MEET &lt;ip&gt; &lt;port&gt;。 收到命令的节点 A 将与节点 B 进行握手（handshake），以此来确认彼此的存在，并为将来的进一步通信打好基础： 节点 A 会为节点 B 创建一个 clusterNode 结构，并将该结构添加到自己的 clusterState.nodes 字典里面。 之后，节点 A 将根据 CLUSTER MEET 命令给定的 IP 地址和端口号， 向节点 B 发送一条 MEET 消息（message）。 如果一切顺利，节点 B 将接收到节点 A 发送的 MEET 消息，节点 B 会为节点 A 创建一个 clusterNode 结构，并将该结构添加到自己的 clusterState.nodes 字典里面。 之后，节点 B 将向节点 A 返回一条 PONG 消息。 如果一切顺利，节点 A 将接收到节点 B 返回的 PONG 消息，通过这条 PONG 消息节点 A 可以知道节点 B 已经成功地接收到了自己发送的 MEET 消息。 之后，节点 A 将向节点 B 返回一条 PING 消息。 如果一切顺利，节点 B 将接收到节点 A 返回的 PING 消息，通过这条 PING 消息节点 B 可以知道节点 A 已经成功地接收到了自己返回的 PONG 消息，握手完成。 之后，节点 A 会将节点 B 的信息通过 Gossip 协议传播给集群中的其他节点，让其他节点也与节点 B 进行握手，最终，经过一段时间之后，节点 B 会被集群中的所有节点认识。 2. 槽指派Redis 集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为 16384 个槽（slot），数据库中的每个键都属于这 16384 个槽的其中一个，集群中的每个节点可以处理 0 个或最多 16384 个槽。 当数据库中的 16384 个槽都有节点在处理时，集群处于上线状态（ok）；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态（fail）。 通过向节点发送 CLUSTER ADDSLOTS 命令，我们可以将一个或多个槽指派（assign）给节点负责： 1CLUSTER ADDSLOTS &lt;slot&gt; [slot …] 2.1 记录节点的槽指派信息clusterNode 结构的 slots 属性和 numslot 属性记录了节点负责处理哪些槽： 1234567891011struct clusterNode &#123; // ... unsigned char slots[16384/8]; int numslots; // ... &#125;; slots 属性是一个二进制位数组（bit array），这个数组的长度为 16384/8=2048 个字节，共包含 16384 个二进制位。 Redis 以 0 为起始索引，16383 为终止索引，对 slots 数组中的 16384 个二进制位进行编号，并根据索引 i 上的二进制位的值来判断节点是否负责处理槽 i： 如果 slots 数组在索引 i 上的二进制位的值为 1，那么表示节点负责处理槽 i； 如果 slots 数组在索引 i 上的二进制位的值为 0，那么表示节点不负责处理槽 i； 因为取出和设置 slots 数组中的任意一个二进制位的值的复杂度仅为 $O(1)$，所以对于一个给定节点的 slots 数组来说，程序检查节点是否负责处理某个槽，又或者将某个槽指派给节点负责，这两个动作的复杂度都是 $O(1)$。 至于 numslots 属性则记录节点负责处理的槽的数量，也即是 slots 数组中值为 1 的二进制位的数量。 2.2 传播节点的槽指派信息一个节点除了会将自己负责处理的槽记录在 clusterNode 结构的 slots 属性和 numslots 属性之外，它还会将自己的 slots 数组通过消息发送给集群中的其他节点，以此来告知其他节点自己目前负责处理哪些槽。 当节点 A 通过消息从节点 B 那里接收到节点 B 的 slots 数组时，节点 A 会在自己的 clusterState.nodes 字典中查找节点 B 对应的 clusterNode 结构，并对结构中的 slots 数组进行保存或者更新。 因为集群中的每个节点都会将自己的 slots 数组通过消息发送给集群中的其他节点，并且每个接收到 slots 数组的节点都会将数组保存到相应节点的 clusterNode 结构里面，因此，集群中的每个节点都会知道数据库中的 16384 个槽分别被指派给了集群中的哪些节点。 2.3 记录集群所有槽的指派信息clusterState 结构中的 slots 数组记录了集群中所有 16384 个槽的指派信息： 123456789typedef struct clusterState &#123; // ... clusterNode *slots[16384]; // ... &#125; clusterState; slots 数组包含了 16384 个项，每个数组项都是一个指向 clusterNode 结构的指针： 如果 slots[i] 指针指向 NULL，那么表示槽 i 尚未指派给任何节点。 如果 slots[i] 指针指向一个 clusterNode 结构，那么表示槽 i 已经指派给了 clusterNode 结构所代表的节点。 如果只将槽指派信息保存在各个节点的 clusterNode.slots 数组里，会出现一些无法高效地解决的问题，而 clusterState.slots 数组的存在解决了这些问题： 如果节点只使用 clusterNode.slots 数组来记录槽的指派信息，那么为了知道槽 i 是否已经被指派，或者槽 i 被指派给了哪个节点，程序需要遍历 clusterState.nodes 字典中的所有 clusterNode 结构，检查这些结构的 slots 数组，直到找到负责处理槽 i 的节点为止，这个过程的复杂度为 $O(N)$，其中 $N$ 为 clusterState.nodes 字典保存的 clusterNode 结构的数量。 而通过将所有槽的指派信息保存在 clusterState.slots 数组里面，程序要检查槽 i 是否已经被指派，又或者取得负责处理槽 i 的节点，只需要访问 clusterState.slots[i] 的值即可，这个操作的复杂度仅为 $O(1)$。 要说明的一点是，虽然 clusterState.slots 数组中记录了集群中所有槽的指派信息，但使用 clusterNode 结构的 slots 数组来记录单个节点的槽指派信息仍然是有必要的： 因为当程序需要将某个节点的槽指派信息通过消息发送给其他节点时，程序只需要将相应节点的 clusterNode.slots 数组整个发送出去就可以了。 另一方面，如果 Redis 不使用 clusterNode.slots 数组，而单独使用 clusterState.slots 数组的话，那么每次要将节点 A 的槽指派信息传播给其他节点时，程序必须先遍历整个 clusterState.slots 数组，记录节点 A 负责处理哪些槽，然后才能发送节点 A 的槽指派信息，这比直接发送 clusterNode.slots 数组要麻烦和低效得多。 clusterState.slots 数组记录了集群中所有槽的指派信息，而 clusterNode.slots 数组只记录了 clusterNode 结构所代表的节点的槽指派信息，这是两个 slots 数组的关键区别所在。 2.4 CLUSTER ADDSLOTS命令的实现CLUSTER ADDSLOTS 命令接受一个或多个槽作为参数，并将所有输入的槽指派给接收该命令的节点负责： 1CLUSTER ADDSLOTS &lt;slot&gt; [slot ...] CLUSTER ADDSLOTS 命令的实现可以用以下伪代码来表示： 12345678910111213141516171819202122def CLUSTER_ADDSLOTS(*all_input_slots): # 遍历所有输入槽，检查它们是否都是未指派槽 for i in all_input_slots: # 如果有哪怕一个槽已经被指派给了某个节点 # 那么向客户端返回错误，并终止命令执行 if clusterState.slots[i] != NULL: reply_error() return # 如果所有输入槽都是未指派槽 # 那么再次遍历所有输入槽，将这些槽指派给当前节点 for i in all_input_slots: # 设置clusterState结构的slots数组 # 将slots[i]的指针指向代表当前节点的clusterNode结构 clusterState.slots[i] = clusterState.myself # 访问代表当前节点的clusterNode结构的slots数组 # 将数组在索引i上的二进制位设置为 1 setSlotBit(clusterState.myself.slots, i) 最后，在 CLUSTER ADDSLOTS 命令执行完毕之后，节点会通过发送消息告知集群中的其他节点，自己目前正在负责处理哪些槽。 3. 在集群中执行命令在对数据库中的 16384 个槽都进行了指派之后，集群就会进入上线状态，这时客户端就可以向集群中的节点发送数据命令了。 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己： 如果键所在的槽正好指派了当前节点，那么节点直接执行这个命令。 如果键所在的槽并没有指派给当前节点，那么节点会向客户端返回一个 MOVED 错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令。 3.1 计算键属于哪个槽节点使用以下算法来计算给定键 key 属于哪个槽： 12def slot_number(key): return CRC16(key) &amp; 16383 其中 CRC16(key) 语句用于计算键 key 的 CRC-16 校验和，而 &amp; 16383 语句则用于计算出一个介于0 至 16383 之间的整数作为键 key 的槽号。 使用 CLUSTER KEYSLOT &lt;key&gt; 命令可以查看一个给定键属于哪个槽，以下是该命令的伪代码实现： 1234567def CLUSTER_KEYSLOT(key) # 计算槽号 slot = slot_number(key) # 将槽号返回给客户端 reply_client(slot) 3.2 判断槽是否由当前节点负责处理当节点计算出键所属的槽 i 之后，节点就会检查自己在 clusterState.slots 数组中的项 i，判断键所在的槽是否由自己负责： 如果 clusterState.slots[i] 等于 clusterState.myself，那么说明槽 i 由当前节点负责，节点可以执行客户端发送的命令。 如果 clusterState.slots[i] 不等于 clusterState.myself，那么说明槽 i 并非由当前节点负责，节点会根据 clusterState.slots[i] 指向的 clusterNode 结构所记录的节点 IP 和端口，向客户端返回 MOVED 错误，指引客户端转向至正在处理槽 i 的节点。 3.3 MOVED 错误当节点发现键所在的槽并非由自己负责处理时，节点会向客户端返回一个 MOVED 错误，指引客户端转向至正在负责槽的节点，MOVED 错误的格式为： 1MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt; 其中 slot 为键所在的槽，而 ip 和 port 则是负责处理槽 slot 的节点的 IP 地址和端口号。 当客户端接收到节点返回的 MOVED 错误时，客户端会根据 MOVED 错误中提供的 IP 地址和端口号，转向至负责处理槽 slot 的节点，并向该节点重新发送之前想要执行的命令。 一个集群客户端通常会与集群中的多个节点创建套接字连接，而所谓的节点转向实际上就是换一个套接字来发送命令。 如果客户端尚未与想要转向的节点创建套接字连接，那么客户端会现根据 MOVED 错误提供的 IP 地址和端口号来连接节点，然后再进行转向。 集群模式的 redis-cli 客户端在接收到 MOVED 错误时，并不会打印出 MOVED 错误，而是根据 MOVED 错误自动进行节点跳转，并打印出转向信息，所以我们是看不见节点返回的 MOVED 错误的。 但是，如果我们使用单机（stand alone）模式的 redis-cli 客户端，再次向节点发送相同的命令，那么 MOVED 错误就会被客户端打印出来。这是因为单机模式的 redis-cli 客户端不清楚 MOVED 错误的作用，所以它只会直接将 MOVED 错误直接打印出来，而不会进行自动转向。 3.4 节点数据库的实现节点和单机服务器在数据库方面的一个区别是，节点只能使用 0 号数据库，而单机 Redis 服务器则没有这一限制。 另外，除了将键值对保存在数据库里面之外，节点还会用 clusterState 结构中的 slots_to_keys 跳跃表来保存键和槽之间的关系： 123456789typdef struct clusterState &#123; // ... zskiplist *slots_to_keys; // ... &#125; clusterState; slots_to_keys 跳跃表每个节点的分值（score）都是一个槽号，而每个节点的成员（member）都是一个数据库键： 每当节点往数据库中添加一个新的键值对时，节点就会将这个键以及键的槽号关联到 slots_to_keys 跳跃表。 当节点删除数据库中的某个键值对时，节点就会在 slots_to_keys 跳跃表解除被删除键与槽号的关联。 通过在 slots_to_keys 跳跃表中记录各个数据库键所属的槽，节点可以很方便地对属于某个或某些槽的所有数据库键进行批量操作。 4. 重新分片Redis 集群的重新分片操作可以将任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点），并且相关槽所属的键值对也会从源节点被移动到目标节点。 重新分片操作可以在线（online）进行，在重新分片过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求。 Redis 集群的重新分片操作由 Redis 的集群管理软件 redis-trib 负责执行，Redis 提供了进行重新分片所需的所有命令，而 redis-trib 则通过向源节点和目标节点发送命令来进行重新分片操作。 redis-trib 对集群的单个槽 slot 进行重新分片的步骤如下： redis-trib 对目标节点发送 CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt; 命令，让目标节点准备好从源节点导入（import）属于槽 slot 的键值对。 redis-trib 对源节点发送 CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;target_id&gt; 命令，让源节点准备好将属于槽 slot 的键值对迁移（migrate）至目标节点。 redis-trib 向源节点发送 CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt; 命令，获得最多 count 个属于槽 slot 的键值对的键名。 对于步骤 3 获得的每个键名，redis-trib 都向源节点发送一个 MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt; 命令，将被选中的键原子地从源节点迁移至目标节点。 重复执行步骤 3 和步骤 4，直到源节点保存的所有属于槽 slot 的键值对都被迁移至目标节点为止。 redis-trib 向集群中的任意一个节点发送 CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt; 命令，将槽 slot 指派给目标节点，这一指派信息会通过消息发送至整个集群，最终集群中的所有节点都会知道槽 slot 已经被指派给了目标节点。 如果重新分片涉及多个槽，那么 redis-trib 将对每个给定的槽分别执行上面给出的步骤。 5. ASK 错误在进行重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种情况：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对则保存在目标节点里面。 当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的数据库键恰好就属于正在被迁移的槽时： 源节点会先在自己的数据库里面查找指定的键，如果找到的话，就直接执行客户端发送的命令 相反地，如果源节点没能在自己的数据库里面找到指定的键，那么这个键有可能已经被迁移到了目标节点，源节点将向客户端返回一个 ASK 错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令。 5.1 CLUSTER SETSLOT IMPORTING 命令的实现clusterState 结构的 importing_slots_from 数组记录了当前节点正在从其他节点导入的槽： 123456789typedef struct clusterState &#123; // ... clusterNode *importing_slots_from[16384] // ... &#125; clusterState; 如果 importing_slots_from[i] 的值不为 NULL，而是指向一个 clusterNode 结构，那么表示当前节点正在从 clusterNode 所代表的节点导入槽 i。 在对集群进行重新分片的时候，向目标节点发送命令： 12 可以将目标节点 clusterState.importing_slots_from[i] 的值设置为 source_id 所代表节点的 clusterNode 结构。 5.2 CLUSTER SETSLOT MIGRATING 命令的实现clusterState 结构的 migrating_slots_to 数组记录了当前节点正在迁移至其他节点的槽： 123456789typedef struct clusterState &#123; // ... clusterNode *migrating_slots_to[16384] // ... &#125; clusterState; 如果 migrating_slots_to[i] 的值不为 NULL，而是指向一个 clusterNode 结构，那么表示当前节点正在将槽 i 迁移至 clusterNode 所代表的节点。 在对集群进行重新分片的时候，向源节点发送命令： 1CLUSTER SETSLOT &lt;i&gt; MIGRATING &lt;target_id&gt; 可以将源节点 clusterState.migrating_slots_to[i] 的值设置为 target_id 所代表节点的 clusterNode 结构。 5.3 ASK 错误如果节点收到一个关于键 key 的命令请求，并且键 key 所属的槽 i 正好就指派给了这个节点，那么节点会尝试在自己的数据库里查找键 key，如果找到了的话，节点就直接执行客户端发送的命令。 与此相反，如果节点没有在自己的数据库里找到键 key，那么节点会检查自己的 clusterState.migrating_slots_to[i]，看键 key 所属的槽 i 是否正在进行迁移，如果槽 i 的确在进行迁移的话，那么节点会向客户端发送一个 ASK 错误，引导客户端到正在导入槽 i 的节点去超找键 key。 接到 ASK 错误的客户端会根据错误提供的 IP 和端口号，转向至正在导入槽的目标节点，然后首先向目标节点发送一个 ASKING 命令，之后再重新发送原本想要执行的命令。 5.4 ASKING 命令ASKING 命令唯一要做的就是打开发送该命令的客户端的 REDIS_ASKING 标识，以下是该命令的伪代码实现： 1234567def ASKING(): # 打开标识 client.flags != REDIS_ASKING # 向客户端发送 OK 回复 reply(&quot;OK) 在一般情况下，如果客户端向节点发送一个关于槽 i 的命令，而槽 i 又没有指派给这个节点的话，那么节点将向客户端返回一个 MOVED 错误；但是，如果节点的 clusterState.importing_slots_from[i] 显示节点正在导入槽 i， 并且发送命令的客户端带有 REDIS_ASKING 标识，那么节点将破例执行这个关于槽 i 的命令一次。 当客户端接收到 ASK 错误并转向至正在导入槽的节点时，客户端会先向节点发送一个 ASKING 命令，然后才重新发送想要执行的命令，这是因为如果客户端不发送 ASKING 命令，而直接发送想要执行的命令的话，那么客户端发送的命令将被节点拒绝执行，并返回 MOVED 错误。 另外要注意的是，客户端的 REDIS_ASKING 标识是一个一次性标识，当节点执行了一个带有 REDIS_ASKING 标识的客户端发送的命令之后，客户端的 REDIS_ASKING 标识就会被移除。 5.5 ASK 错误和 MOVED 错误的区别ASK 错误和 MOVED 错误都会导致客户端转向，它们的区别在于： MOVED 错误代表槽的负责权已经从一个节点转移到了另一个节点：客户端收到关于槽 i 的 MOVED 错误之后，客户端每次收到关于槽 i 的命令请求时，都可以直接将命令请求发送至 MOVED 错误所指向的节点，因为该节点就是目前负责处理槽 i 的节点。 与此相反，ASK 错误只是两个节点在迁移槽的过程中使用的一种临时措施：在客户端收到关于槽 i 的 ASK 错误之后，客户端只会在接下来的一次命令请求中将关于槽 i 的命令请求发送至 ASK 错误所指向的节点，但这种转向不会对客户端今后发送关于槽 i 的命令请求产生任何影响，客户端仍然会将关于槽 i 的命令请求发送至目前负责处理槽 i 的节点，除非 ASK 错误再次出现。 6. 复制与故障迁移Redis 集群中的节点分为主节点（master）和从节点（slave），其中主节点用于处理槽，而从节点则用于复制某个主节点，并在被复制的主节点下线时，代替下线主节点继续处理命令请求。 6.1 设置从节点向一个节点发送命令： 1CLUSTER REPLICATE &lt;node_id&gt; 可以让接收命令的节点成为 node_id 所指定节点的从节点，并开始对主节点进行复制： 接收到该命令的节点首先会在自己的 clusterState.nodes 字典里找到 node_id 所对应节点的 clusterNode 结构，并将自己的 clusterState.myself.slaveof 指针指向这个结构，以此来记录这个节点正在复制的主节点： 123456789struct clusterNode &#123; // ... // 如果这是一个从节点，那么指向主节点 struct clusterNode *slaveof; // ... &#125; 然后节点会修改自己在 clusterState.myself.flags 中的属性，关闭原本的 REDIS_NODE_MASTER 标识，打开 REDIS_NODE_SLAVE 标识，表示这个节点已经由原来的主节点变成了从节点。 最后，节点会调用复制代码，并根据 clusterState.myself.slaveof 指向的 clusterNode 结构所保存的 IP 地址和端口号，对主节点进行复制。因为节点的复制功能和单机 Redis 服务器的复制功能使用了相同的代码，所以让从节点复制主节点相当于向从节点发送命令 SLAVEOF &lt;master_ip&gt; &lt;master_port&gt;。 一个节点成为从节点，并开始复制某个主节点这一信息会通过消息发送给集群中的其他节点，最终集群中的所有节点都会知道某个从节点正在复制某个主节点。 集群中的所有节点都会在代表主节点的 clusterNode 结构的 slaves 属性和 numslaves 属性中记录正在复制这个主节点的从节点名单： 1234567891011121314struct clusterNode &#123; // ... // 正在复制这个主节点的从节点数量 int numslaves; // 一个数组 // 每个数组项指向一个正在复制这个主节点的从节点的 clusterNode 结构 struct clusterNode **slaves; // ... &#125; 6.2 故障检测集群中的每个节点都会定期地向集群中的其他节点发送 PING 消息，以此来检测对方是否在线，如果接收 PING 消息的节点没有在规定的时间内，向发送 PING 消息的节点返回 PONG 消息，那么发送 PING 消息的节点就会将接收 PING 消息的节点标记为疑似下线（probable fail，PFAIL）。 集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息。 当一个主节点 A 通过消息得知主节点 B 认为主节点 C 进入了疑似下线状态时，主节点 A 会在自己的 clusterState.nodes 字典中找到主节点 C 所对应的 clusterNode 结构，并将主节点 B 的下线报告（failure report）添加到 clusterNode 结构的 fail_reports 链表里面： 12345678910struct clusterNode &#123; // ... // 一个链表，记录了所有其他节点对该节点的下线报告 list *fail_reports; // ... &#125; 每个下线报告由一个 clusterNodeFailReport 结构表示： 12345678910struct clusterNodeFailReport &#123; // 报告目标节点已经下线的节点 struct clusterNode *node; // 最后一次从 node 节点收到下线报告的时间 // 程序使用这个时间戳来检查下线报告是否过期 // (与当前时间差太久的下线报告会被删除) mstime_t time;&#125; typedef clusterNodeFailReport; 如果在一个集群里面，半数以上负责处理槽的主节点都将某个主节点 x 报告为疑似下线，那么这个主节点 x 将被标记为已下线（FAIL），将主节点 x 标记为已下线的节点会向集群广播一条关于主节点 x 的 FAIL 消息，所有收到这条 FAIL 消息的节点都会立即将主节点 x 标记为已下线。 6.3 故障转移当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移的执行步骤： 复制下线主节点的所有从节点里面，会有一个从节点被选中。 被选中的从节点会执行 SLAVEOF no one 命令，成为新的主节点。 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。 新的主节点向集群广播一条 PONG 消息，这条 PONG 消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。 6.4 选举新的主节点新的主节点是通过选举产生的，以下是集群选举新的主节点的方法： 集群的配置纪元是一个自增计数器，它的初始值为 0。 当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值会被增一。 对于每个配置纪元，集群里每个负责处理槽的主节点都有一次投票的机会，而第一个向主节点要求投票的从节点将获得主节点的投票。 当从节点发现自己正在复制的主节点进入已下线状态时，从节点会想集群广播一条 CLUSTER_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有接收到这条消息、并且具有投票权的主节点向这个从节点投票。 如果一个主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，表示这个主节点支持从节点成为新的主节点。 每个参与选举的从节点都会接收 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己收到了多少条这种消息来同济自己获得了多少主节点的支持。 如果集群里有 N 个具有投票权的主节点，那么当一个从节点收集到大于等于 N/2+1 张支持票时，这个从节点就会当选为新的主节点。 因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有 N 个主节点进行投票，那么具有大于等于 N/2+1 张支持票的从节点只会有一个，这确保了新的主节点只会有一个。 如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，知道选出新的主节点为止。 7. 消息集群中的各个节点通过发送和接收消息（message）来进行通信，我们称发送消息的节点为发送者（sender），接收消息的节点为接收者（receiver）。节点发送的消息主要有以下五种： MEET 消息：当发送者接到客户端发送的 CLUSTER MEET 命令时，发送者会向接收者发送 MEET 消息， 请求接收者加入到发送者当前所处的集群里面。 PING 消息：集群里的每个节点默认每隔一秒钟就会从已知节点列表中随机选出五个节点，然后对这五个节点中最长时间没有发送过 PING 消息的节点发送 PING 消息，以此来检测被选中的节点是否在线。除此以外，如果节点 A 最后一次收到节点 B 发送的 PONG 消息的时间，距离当前时间已经超过了节点 A 的 cluster-node-timeout 选项设置时长的一半，那么节点 A 也会向节点 B 发送 PING 消息，这可以防止节点 A 因为长时间没有随机选中节点 B 作为 PING 消息的发送对象而导致对节点 B 的信息更新滞后。 PONG 消息：当接收者收到发送者发来的 MEET 消息或者 PING 消息时，为了向发送者确认这条 MEET 消息或者 PING 消息已到达，接收者会向发送者返回一条 PONG 消息。另外，一个节点也可以通过向集群广播 PONG 消息来让集群中的其他节点立即刷新关于这个节点的认识，例如当一次故障转移操作成功之后，新的主节点会向集群广播一条 PONG 消息，以此来让集群中的其他节点立即知道这个节点已经变成了主节点，并且接管了已下线节点负责的槽。 FAIL 消息：当一个主节点 A 判断另一个主节点 B 已经进入 FAIL 状态时，节点 A 会向集群广播一条关于节点 B 的 FAIL 消息，所有收到这条消息的节点都会立即将节点 B 标记为已下线。 PUBLISH 消息：当节点收到一个 PUBLISH 命令时，节点会执行这个命令，并向集群广播一条 PUBLISH 消息，所有接收到这条 PUBLISH 消息的节点都会执行相同的 PUBLISH 命令。 一条消息由消息头（header）和消息正文（data）组成。 7.1 消息头节点发送的所有消息都由一个消息头包裹，消息头除了包含消息正文之外，还记录了消息发送者自身的一些信息，因为这些信息也会被消息接受者用到，所以严格来讲，我们可以认为消息头本身也是消息的一部分。 每个消息头都由一个cluster.h/clusterMsg结构表示： 12345678910111213141516171819202122232425262728293031323334353637383940typedef struct &#123; // 消息的长度，包括消息头和消息正文 uint32_t totlen; // 消息的类型 uint16_t type; // 消息正文包含的节点信息数量 // 只在发送MEET、PING、PONG这三种Gossip协议的消息时使用 uint16_t count; // 发送者所处的配置纪元 uint64_t currentEpoch; // 如果发送者是一个master，那么这里记录的是发送者的配置纪元 // 如果发送者是一个slave，那么这里记录的是发送者正在复制的master的配置纪元 uint64_t configEpoch; // 发送者的名字(ID) char sender[REDIS_CLUSTER_NAMELEN]; // 发送者目前的槽指派信息 unsigned char myslots[REDIS_CLUSTER_SLOTS/8]; // 如果发送者是一个slave，那么这里记录的是它正在复制的master的名字 // 如果发送者是一个master，那么这里记录的是REDIS_NODE_NULL_NAME char slaveof[REDIS_CLUSTER_NAMELEN]; // 发送者的端口号 uint16_t port; // 发送者的标识值 uint16_t flags; // 发送者所处集群的状态 unsigned char state; // 消息的正文 union clusterMsgData data;&#125; cllusterMsg; clusterMsg.data 属性指向联合体 cluster.h/clusterMsgData，这个联合体就是消息的正文： 12345678910111213141516union clusterMsgData &#123; struct &#123; // 每条 MEET、PING、PONG 消息都包含两个 clusterMsgDataGossip 结构 clusterMsgDataGossip[1]; &#125; ping; // FAIL 消息的正文 struct &#123; clusterMsgDataFail about; &#125; fail; // PUBLISH 消息的正文 struct &#123; clusterMsgDataPublish msg; &#125; publish;&#125;; clusterMsg 结构的 currentEpoch、sender、myslots 等属性记录了发送者的节点信息，接收者可以根据这些信息，在自己的 clusterState.nodes字典中找到发送者对应的 clusterNode 结构进行更新。 7.2 MEET、PING、PONG 消息的实现Redis 集群中的各个节点通过 Gossip 协议来交换节点的状态信息，其中 Gossip 协议由 MEET、PING、PONG 三种消息实现，这三种消息的正文都是由两个 cluster.h/clusterMsgDataGossip 结构组成： 12345678910111213141516171819typedef struct &#123; // 节点的名字 char nodename[REDIS_CLUSTER_NAMELEN]; // 最后一次向该节点发送 PING 消息的时间戳 uint32_t ping_sent; // 最后一次从该节点接收到 PONG 消息的时间戳 uint32_t pong_received; // 节点的IP char ip[16]; // 节点的端口 uint16_t port; // 节点的标识符 uint16_t flags;&#125; clusterMsgDataGossip; 因为 MEET、PING、PONG 三种消息都是用相同的消息正文，所以节点通过消息头的 type 属性来判断一条消息是 MEET消息、PING 消息还是 PONG 消息。 每次发送 MEET、PING、PONG 消息时，发送者从自己的已知节点中随机选出两个节点（可以是主节点或从节点），并将这两个被选中的节点的信息分别保存到两个 cluster.h/clusterMsgDataGossip 结构里面。 clusterMsgDataGossip 结构记录了被选中的节点的名字、发送者与被选中节点最后一次发送和接收 PING 和 PONG 消息的时间戳，被选中节点的 IP 地址和端口号，以及被选中节点的标识值。 当接收者收到 MEET、PING、PONG 消息时，接收者会访问消息正文中的两个 clusterMsgDataGossip 结构，并根据自己是否认识 clusterMsgDataGossip 记录的被选中节点来选择进行哪种操作： 如果被选中节点不存在于接收者的已知节点列表，那么说明接收者是第一次接触到被选中节点，接收者将根据结构中记录的 IP 地址和端口号等信息，与被选中节点进行握手。 如果被选中节点存在于接收者的已知节点列表，那么说明接收者之前已经与被选中节点进行过接触，接收者将根据 clusterMsgDataGossip 结构记录的信息，对被选中的节点所对应的 clusterNode 结构进行更新。 7.3 FAIL 消息的实现当集群里的主节点 A 将主节点 B 标记为已下线时（FAIL）时，主节点 A 将向集群广播一条关于主节点 B 的 FAIL 消息，所有接收到这条 FAIL 消息的节点都会将主节点 B 标记为已下线。 FAIL 消息的正文由 cluster.h/clusterMsgDataFail 结构表示，这个结构只包含一个 nodeName 属性，该属性记录了已下线节点的名字： 123typedef struct &#123; char nodename[REDIS_CLUSTER_NAMELEN];&#125; clusterMsgDataFail; 7.4 PUBLISH 消息的实现当客户端向集群中的某个节点发送命令： 1PUBLISH &lt;channel&gt; &lt;message&gt; 的时候，接收到 PUBLISH 命令的节点不仅会向 channel 频道发送消息 message，它还会向集群广播一条 PUBLISH 消息，所有接收到这条 PUBLISH 消息的节点都会向 channnel 频道发送 message 消息。 PUBLISH 消息的正文由 cluster.h/clusterMsgDataPublish 结构表示： 1234567891011typedef struct &#123; uint32_t channel_len; uint32_t message_len; // 定义为 8 字节只是为了对齐其他消息结构 // 实际的长度由保存的内容决定 unsigned char bulk_data[8]; &#125; clusterMsgDataPublish; clusterMsgDataPublish 结构的 bulk_data 属性是一个字节数组，这个字节数组保存了客户端通过 PUBLISH 命令发送给节点的 channel 参数和 message 参数，而结构的 channel_len 和 message_len 则分别保存了 channel 参数的长度和 message 参数的长度： 其中 bulk_data 的 0 字节至 channel_len - 1 字节保存的是 channel 参数。 而 bulk_data 的 channel_len 字节至 channel_len + message_len - 1 字节保存的是 message 参数。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：服务器》]]></title>
    <url>%2F2017%2F10%2F06%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E6%9C%8D%E5%8A%A1%E5%99%A8%E3%80%8B%2F</url>
    <content type="text"><![CDATA[0. redisServer 数据结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232struct redisServer &#123; /* General */ char *configfile; /* Absolute config file path, or NULL */ int hz; /* serverCron() calls frequency in hertz */ redisDb *db; dict *commands; /* Command table */ dict *orig_commands; /* Command table before command renaming. */ aeEventLoop *el; unsigned lruclock:REDIS_LRU_BITS; /* Clock for LRU eviction */ int shutdown_asap; /* SHUTDOWN needed ASAP */ int activerehashing; /* Incremental rehash in serverCron() */ char *requirepass; /* Pass for AUTH command, or NULL */ char *pidfile; /* PID file path */ int arch_bits; /* 32 or 64 depending on sizeof(long) */ int cronloops; /* Number of times the cron function run */ char runid[REDIS_RUN_ID_SIZE+1]; /* ID always different at every exec. */ int sentinel_mode; /* True if this instance is a Sentinel. */ /* Networking */ int port; /* TCP listening port */ int tcp_backlog; /* TCP listen() backlog */ char *bindaddr[REDIS_BINDADDR_MAX]; /* Addresses we should bind to */ int bindaddr_count; /* Number of addresses in server.bindaddr[] */ char *unixsocket; /* UNIX socket path */ mode_t unixsocketperm; /* UNIX socket permission */ int ipfd[REDIS_BINDADDR_MAX]; /* TCP socket file descriptors */ int ipfd_count; /* Used slots in ipfd[] */ int sofd; /* Unix socket file descriptor */ list *clients; /* List of active clients */ list *clients_to_close; /* Clients to close asynchronously */ list *slaves, *monitors; /* List of slaves and MONITORs */ redisClient *current_client; /* Current client, only used on crash report */ char neterr[ANET_ERR_LEN]; /* Error buffer for anet.c */ uint64_t next_client_id; /* Next client unique ID. Incremental. */ /* RDB / AOF loading information */ int loading; /* We are loading data from disk if true */ off_t loading_total_bytes; off_t loading_loaded_bytes; time_t loading_start_time; off_t loading_process_events_interval_bytes; /* Fast pointers to often looked up command */ struct redisCommand *delCommand, *multiCommand, *lpushCommand, *lpopCommand, *rpopCommand; /* Fields used only for stats */ time_t stat_starttime; /* Server start time */ long long stat_numcommands; /* Number of processed commands */ long long stat_numconnections; /* Number of connections received */ long long stat_expiredkeys; /* Number of expired keys */ long long stat_evictedkeys; /* Number of evicted keys (maxmemory) */ long long stat_keyspace_hits; /* Number of successful lookups of keys */ long long stat_keyspace_misses; /* Number of failed lookups of keys */ size_t stat_peak_memory; /* Max used memory record */ long long stat_fork_time; /* Time needed to perform latest fork() */ double stat_fork_rate; /* Fork rate in GB/sec. */ long long stat_rejected_conn; /* Clients rejected because of maxclients */ long long stat_sync_full; /* Number of full resyncs with slaves. */ long long stat_sync_partial_ok; /* Number of accepted PSYNC requests. */ long long stat_sync_partial_err;/* Number of unaccepted PSYNC requests. */ list *slowlog; /* SLOWLOG list of commands */ long long slowlog_entry_id; /* SLOWLOG current entry ID */ long long slowlog_log_slower_than; /* SLOWLOG time limit (to get logged) */ unsigned long slowlog_max_len; /* SLOWLOG max number of items logged */ size_t resident_set_size; /* RSS sampled in serverCron(). */ long long stat_net_input_bytes; /* Bytes read from network. */ long long stat_net_output_bytes; /* Bytes written to network. */ /* The following two are used to track instantaneous metrics, like * number of operations per second, network traffic. */ struct &#123; long long last_sample_time; /* Timestamp of last sample in ms */ long long last_sample_count;/* Count in last sample */ long long samples[REDIS_METRIC_SAMPLES]; int idx; &#125; inst_metric[REDIS_METRIC_COUNT]; /* Configuration */ int verbosity; /* Loglevel in redis.conf */ int maxidletime; /* Client timeout in seconds */ int tcpkeepalive; /* Set SO_KEEPALIVE if non-zero. */ int active_expire_enabled; /* Can be disabled for testing purposes. */ size_t client_max_querybuf_len; /* Limit for client query buffer length */ int dbnum; /* Total number of configured DBs */ int daemonize; /* True if running as a daemon */ clientBufferLimitsConfig client_obuf_limits[REDIS_CLIENT_TYPE_COUNT]; /* AOF persistence */ int aof_state; /* REDIS_AOF_(ON|OFF|WAIT_REWRITE) */ int aof_fsync; /* Kind of fsync() policy */ char *aof_filename; /* Name of the AOF file */ int aof_no_fsync_on_rewrite; /* Don't fsync if a rewrite is in prog. */ int aof_rewrite_perc; /* Rewrite AOF if % growth is &gt; M and... */ off_t aof_rewrite_min_size; /* the AOF file is at least N bytes. */ off_t aof_rewrite_base_size; /* AOF size on latest startup or rewrite. */ off_t aof_current_size; /* AOF current size. */ int aof_rewrite_scheduled; /* Rewrite once BGSAVE terminates. */ pid_t aof_child_pid; /* PID if rewriting process */ list *aof_rewrite_buf_blocks; /* Hold changes during an AOF rewrite. */ sds aof_buf; /* AOF buffer, written before entering the event loop */ int aof_fd; /* File descriptor of currently selected AOF file */ int aof_selected_db; /* Currently selected DB in AOF */ time_t aof_flush_postponed_start; /* UNIX time of postponed AOF flush */ time_t aof_last_fsync; /* UNIX time of last fsync() */ time_t aof_rewrite_time_last; /* Time used by last AOF rewrite run. */ time_t aof_rewrite_time_start; /* Current AOF rewrite start time. */ int aof_lastbgrewrite_status; /* REDIS_OK or REDIS_ERR */ unsigned long aof_delayed_fsync; /* delayed AOF fsync() counter */ int aof_rewrite_incremental_fsync;/* fsync incrementally while rewriting? */ int aof_last_write_status; /* REDIS_OK or REDIS_ERR */ int aof_last_write_errno; /* Valid if aof_last_write_status is ERR */ int aof_load_truncated; /* Don't stop on unexpected AOF EOF. */ /* RDB persistence */ long long dirty; /* Changes to DB from the last save */ long long dirty_before_bgsave; /* Used to restore dirty on failed BGSAVE */ pid_t rdb_child_pid; /* PID of RDB saving child */ struct saveparam *saveparams; /* Save points array for RDB */ int saveparamslen; /* Number of saving points */ char *rdb_filename; /* Name of RDB file */ int rdb_compression; /* Use compression in RDB? */ int rdb_checksum; /* Use RDB checksum? */ time_t lastsave; /* Unix time of last successful save */ time_t lastbgsave_try; /* Unix time of last attempted bgsave */ time_t rdb_save_time_last; /* Time used by last RDB save run. */ time_t rdb_save_time_start; /* Current RDB save start time. */ int rdb_child_type; /* Type of save by active child. */ int lastbgsave_status; /* REDIS_OK or REDIS_ERR */ int stop_writes_on_bgsave_err; /* Don't allow writes if can't BGSAVE */ int rdb_pipe_write_result_to_parent; /* RDB pipes used to return the state */ int rdb_pipe_read_result_from_child; /* of each slave in diskless SYNC. */ /* Propagation of commands in AOF / replication */ redisOpArray also_propagate; /* Additional command to propagate. */ /* Logging */ char *logfile; /* Path of log file */ int syslog_enabled; /* Is syslog enabled? */ char *syslog_ident; /* Syslog ident */ int syslog_facility; /* Syslog facility */ /* Replication (master) */ int slaveseldb; /* Last SELECTed DB in replication output */ long long master_repl_offset; /* Global replication offset */ int repl_ping_slave_period; /* Master pings the slave every N seconds */ char *repl_backlog; /* Replication backlog for partial syncs */ long long repl_backlog_size; /* Backlog circular buffer size */ long long repl_backlog_histlen; /* Backlog actual data length */ long long repl_backlog_idx; /* Backlog circular buffer current offset */ long long repl_backlog_off; /* Replication offset of first byte in the backlog buffer. */ time_t repl_backlog_time_limit; /* Time without slaves after the backlog gets released. */ time_t repl_no_slaves_since; /* We have no slaves since that time. Only valid if server.slaves len is 0. */ int repl_min_slaves_to_write; /* Min number of slaves to write. */ int repl_min_slaves_max_lag; /* Max lag of &lt;count&gt; slaves to write. */ int repl_good_slaves_count; /* Number of slaves with lag &lt;= max_lag. */ int repl_diskless_sync; /* Send RDB to slaves sockets directly. */ int repl_diskless_sync_delay; /* Delay to start a diskless repl BGSAVE. */ /* Replication (slave) */ char *masterauth; /* AUTH with this password with master */ char *masterhost; /* Hostname of master */ int masterport; /* Port of master */ int repl_timeout; /* Timeout after N seconds of master idle */ redisClient *master; /* Client that is master for this slave */ redisClient *cached_master; /* Cached master to be reused for PSYNC. */ int repl_syncio_timeout; /* Timeout for synchronous I/O calls */ int repl_state; /* Replication status if the instance is a slave */ off_t repl_transfer_size; /* Size of RDB to read from master during sync. */ off_t repl_transfer_read; /* Amount of RDB read from master during sync. */ off_t repl_transfer_last_fsync_off; /* Offset when we fsync-ed last time. */ int repl_transfer_s; /* Slave -&gt; Master SYNC socket */ int repl_transfer_fd; /* Slave -&gt; Master SYNC temp file descriptor */ char *repl_transfer_tmpfile; /* Slave-&gt; master SYNC temp file name */ time_t repl_transfer_lastio; /* Unix time of the latest read, for timeout */ int repl_serve_stale_data; /* Serve stale data when link is down? */ int repl_slave_ro; /* Slave is read only? */ time_t repl_down_since; /* Unix time at which link with master went down */ int repl_disable_tcp_nodelay; /* Disable TCP_NODELAY after SYNC? */ int slave_priority; /* Reported in INFO and used by Sentinel. */ char repl_master_runid[REDIS_RUN_ID_SIZE+1]; /* Master run id for PSYNC. */ long long repl_master_initial_offset; /* Master PSYNC offset. */ /* Replication script cache. */ dict *repl_scriptcache_dict; /* SHA1 all slaves are aware of. */ list *repl_scriptcache_fifo; /* First in, first out LRU eviction. */ unsigned int repl_scriptcache_size; /* Max number of elements. */ /* Limits */ unsigned int maxclients; /* Max number of simultaneous clients */ unsigned long long maxmemory; /* Max number of memory bytes to use */ int maxmemory_policy; /* Policy for key eviction */ int maxmemory_samples; /* Pricision of random sampling */ /* Blocked clients */ unsigned int bpop_blocked_clients; /* Number of clients blocked by lists */ list *unblocked_clients; /* list of clients to unblock before next loop */ list *ready_keys; /* List of readyList structures for BLPOP &amp; co */ /* Sort parameters - qsort_r() is only available under BSD so we * have to take this state global, in order to pass it to sortCompare() */ int sort_desc; int sort_alpha; int sort_bypattern; int sort_store; /* Zip structure config, see redis.conf for more information */ size_t hash_max_ziplist_entries; size_t hash_max_ziplist_value; size_t list_max_ziplist_entries; size_t list_max_ziplist_value; size_t set_max_intset_entries; size_t zset_max_ziplist_entries; size_t zset_max_ziplist_value; size_t hll_sparse_max_bytes; time_t unixtime; /* Unix time sampled every cron cycle. */ long long mstime; /* Like 'unixtime' but with milliseconds resolution. */ /* Pubsub */ dict *pubsub_channels; /* Map channels to list of subscribed clients */ list *pubsub_patterns; /* A list of pubsub_patterns */ int notify_keyspace_events; /* Events to propagate via Pub/Sub. This is an xor of REDIS_NOTIFY... flags. */ /* Scripting */ lua_State *lua; /* The Lua interpreter. We use just one for all clients */ redisClient *lua_client; /* The "fake client" to query Redis from Lua */ redisClient *lua_caller; /* The client running EVAL right now, or NULL */ dict *lua_scripts; /* A dictionary of SHA1 -&gt; Lua scripts */ mstime_t lua_time_limit; /* Script timeout in milliseconds */ mstime_t lua_time_start; /* Start time of script, milliseconds time */ int lua_write_dirty; /* True if a write command was called during the execution of the current script. */ int lua_random_dirty; /* True if a random command was called during the execution of the current script. */ int lua_timedout; /* True if we reached the time limit for script execution. */ int lua_kill; /* Kill the script if true. */ /* Latency monitor */ long long latency_monitor_threshold; dict *latency_events; /* Assert &amp; bug reporting */ char *assert_failed; char *assert_file; int assert_line; int bug_report_start; /* True if bug report header was already logged. */ int watchdog_period; /* Software watchdog period in ms. 0 = off */&#125;; 1. 命令请求的执行过程1.1 发送命令请求Redis 服务器的命令请求来自 Redis 客户端，当用户在客户端中键入一个命令请求时，客户端会将这个命令请求转换成协议格式，然后通过连接到服务器的套接字，将协议格式的命令请求发送给服务器。 1.2 读取命令请求当客户端与服务器之间的连接套接字因为客户端的写入而变得可读时，服务器将调用命令请求处理器来执行以下操作： 读取套接字中协议格式的命令请求，并将其保存到客户端状态的输入缓冲区里面。 对输入缓冲区中的命令请求进行分析，提取出命令请求中包含的命令参数，以及命令参数的个数，然后分别将参数和参数个数保存到客户端状态的 argv 属性和 argc 属性里面。 调用命令执行器，执行客户端指定的命令。 1.3 命令执行器（1）：查找命令实现命令执行器要做的第一件事就是根据客户端状态的 argv[0] 参数，在命令表（command table）中查找参数所指定的命令，并将找到的命令保存到客户端状态的 cmd 属性里面。 命令表是一个字典，字典的键是一个个命令名字，比如 &quot;set&quot;、&quot;get&quot;、&quot;del&quot;，等等；而字典的值则是一个个 redisCommand 结构，每个 redisCommand 结构记录了一个 Redis 命令的实现信息： 1234567891011121314struct redisCommand &#123; char *name; redisCommandProc *proc; int arity; char *sflags; /* Flags as string representation, one char per flag. */ int flags; /* The actual flags, obtained from the 'sflags' field. */ /* Use a function to determine keys arguments in a command line. */ redisGetKeysProc *getkeys_proc; /* What keys should be loaded in background when calling this command? */ int firstkey; /* The first argument that's a key (0 = no keys) */ int lastkey; /* The last argument that's a key */ int keystep; /* The step between first and last key */ long long microseconds, calls;&#125;; 属性名 类型 作用 name char * 命令的名字，比如 &quot;set&quot; 。 proc redisCommandProc * 函数指针，指向命令的实现函数，比如 setCommand。 redisCommandProc 类型的定义为 typedef void redisCommandProc(redisClient *c);。 arity int 命令参数的个数，用于检查命令请求的格式是否正确。如果这个值为负数 -N，那么表示参数的数量大于等于 N。 注意命令的名字本身也是一个参数，比如说 SET msg&quot;hello world&quot; 命令的参数是 &quot;SET&quot;、&quot;msg&quot;、&quot;hello world&quot;，而不仅仅是 &quot;msg&quot; 和 &quot;hello world&quot;。 sflags char * 字符串形式的标识值，这个值记录了命令的属性，比如这个命令是写命令还是读命令，这个命令是否允许在载入数据时使用，这个命令是否允许在 Lua 脚本中使用，等等。 flags int 对 sflags 标识进行分析得出的二进制标识，由程序自动生成。服务器对命令标识进行检查时使用的都是 flags 属性而不是 sflags 属性，因为对二进制标识的检查可以方便地通过 &amp;、^、~ 等操作来完成。 calls long long 服务器总共执行了多少次这个命令。 milliseconds long long 服务器执行这个命令所耗费的总时长。 flags 属性可以使用的标识符及意义： 标识 意义 带有这个标识的命令 w 这是一个写入命令，可能会修改数据库。 SET、RPUSH、DEL，等等。 r 这是一个只读命令，不会修改数据库。 GET、STRLEN、EXISTS，等等。 m 这个命令可能会占用大量内存，执行之前需要先检查服务器的内存使用情况，如果内存紧缺的话就禁止执行这个命令。 SET、APPEND、RPUSH、 LPUSH、SADD、SINTERSTORE，等等。 a 这是一个管理命令。 SAVE、BGSAVE、SHUTDOWN，等等。 p 这是一个发布与订阅功能方面的命令。 PUBLISH、SUBSCRIBE、PUBSUB，等等。 s 这个命令不可以在 Lua 脚本中使用。 BRPOP、BLPOP、BRPOPLPUSH、SPOP，等等。 R 这是一个随机命令，对于相同的数据集和相同的参数，命令返回的结果可能不同。 SPOP、SRANDMEMBER、SSCAN、RANDOMKEY，等等。 S 当在 Lua 脚本中使用这个命令时，对这个命令的输出结果进行一次排序，使得命令的结果有序。 SINTER、SUNION、SDIFF、SMEMBERS、KEYS，等等。 l 这个命令可以在服务器载入数据的过程中使用。 INFO、SHUTDOWN、PUBLISH，等等。 t 这是一个允许从服务器在带有过期数据时使用的命令。 SLAVEOF、PING、INFO，等等。 M 这个命令在监视器（monitor）模式下不会自动被传播（propagate）。 EXEC 1.4 命令执行器（2）：执行预备操作到目前为止，服务器已经将执行命令所需的命令实现函数（保存在客户端状态的 cmd 属性）、参数（保存在客户端状态的 argv 属性）、参数个数（保存在客户端状态的 argc 属性）都收集齐了，但是在真正执行命令之前，程序还需要进行一些预备操作，从而确保命令可以正确、顺利地被执行，这些操作包括： 检查客户端状态的 cmd 指针是否指向 NULL ，如果是的话，那么说明用户输入的命令名字找不到相应的命令实现，服务器不再执行后续步骤，并向客户端返回一个错误。 根据客户端 cmd 属性指向的 redisCommand 结构的 arity 属性，检查命令请求所给定的参数个数是否正确，当参数个数不正确时，不再执行后续步骤，直接向客户端返回一个错误。比如说，如果 redisCommand 结构的 arity 属性的值为 -3，那么用户输入的命令参数个数必须大于等于 3 个才行。 检查客户端是否已经通过了身份验证，未通过身份验证的客户端只能执行 AUTH 命令，如果未通过身份验证的客户端试图执行除 AUTH 命令之外的其他命令，那么服务器将向客户端返回一个错误。 如果服务器打开了 maxmemory 功能，那么在执行命令之前，先检查服务器的内存占用情况，并在有需要时进行内存回收，从而使得接下来的命令可以顺利执行。如果内存回收失败，那么不再执行后续步骤，向客户端返回一个错误。 如果服务器上一次执行 BGSAVE 命令时出错，并且服务器打开了 stop-writes-on-bgsave-error 功能，而且服务器即将要执行的命令是一个写命令，那么服务器将拒绝执行这个命令，并向客户端返回一个错误。 如果客户端当前正在用 SUBSCRIBE 命令订阅频道， 或者正在用 PSUBSCRIBE 命令订阅模式， 那么服务器只会执行客户端发来的 SUBSCRIBE、PSUBSCRIBE、UNSUBSCRIBE、PUNSUBSCRIBE 四个命令， 其他别的命令都会被服务器拒绝。 如果服务器正在进行数据载入，那么客户端发送的命令必须带有 l 标识（比如 INFO、SHUTDOWN、PUBLISH，等等）才会被服务器执行，其他别的命令都会被服务器拒绝。 如果服务器因为执行 Lua 脚本而超时并进入阻塞状态，那么服务器只会执行客户端发来的 SHUTDOWN nosave 命令和 SCRIPT KILL 命令， 其他别的命令都会被服务器拒绝。 如果客户端正在执行事务， 那么服务器只会执行客户端发来的 EXEC、DISCARD、MULTI、WATCH 四个命令， 其他命令都会被放进事务队列中。 如果服务器打开了监视器功能， 那么服务器会将要执行的命令和参数等信息发送给监视器。 当完成了以上预备操作之后， 服务器就可以开始真正执行命令了。 1.5 命令执行器（3）：调用命令的实现函数在前面的操作中，服务器已经将要执行命令的实现保存到了客户端状态的 cmd 属性里面，并将命令的参数和参数个数分别保存到了客户端状态的 argv 属性和 argc 属性里面，当服务器决定要执行命令时，它只要执行以下语句就可以了： 123// client 是指向客户端状态的指针client-&gt;cmd-&gt;proc(client); 因为执行命令所需的实际参数都已经保存到客户端状态的 argv 属性里面了，所以命令的实现函数只需要一个指向客户端状态的指针作为参数即可。 被调用的命令实现函数会执行指定的操作，并产生相应的命令回复，这些回复会被保存在客户端状态的输出缓冲区里面（buf 属性和 reply 属性），之后实现函数还会为客户端的套接字关联命令回复处理器，这个处理器负责将命令回复返回给客户端。 1.6 命令执行器（4）：执行后续工作在执行完实现函数之后，服务器还需要执行一些后续工作： 如果服务器开启了慢查询日志功能，那么慢查询日志模块会检查是否需要为刚刚执行完的命令请求添加一条新的慢查询日志。 根据刚刚执行命令所耗费的时长，更新被执行命令的 redisCommand 结构的 milliseconds 属性，并将命令的 redisCommand 结构的 calls 计数器的值增一。 如果服务器开启了 AOF 持久化功能，那么 AOF 持久化模块会将刚刚执行的命令请求写入到 AOF 缓冲区里面。 如果有其他从服务器正在复制当前这个服务器，那么服务器会将刚刚执行的命令传播给所有从服务器。 当以上操作都执行完了之后，服务器对于当前命令的执行到此就告一段落了，之后服务器就可以继续从文件事件处理器中取出并处理下一个命令请求了。 1.7 将命令回复发送给客户端命令实现函数会将命令回复保存到客户端的输出缓冲区里面，并为客户端的套接字关联命令回复处理器，当客户端套接字变为可写状态时，服务器就会执行命令回复处理器，将保存在客户端输出缓冲区中的命令回复发送给客户端。 当命令回复发送完毕之后，回复处理器会清空客户端状态的输出缓冲区，为处理下一个命令请求做好准备。 1.8 客户端接收并打印命令回复当客户端接收到协议格式的命令回复之后，它会将这些回复转换成人类可读的格式，并打印给用户观看。 2. serverCron 函数2.1 更新服务器时间缓存Redis 服务器中有不少功能需要获取系统的当前时间，而每次获取系统的当前时间都需要执行一次系统调用，为了减少系统调用的执行次数，服务器状态中的 unixtime 属性和 mstime 属性被用作当前时间的缓存。 由于 serverCron 函数默认会以每 100 毫秒一次的频率更新 unixtime 属性和 mstime 属性，所以这两个属性记录的时间精确度并不高： 服务器只会在打印日志、更新服务器的 LRU 时钟、决定是否执行持久化任务、计算服务器上线时间（uptime）这类对事件精确度要求不高的功能上 “使用 unixtime 属性和 mstime 属性”。 对于为键设置过期时间、添加慢查询日志这种需要高精度时间的功能来说，服务器还是会再次执行系统调用，从而获得最准确的系统当前时间。 2.2 更新 LRU 时钟服务器状态中的 lruclock 属性保存了服务器的 LRU 时钟，也是服务器时间缓存的一种： 1234567891011struct redisServer&#123; //... // 默认每 10 秒更新一次时钟缓存 // 用于计算键的空转(idle)时长 unsigned lruclock:22; //...&#125; 每个 Redis 对象都会有一个 lru 属性，保存了对象最后一次被命令访问的时间： 12345678typedef struct redisObject &#123; //... unsigned lrulock:22; //...&#125; robj; 当服务器要计算一个数据库键的空转时间（也即是数据库键对应的值对象的空转时间），程序会用服务器的 lruclock 属性记录的时间减去对象的 lru 属性记录的时间，得出的计算结果就是这个对象的空转时间。 serverCron 函数默认以每 10 秒一次的频率更新 lruclock 属性的值，因为这个时钟不是实时的，所以根据这个属性计算出来的 LRU 时间实际上只是一个模糊的估算值。 lruclock 时钟的当前值可以通过 INFO server 命令的 lru_clock 域查看。 2.3 更新服务器每秒执行命令次数serverCron函数中的trackOperationsPerSecond函数会以每 100ms 一次的频率执行，这个函数的功能是以抽样计算的方式，估算并记录服务器在最近一秒钟处理的命令请求数量。可以通过INFO stats命令的instantaneous_ops_per_sec ` 域查看。 2.4 更新服务器内存峰值记录服务器状态中的 stat_peak_memory 属性记录了服务器的内存峰值大小： 12345678910struct redisServer&#123; //... // 已使用内存峰值 size_t stat_peak_memory; //...&#125; 每次 serverCron 函数执行时，程序都会查看服务器当前使用的内存数量，并与 stat_peak_memory 保存的数值进行比较，如果当前使用的内存数量比 stat_peak_memory 属性记录的值要大，那么程序就将当前使用的内存数量记录到 stat_peak_memory 属性里面。 INFO memory 命令的 used_memory_peak 和 used_memory_peak_human 两个域分别以两种格式记录了服务器的内存峰值： 123456redis&gt;INFO memory# Memory...used_momory_peak:501824used_memory_peak_human:490.06K... 2.5 处理SIGTERM信号在启动服务器时，Redis 会为服务器进程的 SIGTERM 信号关联处理器 sigtermHandler 函数，这个信号处理器负责在服务器接到 SIGTERM 信号时，打开服务器状态的 shutdown_asap 标识： 12345678910// SIGTERM信号的处理器static void sigtermHandler(int sig)&#123; // 打印日至 redisLogFromHandler(REDIS_WARNIING,"Received SIGTERM,scheduling shutdown..."); // 打开关闭标识 server.shutdown_asap = 1;&#125; 每次 serverCron 函数运行时，程序都会对服务器状态的 shutdown_asap 属性进行检查，并根据属性的值决定是否关闭服务器： 123456789101112struct redisServer&#123; //... // 关闭服务器的标识： // 值为1时，关闭服务器， // 值为0时，不做动作。 int shutdown_asap; //...&#125;; 服务器在关闭自身之前会进行 RDB 持久化操作，这也是服务器拦截 SIGTERM 信号的原因，如果服务器一接到 SIGTERM 信号就立即关闭，那么它就没办法执行持久化操作了。 2.6 管理客户端资源serverCron 函数每次执行都会调用 clientsCron 函数，clientsCron 函数会对一定数量的客户端进行以下两种检查： 如果客户端和服务器之间的连接已经超时，那么程序释放这个客户端。 如果客户端在上一次执行命令请求后，输入缓冲区的大小超过了一定的长度，那么程序会释放客户端当前的输入缓冲区，并重新创建一个默认大小的输入缓冲区，从而防止客户端的输入缓冲区耗费了过多的内存。 2.7 管理数据库资源serverCron 函数每次执行都会调用 databaseCron 函数，这个函数会对服务器中的一部分数据库进行检查，删除其中的过期键，并在有需要时，对字典进行收缩操作。 2.8 执行被延迟的 BGREWRITEAOF服务器在执行 BGSAVE 期间，如果客户端向服务器请求了 BGREWRITEAOF 命令，那么服务器会将 BGREWRITEAOF 命令延迟到 BGSAVE 执行完毕之后执行。 服务器的 aof_rewrite_scheduled 标识记录了服务器是否延迟了 BGREWRITEAOF 命令： 12345678910struct redisServer&#123; //... // 如果为 1，那么表示有 BGREWRITEAOF 命令被延迟了 int aof_rewrite_scheduled; //...&#125;; 每次 serverCron 函数执行时，函数都会检查 BGSAVE 命令或者 BGREWRITEAOF 命令是否正在执行，如果这两个命令都没在执行，并且 aof_rewrite_scheduled 属性的值为 1，那么服务器就会执行之前被推延的 BGREWRITEAOF 命令。 2.9 检查持久化操作的运行状态服务器状态用 rdb_child_pid 和 aof_child_pid 属性记录了执行 BGSAVE 命令和 BGREWRITEAOF 命令的子进程的 ID，这两个属性可以用于检查这两个命令是否正在执行： 1234567891011121314151617struct redisServer&#123; //... // 记录执行 BGSAVE 命令的子进程 ID： // 如果服务器没有在执行 BGSAVE， // 那么这个属性的值为 -1。 pid_t rdb_child_pid; // 记录执行 BGREWRITEAOF 命令的子进程 ID： // 如果服务器没有在执行 BGREWRITEAOF， // 那么这个属性的值为 -1。 pid_t aof_child_pid; //...&#125;; serverCron 函数每次执行都会检查 rdb_child_pid 和 aof_child_pid 两个属性的值，只要其中一个属性的值不为 -1，程序会执行一次 wait3 函数，检查子进程是否有信号发来服务器进程： 如果有信号到达，那么表示新的 RDB 文件已经生成完毕（对于 BGSAVE 命令来说）或者 AOF 文件已经重写完毕（对于 BGREWRITEAOF 命令来说），服务器需要进行相应命令的后续操作，比如用新的 RDB 文件替换现有的 RDB 文件，或者用重写后的 AOF 文件替换现有的 AOF 文件。 如果没有信号到达，那么表示持久化操作未完成，程序不做动作。 另一方面，如果 rdb_child_pid 和 aof_child_pid 两个属性的值都为 -1，那么表示服务器没有在进行持久化操作，在这种情况下，程序执行以下三个检查： 查看是否有 BGREWRITEAOF 被延迟了，如果有的话，那么开始一次新的 BGREWRITEAOF 操作。 检查服务器自动保存条件是否已经被满足，如果条件满足，并且服务器没有在执行其他持久化操作，那么服务器开始一次新的 BGSAVE 操作（因为条件 1 可能会引发一次 BGREWRITEAOF，所以在这个检查中，程序会再次确认服务器是否已经在执行持久化操作了）。 检查服务器设置的 AOF 重写条件是否满足，如果条件满足，并且服务器没有在执行其他持久化操作，那么服务器将开始一次新的 BGREWRITEAOF 操作（因为条件 1 和条件 2 都可能会引起新的持久化操作，所以在这个检查中，我们要再次确认服务器是否已经在执行持久化操作了）。 2.10 将 AOF 缓冲区中的内容写入 AOF 文件如果服务器开启了 AOF 持久化功能，并且 AOF 缓冲区里面还有待写入的数据，那么 serverCron 函数会调用相应的程序，将 AOF 缓冲区中的内容写入到 AOF 文件里面。 2.11 关闭异步客户端服务器会关闭那些输出缓冲区大小超出限制的客户端。 2.12 增加 cronloops 计数器的值服务器状态的 cronloops 属性记录了 serverCron 函数执行的次数： 12345678910struct redisServer &#123; //... // serverCron 函数的运行次数计数器 // serverCron 函数每执行一次，这个属性的值就增一 int cronloops; //...&#125; cronloops 属性目前在服务器中的唯一作用，就是在复制模块中实现 “每执行 serverCron 函数 N 次就执行一次指定代码” 的功能。 3. 初始化服务器3.1 初始化服务器状态结构初始化服务器的第一步就是创建一个 struct redisServer 类型的实例变量 server 作为服务器的状态，并为结构中的各个属性设置默认值。初始化 server 变量的工作由 redis.c/initServerConfig 函数完成。 initServerConfig 函数中，大部分是对 server 的属性设置默认值，还有一部分是调用 populateCommandTable 函数对 Redis 的命令表初始化。全局变量 redisCommandTable 是 redisCommand 类型的数组，保存 Redis 支持的所有命令。server.commands 是一个 dict，保存命令名到 redisCommand 的映射。populateCommandTable 函数会遍历全局 redisCommandTable 表，把每条命令插入到 server.commands 中，根据每个命令的属性设置其 flags。以下是这个函数的部分代码： 123456789101112131415161718192021222324252627282930313233343536373839void initServerConfig(void) &#123; // 设置服务器的运行 id getRandomHexChars(server.runid,REDIS_RUN_ID_SIZE); // 为运行 id 加上结尾字符 server.runid[REDIS_RUN_ID_SIZE] = '\0'; // 设置默认配置文件路径 server.configfile = NULL; // 设置默认服务器频率 server.hz = REDIS_DEFAULT_HZ; // 设置服务器的运行架构 server.arch_bits = (sizeof(long) == 8) ? 64 : 32; // 设置默认服务器端口号 server.port = REDIS_SERVERPORT; // ... /* Command table -- we initiialize it here as it is part of the * initial configuration, since command names may be changed via * redis.conf using the rename-command directive. */ // 初始化命令表 // 在这里初始化是因为接下来读取 .conf 文件时可能会用到这些命令 server.commands = dictCreate(&amp;commandTableDictType,NULL); server.orig_commands = dictCreate(&amp;commandTableDictType,NULL); populateCommandTable(); server.delCommand = lookupCommandByCString("del"); server.multiCommand = lookupCommandByCString("multi"); server.lpushCommand = lookupCommandByCString("lpush"); server.lpopCommand = lookupCommandByCString("lpop"); server.rpopCommand = lookupCommandByCString("rpop"); // ... &#125; 以下是 initServerConfig 函数完成的主要工作： 设置服务器的运行 ID。 设置服务器的默认运行频率。 设置服务器的默认配置文件路径。 设置服务器的运行架构。 设置服务器的默认端口号。 设置服务器的默认 RDB 持久化条件和 AOF 持久化条件。 初始化服务器的 LRU 时钟。 创建命令表。 initServerConfig 函数设置的服务器状态属性基本都是一些整数、浮点数、或者字符串属性，除了命令表之外，initServerConfig 函数没有创建服务器状态的其他数据结构，数据库、慢查询日志、Lua 环境、共享对象这些数据结构在之后的步骤才会被创建出来。 3.2 载入配置选项在启动服务器时，用户可以通过给定配置参数或者指定配置文件来修改服务器的默认配置。服务器在用 initServerConfig 函数初始化完 server 变量之后，就会开始载入用户给定的配置参数和配置文件，并根据用户设定的配置，对 server 变量相关属性的值进行修改。 如果用户为这些属性的相应选项指定了新的值，那么服务器就使用用户指定的值来更新相应的属性。 如果用户没有为属性的相应选项设置新的值，那么服务器就沿用之前 initServerConfig 函数为属性设置的默认值。 3.3 初始化服务器数据结构在之前执行 initServerConfig 函数初始化 server 状态时，程序只创建了命令表一个数据结构，不过除了命令表之外，服务器状态还包含其他数据结构，比如： server.clients 链表，这个链表记录了所有与服务器相连的客户端的状态结构，链表的每一个节点都包含一个 redisClient 结构实例。 server.db 数组，数组中包含了服务器的所有数据库。 用于保存频道订阅信息的 server.pubsub_channels 字典，以及用于保存模式订阅信息的 server.pubsub_patterns 链表。 用于执行 Lua 脚本的 Lua 环境 server.lua。 用于保存慢查询日志的 server.slowlog 属性。 当初始化服务器进行到这一步，服务器将调用initServer函数，为以上提到的数据结构分配内存，并在有需要时，为这些数据结构设置或关联初始化值。 服务器到现在才初始化数据结构的原因在于，服务器必须先载入用户指定的配置选项，然后才能正确地对数据结构进行初始化。如果在执行 initServerConfig 函数时就对数据结构进行初始化，那么一旦用户通过配置选项修改了和数据结构有关的服务器状态属性，服务器就要重新调整和修改已创建的数据结构。为了避免出现这种麻烦的情况，服务器选择了将 server 状态的初始化分为两步进行，initServerConfig 函数主要负责初始化一般属性，而 initServer 函数主要负责初始化数据结构。 除了初始化数据结构之外，initServer 还进行了一些非常重要的设置操作： 为服务器设置进程信号处理器。 创建共享对象，这些对象包含 Redis 服务器经常用到的一些值，服务器通过重用这些共享对象来避免反复创建相同的对象。 打开服务器的监听端口，并为监听套接字关联连接应答事件处理器，等待服务器正式运行时接受客户端的连接。 为 serverCron 函数创建时间事件，等待服务器正式运行时执行 serverCron 函数。 如果 AOF 持久化功能已经打开，那么打开现有的 AOF 文件，如果 AOF 文件不存在，那么创建并打开一个新的 AOF 文件，为 AOF 写入做好准备。 初始化服务器后台 I/O 模块（bio），为将来的 I/O 操作做准备。 当 initServer 函数执行完毕之后，服务器将用 ASCII 字符在日志中打印出 Redis 的图标，以及 Redis 的版本号信息。 3.4 还原数据库状态在完成了对服务器状态 server 变量的初始化之后，服务器需要载入 RDB 文件或者 AOF 文件，并根据文件记录的内容来还原服务器的数据库状态。 根据服务器是否启用了 AOF 持久化功能，服务器载入数据时所使用的目标文件会有所不同： 如果服务器启用了 AOF 持久化功能，那么服务器使用 AOF 文件来还原数据库状态； 相反地，如果服务器没有启用 AOF 持久化功能，那么服务器使用 RDB 文件来还原数据库状态。 当服务器完成数据库状态还原工作之后，服务器将在日志中打印出载入文件并还原数据库状态所耗费的时长： 1[5244] 21 Nov 22:43:49.084 * DB loaded from disk: 0.068 seconds 3.5 执行事件循环在初始化的最后一步，服务器将打印出以下日志： 1[5244] 21 Nov 22:43:49.084 * The server is now ready to accept connections on port 6379 并开始执行服务器的事件循环。 至此，服务器的初始化工作圆满完成，服务器现在开始可以接受客户端的连接请求，并处理客户端发来的命令请求了。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：事务》]]></title>
    <url>%2F2017%2F10%2F05%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E4%BA%8B%E5%8A%A1%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 事务的实现一个事务从开始到结束通常会经历以下三个阶段： 事务开始。 命令入队。 事务执行。 1.1 事务开始MULTI 命令的执行标志着事务的开始： 12redis&gt; MULTIOK MULTI 命令可以将执行该命令的客户端从非事务状态切换至事务状态，这一切换是通过在客户端状态的 flags 属性中打开 REDIS_MULTI 标识来完成的，MULTI 命令的实现可以用以下伪代码来表示： 1234567def MULTI(): # 打开事务标识 client.flags |= REDIS_MULTI # 返回 OK 回复 replyOK() 1.2 命令入队当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。与此不同的是，当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作： 如果客户端发送的命令为 EXEC、 DISCARD、 WATCH、 MULTI 四个命令的其中一个，那么服务器立即执行这个命令。 与此相反，如果客户端发送的命令是 EXEC、DISCARD、WATCH、MULTI 四个命令以外的其他命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回 QUEUED 回复。 1.3 事务队列每个 Redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的 mstate 属性里面： 12345678910typedef struct redisClient &#123; // ... // 事务状态 multiState mstate; /* MULTI/EXEC state */ // ...&#125; redisClient; 事务状态包含一个事务队列，以及一个已入队命令的计数器（也可以说是事务队列的长度）： 123456789typedef struct multiState &#123; // 事务队列，FIFO 顺序 multiCmd *commands; // 已入队命令计数 int count;&#125; multiState; 事务队列是一个 multiCmd 类型的数组，数组中的每个 multiCmd 结构都保存了一个已入队命令的相关信息，包括指向命令实现函数的指针，命令的参数，以及参数的数量： 123456789101112typedef struct multiCmd &#123; // 参数 robj **argv; // 参数数量 int argc; // 命令指针 struct redisCommand *cmd;&#125; multiCmd; 事务队列以先进先出（FIFO）的方式保存入队的命令：较先入队的命令会被放到数组的前面，而较后入队的命令则会被放到数组的后面。 1.4 执行事务当一个处于事务状态的客户端向服务器发送 EXEC 命令时，这个 EXEC 命令将立即被服务器执行： 服务器会遍历这个客户端的事务队列，执行队列中保存的所有命令，最后将执行命令所得的结果全部返回给客户端。 EXEC 命令的实现原理可以用以下伪代码来描述： 1234567891011121314151617181920212223242526def EXEC(): # 创建空白的回复队列 reply_queue = [] # 遍历事务队列中的每个项 # 读取命令的参数，参数的个数，以及要执行的命令 for argv, argc, cmd in client.mstate.commands: # 执行命令，并取得命令的返回值 reply = execute_command(cmd, argv, argc) # 将返回值追加到回复队列末尾 reply_queue.append(reply) # 移除 REDIS_MULTI 标识，让客户端回到非事务状态 client.flags &amp;= ~REDIS_MULTI # 清空客户端的事务状态，包括： # 1）清零入队命令计数器 # 2）释放事务队列 client.mstate.count = 0 release_transaction_queue(client.mstate.commands) # 将事务的执行结果返回给客户端 send_reply_to_client(client, reply_queue) 2. WATCH 命令的实现WATCH 命令是一个乐观锁（optimistic locking），它可以在 EXEC 命令执行之前，监视任意数量的数据库键，并在 EXEC 命令执行时，检查被监视的键是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空回复（nil）。 WATCH 命令总是返回 OK。 2.1 使用 WATCH 命令监视数据库键每个 Redis 数据库都保存着一个 watched_keys 字典，这个字典的键是某个被 WATCH 命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端： 12345678typedef struct redisDb &#123; // ... dict *watched_keys; // ... &#125; redisDb; 通过 watched_keys 字典，服务器可以清楚地知道哪些数据库键正在被监视，以及哪些客户端正在监视这些数据库键。 通过执行 WATCH 命令，客户端可以在 watched_keys 字典中与被监视的键进行关联。 2.2 监视机制的触发所有对数据库进行修改的命令，比如 SET、LPUSH、SADD、ZREM、DEL、FLUSHDB 等等，在执行之后都会调用 multi.c/touchWatchKey 函数对 watched_keys 字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键，如果有的话，那么 touchWatchKey 函数就会将监视被修改键的客户端的 REDIS_DIRTY_CAS 标识打开，表示该客户端的事务安全性已经被破坏。 touchWatchKey 函数的定义可以用以下伪代码来描述： 1234567891011def touchWatchKey(db, key): # 如果键 key 存在于数据库的 watched_keys 字典中 # 那么说明至少有一个客户端在监视这个 key if key in db.watched_keys: # 遍历所有监视键 key 的客户端 for client in db.watched_keys[key]: # 打开标识 client.flags |= REDIS_DIRTY_CAS 2.3 判断事务是否安全当服务器接收到一个客户端发来的 EXEC 命令时，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务： 如果客户端的 REDIS_DIRTY_CAS 标识已经被打开，那么说明客户端所监视的键当中，至少有 一个键已经被修改过了，在这种情况下，客户端提交的事务已经不再安全，所以服务器会拒绝执行客户端提交的事务。 如果客户端的 REDIS_DIRTY_CAS 标识没有被打开，那么说明客户端监视的所有键都没有被修改过（或者客户端没有监视任何键），事务仍然是安全的，服务器将执行客户端提交的这个事务。 3. 事务的 ACID 性质在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的可靠性和安全性。 在 Redis 中，事务总是具有原子性（Atomicity）， 一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有耐久性（Durability）。 3.1 原子性事务具有原子性指的是，数据库将事务中的多个操作当作一个整体来执行，服务器要么就执行事务中的所有操作，要么就一个操作也不执行。 对于 Redis 的事务功能来说，事务队列中的命令要么就全部执行，要么就一个都不执行，因此，Redis 的事务是具有原子性的。 Redis 的事务和传统的关系型数据库事务的最大区别在于，Redis 不支持事务的回滚机制（rollback），即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止。 3.2 一致性事务具有一致性指的是，如果数据库在执行事务之前是一致的，那么在事务执行之后，无论事务是否执行成功，数据库也应该仍然是一致的。 ”一致“ 指的是数据符合数据库本身的定义和要求，没有包含非法或者无效的错误数据。 Redis 通过谨慎的错误检测和简单的设计来保证事务一致性。 3.2.1 入队错误一个事务在入队命令的过程中，出现了命令不存在或者命令格式不正确等情况，那么 Redis 将拒绝执行这个事务，因此 Redis 事务的一致性不会被带有入队错误的事务影响。 3.2.2 执行错误因为在事务执行的过程中，出错的命令会被服务器识别出来，并进行相应的错误处理，所以这些出错命令不会对数据库做任何修改，也不会对事务的一致性产生任何影响。 3.2.3 服务器停机如果 Redis 服务器在执行事务的过程中停机，那么根据服务器所使用的持久化模式，可能有以下情况出现： 如果服务器运行在无持久化的内存模式下，那么重启之后的数据库将是空白的，因此数据总是一致的。 如果服务器运行在 RDB 模式下，那么在事务中途停机不会导致不一致性，因为服务器可以根据现有的 RDB 文件来恢复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 RDB 文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。 如果服务器运行在 AOF 模式下，那么在事务中途停机不会导致不一致性，因为服务器可以根据现有的 AOF 文件来恢复数据，从而将数据库还原到一个一致的状态。如果找不到可供使用的 AOF 文件，那么重启之后的数据库将是空白的，而空白数据库总是一致的。 综上所述，无论 Redis 服务器运行在哪种持久化模式下，事务执行中途发生的停机都不会影响数据库的一致性。 3.3 隔离性事务的隔离性指的是，即使数据库中有多个事务并发地执行，各个事务之间也不会互相影响，并且在并发状态下执行的事务和串行执行的事务产生的结果完全 相同。 因为 Redis 使用单线程的方式来执行事务（以及事务队列中的命令），并且服务器保证，在执行事务期间不会对事物进行中断，因此，Redis 的事务总是以串行的方式运行的，并且事务也总是具有隔离性的。 3.4 耐久性事务的耐久性指的是，当一个事务执行完毕时，执行这个事务所得的结果已经被保持到永久存储介质（比如硬盘）里面，即使服务器在事务执行完毕之后停机，执行事务所得的结果也不会丢失。 因为 Redis 事务不过是简单的用队列包裹起了一组 Redis 命令，Redis 并没有为事务提供任何额外的持久化功能，所以 Redis 事务的耐久性由 Redis 所使用的持久化模式决定： 当服务器在无持久化的内存模式下运作时，事务不具有耐久性：一旦服务器停机，包括事务数据在内的所有服务器数据都将丢失。 当服务器在 RDB 持久化模式下运作时，服务器只会在特定的保存条件被满足时，才会执行 BGSAVE 命令，对数据库进行保存操作，并且异步执行的 BGSAVE 不能保证事务数据被第一时间保存到硬盘里面，因此 RDB 持久化模式下的事务也不具有耐久性。 当服务器运行在 AOF 持久化模式下，并且 appedfsync 选项的值为 always 时，程序总会在执行命令之后调用同步（sync）函数，将命令数据真正地保存到硬盘里面，因此这种配置下的事务是具有耐久性的。 当服务器运行在 AOF 持久化模式下，并且 appedfsync 的选项的值为 everysec 时，程序会每秒同步一次命令数据到磁盘。因为停机可能会恰好发生在等待同步的那一秒钟之内，这可能会造成事务数据丢失，所以这种配置下的事务不具有耐久性。 当服务器运行在 AOF 持久化模式下，并且 appedfsync 的选项的值为 no 时，程序会交由操作系统来决定何时将命令数据同步到硬盘。因为事务数据可能在等待同步的过程中丢失，所以这种配置下的事务不具有耐久性。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：事件》]]></title>
    <url>%2F2017%2F10%2F04%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E4%BA%8B%E4%BB%B6%E3%80%8B%2F</url>
    <content type="text"><![CDATA[Redis 服务器是一个事件驱动程序，服务器需要处理以下两类事件： 文件事件（file event）：Redis 服务器通过套接字与客户端（或者其他 Redis 服务器）进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端（或者其他服务器）的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列网络通信操作。 时间事件（time event）：Redis 服务器中的一些操作（比如 serverCron 函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。 1. 文件事件Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）： 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器即实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。 1.1 文件事件处理器的构成文件事件处理器有四个组成部分，它们分别是套接字、I/O 多路复用程序、文件事件分派器（dispatcher），以及事件处理器。 文件事件是对套接字操作的抽象，每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时，就会产生一个文件事件。因为一个服务器通常会连接多个套接字，所以多个文件事件有可能会并发地出现。 I/O 多路复用程序负责监听多个套接字，并向文件事件分派器传送那些产生了事件的套接字。 尽管多个文件事件可能会并发地出现，但 I/O 多路复用程序总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字。当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕），I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字。 文件事件分派器接收 I/O 多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器。 事件处理器是一个个函数，它们定义了某个事件发生时，服务器应该执行的动作。 1.2 I/O 多路复用程序的实现Redis 的 I/O 多路复用程序的所有功能都是通过包装常见的 select、epoll、evport 和 kqueue 这些 I/O 多路复用函数库来实现的，每个 I/O 多路复用函数库在 Redis 源码中都对应一个单独的文件，比如 ae_select.c、ae_epoll.c、ae_kqueue.c，诸如此类。 因为 Redis 为每个 I/O 多路复用函数库都实现了相同的 API，所以 I/O 多路复用程序的底层实现是可以互换的。 Redis 在 I/O 多路复用程序的实现源码中用 #include 宏定义了相应的规则，程序会在编译时自动选择系统中性能最高的 I/O 多路复用函数库来作为 Redis 的 I/O 多路复用程序的底层实现： 123456789101112131415/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */# ifdef HAVE_EVPORT# include "ae_evport.c"# else # ifdef HAVE_EPOLL # include "ae_epoll.c" # else # ifdef HAVE_KQUEUE # include "ae_kqueue.c" # else # include "ae_select.c" # endif # endif# endif 1.3 事件的类型I/O 多路复用程序可以监听多个套接字的 ae.h/AE_READABLE 事件和 ae.h/AE_WRITABLE 事件，这两类事件和套接字操作之间的对应关系如下： 当套接字变得可读时（客户端对套接字执行 write 操作，或者执行 close 操作），或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行 connect 操作），套接字产生 AE_READABLE 事件； 当套接字变得可写时（客户端对套接字执行 read 操作），套接字产生 AE_WRITABLE 事件。 I/O 多路复用程序允许服务器同时监听套接字的 AE_READABLE 事件和 AE_WRITABLE 事件，如果一个套接字同时产生了这两种事件，那么文件事件分派器会优先处理 AE_READABLE 事件，等到 AE_READABLE 事件处理完之后，才处理 AE_WRITABLE 事件。这也就是说，如果一个套接字又可读又可写的话，那么服务器将先读套接字，后写套接字。 1.4 API ae.c/aeCreateFileEvent 函数接受一个套接字描述符、一个事件类型，以及一个事件处理器作为参数，将给定套接字的给定事件加入到 I/O 多路复用程序的监听范围之内，并对事件和事件处理器进行关联。 ae.c/aeDeleteFileEvent 函数接受一个套接字描述符和一个监听事件类型作为参数，让 I/O 多路复用程序取消对给定套接字的给定事件的监听，并取消事件和事件处理器之间的关联。 ae.c/aeGetFileEvents函数接受一个套接字描述符，返回该套接字正在被监听的事件类型： 如果套接字没有任何事件被监听，那么函数返回 AE_NONE。 如果套接字的读事件正在被监听，那么函数返回 AE_READABLE。 如果套接字的写事件正在被监听，那么函数返回 AE_WRITABLE。 如果套接字的读事件和写事件正在被监听，那么函数返回 AE_READABLE|AE_WRITABLE。 ae.c/aeWait 函数接受一个套接字描述符、一个事件类型和一个毫秒数为参数，在给定的时间内阻塞并等待套接字的给定类型事件产生，当事件成功产生，或者等待超时之后，函数返回。 ae.c/aeApiPoll 函数接受一个 sys/time.h/struct timeval 结构为参数，并在指定的时间內，阻塞并等待所有被 aeCreateFileEvent 函数设置为监听状态的套接字产生文件事件，当有至少一个事件产生，或者等待超时后，函数返回。 ae.c/aeProcessEvents 函数是文件事件分派器，它先调用 aeApiPoll 函数来等待事件产生，然后遍历所有已产生的事件，并调用相应的事件处理器来处理这些事件。 ae.c/aeGetApiName 函数返回 I/O 多路复用程序底层所使用的 I/O 多路复用函数库的名称：返回 “epoll” 表示底层为 epoll 函数库，返回 “select” 表示底层为 select 函数库，诸如此类。 1.5 文件事件处理器1.5.1 连接应答处理器networking.c/acceptTcpHandler 函数是 Redis 的连接应答处理器，这个处理器用于对连接服务器监听套接字的客户端进行应答，其主要调用 anet.c中anetTcpAccept 函数实现，具体实现为 sys/socket.h/accept 函数的包装。 当 Redis 服务器进行初始化的时候，程序会将这个连接应答处理器和服务器监听套接字的 AE_READABLE 事件关联起来，当有客户端用 sys/socket.h/connect 函数连接服务器监听套接字的时候，套接字就会产生 AE_READABLE 事件，引发连接应答处理器执行，并执行相应的套接字应答操作。 1.5.1 命令请求处理器networking.c/readQueryFromClient函数是 Redis 的命令请求处理器，这个处理器负责从套接字中读入客户端发送的命令请求内容，具体实现为 unistd.h/read 函数的包装。 当一个客户端通过连接应答处理器成功连接到服务器之后，服务器会将客户端套接字的 AE_READABLE 事件和命令请求处理器关联起来，当客户端向服务器发送命令请求的时候，套接字就会产生 AE_READABLE 事件，引发命令请求处理器执行，并执行相应的套接字读入操作； 在客户端连接服务器的整个过程中，服务器都会一直为客户端套接字的 AE_READABLE 事件关联命令请求处理器。 1.5.2 命令回复处理器networking.c/sendReplyToClient 函数是 Redis 的命令回复处理器，这个处理器负责将服务器执行命令后得到的命令回复通过套接字返回给客户端，具体实现为 unistd.h/write 函数的包装。 当服务器有命令回复需要传送给客户端的时候，服务器会将客户端套接字的 AE_WRITABLE 事件和命令回复处理器关联起来，当客户端准备好接收服务器传回的命令回复时，就会产生 AE_WRITABLE 事件，引发命令回复处理器执行，并执行相应的套接字写入操作。 2. 时间事件时间事件分为以下两类： 定时事件：让一段程序在指定的时间之后执行一次。比如说，让程序 X 在当前时间的 30 毫秒之后执行一次。 周期性事件：让一段程序每隔指定时间就执行一次。比如说，让程序 Y 每隔 30 毫秒就执行一次。 时间事件主要由以下三个属性组成： id：服务器为时间事件创建的全局唯一 ID（标识号）。ID 号按从小到大的顺序递增，新事件的 ID 号比旧事件的 ID 号要大。 when：毫秒精度的 UNIX 时间戳，记录了时间事件的到达（arrive）时间; timeProc：时间事件处理器，一个函数。当时间事件到达时，服务器就会调用相应的处理器来处理事件。 一个时间事件是定时事件还是周期性事件取决于时间事件处理器的返回值： 如果事件处理器返回 ae.h/AE_NOMORE，那么这个事件为定时事件：该事件在达到一次之后就会被删除，之后不再到达; 如果事件处理器返回一个非 AE_NOMORE 的整数值，那么这个事件为周期性时间：当一个时间事件到达之后，服务器会根据事件处理器返回的值，对时间事件的 when 属性进行更新，让这个事件在一段时间之后再次到达，并以这种方式一直更新并运行下去。比如说，如果一个时间事件的处理器返回整数值 30，那么服务器应该对这个时间事件进行更新，让这个事件在 30 毫秒之后再次到达。 目前版本的 Redis 只使用周期性事件，而没有使用定时事件。 2.1 实现服务器将所有时间事件都存放在一个无序链表中，每当时间事件执行器执行时，它就遍历整个链表，找到所有已到达的时间事件并调用相应事件处理器。这里的的无序链表，指的是不按 when 属性大小排序，而按 ID 排序，新的时间事件总是插入链表的表头。因此，当时间事件执行器运行的时候，它必须遍历链表中的所有时间事件，这样才能确保服务器中所有已到达的时间事件都会被处理。 2.2 APIae.c/aeCreateTimeEvent 函数接受一个毫秒数 milliseconds 和一个时间事件处理器 proc 作为参数，将一个新的时间事件添加到服务器，这个新的时间事件将在当前时间的 milliseconds 毫秒之后到达，而事件的处理器为 proc。 ae.c/aeDeleteFileEvent 函数接受一个时间事件 ID 作为参数，然后从服务器中删除该 ID 所对应的时间事件。 ae.c/aeSearchNearestTimer函数返回到达时间距离当前时间最接近的那个时间事件； ae.c/processTimeEvents 函数是时间事件的执行器，这个函数会遍历所有已到达的时间事件，并调用这些事件的处理器。已到达指的是，时间事件的 when 属性记录的 UNIX 时间戳等于或小于当前时间的 UNIX 时间戳。 processTimeEvents 函数的定义可以用以下伪代码来描述： 12345678910111213141516171819def processTimeEvents(): # 遍历服务器中的所有时间事件 for time_event in all_time_event(): # 检查事件是否已经到达 if time_event.when &lt;= unix_ts_now(): # 事件已到达 # 执行事件处理器，并获取返回值 retval = time_event.timeProc() # 如果这是一个定时事件 if retval == AE_NOMORE: # 那么将该事件从服务器中删除 delete_time_event_from_server(time_event) # 如果这是一个周期性事件 else: # 那么按照事件处理器的返回值更新时间事件的 when 属性 # 让这个事件在指定的时间之后再次到达 update_when(time_event, retval) 2.3 时间事件应用实例：serverCron 函数持续运行的 Redis 服务器需要定期对自身的资源和状态进行检查和调整，从而确保服务器可以长期、稳定地运行，这些定期操作由 redis.c/serverCron 函数负责执行，它的主要工作包括： 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。 清理数据库中的过期键值对。 关闭和清理连接失效的客户端。 尝试进行 AOF 或 RDB 持久化操作。 如果服务器是主服务器，那么对从服务器进行定期同步。 如果处于集群模式，对集群进行定期同步和连接测试。 Redis 服务器以周期性事件的方式来运行 serverCron 函数，在服务器运行期间，每隔一段时间，serverCron 就会执行一次，直到服务器关闭。 3. 事件的调度与执行事件的调度和执行由 ae.c/aeProcessEvents 函数负责，以下是该函数的伪代码表示： 1234567891011121314151617181920212223def aeProcessEvents(): # 获取到达时间离当前时间最接近的时间事件 time_event = aeSearchNearestTimer() # 计算最接近的时间事件距离到达还有多少毫秒 remaind_ms = time_event.when - unix_ts_now() # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设定为 0 if remaind_ms &lt; 0: remaind_ms = 0 # 根据remaind_ms的值，创建timeval结构 timeval = create_timeval_with_ms(remaind_ms) # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 结构决定 # 如果 remaind_ms 的值为0，那么 aeApiPoll 调用之后马上返回，不阻塞 aeApiPoll(timeval) # 处理所有已产生的文件事件 processFileEvents() # 处理所有已到达的时间事件 processTimeEvents() 将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，这就构成了 Redis 服务器的主函数，以下是该函数的伪代码表示： 1234567891011def main(): # 初始化服务器 init_server() # 一直处理事件，直到服务器关闭为止 while server_is_not_shutdown(): aeProcessEvents() # 服务器关闭，执行清理操作 clean_server() 以下是事件的调度和执行规则： aeApiPoll 函数的最大阻塞时间由到达时间最接近当前时间的时间事件决定，这个方法既可以避免服务器对时间事件进行频繁的轮询（忙等待），也可以确保 aeApiPoll 函数不会阻塞过长时间。 因为文件事件是随机出现的，如果等待并处理完一次文件事件后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这是服务器就可以开始处理到达的时间事件了。 对文件事件和时间事件的处理都是同步、有序、原子地执行的，服务器不会中途中断事件处理，也不会对事件进行抢占，因此，文件事件和时间事件的处理器都会尽可能地减少程序的阻塞时间，并在有需要时主动让出执行权，从而降低造成事件饥饿的可能性。 因为时间事件在文件事件后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间通常会比时间事件设定的到达时间稍晚一些。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：数据库》]]></title>
    <url>%2F2017%2F10%2F03%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 服务器中的数据库Redis 服务器将所有数据库都保存在服务器状态 redis.h/redisServer 结构的 db 数组中，db 数组的每个项都是一个 redis.h/redisDb 结构，每个 redisDb 结构代表一个数据库： 12345678910struct redisServer&#123; //... //一个数组，保存着服务器中的所有数据库 redisDb *db; //服务器的数据库数量 int dbnum;&#125;; 在初始化服务器时，程序会根据服务器状态的 dbnum 属性来决定应该创建多少个数据库。 dbnum 属性的值由服务器配置的 database 选项决定，默认情况下，该选项的值为 16，所以 Redis 服务器默认会创建 16 个数据库。 2. 切换数据库每个 Redis 客户端都有自己的目标数据库，每当客户端执行数据库写命令或者数据库读命令的时候，目标数据库就会成为这些命令的操作对象。 默认情况下，Redis 客户端的目标数据库为 0 号数据库，但客户端可以通过执行 SELECT 命令来切换目标数据库。 在服务器内部，客户端状态 redisClient 结构的 db 属性记录了客户端当前的目标数据库，这个属性是一个指向 redisDb 结构的指针： 12345678910typedef struct redisClient &#123; // ... //记录客户端当前正在使用的数据库 redisDb *db; // ... &#125; redisClient; redisClient.db 指针指向 redisServer.db 数组的其中一个元素，而被指向的元素就是客户端的目标数据库。 通过修改 redisClient.db 指针，让它指向服务器中的不同数据库，从而实现切换目标数据库的功能——这就是 SELECT 命令的实现原理。 3. 数据库空间Redis 是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个 redis.h/redisDb 结构表示，其中，redisDb 结构的 dict 字典保存了数据库中的所有键值对，我们将这个字典称为键空间（key space）： 123456789typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ dict *expires; /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) */ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; long long avg_ttl; /* Average TTL, just for stats */&#125; redisDb; 键空间和用户所见的数据库是直接对应的： 键空间的键也就是数据库的键，每个键都是一个字符串对象。 键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种 Redis 对象。 当使用 Redis 命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，其中包括： 在读取一个键之后（读操作和写操作都要对键进行读取），服务器会根据键是否存在来更新服务器的键空间命中（hit）次数或键空间不命中（miss）次数，这两个值可以在 INFO stats 命令的 keyspace_hits 属性和 keyspace_misses 属性中查看。 在读取一个键之后，服务器会更新键的 LRU（最后一次使用）时间，这个值可以用于计算键的闲置时间，使用 OBJECT idletime 命令可以查看键 key 的闲置时间。 如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其他操作。 如果有客户端使用 WATCH 命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏（dirty），从而让事务程序注意到这个键已经被修改过。 服务器每次修改一个键之后，都会对脏（dirty）键计数器的值增 1，这个计数器会触发服务器的持久化以及复制操作。 如果服务器开启了数据库通知功能，那么在对键进行修改之后，服务器将按配置发送相应的数据库通知。 4. 设置键的生存时间或过期时间通过 EXPIRE 命令或者 PEXPIRE 命令，客户端可以以秒或者毫秒精度为数据库中的某个键设置生存时间（Time To Live，TTL），在经过指定的秒数或者毫秒数之后，服务器就会自动删除生存时间为 0 的键。 与 EXPIRE 命令和 PEXPIRE 命令类似，客户端可以通过 EXPIREAT 命令或 PEXPIREAT 命令，以秒或者毫秒精度给数据库中的某个键设置过期时间（expire time）。 TTL 命令和 PTTL 命令接受一个带有生存时间或者过期时间的键，返回这个键的剩余生存时间，也就是，返回距离这个键被服务器自动删除还有多长时间。 4.1 设置过期时间Redis 有四个不同的命令可以用于设置键的生存时间（键可以存在多久）或过期时间（键什么时候会被删除）： EXPIRE＜key＞＜ttl＞ 命令用于将键 key 的生存时间设置为 ttl 秒。 PEXPIRE＜key＞＜ttl＞ 命令用于将键 key 的生存时间设置为 ttl 毫秒。 EXPIREAT＜key＞＜timestamp＞ 命令用于将键 key 的过期时间设置为 timestamp 所指定的秒数时间戳。 PEXPIREAT＜key＞＜timestamp＞ 命令用于将键 key 的过期时间设置为 timestamp 所指定的毫秒数时间戳。 虽然有多种不同单位和不同形式的设置命令，但实际上 EXPIRE、PEXPIRE、EXPIREAT 三个命令都是使用 PEXPIREAT 命令来实现的：无论客户端执行的是以上四个命令中的哪一个，经过转换之后，最终的执行效果都和执行 PEXPIREAT 命令一样。 首先，EXPIRE 命令可以转换成 PEXPIRE 命令： 123456def EXPIRE(key,ttl_in_sec): #将TTL从秒转换成毫秒 ttl_in_ms = sec_to_ms(ttl_in_sec) PEXPIRE(key, ttl_in_ms) 接着，PEXPIRE 命令又可以转换成 PEXPIREAT 命令： 1234567def PEXPIRE(key,ttl_in_ms): #获取以毫秒计算的当前 UNIX 时间戳 now_ms = get_current_unix_timestamp_in_ms() #当前时间加上 TTL，得出毫秒格式的键过期时间 PEXPIREAT(key,now_ms+ttl_in_ms) 并且，EXPIREAT 命令也可以转换成 PEXPIREAT 命令： 123456def EXPIREAT(key,expire_time_in_sec): #将过期时间从秒转换为毫秒 expire_time_in_ms = sec_to_ms(expire_time_in_sec) PEXPIREAT(key, expire_time_in_ms) 最终，EXPIRE、PEXPIRE 和 EXPIREAT 三个命令都会转换成 PEXPIREAT 命令来执行。 4.2 保存过期时间redisDb 结构的 expires 字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典： 过期字典的键是一个指针，这个指针指向键空间中的某个键对象（也即是某个数据库键）。在实际中，键空间的键和过期字典的键都指向同一个键对象。 过期字典的值是一个 long long 类型的整数，这个整数保存了键所指向的数据库键的过期时间——一个毫秒精度的 UNIX 时间戳。 当客户端执行 PEXPIREAT 命令（或者其他三个会转换成 PEXPIREAT 命令的命令）为一个数据库键设置过期时间时，服务器会在数据库的过期字典中关联给定的数据库键和过期时间。 以下是 PEXPIREAT 命令的伪代码定义： 1234567891011def PEXPIREAT(key, expire_time_in_ms): #如果给定的键不存在于键空间，那么不能设置过期时间 if key not in redisDb.dict: return0 #在过期字典中关联键和过期时间 redisDb.expires[key] = expire_time_in_ms #过期时间设置成功 return 1 4.3 移除过期时间PERSIST 命令可以移除一个键的过期时间，它是 PEXPIREAT 命令的反操作： PERSIST 命令在过期字典中查找给定的键，并解除键和值（过期时间）在过期字典中的关联。 以下是 PERSIST 命令的伪代码定义： 12345678def PERSIST(key): #如果键不存在，或者键没有设置过期时间，那么直接返回 if key not in redisDb.expires: return0 #移除过期字典中给定键的键值对关联 redisDb.expires.remove(key) #键的过期时间移除成功 return 1 4.4 计算并返回剩余生存时间TTL 命令以秒为单位返回键的剩余生存时间，而 PTTL 命令则以毫秒为单位返回键的剩余生存时间。TTL 和 PTTL 两个命令都是通过计算键的过期时间和当前时间之间的差来实现的，以下是这两个命令的伪代码实现： 12345678910111213141516171819202122232425262728293031def PTTL(key): #键不存在于数据库 if key not in redisDb.dict: return-2 #尝试取得键的过期时间 #如果键没有设置过期时间，那么 expire_time_in_ms将为 None expire_time_in_ms = redisDb.expires.get(key) #键没有设置过期时间 if expire_time_in_ms is None: return -1 #获得当前时间 now_ms = get_current_unix_timestamp_in_ms() #过期时间减去当前时间，得出的差就是键的剩余生存时间 return(expire_time_in_ms - now_ms) def TTL(key): #获取以毫秒为单位的剩余生存时间 ttl_in_ms = PTTL(key) if ttl_in_ms ＜ 0: #处理返回值为-2和-1的情况 return ttl_in_ms else: #将毫秒转换为秒 return ms_to_sec(ttl_in_ms) 4.5 过期键的判定通过过期字典，程序可以用以下步骤检查一个给定键是否过期： 检查给定键是否存在于过期字典：如果存在，那么取得键的过期时间。 检查当前 UNIX 时间戳是否大于键的过期时间：如果是的话，那么键已经过期；否则的话，键未过期。 可以用伪代码来描述这一过程： 12345678910111213141516171819def is_expired(key): #取得键的过期时间 expire_time_in_ms = redisDb.expires.get(key) #键没有设置过期时间 if expire_time_in_ms is None: return False #取得当前时间的UNIX时间戳 now_ms = get_current_unix_timestamp_in_ms() #检查当前时间是否大于键的过期时间 if now_ms ＞ expire_time_in_ms: #是，键已经过期 return True else: #否，键未过期 return False 5. 过期键删除策略有三种不同的过期键删除策略： 定时删除：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。 在这三种策略中，第一种和第三种为主动删除策略，而第二种则为被动删除策略。 5.1 定时删除定时删除策略对内存是最友好的：通过使用定时器，定时删除策略可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存。 另一方面，定时删除策略的缺点是，它对 CPU 时间是最不友好的：在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分 CPU 时间，在内存不紧张但是 CPU 时间非常紧张的情况下，将 CPU 时间用在删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。 除此之外，创建一个定时器需要用到 Redis 服务器中的时间事件，而当前时间事件的实现方式——无序链表，查找一个事件的时间复杂度为 $O(N)$ ——并不能高效地处理大量时间事件。 5.2 惰性删除惰性删除策略对 CPU 时间来说是最友好的：程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行，并且删除的目标仅限于当前处理的键，这个策略不会在删除其他无关的过期键上花费任何 CPU 时间。 惰性删除策略的缺点是，它对内存是最不友好的：如果一个键已经过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，它所占用的内存就不会释放。 在使用惰性删除策略时，如果数据库中有非常多的过期键，而这些过期键又恰好没有被访问到的话，那么它们也许永远也不会被删除（除非用户手动执行 FLUSHDB），我们甚至可以将这种情况看作是一种内存泄漏——无用的垃圾数据占用了大量的内存，而服务器却不会自己去释放它们，这对于运行状态非常依赖于内存的 Redis 服务器来说，肯定不是一个好消息。 5.3 定期删除从上面对定时删除和惰性删除的讨论来看，这两种删除方式在单一使用时都有明显的缺陷： 定时删除占用太多 CPU 时间，影响服务器的响应时间和吞吐量。 惰性删除浪费太多内存，有内存泄漏的危险。 定期删除策略是前两种策略的一种整合和折中： 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。 除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费。 定期删除策略的难点是确定删除操作执行的时长和频率： 如果删除操作执行得太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将 CPU 时间过多地消耗在删除过期键上面。 如果删除操作执行得太少，或者执行的时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况。 因此，如果采用定期删除策略的话，服务器必须根据情况，合理地设置删除操作的执行时长和执行频率。 6. Redis的过期键删除策略Redis 服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡。 6.1 惰性删除策略的实现过期键的惰性删除策略由 db.c/expireIfNeeded 函数实现，所有读写数据库的 Redis 命令在执行之前都会调用 expireIfNeeded 函数对输入键进行检查： 如果输入键已经过期，那么 expireIfNeeded 函数将输入键从数据库中删除。 如果输入键未过期，那么 expireIfNeeded 函数不做动作。 expireIfNeeded 函数就像一个过滤器，它可以在命令真正执行之前，过滤掉过期的输入键，从而避免命令接触到过期键。 另外，因为每个被访问的键都可能因为过期而被 expireIfNeeded 函数删除，所以每个命令的实现函数都必须能同时处理键存在以及键不存在这两种情况： 当键存在时，命令按照键存在的情况执行。 当键不存在或者键因为过期而被 expireIfNeeded 函数删除时，命令按照键不存在的情况执行。 6.2 定期删除策略的实现过期键的定期删除策略由 redis.c/activeExpireCycle 函数实现，每当 Redis 的服务器周期性操作 redis.c/serverCron 函数执行时，activeExpireCycle 函数就会被调用，它在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的 expires 字典中随机检查一部分键的过期时间，并删除其中的过期键。 整个过程可以用伪代码描述如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#默认每次检查的数据库数量DEFAULT_DB_NUMBERS = 16#默认每个数据库检查的键数量DEFAULT_KEY_NUMBERS = 20#全局变量，记录检查进度current_db = 0def activeExpireCycle(): #初始化要检查的数据库数量 #如果服务器的数据库数量比 DEFAULT_DB_NUMBERS要小 #那么以服务器的数据库数量为准 if server.dbnum ＜ DEFAULT_DB_NUMBERS: db_numbers = server.dbnum else: db_numbers = DEFAULT_DB_NUMBERS #遍历各个数据库 for i in range(db_numbers): #如果current_db的值等于服务器的数据库数量 #这表示检查程序已经遍历了服务器的所有数据库一次 #将current_db重置为0，开始新的一轮遍历 if current_db == server.dbnum: current_db = 0 #获取当前要处理的数据库 redisDb = server.db[current_db] #将数据库索引增1，指向下一个要处理的数据库 current_db += 1 #检查数据库键 for j in range(DEFAULT_KEY_NUMBERS): #如果数据库中没有一个键带有过期时间，那么跳过这个数据库 if redisDb.expires.size() == 0: break #随机获取一个带有过期时间的键 key_with_ttl = redisDb.expires.get_random_key() #检查键是否过期，如果过期就删除它 if is_expired(key_with_ttl): delete_key(key_with_ttl) #已达到时间上限，停止处理 if reach_time_limit(): return activeExpireCycle 函数的工作模式可以总结如下： 函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键。 全局变量 current_db 会记录当前 activeExpireCycle 函数检查的进度，并在下一次 activeExpireCycle 函数调用时，接着上一次的进度进行处理。 随着 activeExpireCycle 函数的不断执行，服务器中的所有数据库都会被检查一遍，这时函数将 current_db 变量重置为 0，然后再次开始新一轮的检查工作。 7. AOF、RDB 和复制功能对过期键的处理7.1 生成 RDB 文件在执行 SAVE 命令或者 BGSAVE 命令创建一个新的 RDB 文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的 RDB 文件中。 因此，数据库中包含过期键不会对生成新的RDB文件造成影响。 7.2 载入 RDB 文件在启动 Redis 服务器时，如果服务器开启了 RDB 功能，那么服务器将对 RDB 文件进行载入： 如果服务器以主服务器模式运行，那么在载入 RDB 文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入 RDB 文件的主服务器不会造成影响。 如果服务器以从服务器模式运行，那么在载入 RDB 文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空，所以一般来讲，过期键对载入 RDB 文件的从服务器也不会造成影响。 7.3 AOF 文件写入当服务器以 AOF 持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么 AOF 文件不会因为这个过期键而产生任何影响。 当过期键被惰性删除或者定期删除之后，程序会向 AOF 文件追加（append）一条 DEL 命令，来显式地记录该键已被删除。 7.4 AOF 重写和生成 RDB 文件时类似，在执行 AOF 重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的 AOF 文件中。 7.5 复制当服务器运行在复制模式下时，从服务器的过期键删除动作由主服务器控制： 主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个 DEL 命令，告知从服务器删除这个过期键。 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键。 从服务器只有在接到主服务器发来的 DEL 命令之后，才会删除过期键。 通过由主服务器来控制从服务器统一地删除过期键，可以保证主从服务器数据的一致性，也正是因为这个原因，当一个过期键仍然存在于主服务器的数据库时，这个过期键在从服务器里的复制品也会继续存在。 举个例子，有一对主从服务器，它们的数据库中都保存着同样的三个键 message、xxx 和 yyy，其中 message 为过期键。如果这时有客户端向从服务器发送命令 GET message，那么从服务器将发现 message 键已经过期，但从服务器并不会删除 message 键，而是继续将 message 键的值返回给客户端，就好像 message 键并没有过期一样。假设在此之后，有客户端向主服务器发送命令 GET message，那么主服务器将发现键 message 已经过期：主服务器会删除 message 键，向客户端返回空回复，并向从服务器发送 DEL message 命令。从服务器在接收到主服务器发来的 DEL message 命令之后，也会从数据库中删除 message 键，在这之后，主从服务器都不再保存过期键 message 了。 8. 数据库通知数据库通知是 Redis 2.8 版本新增加的功能，这个功能可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变化，以及数据库中命令的执行情况。 关注 “某个键执行了什么命令” 的通知称为键空间通知（key-space notification），除此之外，还有另一类称为键事件通知（key-event notification）的通知，它们关注的是 “某个命令被什么键执行了”。 服务器配置的 notify-keyspace-events 选项决定了服务器所发送通知的类型： 想让服务器发送所有类型的键空间通知和键事件通知，可以将选项的值设置为 AKE。 想让服务器发送所有类型的键空间通知，可以将选项的值设置为 AK。 想让服务器发送所有类型的键事件通知，可以将选项的值设置为 AE。 想让服务器只发送和字符串键有关的键空间通知，可以将选项的值设置为 K$。 想让服务器只发送和列表键有关的键事件通知，可以将选项的值设置为 El。 8.1 发送通知发送数据库通知的功能是由 notify.c/notifyKeyspaceEvent 函数实现的： 1void notifyKeyspaceEvent(int type,char *event,robj *key,int dbid); 函数的 type 参数是当前想要发送的通知的类型，程序会根据这个值来判断通知是否就是服务器配置 notify-keyspace-events 选项所选定的通知类型，从而决定是否发送通知。 event、keys 和 dbid 分别是事件的名称、产生事件的键，以及产生事件的数据库号码，函数会根据 type 参数以及这三个参数来构建事件通知的内容，以及接收通知的频道名。 每当一个 Redis 命令需要发送数据库通知的时候，该命令的实现函数就会调用 notify-KeyspaceEvent 函数，并向函数传递传递该命令所引发的事件的相关信息。 8.2 发送通知的实现以下是 notifyKeyspaceEvent 函数的伪代码实现： 12345678910111213141516171819202122232425262728def notifyKeyspaceEvent(type, event, key, dbid): #如果给定的通知不是服务器允许发送的通知，那么直接返回 if not(server.notify_keyspace_events &amp; type): return #发送键空间通知 if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYSPACE: #将通知发送给频道__keyspace@＜dbid＞__:＜key＞ #内容为键所发生的事件 ＜event＞ #构建频道名字 chan = &quot;__keyspace@&#123;dbid&#125;__:&#123;key&#125;&quot;.format(dbid=dbid, key=key) #发送通知 pubsubPublishMessage(chan, event) #发送键事件通知 if server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYEVENT: #将通知发送给频道__keyevent@＜dbid＞__:＜event＞ #内容为发生事件的键 ＜key＞ #构建频道名字 chan = &quot;__keyevent@&#123;dbid&#125;__:&#123;event&#125;&quot;.format(dbid=dbid,event=event) #发送通知 pubsubPublishMessage(chan, key) notifyKeyspaceEvent 函数执行以下操作： server.notify_keyspace_events 属性就是服务器配置 notify-keyspace-events 选项所设置的值，如果给定的通知类型 type 不是服务器允许发送的通知类型，那么函数会直接返回，不做任何动作。 如果给定的通知是服务器允许发送的通知，那么下一步函数会检测服务器是否允许发送键空间通知，如果允许的话，程序就会构建并发送事件通知。 最后，函数检测服务器是否允许发送键事件通知，如果允许的话，程序就会构建并发送事件通知。 另外，pubsubPublishMessage 函数是 PUBLISH 命令的实现函数，执行这个函数等同于执行 PUBLISH 命令，订阅数据库通知的客户端收到的信息就是由这个函数发出的。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Redis 设计与实现：数据结构与对象》]]></title>
    <url>%2F2017%2F10%2F02%2F%E3%80%8ARedis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AF%B9%E8%B1%A1%E3%80%8B%2F</url>
    <content type="text"><![CDATA[1. 简单动态字符串Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将 SDS 用作 Redis 的默认字符串表示。 当 Redis 需要的不仅仅是一个字符串字面量，而是一个可以被修改的字符串值时，Redis 就会使用 SDS 来表示字符串值：比如在 Redis 的数据库里面，包含字符串值的键值对在底层都是由 SDS 实现的。 除了用来保存数据库中的字符串值之外，SDS 还被用作缓冲区（buffer）：AOF 模块中的 AOF 缓冲区，以及客户端状态中的输入缓冲区，都是由 SDS 实现的。 1.1 SDS 的定义每个 sds.h/sdshdr 结构表示一个 SDS 值： 12345678910111213struct sdshdr &#123; // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];&#125;; SDS 遵循 C 字符串以空字符结尾的惯例，保存空字符的 1 字节空间不计算在 SDS 的 len 属性里面，并且为空字符分配额外的 1 字节空间，以及添加空字符到字符串末尾等操作都是由 SDS 函数自动完成的，所以这个空字符对于 SDS 的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS 可以直接重用一部分 C 字符串函数库里面的函数。 1.2 SDS 与 C 字符串的区别1.2.1 常数复杂度获取字符串长度因为 C 字符串并不记录自身的长度信息，所以为了获取一个 C 字符串的长度，程序必须遍历整个字符串，对遇到的每个字符进行计数，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为 $O(N)$ 。 通过使用 SDS 而不是 C 字符串，Redis 将获取字符串长度所需的复杂度从 $O(N) $ 降低到了 $O(1)$ ，这确保了获取字符串长度的工作不会成为 Redis 的性能瓶颈。 1.2.2 杜绝缓冲区溢出当 SDS API 需要对 SDS 进行修改时，API 会先检查 SDS 的空间是否满足修改所需的要求，如果不满足的话，API 会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现缓冲区溢出问题。 1.2.3 减少修改字符串时带来的内存重分配次数空间预分配空间预分配用于优化 SDS 的字符串增长操作：当 SDS 的 API 对一个 SDS 进行修改，并且需要对 SDS 进行空间扩展的时候，程序不仅会为 SDS 分配修改所必须要的空间，还会为 SDS 分配额外的未使用空间。 其中，额外分配的未使用空间数量由以下公式决定： 如果对 SDS 进行修改之后，SDS 的长度（也即是 len 属性的值）将小于 1 MB，那么程序分配和 len 属性同样大小的未使用空间，这时 SDS len 属性的值将和 free 属性的值相同。 如果对 SDS 进行修改之后，SDS 的长度将大于等于 1 MB，那么程序会分配 1 MB 的未使用空间。 在扩展 SDS 空间之前，SDS API 会先检查未使用空间是否足够，如果足够的话，API 就会直接使用未使用空间，而无须执行内存重分配。 通过这种预分配策略，SDS 将连续增长 N 次字符串所需的内存重分配次数从必定 N 次降低为最多 N 次。 惰性空间释放惰性空间释放用于优化 SDS 的字符串缩短操作：当 SDS 的 API 需要缩短 SDS 保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。 通过惰性空间释放策略，SDS 避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。 与此同时，SDS 也提供了相应的 API ，让我们可以在有需要时，真正地释放 SDS 里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。 1.2.4 二进制安全C 字符串中的字符必须符合某种编码（比如 ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾——这些限制使得 C 字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。 SDS 的 API 都是二进制安全的（binary-safe）：所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设——数据在写入时是什么样的，它被读取时就是什么样。 这也是我们将 SDS 的 buf 属性称为字节数组的原因—— Redis 不是用这个数组来保存字符，而是用它来保存一系列二进制数据。 1.2.5 兼容部分 C 字符串函数虽然 SDS 的 API 都是二进制安全的，但它们一样遵循 C 字符串以空字符结尾的惯例：这些 API 总会将 SDS 保存的数据的末尾设置为空字符，并且总会在为 buf 数组分配空间时多分配一个字节来容纳这个空字符，这是为了让那些保存文本数据的 SDS 可以重用一部分 &lt;string.h&gt; 库定义的函数。 1.2.6 总结 C 字符串 SDS 获取字符串长度的复杂度为 $O(N)$。 获取字符串长度的复杂度为 $O(1)$。 API 是不安全的，可能会造成缓冲区溢出。 API 是安全的，不会造成缓冲区溢出。 修改字符串长度 N 次必然需要执行 N 次内存重分配。 修改字符串长度 N 次最多需要执行 N 次内存重分配。 只能保存文本数据。 可以保存文本或者二进制数据。 可以使用所有 &lt;string.h&gt; 库中的函数。 1.3 SDS API 函数 作用 时间复杂度 sdsnew 创建一个包含给定 C 字符串的 SDS 。 $O(N)$，N 为给定 C 字符串的长度。 sdsempty 创建一个不包含任何内容的空 SDS 。 $O(1)$ sdsfree 释放给定的 SDS 。 $O(1)$ sdslen 返回 SDS 的已使用空间字节数。 这个值可以通过读取 SDS 的 len 属性来直接获得，复杂度为 $O(1)$。 sdsavail 返回 SDS 的未使用空间字节数。 这个值可以通过读取 SDS 的 free 属性来直接获得，复杂度为 $O(1)$。 sdsdup 创建一个给定 SDS 的副本（copy）。 $O(N)$，N 为给定 SDS 的长度。 sdsclear 清空 SDS 保存的字符串内容。 因为惰性空间释放策略，复杂度为 $O(1)$。 sdscat 将给定 C 字符串拼接到 SDS 字符串的末尾。 $O(N)$，N 为被拼接 C 字符串的长度。 sdscatsds 将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾。 $O(N)$，N为被拼接 SDS 字符串的长度。 sdscpy 将给定的 C 字符串复制到 SDS 里面， 覆盖 SDS 原有的字符串。 $O(N)$，N 为被复制 C 字符串的长度。 sdsgrowzero 用空字符将 SDS 扩展至给定长度。 $O(N)$，N 为扩展新增的字节数。 sdsrange 保留 SDS 给定区间内的数据， 不在区间内的数据会被覆盖或清除。 $O(N)$，N 为被保留数据的字节数。 sdstrim 接受一个 SDS 和一个 C 字符串作为参数， 从 SDS 左右两端分别移除所有在 C 字符串中出现过的字符。 $O(M*N)$，M 为 SDS 的长度，N 为给定 C 字符串的长度。 sdscmp 对比两个 SDS 字符串是否相同。 $O(N)$，N 为两个 SDS 中较短的那个 SDS 的长度。 2. 链表2.1 链表和链表节点的实现每个链表节点使用一个 adlist.h/listNode 结构来表示： 123456789101112typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value;&#125; listNode; 多个 listNode 可以通过 prev 和 next 指针组成双端链表。 虽然仅仅使用多个 listNode 结构就可以组成链表，但使用 adlist.h/list 来持有链表的话，操作起来会更方便： 123456789101112131415161718192021typedef struct list &#123; // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr, void *key);&#125; list; list 结构为链表提供了表头指针 head、表尾指针 tail，以及链表长度计数器 len，而 dup、free 和 match 成员则是用于实现多态链表所需的类型特定函数： dup 函数用于复制链表节点所保存的值； free 函数用于释放链表节点所保存的值； match 函数则用于对比链表节点所保存的值和另一个输入值是否相等。 Redis 的链表实现的特性可以总结如下： 双端：链表节点带有 prev 和 next 指针，获取某个节点的前置节点和后置节点的复杂度都是 $O(1)$。 无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL，对链表的访问以 NULL 为终点。 带表头指针和表尾指针：通过 list 结构的 head 指针和 tail 指针，程序获取链表的表头节点和表尾节点的复杂度为 $O(1)$。 带链表长度计数器：程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数，程序获取链表中节点数量的复杂度为 $O(1)$。 多态：链表节点使用 void* 指针来保存节点值，并且可以通过 list 结构的 dup、free、match 三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。 2.2 链表和链表节点的 API 函数 作用 时间复杂度 listSetDupMethod 将给定的函数设置为链表的节点值复制函数。 $O(1)$。 listGetDupMethod 返回链表当前正在使用的节点值复制函数。 复制函数可以通过链表的 dup 属性直接获得，$O(1)$ listSetFreeMethod 将给定的函数设置为链表的节点值释放函数。 $O(1)$ listGetFree 返回链表当前正在使用的节点值释放函数。 $O(1)$ listSetMatchMethod 将给定的函数设置为链表的节点值对比函数。 $O(1)$ listGetMatchMethod 返回链表当前正在使用的节点值对比函数。 对比函数可以通过链表的 match 属性直接获得，$O(1)$ listLength 返回链表的长度（包含了多少个节点）。 链表长度可以通过链表的 len 属性直接获得，$O(1)$。 listFirst 返回链表的表头节点。 表头节点可以通过链表的 head 属性直接获得，$O(1)$。 listLast 返回链表的表尾节点。 表尾节点可以通过链表的 tail 属性直接获得，$O(1)$。 listPrevNode 返回给定节点的前置节点。 前置节点可以通过节点的 prev 属性直接获得，$O(1)$。 listNextNode 返回给定节点的后置节点。 后置节点可以通过节点的 next 属性直接获得，$O(1)$。 listNodeValue 返回给定节点目前正在保存的值。 节点值可以通过节点的 value 属性直接获得，$O(1)$。 listCreate 创建一个不包含任何节点的新链表。 $O(1)$ listAddNodeHead 将一个包含给定值的新节点添加到给定链表的表头。 $O(1)$ listAddNodeTail 将一个包含给定值的新节点添加到给定链表的表尾。 $O(1)$ listInsertNode 将一个包含给定值的新节点添加到给定节点的之前或者之后。 $O(1)$ listSearchKey 查找并返回链表中包含给定值的节点。 $O(N)$，N 为链表长度。 listIndex 返回链表在给定索引上的节点。 $O(N)$，N 为链表长度。 listDelNode 从链表中删除给定节点。 $O(1)$ listRotate 将链表的表尾节点弹出，然后将被弹出的节点插入到链表的表头， 成为新的表头节点。 $O(1)$ listDup 复制一个给定链表的副本。 $O(N)$，N 为链表长度。 listRelease 释放给定链表，以及链表中的所有节点。 $O(N)$，N 为链表长度。 3. 字典3.1 字典的实现3.1.1 哈希表Redis 字典所使用的哈希表由 dict.h/dictht 结构定义： 12345678910111213141516typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dictht; table 属性是一个数组，数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针，每个 dictEntry 结构保存着一个键值对。 size 属性记录了哈希表的大小，也即是 table 数组的大小，而 used 属性则记录了哈希表目前已有节点（键值对）的数量。 sizemask 属性的值总是等于 size - 1，这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。 3.1.2 哈希表节点哈希表节点使用 dictEntry 结构表示，每个 dictEntry 结构都保存着一个键值对： 12345678910111213141516typedef struct dictEntry &#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;&#125; dictEntry; key 属性保存着键值对中的键，而 v 属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个 uint64_t 整数，又或者是一个 int64_t 整数。 next 属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。 3.1.3 字典Redis 中的字典由 dict.h/dict 结构表示： 12345678910111213141516typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，值为 -1 int rehashidx; /* rehashing not in progress if rehashidx == -1 */&#125; dict; type 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的： type 属性是一个指向 dictType 结构的指针，每个 dictType 结构保存了一簇用于操作特定类型键值对的函数，Redis 会为用途不同的字典设置不同的类型特定函数。 而 privdata 属性则保存了需要传给那些类型特定函数的可选参数。 123456789101112131415161718192021typedef struct dictType &#123; // 计算哈希值的函数 unsigned int (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj);&#125; dictType; ht 属性是一个包含两个项的数组，数组中的每个项都是一个 dictht 哈希表，一般情况下，字典只使用 ht[0] 哈希表，ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。 除了 ht[1] 之外，另一个和 rehash 有关的属性就是 rehashidx：它记录了 rehash 目前的进度，如果目前没有在进行 rehash ，那么它的值为 -1。 3.2 哈希算法当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。 Redis 计算哈希值和索引值的方法如下： 123456# 使用字典设置的哈希函数，计算键 key 的哈希值hash = dict-&gt;type-&gt;hashFunction(key);# 使用哈希表的 sizemask 属性和哈希值，计算出索引值# 根据情况不同， ht[x] 可以是 ht[0] 或者 ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 3.3 解决键冲突Redis 的哈希表使用链地址法（separate chaining）来解决键冲突：每个哈希表节点都有一个 next 指针，多个哈希表节点可以用 next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。 因为 dictEntry 节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点添加到链表的表头位置（复杂度为 $O(1)$），排在其他已有节点的前面。 3.4 rehash扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成，Redis 对字典的哈希表执行 rehash 的步骤如下： 为字典的 ht[1] 哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）： 如果执行的是扩展操作，那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 $2^n$； 如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 $2^n$。 将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面：rehash 指的是重新计算键的哈希值和索引值，然后将键值对放置到 ht[1]哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表），释放 ht[0]，将 ht[1] 设置为 ht[0]，并在 ht[1] 新创建一个空白哈希表，为下一次 rehash 做准备。 因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0]里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。 3.5 渐进式 rehash为了避免 rehash 对服务器性能造成影响，服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1]，而是分多次、渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1]。 以下是哈希表渐进式 rehash 的详细步骤： 为 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ，并将它的值设置为 0，表示 rehash 工作正式开始。 在 rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ，当 rehash 工作完成之后，程序将 rehashidx 属性的值增一。 随着字典操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1] ，这时程序将 rehashidx 属性的值设为 -1，表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式，将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式 rehash 而带来的庞大计算量。 3.6 字典 API 函数 作用 时间复杂度 dictCreate 创建一个新的字典。 $O(1)$ dictAdd 将给定的键值对添加到字典里面。 $O(1)$ dictReplace 将给定的键值对添加到字典里面，如果键已经存在于字典，那么用新值取代原有的值。 $O(1)$ dictFetchValue 返回给定键的值。 $O(1)$ dictGetRandomKey 从字典中随机返回一个键值对。 $O(1)$ dictDelete 从字典中删除给定键所对应的键值对。 $O(1)$ dictRelease 释放给定字典，以及字典中包含的所有键值对。 $O(N)$，N 为字典包含的键值对数量。 4. 跳跃表跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表支持平均 $O(log N)$ 最坏 $O(N)$ 复杂度的节点查找，还可以通过顺序性操作来批量处理节点。 在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单， 所以有不少程序都使用跳跃表来代替平衡树。 Redis 使用跳跃表作为有序集合键的底层实现之一：如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis 就会使用跳跃表来作为有序集合键的底层实现。 Redis 只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。 4.1 跳跃表的实现Redis 的跳跃表由 redis.h/zskiplistNode 和 redis.h/zskiplist 两个结构定义，其中 zskiplistNode 结构用于表示跳跃表节点，而 zskiplist 结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针。 4.1.1 跳跃表节点跳跃表节点的实现由 redis.h/zskiplistNode 结构定义： 1234567891011121314151617181920212223typedef struct zskiplistNode &#123; // 后退指针 struct zskiplistNode *backward; // 分值 double score; // 成员对象 robj *obj; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[];&#125; zskiplistNode; 1. 层跳跃表节点的 level 数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度，一般来说，层的数量越多，访问其他节点的速度就越快。 每次创建一个新跳跃表节点的时候，程序都根据幂次定律 （power law，越大的数出现的概率越小） 随机生成一个介于 1 和 32 之间的值作为 level 数组的大小，这个大小就是层的 “高度”。 2. 前进指针每个层都有一个指向表尾方向的前进指针（level[i].forward 属性），用于从表头向表尾方向访问节点。 3. 跨度层的跨度（level[i].span 属性）用于记录两个节点之间的距离： 两个节点之间的跨度越大，它们相距得就越远。 指向 NULL 的所有前进指针的跨度都为 0，因为它们没有连向任何节点。 遍历操作只使用前进指针就可以完成了，跨度实际上是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。 4. 后退指针节点的后退指针（backward 属性）用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。 5. 分值和成员节点的分值（score 属性）是一个 double 类型的浮点数，跳跃表中的所有节点都按分值从小到大来排序。 节点的成员对象（obj 属性）是一个指针，它指向一个字符串对象，而字符串对象则保存着一个 SDS 值。 在同一个跳跃表中，各个节点保存的成员对象必须是唯一的，但是多个节点保存的分值却可以是相同的：分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象较小的节点会排在前面（靠近表头的方向），而成员对象较大的节点则会排在后面（靠近表尾的方向）。 4.1.2 跳跃表通过使用一个 zskiplist 结构来持有节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，又或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息。 zskiplist 结构的定义如下： 123456789101112typedef struct zskiplist &#123; // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125; zskiplist; header 和 tail 指针分别指向跳跃表的表头和表尾节点，通过这两个指针，程序定位表头节点和表尾节点的复杂度为 $O(1)$。 通过使用 length 属性来记录节点的数量，程序可以在 $O(1)$ 复杂度内返回跳跃表的长度。 level 属性则用于在 $O(1)$ 复杂度内获取跳跃表中层高最大的那个节点的层数量，注意表头节点的层高并不计算在内。 4.2 跳跃表 API 函数 作用 时间复杂度 zslCreate 创建一个新的跳跃表。 $O(1)$ zslFree 释放给定跳跃表，以及表中包含的所有节点。 $O(N)$，N 为跳跃表的长度。 zslInsert 将包含给定成员和分值的新节点添加到跳跃表中。 平均 $O(log N)$，最坏 $O(N)$，N 为跳跃表长度。 zslDelete 删除跳跃表中包含给定成员和分值的节点。 平均 $O(log N)$，最坏 $O(N)$，N 为跳跃表长度。 zslGetRank 返回包含给定成员和分值的节点在跳跃表中的排位。 平均 $O(log N)$，最坏 $O(N)$，N 为跳跃表长度。 zslGetElementByRank 返回跳跃表在给定排位上的节点。 平均 $O(log N)$，最坏 $O(N)$，N 为跳跃表长度。 zslIsInRange 给定一个分值范围（range），如果给定的分值范围包含在跳跃表的分值范围之内，那么返回 1，否则返回 0。 通过跳跃表的表头节点和表尾节点，这个检测可以用 $O(1)$ 复杂度完成。 zslFirstInRange 给定一个分值范围，返回跳跃表中第一个符合这个范围的节点。 平均 $O(log N)$，最坏 $O(N)$。N 为跳跃表长度。 zslLastInRange 给定一个分值范围，返回跳跃表中最后一个符合这个范围的节点。 平均 $O(log N)$，最坏 $O(N)$。N 为跳跃表长度。 zslDeleteRangeByScore 给定一个分值范围，删除跳跃表中所有在这个范围之内的节点。 $O(N)$，N 为被删除节点数量。 zslDeleteRangeByRank 给定一个排位范围，删除跳跃表中所有在这个范围之内的节点。 $O(N)$，N 为被删除节点数量。 5. 整数集合整数集合（intset）是集合键的底层实现之一：当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。 5.1 整数集合的实现整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构，它可以保存类型为 int16_t、 int32_t 或者 int64_t 的整数值，并且保证集合中不会出现重复元素。 每个 intset.h/intset 结构表示一个整数集合： 123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; contents 数组是整数集合的底层实现：整数集合的每个元素都是 contents 数组的一个数组项（item），各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。 length 属性记录了整数集合包含的元素数量，也即是 contents 数组的长度。 虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组，但实际上 contents 数组并不保存任何 int8_t 类型的值 —— contents 数组的真正类型取决于 encoding 属性的值： 如果 encoding 属性的值为 INTSET_ENC_INT16 ，那么 contents 就是一个 int16_t 类型的数组，数组里的每个项都是一个 int16_t类型的整数值（最小值为 -32,768，最大值为 32,767）。 如果 encoding 属性的值为 INTSET_ENC_INT32 ，那么 contents 就是一个 int32_t 类型的数组，数组里的每个项都是一个 int32_t类型的整数值（最小值为 -2,147,483,648，最大值为 2,147,483,647）。 如果 encoding 属性的值为 INTSET_ENC_INT64 ，那么 contents 就是一个 int64_t 类型的数组，数组里的每个项都是一个 int64_t类型的整数值（最小值为 -9,223,372,036,854,775,808，最大值为 9,223,372,036,854,775,807）。 5.2 升级每当我们要将一个新元素添加到整数集合里面，并且新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要先进行升级（upgrade），然后才能将新元素添加到整数集合里面。 升级整数集合并添加新元素共分为三步进行： 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。 将新元素添加到底层数组里面。 因为每次向整数集合添加新元素都可能会引起升级，而每次升级都需要对底层数组中已有的所有元素进行类型转换，所以向整数集合添加新元素的时间复杂度为 $O(N)$。 因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大，所以这个新元素的值要么就大于所有现有元素，要么就小于所有现有元素： 在新元素小于所有现有元素的情况下，新元素会被放置在底层数组的最开头（索引 0 ）； 在新元素大于所有现有元素的情况下，新元素会被放置在底层数组的最末尾（索引 length-1 ）。 5.3 降级整数集合不支持降级操作。 5.4 整数集合 API 函数 作用 时间复杂度 intsetNew 创建一个新的整数集合。 $O(1)$ intsetAdd 将给定元素添加到整数集合里面。 $O(N)$ intsetRemove 从整数集合中移除给定元素。 $O(N)$ intsetFind 检查给定值是否存在于集合。 因为底层数组有序，查找可以通过二分查找法来进行， 所以复杂度为 $O(log N)$。 intsetRandom 从整数集合中随机返回一个元素。 $O(1)$ intsetGet 取出底层数组在给定索引上的元素。 $O(1)$ intsetLen 返回整数集合包含的元素个数。 $O(1)$ intsetBlobLen 返回整数集合占用的内存字节数。 $O(1)$ 6. 压缩列表整数集合（intset）是集合键的底层实现之一：当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。 另外，当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做哈希键的底层实现。 6.1 压缩列表的构成压缩列表是 Redis 为了节约内存而开发的，由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。 一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 1zlbytes | zltail | zllen | entry1 | entry2 | ... | entryN | zlend 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend的位置时使用。 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255），用于标记压缩列表的末端。 6.2 压缩列表节点的构成每个压缩列表节点可以保存一个字节数组或者一个整数值，其中，字节数组可以是以下三种长度的其中一种： 长度小于等于 63（$2^{6}-1$）字节的字节数组； 长度小于等于 16383（$2^{14}-1$） 字节的字节数组； 长度小于等于 4294967295（$2^{32}-1$）字节的字节数组； 每个压缩列表节点都由 previous_entry_length、 encoding、 content 三个部分组成： 1previous_entry_length | encoding | content 6.2.1 previous_entry_length节点的 previous_entry_length 属性以字节为单位，记录了压缩列表中前一个节点的长度。 previous_entry_length 属性的长度可以是 1 字节或者 5 字节： 如果前一节点的长度小于 254 字节，那么 previous_entry_length 属性的长度为 1 字节：前一节点的长度就保存在这一个字节里面。 如果前一节点的长度大于等于 254 字节， 那么 previous_entry_length 属性的长度为 5 字节：其中属性的第一字节会被设置为 0xFE（十进制值 254），而之后的四个字节则用于保存前一节点的长度。 因为节点的 previous_entry_length 属性记录了前一个节点的长度，所以程序可以通过指针运算，根据当前节点的起始地址来计算出前一个节点的起始地址。 压缩列表的从表尾向表头遍历操作就是使用这一原理实现的：只要我们拥有了一个指向某个节点起始地址的指针，那么通过这个指针以及这个节点的 previous_entry_length 属性，程序就可以一直向前一个节点回溯，最终到达压缩列表的表头节点。 6.2.2 encoding节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度： 一字节、两字节或者五字节长，值的最高位为 00、01 或者 10 的是字节数组编码：这种编码表示节点的 content 属性保存着字节数组，数组的长度由编码除去最高两位之后的其他位记录； 一字节长，值的最高位以 11 开头的是整数编码：这种编码表示节点的 content 属性保存着整数值，整数值的类型和长度由编码除去最高两位之后的其他位记录。 6.2.3 content节点的 content 属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的 encoding 属性决定。 6.3 连锁更新对 ziplist 添加和删除节点时，可能引起连续多次空间扩展操作，称为 “连锁更新”。 因为连锁更新在最坏情况下需要对压缩列表执行 N 次空间重分配操作，而每次空间重分配的最坏复杂度为 $O(N)$，所以连更新的最坏复杂度为 $O(N^2)$。 要注意的是，尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的： 首先，压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见； 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的； 因为以上原因，ziplistPush 等命令的平均复杂度仅为 $O(N)$，在实际中，我们可以放心地使用这些函数，而不必担心连锁更新会影响压缩列表的性能。 6.4 压缩列表 API 函数 作用 算法复杂度 ziplistNew 创建一个新的压缩列表。 $O(1)$ ziplistPush 创建一个包含给定值的新节点，并将这个新节点添加到压缩列表的表头或者表尾。 平均 $O(N)$，最坏 $O(N^2)$。 ziplistInsert 将包含给定值的新节点插入到给定节点之后。 平均 $O(N)$，最坏 $O(N^2)$。 ziplistIndex 返回压缩列表给定索引上的节点。 $O(N)$ ziplistFind 在压缩列表中查找并返回包含了给定值的节点。 因为节点的值可能是一个字节数组，所以检查节点值和给定值是否相同的复杂度为 $O(N)$，而查找整个列表的复杂度则为 $O(N^2)$。 ziplistNext 返回给定节点的下一个节点。 $O(1)$ ziplistPrev 返回给定节点的前一个节点。 $O(1)$ ziplistGet 获取给定节点所保存的值。 $O(1)$ ziplistDelete 从压缩列表中删除给定的节点。 平均 $O(N)$，最坏 $O(N^2)$。 ziplistDeleteRange 删除压缩列表在给定索引上的连续多个节点。 平均 $O(N)$，最坏 $O(N^2)$。 ziplistBlobLen 返回压缩列表目前占用的内存字节数。 $O(1)$ ziplistLen 返回压缩列表目前包含的节点数量。 节点数量小于 65535 时 $O(1)$， 大于 65535 时 $O(N)$。 因为 ziplistPush、ziplistInsert、ziplistDelete 和 ziplistDeleteRange 四个函数都有可能会引发连锁更新，所以它们的最坏复杂度都是 $O(N^2)$。 7. 对象7.1 对象的类型与编码Redis 使用对象来表示数据库中的键和值，每次当我们在 Redis 的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。 Redis 中的每个对象都由一个 redisObject 结构表示，该结构中和保存数据有关的三个属性分别是 type 属性、encoding 属性和 ptr 属性： 1234567typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr;&#125; robj; 7.1.1 类型对象的 type 属性记录了对象的类型，这个属性的值可以是 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 对于 Redis 数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种，因此： 当我们称呼一个数据库键为 “字符串键” 时，我们指的是 “这个数据库键所对应的值为字符串对象”； 当我们称呼一个键为 “列表键” 时，我们指的是 “这个数据库键所对应的值为列表对象”。 TYPE 命令的实现方式也与此类似，当我们对一个数据库键执行 TYPE 命令时，命令返回的结果为数据库键对应的值对象的类型， 而不是键对象的类型。 7.1.2 编码和底层实现对象的 ptr 指针指向对象的底层实现数据结构，而这些数据结构由对象的 encoding 属性决定。 encoding 属性记录了对象所使用的编码，也即是说这个对象使用了什么数据结构作为对象的底层实现，这个属性的值可以是： 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 每种类型的对象都至少使用了两种不同的编码： 类型 编码 对象 REDIS_STRING REDIS_ENCODING_INT 使用整数值实现的字符串对象。 REDIS_STRING REDIS_ENCODING_EMBSTR 使用 embstr 编码的简单动态字符串实现的字符串对象。 REDIS_STRING REDIS_ENCODING_RAW 使用简单动态字符串实现的字符串对象。 REDIS_LIST REDIS_ENCODING_ZIPLIST 使用压缩列表实现的列表对象。 REDIS_LIST REDIS_ENCODING_LINKEDLIST 使用双端链表实现的列表对象。 REDIS_HASH REDIS_ENCODING_ZIPLIST 使用压缩列表实现的哈希对象。 REDIS_HASH REDIS_ENCODING_HT 使用字典实现的哈希对象。 REDIS_SET REDIS_ENCODING_INTSET 使用整数集合实现的集合对象。 REDIS_SET REDIS_ENCODING_HT 使用字典实现的集合对象。 REDIS_ZSET REDIS_ENCODING_ZIPLIST 使用压缩列表实现的有序集合对象。 REDIS_ZSET REDIS_ENCODING_SKIPLIST 使用跳跃表和字典实现的有序集合对象。 使用 OBJECT ENCODING 命令可以查看一个数据库键的值对象的编码。不同编码的对象所对应的 OBJECT ENCODING 命令输出： 对象所使用的底层数据结构 编码常量 OBJECT ENCODING 命令输出 整数 REDIS_ENCODING_INT &quot;int&quot; embstr 编码的简单动态字符串（SDS） REDIS_ENCODING_EMBSTR &quot;embstr&quot; 简单动态字符串 REDIS_ENCODING_RAW &quot;raw&quot; 字典 REDIS_ENCODING_HT &quot;hashtable&quot; 双端链表 REDIS_ENCODING_LINKEDLIST &quot;linkedlist&quot; 压缩列表 REDIS_ENCODING_ZIPLIST &quot;ziplist&quot; 整数集合 REDIS_ENCODING_INTSET &quot;intset&quot; 跳跃表和字典 REDIS_ENCODING_SKIPLIST &quot;skiplist&quot; 通过 encoding 属性来设定对象所使用的编码，而不是为特定类型的对象关联一种固定的编码，极大地提升了 Redis 的灵活性和效率，因为 Redis 可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率。 7.2 字符串对象字符串对象的编码可以是 int、raw 或者 embstr。 如果一个字符串对象保存的是整数值，并且这个整数值可以用 long 类型来表示，那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ），并将字符串对象的编码设置为 int 。 如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于 39 字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为 raw 。 如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于 39 字节，那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。 embstr 编码是专门用于保存短字符串的一种优化编码方式，这种编码和 raw 编码一样，都使用 redisObject 结构和 sdshdr 结构来表示字符串对象，但 raw 编码会调用两次内存分配函数来分别创建 redisObject 结构和 sdshdr 结构，而 embstr 编码则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含 redisObject 和 sdshdr 两个结构。 embstr 编码的字符串对象在执行命令时，产生的效果和 raw 编码的字符串对象执行命令时产生的效果是相同的，但使用 embstr 编码的字符串对象来保存短字符串值有以下好处： embstr 编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次。 释放 embstr 编码的字符串对象只需要调用一次内存释放函数，而释放 raw 编码的字符串对象需要调用两次内存释放函数。 因为 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起 raw 编码的字符串对象能够更好地利用缓存带来的优势。 最后要说的是，可以用 long double 类型表示的浮点数在 Redis 中也是作为字符串值来保存的：如果我们要保存一个浮点数到字符串对象里面，那么程序会先将这个浮点数转换成字符串值，然后再保存起转换所得的字符串值。在有需要的时候，程序会将保存在字符串对象里面的字符串值转换回浮点数值，执行某些操作，然后再将执行操作所得的浮点数值转换回字符串值，并继续保存在字符串对象里面。 7.2.1 编码的转换int 编码的字符串对象和 embstr 编码的字符串对象在条件满足的情况下，会被转换为 raw 编码的字符串对象。 对于 int 编码的字符串对象来说，如果我们向对象执行了一些命令，使得这个对象保存的不再是整数值，而是一个字符串值，那么字符串对象的编码将从 int 变为 raw。 另外，因为 Redis 没有为 embstr 编码的字符串对象编写任何相应的修改程序 （只有 int 编码的字符串对象和 raw 编码的字符串对象有这些程序），所以 embstr 编码的字符串对象实际上是只读的：当我们对 embstr 编码的字符串对象执行任何修改命令时，程序会先将对象的编码从 embstr 转换成 raw ，然后再执行修改命令；因为这个原因，embstr 编码的字符串对象在执行修改命令之后，总会变成一个 raw 编码的字符串对象。 7.2.2 字符串命令的实现 命令 int 编码的实现方法 embstr 编码的实现方法 raw 编码的实现方法 SET 使用 int 编码保存值。 使用 embstr 编码保存值。 使用 raw 编码保存值。 GET 拷贝对象所保存的整数值，将这个拷贝转换成字符串值，然后向客户端返回这个字符串值。 直接向客户端返回字符串值。 直接向客户端返回字符串值。 APPEND 将对象转换成 raw 编码，然后按 raw 编码的方式执行此操作。 将对象转换成 raw 编码，然后按 raw 编码的方式执行此操作。 调用 sdscatlen 函数，将给定字符串追加到现有字符串的末尾。 INCRBYFLOAT 取出整数值并将其转换成 longdouble 类型的浮点数，对这个浮点数进行加法计算，然后将得出的浮点数结果保存起来。 取出字符串值并尝试将其转换成long double 类型的浮点数，对这个浮点数进行加法计算，然后将得出的浮点数结果保存起来。 如果字符串值不能被转换成浮点数，那么向客户端返回一个错误。 取出字符串值并尝试将其转换成 longdouble 类型的浮点数，对这个浮点数进行加法计算，然后将得出的浮点数结果保存起来。如果字符串值不能被转换成浮点数，那么向客户端返回一个错误。 INCRBY 对整数值进行加法计算，得出的计算结果会作为整数被保存起来。 embstr 编码不能执行此命令，向客户端返回一个错误。 raw 编码不能执行此命令，向客户端返回一个错误。 DECRBY 对整数值进行减法计算，得出的计算结果会作为整数被保存起来。 embstr 编码不能执行此命令，向客户端返回一个错误。 raw 编码不能执行此命令，向客户端返回一个错误。 STRLEN 拷贝对象所保存的整数值，将这个拷贝转换成字符串值，计算并返回这个字符串值的长度。 调用 sdslen 函数，返回字符串的长度。 调用 sdslen 函数，返回字符串的长度。 SETRANGE 将对象转换成 raw 编码，然后按 raw 编码的方式执行此命令。 将对象转换成 raw 编码，然后按 raw 编码的方式执行此命令。 将字符串特定索引上的值设置为给定的字符。 GETRANGE 拷贝对象所保存的整数值，将这个拷贝转换成字符串值，然后取出并返回字符串指定索引上的字符。 直接取出并返回字符串指定索引上的字符。 直接取出并返回字符串指定索引上的字符。 7.3 列表对象列表对象的编码可以是 ziplist 或者 linkedlist。 ziplist 编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点（entry）保存了一个列表元素。 另一方面，linkedlist 编码的列表对象使用双端链表作为底层实现，每个双端链表节点（node）都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。 注意，linkedlist 编码的列表对象在底层的双端链表结构中包含了多个字符串对象，这种嵌套字符串对象的行为在稍后介绍的哈希对象、集合对象和有序集合对象中都会出现，字符串对象是 Redis 五种类型的对象中唯一一种会被其他四种类型对象嵌套的对象。 7.3.1 编码转换当列表对象可以同时满足以下两个条件时，列表对象使用 ziplist 编码： 列表对象保存的所有字符串元素的长度都小于 64 字节； 列表对象保存的元素数量小于 512 个； 不能满足这两个条件的列表对象需要使用 linkedlist 编码。 对于使用 ziplist 编码的列表对象来说，当使用 ziplist 编码所需的两个条件的任意一个不能被满足时，对象的编码转换操作就会被执行：原本保存在压缩列表里的所有列表元素都会被转移并保存到双端链表里面，对象的编码也会从 ziplist 变为 linkedlist。 7.3.2 列表命令的实现 命令 ziplist 编码的实现方法 linkedlist 编码的实现方法 LPUSH 调用 ziplistPush 函数，将新元素推入到压缩列表的表头。 调用 listAddNodeHead 函数，将新元素推入到双端链表的表头。 RPUSH 调用 ziplistPush 函数，将新元素推入到压缩列表的表尾。 调用 listAddNodeTail 函数，将新元素推入到双端链表的表尾。 LPOP 调用 ziplistIndex 函数定位压缩列表的表头节点，在向用户返回节点所保存的元素之后，调用 ziplistDelete 函数删除表头节点。 调用 listFirst 函数定位双端链表的表头节点，在向用户返回节点所保存的元素之后，调用 listDelNode 函数删除表头节点。 RPOP 调用 ziplistIndex 函数定位压缩列表的表尾节点，在向用户返回节点所保存的元素之后，调用 ziplistDelete 函数删除表尾节点。 调用 listLast 函数定位双端链表的表尾节点，在向用户返回节点所保存的元素之后，调用 listDelNode 函数删除表尾节点。 LINDEX 调用 ziplistIndex 函数定位压缩列表中的指定节点，然后返回节点所保存的元素。 调用 listIndex 函数定位双端链表中的指定节点，然后返回节点所保存的元素。 LLEN 调用 ziplistLen 函数返回压缩列表的长度。 调用 listLength 函数返回双端链表的长度。 LINSERT 插入新节点到压缩列表的表头或者表尾时，使用 ziplistPush 函数；插入新节点到压缩列表的其他位置时，使用 ziplistInsert 函数。 调用 listInsertNode 函数，将新节点插入到双端链表的指定位置。 LREM 遍历压缩列表节点，并调用 ziplistDelete 函数删除包含了给定元素的节点。 遍历双端链表节点，并调用 listDelNode 函数删除包含了给定元素的节点。 LTRIM 调用 ziplistDeleteRange 函数，删除压缩列表中所有不在指定索引范围内的节点。 遍历双端链表节点，并调用 listDelNode 函数删除链表中所有不在指定索引范围内的节点。 LSET 调用 ziplistDelete 函数，先删除压缩列表指定索引上的现有节点，然后调用 ziplistInsert 函数，将一个包含给定元素的新节点插入到相同索引上面。 调用 listIndex 函数，定位到双端链表指定索引上的节点，然后通过赋值操作更新节点的值。 7.4 哈希对象哈希对象的编码可以是 ziplist 或者 hashtable。 ziplist 编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾，因此： 保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后； 先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。 另一方面，hashtable 编码的哈希对象使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值对来保存： 字典的每个键都是一个字符串对象，对象中保存了键值对的键； 字典的每个值都是一个字符串对象，对象中保存了键值对的值。 7.4.1 编码转换当哈希对象可以同时满足以下两个条件时，哈希对象使用 ziplist 编码： 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节； 哈希对象保存的键值对数量小于 512 个； 不能满足这两个条件的哈希对象需要使用 hashtable 编码。 对于使用 ziplist 编码的列表对象来说，当使用 ziplist 编码所需的两个条件的任意一个不能被满足时，对象的编码转换操作就会被执行：原本保存在压缩列表里的所有键值对都会被转移并保存到字典里面，对象的编码也会从 ziplist 变为 hashtable。 7.4.2 哈希命令的实现 命令 ziplist 编码实现方法 hashtable 编码的实现方法 HSET 首先调用 ziplistPush 函数，将键推入到压缩列表的表尾，然后再次调用 ziplistPush 函数，将值推入到压缩列表的表尾。 调用 dictAdd 函数，将新节点添加到字典里面。 HGET 首先调用 ziplistFind 函数，在压缩列表中查找指定键所对应的节点，然后调用 ziplistNext 函数，将指针移动到键节点旁边的值节点，最后返回值节点。 调用 dictFind 函数，在字典中查找给定键，然后调用 dictGetVal 函数，返回该键所对应的值。 HEXISTS 调用 ziplistFind 函数，在压缩列表中查找指定键所对应的节点，如果找到的话说明键值对存在，没找到的话就说明键值对不存在。 调用 dictFind 函数，在字典中查找给定键，如果找到的话说明键值对存在，没找到的话就说明键值对不存在。 HDEL 调用 ziplistFind 函数，在压缩列表中查找指定键所对应的节点，然后将相应的键节点、以及键节点旁边的值节点都删除掉。 调用 dictDelete 函数，将指定键所对应的键值对从字典中删除掉。 HLEN 调用 ziplistLen 函数，取得压缩列表包含节点的总数量，将这个数量除以 2 ，得出的结果就是压缩列表保存的键值对的数量。 调用 dictSize 函数，返回字典包含的键值对数量，这个数量就是哈希对象包含的键值对数量。 HGETALL 遍历整个压缩列表，用 ziplistGet 函数返回所有键和值（都是节点）。 遍历整个字典，用 dictGetKey 函数返回字典的键，用 dictGetVal 函数返回字典的值。 7.5 集合对象集合对象的编码可以是 intset 或者 hashtable。 intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。 另一方面，hashtable 编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为 NULL。 7.5.1 编码的转换当集合对象可以同时满足以下两个条件时，对象使用 intset 编码： 集合对象保存的所有元素都是整数值； 集合对象保存的元素数量不超过 512 个； 不能满足这两个条件的集合对象需要使用 hashtable 编码。 对于使用 intset 编码的集合对象来说，当使用 intset 编码所需的两个条件的任意一个不能被满足时，对象的编码转换操作就会被执行：原本保存在整数集合中的所有元素都会被转移并保存到字典里面，并且对象的编码也会从 intset 变为 hashtable。 7.5.2 集合命令的实现 命令 intset 编码的实现方法 hashtable 编码的实现方法 SADD 调用 intsetAdd 函数，将所有新元素添加到整数集合里面。 调用 dictAdd ，以新元素为键，NULL 为值，将键值对添加到字典里面。 SCARD 调用 intsetLen 函数，返回整数集合所包含的元素数量，这个数量就是集合对象所包含的元素数量。 调用 dictSize 函数，返回字典所包含的键值对数量，这个数量就是集合对象所包含的元素数量。 SISMEMBER 调用 intsetFind 函数，在整数集合中查找给定的元素，如果找到了说明元素存在于集合，没找到则说明元素不存在于集合。 调用 dictFind 函数，在字典的键中查找给定的元素，如果找到了说明元素存在于集合，没找到则说明元素不存在于集合。 SMEMBERS 遍历整个整数集合，使用 intsetGet 函数返回集合元素。 遍历整个字典，使用 dictGetKey 函数返回字典的键作为集合元素。 SRANDMEMBER 调用 intsetRandom 函数，从整数集合中随机返回一个元素。 调用 dictGetRandomKey 函数，从字典中随机返回一个字典键。 SPOP 调用 intsetRandom 函数，从整数集合中随机取出一个元素，在将这个随机元素返回给客户端之后，调用 intsetRemove 函数，将随机元素从整数集合中删除掉。 调用 dictGetRandomKey 函数，从字典中随机取出一个字典键，在将这个随机字典键的值返回给客户端之后，调用 dictDelete 函数，从字典中删除随机字典键所对应的键值对。 SREM 调用 intsetRemove 函数，从整数集合中删除所有给定的元素。 调用 dictDelete 函数，从字典中删除所有键为给定元素的键值对。 7.6 有序集合对象有序集合的编码可以是 ziplist 或者 skiplist。 ziplist 编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。 压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾的方向。 skiplist 编码的有序集合对象使用 zset 结构作为底层实现，一个 zset 结构同时包含一个字典和一个跳跃表： 1234567typedef struct zset &#123; zskiplist *zsl; dict *dict;&#125; zset; zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的 object 属性保存了元素的成员，而跳跃表节点的 score 属性则保存了元素的分值。 通过这个跳跃表，程序可以对有序集合进行范围型操作，比如 ZRANK、ZRANGE 等命令就是基于跳跃表 API 来实现的。 除此之外，zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素：字典的键保存了元素的成员，而字典的值则保存了元素的分值。通过这个字典，程序可以用 $O(1)$ 复杂度查找给定成员的分值，ZSCORE 命令就是根据这一特性实现的，而很多其他有序集合命令都在实现的内部用到了这一特性。 有序集合每个元素的成员都是一个字符串对象，而每个元素的分值都是一个 double 类型的浮点数。值得一提的是，虽然 zset 结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来共享相同元素的成员和分值，所以同时使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值，也不会因此而浪费额外的内存。 7.6.1 编码的转换当有序集合对象可以同时满足以下两个条件时，对象使用 ziplist 编码： 有序集合保存的元素数量小于 128 个； 有序集合保存的所有元素成员的长度都小于 64 字节； 不能满足以上两个条件的有序集合对象将使用 skiplist 编码。 对于使用 ziplist 编码的有序集合对象来说，当使用 ziplist 编码所需的两个条件中的任意一个不能被满足时，程序就会执行编码转换操作，将原本储存在压缩列表里面的所有集合元素转移到 zset 结构里面，并将对象的编码从 ziplist 改为 skiplist。 7.6.2 有序集合命令的实现 命令 ziplist 编码的实现方法 zset 编码的实现方法 ZADD 调用 ziplistInsert 函数，将成员和分值作为两个节点分别插入到压缩列表。 先调用 zslInsert 函数，将新元素添加到跳跃表，然后调用 dictAdd 函数，将新元素关联到字典。 ZCARD 调用 ziplistLen 函数，获得压缩列表包含节点的数量，将这个数量除以 2 得出集合元素的数量。 访问跳跃表数据结构的 length 属性，直接返回集合元素的数量。 ZCOUNT 遍历压缩列表，统计分值在给定范围内的节点的数量。 遍历跳跃表，统计分值在给定范围内的节点的数量。 ZRANGE 从表头向表尾遍历压缩列表，返回给定索引范围内的所有元素。 从表头向表尾遍历跳跃表，返回给定索引范围内的所有元素。 ZREVRANGE 从表尾向表头遍历压缩列表，返回给定索引范围内的所有元素。 从表尾向表头遍历跳跃表，返回给定索引范围内的所有元素。 ZRANK 从表头向表尾遍历压缩列表， 查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员所对应元素的排名。 从表头向表尾遍历跳跃表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员所对应元素的排名。 ZREVRANK 从表尾向表头遍历压缩列表，查找给定的成员，沿途记录经过节点的数量， 当找到给定成员之后，途经节点的数量就是该成员所对应元素的排名。 从表尾向表头遍历跳跃表，查找给定的成员，沿途记录经过节点的数量，当找到给定成员之后，途经节点的数量就是该成员所对应元素的排名。 ZREM 遍历压缩列表，删除所有包含给定成员的节点，以及被删除成员节点旁边的分值节点。 遍历跳跃表，删除所有包含了给定成员的跳跃表节点。并在字典中解除被删除元素的成员和分值的关联。 ZSCORE 遍历压缩列表，查找包含了给定成员的节点，然后取出成员节点旁边的分值节点保存的元素分值。 直接从字典中取出给定成员的分值。 7.7 类型检查与命令多态7.7.1 类型检查的实现在执行一个类型特定的命令之前，Redis 会先检查输入键的类型是否正确，然后再决定是否执行给定的命令。 类型特定命令所进行的类型检查是通过 redisObject 结构的 type 属性来实现的： 在执行一个类型特定命令之前，服务器会先检查输入数据库键的值对象是否为执行命令所需的类型，如果是的话，服务器就对键执行指定的命令； 否则，服务器将拒绝执行命令，并向客户端返回一个类型错误。 7.7.2 多态命令的实现Redis 除了会根据值对象的类型来判断键是否能够执行指定命令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令。 现在，考虑这样一个情况，如果我们对一个键执行 LLEN 命令，那么服务器除了要确保执行命令的是列表键之外，还需要根据键的值对象所使用的编码来选择正确的 LLEN 命令实现： 如果列表对象的编码为 ziplist，那么说明列表对象的实现为压缩列表，程序将使用 ziplistLen 函数来返回列表的长度； 如果列表对象的编码为 linkedlist，那么说明列表对象的实现为双端链表，程序将使用 listLength 函数来返回双端链表的长度； 借用面向对象方面的术语来说，我们可以认为 LLEN 命令是多态（polymorphism)）的：只要执行 LLEN 命令的是列表键，那么无论值对象使用的是 ziplist 编码还是 linkedlist 编码，命令都可以正常执行。 DEL、EXPIRE 等命令和 LLEN 等命令的区别在于， 前者是基于类型的多态——一个命令可以同时用于处理多种不同类型的键， 而后者是基于编码的多态——一个命令可以同时用于处理多种不同编码。 7.8 内存回收Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。 每个对象的引用计数信息由 redisObject 结构的 refcount 属性记录。 对象的引用计数信息会随着对象的使用状态而不断变化： 在创建一个新对象时，引用计数的值会被初始化为 1 ； 当对象被一个新程序使用时，它的引用计数值会被增一； 当对象不再被一个程序使用时，它的引用计数值会被减一； 当对象的引用计数值变为 0 时，对象所占用的内存会被释放。 修改对象引用计数的 API： 函数 作用 incrRefCount 将对象的引用计数值增一。 decrRefCount 将对象的引用计数值减一， 当对象的引用计数值等于 0 时， 释放对象。 resetRefCount 将对象的引用计数值设置为 0， 但并不释放对象， 这个函数通常在需要重新设置对象的引用计数值时使用。 7.9 对象共享在 Redis 中，让多个键共享同一个值对象需要执行以下两个步骤： 将数据库键的值指针指向一个现有的值对象； 将被共享的值对象的引用计数增一。 目前来说，Redis 会在初始化服务器时，创建一万个字符串对象，这些对象包含了从 0 到 9999 的所有整数值， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。 另外，这些共享对象不单单只有字符串键可以使用，那些在数据结构中嵌套了字符串对象的对象（linkedlist 编码的列表对象、hashtable 编码的哈希对象、hashtable 编码的集合对象、以及 zset 编码的有序集合对象）都可以使用这些共享对象。 当服务器考虑将一个共享对象设置为键的值对象时，程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同，只有在共享对象和目标对象完全相同的情况下，程序才会将共享对象用作键的值对象，而一个共享对象保存的值越复杂，验证共享对象和目标对象是否相同所需的复杂度就会越高，消耗的 CPU 时间也会越多： 如果共享对象是保存整数值的字符串对象，那么验证操作的复杂度为 $O(1)$； 如果共享对象是保存字符串值的字符串对象，那么验证操作的复杂度为 $O(N)$； 如果共享对象是包含了多个值（或者对象的）对象，比如列表对象或者哈希对象，那么验证操作的复杂度将会是 $O(N^2)$。 因此，尽管共享更复杂的对象可以节约更多的内存，但受到 CPU 时间的限制，Redis 只对包含整数值的字符串对象进行共享。 7.10 对象的空转时长lru 属性记录了对象最后一次被命令程序访问的时间。 OBJECT IDLETIME 命令可以打印出给定键的空转时长，这一空转时长就是通过将当前时间减去键的值对象的 lru 时间计算得出的。OBJECT IDLETIME 命令的实现是特殊的，这个命令在访问键的值对象时，不会修改值对象的 lru 属性。 除了可以被 OBJECT IDLETIME 命令打印出来之外，键的空转时长还有另外一项作用：如果服务器打开了 maxmemory 选项，并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru，那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时，空转时长较高的那部分键会优先被服务器释放，从而回收内存。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot: 关于management配置]]></title>
    <url>%2F2017%2F09%2F08%2FSpring%20Boot%EF%BC%9A%E5%85%B3%E4%BA%8Emanagement%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[https://github.com/spring-projects/spring-boot/issues/10200]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring Cloud 微服务实战》：属性加载顺序]]></title>
    <url>%2F2017%2F08%2F30%2F%E3%80%8ASpring%20Cloud%20%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9A%E5%B1%9E%E6%80%A7%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[为了能够更合理的重写各属性的值，Spring Boot 使用了下面这种较为特别的属性加载顺序： 命令行中传入的参数。 SPRING_APPLICATION_JSON 中的属性，SPRING_APPLICATION_JSON 是以 JSON 格式配置在系统环境变量中的内容。 java：comp/env 中的 JNDI 属性。 java 的系统属性，可以通过 System.getProperties() 获取的内容操作系统的环境变量。 通过 random.* 配置的随机属性。 位于当前应用 jar 包之外，针对不同 {profile} 环境的配置文件内容。 位于当前应用 jar 包之内，针对不同 {profile} 环境的配置文件内容。 位于当前应用 jar 包之外的 application.properties 配置内容。 位于当前应用 jar 包之内的 application.properties 配置内容。 在 @Configuration 注解修改的类，通过 @PropertySource 注解定义的属性。 应用默认属性，使用 SpringApplication.setDefaultProperties 定义的内容。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Config: 基于服务发现的客户端启动过程]]></title>
    <url>%2F2017%2F08%2F13%2FSpring%20Cloud%20Config%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[当Config Server已注册到Spring Cloud Eureka上时，想从Config Server获取配置信息的Client可以通过从Eureka获得服务注册信息，动态发现Config Server实例。 1. Config Client配置 在application.properties中配置如下项： 12spring.application.name=demo-serverserver.port=10001 在bootstrap-test.properties中配置如下项： 12345spring.cloud.config.discovery.enabled=truespring.cloud.config.discovery.service-id=cloud-configspring.cloud.config.fail-fast=truespring.cloud.config.profile=testeureka.client.serviceUrl.defaultZone = http://localhost:9090/eureka/ 启动时设置spring.profile.active=test。 也可以用bootstrap.properties并采用default的profile。 Config Server运行在localhost:9086，eureka server运行在localhost:9090。Config server已以服务名cloud-config注册到eureka server。Config Server使用本地文件作为仓库。 2. Config Client处理流程： 构建bootstrap的context Spring Cloud Commons的说明： A Spring Cloud application operates by creating a “bootstrap” context, which is a parent context for the main application. Out of the box it is responsible for loading configuration properties from the external sources, and also decrypting properties in the local external configuration files. The two contexts share an Environment which is the source of external properties for any Spring application. Bootstrap properties are added with high precedence, so they cannot be overridden by local configuration, by default. 根据org.springframework.cloud.bootstrap.BootstrapApplicationListener的类说明： A listener that prepares a SpringApplication (e.g. populating its Environment) by delegating to {@link ApplicationContextInitializer} beans in a separate bootstrap context. The bootstrap context is a SpringApplication created from sources defined in spring.factories as {@link BootstrapConfiguration}, and initialized with external config taken from “bootstrap.properties” (or yml), instead of the normal “application.properties”. Spring Cloud会根据boostrap.properties及boostrap-{profile}.properties的配置构建单独的BootStrapContext。这个BootStrapContext是Main Application的父Context，其配置属性可以被子Context获取。 构建CompositePropertySource 根据Spring-Cloud-Commons的文档： “bootstrap”: an optional CompositePropertySource appears with high priority if any PropertySourceLocators are found in the Bootstrap context, and they have non-empty properties. An example would be properties from the Spring Cloud Config Server. See below for instructions on how to customize the contents of this property source. ​ “applicationConfig: [classpath:bootstrap.yml]” (and friends if Spring profiles are active). If you have a bootstrap.yml (or properties) then those properties are used to configure the Bootstrap context, and then they get added to the child context when its parent is set. They have lower precedence than the application.yml (or properties) and any other property sources that are added to the child as a normal part of the process of creating a Spring Boot application. See below for instructions on how to customize the contents of these property sources. 注意，Bootstrap获取到的远程配置具有高优先级，但bootstrap.properties里的配置项本身是低优先级。 在Spring Cloud Config项目中配置了ConfigServicePropertySourceLocator，在BootstrapContext构建阶段，它从bootstrap.properties中拿到eureka.client.serviceUrl.defaultZone，并访问eureka server，请求获取服务注册信息。在config client的console输出中可以看到： 123456789102017-09-07 15:59:53.704 INFO [bootstrap,,,] 77988 --- [ restartedMain] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via configuration2017-09-07 15:59:53.736 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Disable delta property : false2017-09-07 15:59:53.736 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Single vip registry refresh property : null2017-09-07 15:59:53.736 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Force full registry fetch : false2017-09-07 15:59:53.736 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Application is null : false2017-09-07 15:59:53.736 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Registered Applications size is zero : true2017-09-07 15:59:53.737 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Application version is -1: true2017-09-07 15:59:53.737 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Getting all instance registry info from the eureka server2017-09-07 15:59:53.964 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : The response status is 2002017-09-07 15:59:53.966 INFO [bootstrap,,,] 77988 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Not registering with Eureka server per configuration 与此对应的eureka server的log： 1234567891011122017-09-07 15:59:53.882 DEBUG [http-nio-9090-exec-6] org.apache.coyote.http11.Http11InputBuffer: Received [GET /eureka/apps/ HTTP/1.1Accept: application/jsonDiscoveryIdentity-Name: DefaultClientDiscoveryIdentity-Version: 1.4DiscoveryIdentity-Id: 10.236.19.51Accept-Encoding: gzipHost: localhost:9090Connection: Keep-AliveUser-Agent: Java-EurekaClient/v1.6.2] 可以看到Bootstrap阶段config client并不向eureka server注册自己，仅是获取服务列表，并从中查找config server。Bootstrap Context的工作到此结束。 从config server获取配置 config client日志： 123456789101112131415162017-09-07 16:00:08.855 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Could not find key &apos;spring.profiles.default&apos; in any property source2017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.retry.support.RetryTemplate : Retry: count=02017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Could not find key &apos;spring.application.name:application&apos; in any property source2017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Found key &apos;spring.application.name&apos; in [applicationConfig: [classpath:/application.properties]] with type [String]2017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Could not find key &apos;spring.cloud.config.name:demo-server&apos; in any property source2017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Could not find key &apos;spring.cloud.config.name&apos; in any property source2017-09-07 16:00:08.856 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.c.e.PropertySourcesPropertyResolver : Found key &apos;spring.cloud.config.profile&apos; in [applicationConfig: [classpath:/bootstrap-test.properties]] with type [String]2017-09-07 16:00:08.862 INFO [demo-server,,,] 77988 --- [restartedMain] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://localhost:9086/2017-09-07 16:00:08.862 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.web.client.RestTemplate : Created GET request for &quot;http://localhost:9086/demo-server/test&quot;2017-09-07 16:00:08.865 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.web.client.RestTemplate : Setting request Accept header to [application/json, application/*+json]2017-09-07 16:00:08.866 DEBUG [demo-server,,,] 77988 --- [restartedMain] s.n.www.protocol.http.HttpURLConnection : sun.net.www.MessageHeader@a83b1655 pairs: &#123;GET /demo-server/test HTTP/1.1: null&#125;&#123;Accept: application/json, application/*+json&#125;&#123;User-Agent: Java/1.8.0_91&#125;&#123;Host: localhost:9086&#125;&#123;Connection: keep-alive&#125;2017-09-07 16:00:08.997 DEBUG [demo-server,,,] 77988 --- [restartedMain] s.n.www.protocol.http.HttpURLConnection : sun.net.www.MessageHeader@231715a35 pairs: &#123;null: HTTP/1.1 200&#125;&#123;X-Application-Context: cloud-config:native:9086&#125;&#123;Content-Type: application/json;charset=UTF-8&#125;&#123;Transfer-Encoding: chunked&#125;&#123;Date: Thu, 07 Sep 2017 08:00:08 GMT&#125;2017-09-07 16:00:08.998 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.web.client.RestTemplate : GET request for &quot;http://localhost:9086/demo-server/test&quot; resulted in 200 (null)2017-09-07 16:00:08.998 DEBUG [demo-server,,,] 77988 --- [restartedMain] o.s.web.client.RestTemplate : Reading [class org.springframework.cloud.config.environment.Environment] as &quot;application/json;charset=UTF-8&quot; using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@7044a1c0]2017-09-07 16:00:08.999 INFO [demo-server,,,] 77988 --- [restartedMain] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=demo-server, profiles=[test], label=null, version=null, state=null2017-09-07 16:00:08.999 INFO [demo-server,,,] 77988 --- [restartedMain] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource [name=&apos;configService&apos;, propertySources=[MapPropertySource@1198162374 [name=&apos;classpath:native/demo-server-test.properties&apos;, properties=&#123;test-key=test-value&#125;]]] 此时已经到Main Application Context构建阶段，作为Bootstrap Context的子Context，它可以从application.properties，application-{profile}.properties，bootstrap.properties，bootstrap-{profile}.properties和System properties中查找访问config server所需的application name，label，profile等属性。 Moreover，config server可能配置了basic authentication。在这种情况下，config server需要在向eureka server注册的metadataMap中上传user和password参数，以供config client访问。这里的源码如下：org.springframework.cloud.config.client.DiscoveryClientConfigServiceBootstrapConfiguration 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@ConditionalOnProperty(value = "spring.cloud.config.discovery.enabled", matchIfMissing = false)@Configuration@Import(&#123; UtilAutoConfiguration.class &#125;)@EnableDiscoveryClientpublic class DiscoveryClientConfigServiceBootstrapConfiguration &#123; private static Log logger = LogFactory .getLog(DiscoveryClientConfigServiceBootstrapConfiguration.class); @Autowired private ConfigClientProperties config; @Autowired private DiscoveryClient client; private HeartbeatMonitor monitor = new HeartbeatMonitor(); @EventListener(ContextRefreshedEvent.class) public void startup(ContextRefreshedEvent event) &#123; refresh(); &#125; @EventListener(HeartbeatEvent.class) public void heartbeat(HeartbeatEvent event) &#123; if (monitor.update(event.getValue())) &#123; refresh(); &#125; &#125; private void refresh() &#123; try &#123; logger.debug("Locating configserver via discovery"); String serviceId = this.config.getDiscovery().getServiceId(); List&lt;ServiceInstance&gt; instances = this.client.getInstances(serviceId); if (instances.isEmpty()) &#123; logger.warn("No instances found of configserver (" + serviceId + ")"); return; &#125; ServiceInstance server = instances.get(0); String url = getHomePage(server); if (server.getMetadata().containsKey("password")) &#123; String user = server.getMetadata().get("user"); user = user == null ? "user" : user; this.config.setUsername(user); String password = server.getMetadata().get("password"); this.config.setPassword(password); &#125; if (server.getMetadata().containsKey("configPath")) &#123; String path = server.getMetadata().get("configPath"); if (url.endsWith("/") &amp;&amp; path.startsWith("/")) &#123; url = url.substring(0, url.length() - 1); &#125; url = url + path; &#125; this.config.setUri(url); &#125; catch (Exception ex) &#123; logger.warn("Could not locate configserver via discovery", ex); &#125; &#125; private String getHomePage(ServiceInstance server) &#123; return server.getUri().toString() + "/"; &#125;&#125; 向eureka server注册 client log： 1234567891011122017-09-07 15:59:53.882 DEBUG [http-nio-9090-exec-6] org.apache.coyote.http11.Http11InputBuffer: Received [GET /eureka/apps/ HTTP/1.1Accept: application/jsonDiscoveryIdentity-Name: DefaultClientDiscoveryIdentity-Version: 1.4DiscoveryIdentity-Id: 10.236.19.51Accept-Encoding: gzipHost: localhost:9090Connection: Keep-AliveUser-Agent: Java-EurekaClient/v1.6.2] eureka server log: 12345678910112017-09-07 16:00:13.111 DEBUG [http-nio-9090-exec-7] org.apache.coyote.http11.Http11InputBuffer: Received [PUT /eureka/apps/DEMO-SERVER/localhost:10001:demo-server?status=UP&amp;lastDirtyTimestamp=1504771208220 HTTP/1.1DiscoveryIdentity-Name: DefaultClientDiscoveryIdentity-Version: 1.4DiscoveryIdentity-Id: 10.236.19.51Accept-Encoding: gzipContent-Length: 0Host: localhost:9090Connection: Keep-AliveUser-Agent: Java-EurekaClient/v1.6.2] 这个过程甚至发生在config client向config server请求之后。 3. 一个脑洞假如我在config server的远程配置中配置另一个地址作为eureka.client.serviceUrl.defaultZone，config client获取到配置后会怎么办呢？ 仓库修改配置，重启config server。访问http://localhost:9086/demo-server-test.properties得到 1eureka.client.serviceUrl.defaultZone: http://localhost:9091/eureka/ 实际上eureka server仍然运行在localhost:9090。 启动Demo-server。正确地从eureka server拿到了服务注册信息，然后从config server更新了配置： 12017-09-07 17:06:26.782 INFO [demo-server,,,] 78952 --- [ restartedMain] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource [name=&apos;configService&apos;, propertySources=[MapPropertySource@1069590480 [name=&apos;classpath:native/demo-server-test.properties&apos;, properties=&#123;eureka.client.serviceUrl.defaultZone=http://localhost:9091/eureka/&#125;]]] 但此后无法注册到eureka server： 12342017-09-07 17:10:17.698 WARN [demo-server,,,] 78952 --- [tbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient : Request execution failed with message: java.net.ConnectException: Connection refused2017-09-07 17:10:17.698 ERROR [demo-server,,,] 78952 --- [tbeatExecutor-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_DEMO-SERVER/localhost:10001:demo-server - was unable to send heartbeat!com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server 其原因在于org.springframework.cloud.config.client.ConfigServicePropertySourceLocator注解了@Order(0)，会首先执行并更新配置，client注册eureka server时，会使用从config server拿到的更新后的地址。 4. 另一个脑洞如果我是在Demo-Server启动并连接上eureka server后再修改config server里配置的地址呢？ 这种情况下config server的仓库需要配置为git等外部仓库，push到仓库后以post访问demo-server的/refresh endpoint，则之后log里抛出无法连接的异常。 那么以这种方式，应该也同样可以动态配置其他参数。 有一点比较特殊，在这个例子中，修改的是eureka server的注册地址，且config client使用的是基于服务化的查找方式。那么即使我们此后revert掉git仓库的修改，并对demo-server发起refresh请求，由于demo-server无法连接到eureka-server，那么自然也就无法查找config server并获取更新后的配置了。若client是基于uri的形式配置的config server，则可以刷新配置。]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud Config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Config：整合 Spring Cloud Bus]]></title>
    <url>%2F2017%2F08%2F10%2FSpring%20Cloud%20Config%EF%BC%9A%E6%95%B4%E5%90%88%20Spring%20Cloud%20Bus%2F</url>
    <content type="text"><![CDATA[安装 kafka + ZooKeeper 1$ brew install kafka 启动 kafka 和 ZooKeeper 12$ zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties$ kafka-server-start /usr/local/etc/kafka/server.properties 监听 kafka 1$ kafka-console-consumer --zookeeper localhost:2181 创建 Spring Boot 项目 cloud-config 和 demo-server，添加 actuator 和 cloud-bus 依赖： build.gradle: 12compile(&apos;org.springframework.boot:spring-boot-starter-actuator&apos;)compile(&apos;org.springframework.cloud:spring-cloud-starter-bus-kafka&apos;) 以 spring.profile.active=native 启动 config server application.properties: 123456spring.application.name=cloud-configserver.port=9086spring.cloud.config.server.native.search-locations=classpath:native/spring.cloud.stream.kafka.binder.brokers=localhost:9092spring.cloud.stream.kafka.binder.zkNodes=localhost:2181 以 spring.profile.active=test 启动 demo-server bootstrap.properties: 123456spring.application.name=demo-serverserver.port=10001spring.cloud.config.uri=http://localhost:9086spring.cloud.stream.kafka.binder.brokers=localhost:9092spring.cloud.stream.kafka.binder.zkNodes=localhost:2181 发出刷新指令 1$ curl -d "" "localhost:9086/bus/refresh" 查看 kafka console 输出 1234567891011121314151617181920212223242526272829contentType "text/plain"originalContentType "application/json;charset=UTF-8"&#123;"type":"RefreshRemoteApplicationEvent","timestamp":1505074284683,"originService":"cloud-config:native:9086","destinationService":"**","id":"9b4dd274-43a6-4636-b1f3-74fbc7f00ca5"&#125;contentType "text/plain"originalContentType "application/json;charset=UTF-8"&#123;"type":"AckRemoteApplicationEvent","timestamp":1505074284745,"originService":"cloud-config:native:9086","destinationService":"**","id":"df8374db-d89e-43f2-b012-1ca9e58b785e","ackId":"9b4dd274-43a6-4636-b1f3-74fbc7f00ca5","ackDestinationService":"**","event":"org.springframework.cloud.bus.event.RefreshRemoteApplicationEvent"&#125;contentType "text/plain"originalContentType "application/json;charset=UTF-8"&#123;"type":"AckRemoteApplicationEvent","timestamp":1505074376165,"originService":"demo-server:test:10001","destinationService":"**","id":"490bd6ca-aa87-40d4-bb2b-6cd6c7b44b97","ackId":"9b4dd274-43a6-4636-b1f3-74fbc7f00ca5","ackDestinationService":"**","event":"org.springframework.cloud.bus.event.RefreshRemoteApplicationEvent"&#125; 自己往总线上发出的 Ack 消息自己也会收到，这一点可以通过 debug 模式的日志观察到。]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud Config</tag>
        <tag>Spring Cloud Bus</tag>
        <tag>kafka</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Eureka：配置项]]></title>
    <url>%2F2017%2F08%2F04%2FSpring%20Cloud%20Eureka%20%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[1. 服务端配置:org.springframework.cloud.netflix.eureka.server.EurekaServerConfigBean 配置参数 默认值 说明 eureka.server.enable-self-preservation false 关闭注册中心的保护机制，Eureka 会统计15分钟之内心跳失败的比例低于85%将会触发保护机制，不剔除服务提供者，如果关闭服务注册中心将不可用的实例正确剔除 2. 客户端实例相关配置org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean 配置参数 默认值 说明 eureka.instance.prefer-ip-address false 不使用主机名来定义注册中心的地址，而使用IP地址的形式，如果设置了eureka.instance.ip-address 属性，则使用该属性配置的IP，否则自动获取除环路IP外的第一个IP地址 eureka.instance.ip-address IP地址 eureka.instance.hostname 设置当前实例的主机名称 eureka.instance.appname 服务名，默认取 spring.application.name 配置值，如果没有则为 unknown eureka.instance.lease-renewal-interval-in-seconds 30 定义服务续约任务（心跳）的调用间隔，单位：秒 eureka.instance.lease-expiration-duration-in-seconds 90 定义服务失效的时间，单位：秒 eureka.instance.status-page-url-path /info 状态页面的URL，相对路径，默认使用HTTP访问，如果需要使用 HTTPS则需要使用绝对路径配置 eureka.instance.status-page-url 状态页面的URL，绝对路径 eureka.instance.health-check-url-path /health 健康检查页面的URL，相对路径，默认使用HTTP访问，如果需要使用HTTPS则需要使用绝对路径配置 eureka.instance.health-check-url 健康检查页面的URL，绝对路径 3. 客户端注册相关配置:org.springframework.cloud.netflix.eureka.EurekaClientConfigBean 配置参数 默认值 说明 eureka.client.service-url 指定服务注册中心地址，类型为 HashMap，并设置有一组默认值，默认的Key为 defaultZone；默认的Value为http://localhost:8761/eureka，如果服务注册中心为高可用集群时，多个注册中心地址以逗号分隔。如果服务注册中心加入了安全验证，这里配置的地址格式为：http://:@localhost:8761/eureka，其中&lt;username&gt;为安全校验的用户名；&lt;password&gt;为该用户的密码 eureka.client.fetch-registery true 检索服务 eureka.client.registery-fetch-interval-seconds 30 从Eureka服务器端获取注册信息的间隔时间，单位：秒 eureka.client.register-with-eureka true 启动服务注册 eureka.client.eureka-server-connect-timeout-seconds 5 连接Eureka Server的超时时间，单位：秒 eureka.client.eureka-server-read-timeout-seconds 8 读取 Eureka Server 信息的超时时间，单位：秒 eureka.client.filter-only-up-instances true 获取实例时是否过滤，只保留UP状态的实例 eureka.client.eureka-connection-idle-timeout-seconds 30 Eureka 服务端连接空闲关闭时间，单位：秒 eureka.client.eureka-server-total-connections 200 从Eureka 客户端到所有Eureka服务端的连接总数 eureka.client.eureka-server-total-connections-per-host 50 从Eureka客户端到每个Eureka服务主机的连接总数]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《分布式服务框架：原理与实践》：RPC demo]]></title>
    <url>%2F2017%2F07%2F20%2F%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%EF%BC%9A%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9ARPC%20demo%2F</url>
    <content type="text"><![CDATA[下面通过 Java 原生的序列化、Socket 通信、动态代理和反射机制，实现最简单 RPC 框架。它由三部分组成： 服务提供者：运行在服务端，负责提供服务接口定义和服务实现类 服务发布者：运行在 RPC 服务端，负责将本地服务发布成远程服务，供其他消费者调用 本地服务代理：运行在 RPC 客户端，通过代理调用远程服务提供者，然后将结果进行封装返回给本地消费者 代码如下： EchoService 123public interface EchoService &#123; String echo(String ping);&#125; EchoServiceImpl 123456public class EchoServiceImpl implements EchoService &#123; @Override public String echo(String ping) &#123; return ping + " --&gt; I am ok."; &#125;&#125; RpcExporter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class RpcExporter &#123; private static Executor executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); public static void exporter(String hostName, int port) throws Exception &#123; ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(new InetSocketAddress(hostName, port)); try &#123; while (true) &#123; executor.execute(new ExporterTask(serverSocket.accept())); &#125; &#125; finally &#123; serverSocket.close(); &#125; &#125; private static class ExporterTask implements Runnable &#123; Socket socket = null; public ExporterTask(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; try(ObjectInputStream inputStream = new ObjectInputStream(socket.getInputStream()); ObjectOutputStream outputStream = new ObjectOutputStream(socket.getOutputStream())) &#123; String interfaceName = inputStream.readUTF(); //硬编码形式指定接口实现 if(interfaceName.equals("EchoService")) &#123; interfaceName = "EchoServiceImpl"; &#125; Class&lt;?&gt; service = Class.forName(interfaceName); String methodName = inputStream.readUTF(); Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[])inputStream.readObject(); Method method = service.getMethod(methodName, parameterTypes); Object[] arguments = (Object[])inputStream.readObject(); Object result = method.invoke(service.newInstance(), arguments); outputStream.writeObject(result); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; finally &#123; if(socket != null) &#123; try &#123; socket.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; RpcExporter 的主要作用： 作为服务端，监听客户端的 TCP 连接，接收到新的客户端连接之后，将其封装成 Task，由线程池执行。 将客户端发送的码流反序列化成对象，反射调用服务实现者，获取执行结果。 将执行结果对象反序列化，通过 Socket 发送给客户端。 远程服务调用完成后，释放 Socket 等连接资源，防止句柄泄露。 RpcImporter 123456789101112131415161718192021222324252627282930313233public class RpcImporter&lt;S&gt; &#123; public S importer(final Class&lt;?&gt; serviceClass, final InetSocketAddress addr) &#123; return (S) Proxy.newProxyInstance( serviceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;serviceClass.getInterfaces()[0]&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Socket socket = null; ObjectInputStream inputStream = null; ObjectOutputStream outputStream = null; try &#123; socket = new Socket(); socket.connect(addr); outputStream = new ObjectOutputStream(socket.getOutputStream()); outputStream.writeUTF(serviceClass.getName()); outputStream.writeUTF(method.getName()); outputStream.writeObject(method.getParameterTypes()); outputStream.writeObject(args); inputStream = new ObjectInputStream(socket.getInputStream()); return inputStream.readObject(); &#125; catch (Exception e) &#123; e.printStackTrace(); return "error"; &#125; finally &#123; if(socket != null) socket.close(); if(inputStream != null) inputStream.close(); if(outputStream != null) outputStream.close(); &#125; &#125; &#125;); &#125;&#125; RpcImporter 的主要功能： 将本地的接口调用转化成 JDK 的动态代理，在动态代理中实现接口的远程调用。 创建 Socket 客户端，根据指定地址连接远程服务提供者。 将远程服务调用所需的接口类、方法名、参数列表等编码后发送给服务提供者。 同步阻塞等待服务端返回应答，获取应答之后返回数据。 Main 1234567891011121314151617181920212223public class Main &#123; private static final String host = "localhost"; private static final int port = 9300; public static void main(String[] args) throws Exception &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; RpcExporter.exporter(host, port); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); RpcImporter&lt;EchoService&gt; importer = new RpcImporter&lt;EchoService&gt;(); EchoService echoService = importer.importer( EchoService.class, new InetSocketAddress(host, port)); System.out.println(echoService.echo("Are you ok ?")); &#125;&#125; 运行结果 1Are you ok ? --&gt; I am ok. 存在的问题：RpcExporter 中为了 demo 的简便，使用了硬编码形式指定接口的实现类，实际项目中可以用 Spring IoC 的方式配置。]]></content>
      <categories>
        <category>RPC</category>
        <category>架构，读书笔记</category>
      </categories>
      <tags>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《分布式服务框架：原理与实践》：SOA 与微服务]]></title>
    <url>%2F2017%2F07%2F03%2F%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%EF%BC%9A%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9ASOA%20%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[1. SOA 服务化架构SOA 是一种粗粒度、松耦合的以服务为中心的架构，接口之间通过定义明确的协议和接口进行通信。SOA 帮助工程师站在一个新的高度理解企业级架构中各种组件的开发和部署形式，可以帮助企业系统架构以更迅速、可靠和可重用的形式规划整个业务系统。相比传统的非服务化架构，SOA 能够更加从容地应对复杂企业系统集成和需要的快速变化。 1.1 SOA 设计的原则SOA 面向服务的一般原则总结如下 服务可复用：不管是否存在即时复用的机会，服务均被设计为支持潜在的可复用 服务共享一个标准契约：为了与服务提供者交互，消费者需要导入服务提供者的服务契约，这个契约可以是一个 IDL 文件、Java 接口定义、WSDL 文件，甚至是个接口说明文档 服务是松耦合的：服务被设计为功能相对独立、尽量不依赖其他服务的独立功能提供者 服务是底层逻辑的抽象：只有经服务契约所暴露的服务对外部世界可见，契约之外底层的实现逻辑是不可见的 服务是可组合、可编排的：多个服务可能被编排组合成一个新的服务，这允许不同逻辑抽象的自由组合，促进服务的复用 服务是自治的：逻辑由服务所控制，并位于一个清晰的边界内，服务已经在边界内被控制，不依赖其他服务 服务是无状态的：服务应当不需要管理状态信息，因此能够维持送耦合性。服务应该被尽可能设计成无状态，即便这意味着要将状态管理移至他处 服务是可被自动发现的：服务发布上线后，允许被其他消费者自动发现；当服务提供者下线后，允许消费者接收服务下线通知。 1.2 服务治理SOA 服务化之后，应用服务化之后给系统运维带来很大挑战： 分布式框架下的服务调用性能 服务化架构如何支持线性扩展 如何实现高效、实时的服务多维度监控 大规模分布式环境下的故障快速定界和定位 分布式环境下海量日志在线检索、模糊查询 服务的流控、超时控制、服务升降级等管控手段 服务的划分原则，如何实现最大程度复用 …… 此时，SOA 服务治理是关键。SOA 服务治理主要包括如下几个方面： 服务定义：SOA 治理最基础的方面就是监视服务的创建过程。必须对服务进行标识，描述其功能，确定其行为范围并设计其接口。创建服务时需要与使用这些服务的团队进行协调，以确保服务能够满足消费者需求，避免重复工作。 服务生命周期管理：服务的生命周期通常有五个主要的阶段。 计划阶段 测试阶段 运行阶段 弃用阶段 废弃阶段 服务版本治理：新版本的前向兼容性，灰度发布等需要按照统一的策略进行管理。 服务注册中心：需要统一的服务注册中心支持服务的订阅发布和动态发现机制。 服务监控：服务监控中心需要对服务的调用时延、成功率、吞吐率等数据进行实时采样和汇总，通过图形化报表的形式展示，以便运维人员对服务的运行质量进行实时分析和掌控。 运行期服务质量保障：包括服务限流、服务迁入迁出、服务升降级、服务权重调整和服务超时控制等，通过运行期的动态治理，可以在不重启服务的前提下达到快速提升服务运行质量的目标。 2. 微服务架构微服务架构（MSA）是一种服务化架构风格，通过将功能分散到各个离散的服务中以实现对解决方案的解耦。 2.1 什么是微服务微服务架构的主要特征如下： 原子服务：单一职责，“高内聚，松耦合”。 高密度部署：重要的服务可以独立进程部署，非核心服务可以独立打包，合设到同一个进程中，服务被高密度部署。物理机部署，可在一台服务器上部署多个服务实例进程；如果是云端部署，则可以利用 LXC 实现容器级部署，以降低部署成本，提升资源利用率。 敏捷交付：真正的 DevOps。 微自治：服务足够小，功能单一，可以独立打包、部署、升级、回滚和弹性伸缩，不依赖其他服务，实现局部自治。 2.2 微服务架构对比 SOA两者的主要差异如下： 服务拆分粒度：SOA 首先要解决的是异构系统应用的服务化；微服务强调的是服务拆分尽可能小，最好是独立的原子服务。 服务依赖：传统的 SOA 服务，由于需要重用已有的资产，存在大量的服务间依赖；微服务的设计理念是服务自治、功能单一独立，避免依赖其他服务产生耦合，耦合会带来更高的复杂度。 服务规模：传统 SOA 服务粒度比较大，多数会采用将多个服务合并打成 war 包的方案，因此服务实例数比较有限；微服务强调尽可能拆分，同时很多服务会独立部署，这将导致服务规模急剧膨胀，对服务治理和运维带来新的挑战。 架构差异：微服务化之后，服务数量的激增会引起架构质量属性的变化，例如企业集成总线 ESB 逐渐被 P2P 的虚拟总线替代；为了保证高性能、低时延，需要高性能的分布式服务框架保证微服务架构的实施。 服务治理：传统基于 SOA Governance 的静态治理转型为服务运行态微治理、实时生效。 敏捷交付：服务由小研发团队负责微服务设计、开发、测试、部署、线上治理、灰度发布和下线，运维整个生命周期支撑，实现真正的 DevOps。 快速的故障定界定位手段：故障定界定位主要包括两方面的内容。 大规模分布式环境下海量业务/平台日志的采集、汇总和实时在线检索，支持多维度的条件检索、模糊查询，可以快速的在线查看各种系统运行日志，方便问题定位； 分布式消息跟踪，通过调用链打通业务、服务调用和异常，发现线上系统故障源；通过在线和离线调用链大数据分析，得到链路各个依赖的稳定性指标，梳理依赖链路风险表，识别系统核心功能的服务调用依赖关系，评估可能的最大风险点，针对性改进以预防风险，同时为容量规划和扩容提供数据决策依据。 服务安全：服务调用必须能够提供安全功能，对服务的访问进行权限控制，将服务的访问权限仅限于授权使用者。服务安全访问策略有多种，例如可以通过动态生成令牌（Token）的方式做安全访问授权，服务提供者动态生成 Token 并告知服务注册中心，由注册中心告知是否告知消费方，这样就能在注册中心页面上做复杂的授权模型。 总结：量变引起质变，这就是微服务架构和 SOA 服务化架构的最大差异。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>SOA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《微服务架构与实践》：微服务模型]]></title>
    <url>%2F2017%2F07%2F01%2F%E3%80%8A%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%EF%BC%9A%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[1. Martin Fowler 对微服务架构的定义 微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于 HTTP 的 RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。 2. 什么是微服务2.1 多微才够微可以有以下几个参考指标 代码行数 重写时间 团队合适 2.2 单一职责微服务架构中的每个服务，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。 2.3 轻量级通信对于微服务而言，通过使用语言无关、平台无关的轻量级通信机制，使服务于服务之间的协作变得更加标准化，也就意味着在保持服务外部通信机制轻量级的情况下，团队可以选择更适合的语言、工具或者平台来开发服务本身。 2.4 独立性在微服务架构中，每个服务都是一个独立的业务单元，当对某个服务进行改变时，对其他的服务不会产生影响。换句话说，服务与服务之间是独立的。 对于每个服务，都有独立的代码库。当对当前服务的代码进行修改后，并不会影响其他服务。从代码库的层面而言，服务与服务是隔离的。 对于每个服务，都有独立的测试机制，并不必担心破坏其他功能而需要建立大范围的回归测试。也就是说，从测试的角度而言，服务与服务之间是松耦合的。 2.5 进程隔离在微服务架构中，应用程序由多个服务组成，每个服务都是一个具有高度自治的独立业务实体。通常情况下，每个服务都能运行在一个独立的操作系统进程中，这就意味着不同的服务能非常容易地被部署到不同的主机上。 综上所述，微服务架构其实是将单一的应用程序划分为一组小的服务，每个服务都是具有业务属性的独立单元，同时能够被独立开发、独立运行、独立测试以及独立部署。 3. 微服务与 SOA对于微服务的概念而言，它是传统 SOA 的定义的一个子集；而对于其实现方式而言，它是一种更符合现代化互联网发展趋势的实践，是一种更容易帮助企业或组织有效并成功实施服务架构的实践。 4. 微服务的本质 服务作为组件 围绕业务组织团队 关注产品而非项目 技术多样性 业务数据独立 基础设施自动化 演进式架构]]></content>
      <categories>
        <category>读书笔记</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring 实战》：Spring MVC]]></title>
    <url>%2F2017%2F05%2F31%2F%E3%80%8ASpring%20%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9ASpring-MVC%2F</url>
    <content type="text"><![CDATA[1. 请求处理流程在请求离开浏览器时①，会带有用户所请求内容的信息，至少会包含请求的 URL。 请求旅程的第一站是 Spring 的 DispatcherServlet。Spring MVC 所有的请求都会通过一个前端控制器（front controller）Servlet。前端控制器是常用的 Web 应用程序模式，在这里一个单实例的 Servlet 将请求委托给应用程序的其他组件来执行实际的处理。在 Spring MVC 中，DispatcherServlet 就是前端控制器。 DispatcherServlet 的任务是将请求发送给 Spring MVC 控制器（controller）。控制器是一个用于处理请求的 Spring 组件。在典型的应用程序中可能会有多个控制器，DispatcherServlet 需要知道应该将请求发送给哪个控制器。所以DispatcherServlet 以会查询一个或多个处理器映射（handler mapping）②来确定请求的下一站在哪里。处理器映射会根据请求所携带的 URL 信息来进行决策。 一旦选择了合适的控制器，DispatcherServlet 会将请求发送给选中的控制器③。到了控制器，请求会卸下其负载（用户提交的信息）并耐心等待控制器处理这些信息。（实际上，设计良好的控制器本身只处理很少甚至不处理工作，而是将业务逻辑委托给一个或多个服务对象进行处理。） 控制器在完成逻辑处理后，通常会产生一些信息，这些信息需要返回给用户并在浏览器上显示。这些信息被称为模型（model）。不过仅仅给用户返回原始的信息是不够的——这些信息需要以用户友好的方式进行格式化，一般会是 HTML。所以，信息需要发送给一个视图（view），通常会是 JSP。 控制器所做的最后一件事就是将模型数据打包，并且标示出用于渲染输出的视图名。它接下来会将请求连同模型和视图名发送回 DispatcherServlet④。 这样，控制器就不会与特定的视图相耦合，传递给 DispatcherServlet 的视图名并不直接表示某个特定的 JSP。实际上，它甚至并不能确定视图就是 JSP。相反，它仅仅传递了一个逻辑名称，这个名字将会用来查找产生结果的真正视图。DispatcherServlet 将会使用视图解析器（view resolver）⑤来将逻辑视图名匹配为一个特定的视图实现，它可能是也可能不是 JSP。 既然 DispatcherServlet 已经知道由哪个视图渲染结果，那请求的任务基本上也就完成了。它的最后一站是视图的实现（可能是 JSP）⑥，在这里它交付模型数据。请求的任务就完成了。视图将使用模型数据渲染输出，这个输出会通过响应对象传递给客户端。 2. 基于 Java 类配置的 DispatcherServlet123456789101112131415161718192021import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;public class MyWebAppInitializer extends AbstractAnnotationConfigDispactcherServletInitializer&#123; @Override protected String[] getServletMappings() // 将DispatcherServlet映射到“/” &#123; return new String[] &#123;"/"&#125;; &#125; @Override protected class&lt;?&gt;[] getRootConfigClasses() &#123; return new class&lt;?&gt;[] &#123;RootConfig.class&#125;; &#125; @Override protected class&lt;?&gt;[] getServletConfigClasses() // 指定配置类 &#123; return new class&lt;?&gt;[] &#123;WebConfig.class&#125;; &#125;&#125; 扩展 AbstractAnnotationConfigDispatcherServletInitializer 的任意类都会自动地配置 DispatcherServlet 和 Spring 应用上下文，Spring 的应用上下文会位于应用程序的 Servlet 上下文之中。 在 Servlet 3.0 环境中，容器会在类路径中查找实现 javax.servlet.ServletContainerInitializer 接口的类，如果能发现的话，就会用它来配置 Servlet 容器。 Spring 提供了这个接口的实现，名为 SpringServletContainerInitializer，这个类反过来又会查找实现 WebApplicationInitializer 的类并将配置的任务交给它们来完成。Spring 3.2 引入了一个便利的 WebApplicationInitializer 基础实现，也就是 AbstractAnnotationConfigDispatcherServletInitializer。因为我们的 Spittr-WebAppInitializer 扩展了 AbstractAnnotationConfigDispatcherServletInitializer（同时也就实现了 WebApplicationInitializer），因此当部署到 Servlet 3.0 容器中的时候，容器会自动发现它，并用它来配置 Servlet 上下文。 在上述程序中，SpittrWebAppInitializer 重写了三个方法：第一个方法 getServletMappings()，它会将一个或多个路径映射到 DispatcherServlet 上。在本例中，它映射的是“/”，这表示它会是应用的默认 Servlet。它会处理进入应用的所有请求。 AbstractAnnotationConfigDispatcherServletInitializer 会同时创建 DispatcherServlet 和 ContextLoaderListener。GetServletConfigClasses() 方法返回的带有 @Configuration 注解的类将会用来定义 DispatcherServlet 应用上下文中的 bean。getRootConfigClasses() 方法返回的带有 @Configuration 注解的类将会用来配置 ContextLoaderListener 创建的应用上下文中的 bean。 3. ViewResolverSpring 自带了 12 个视图解析器，能够将逻辑视图名转换为物理实现。 视图解析器 描述 BeanNameViewResolver 将视图解析为 Spring 应用上下文中的 bean，其中 bean 的 ID 与视图的名字相同 ContentNegotiatingViewResolver 通过考虑客户端需要的内容类型来解析视图，委托给另外一个能够产生对应内容类型的视图解析器 FreeMarkerViewResolver 将视图解析为 FreeMarker 模板 InternalResourceViewResolver 将视图解析为 Web 应用的内部资源（一般为 JSP） JasperReportsViewResolver 将视图解析为 JasperReports 定义 ResourceBundleViewResolver 将视图解析为资源 bundle（一般为属性文件） TilesViewResolver 将视图解析为 Apache Tile 定义，其中 tile ID 与视图名称相同。注意有两个不同的 TilesViewResolver 实现，分别对应于 Tiles 2.0 和 Tiles 3.0 UrlBasedViewResolver 直接根据视图的名称解析视图，视图的名称会匹配一个物理视图的定义 VelocityLayoutViewResolver 将视图解析为 Velocity 布局，从不同的 Velocity 模板中组合页面 VelocityViewResolver 将视图解析为 Velocity 模板 XmlViewResolver 将视图解析为特定 XML 文件中的 bean 定义。类似于 BeanNameViewResolver XsltViewResolver 将视图解析为 XSLT 转换后的结果 4. HTTPMessageConverter消息转换（message conversion）它能够将控制器产生的数据转换为服务于客户端的表述形式。Spring 提供了多个 HTTP 信息转换器，用于实现资源表述与各种 Java 类型之间的互相转换。 信息转换器 描述 AtomFeedHttpMessageConverter Rome Feed 对象和 Atom feed（媒体类型 application/atom+xml）之间的互相转换。如果 Rome 包在类路径下将会进行注册 BufferedImageHttpMessageConverter BufferedImages 与图片二进制数据之间互相转换 ByteArrayHttpMessageConverter 读取/写入字节数组。从所有媒体类型(*/*)中读取，并以 application/octet-stream 格式写入 FormHttpMessageConverter 将 application/x-www-form-urlencoded 内容读入到 MultiValueMap&lt;String,String&gt; 中，也会将 MultiValueMap&lt;String,String&gt; 写入到 application/x-www-form-urlencoded 中或将 MultiValueMap&lt;String,Object&gt; 写入到 multipart/form-data 中 Jaxb2RootElementHttpMessageConverter 在 XML（ text/xml 或 application/xml）和使用 JAXB2 注解的对象间互相读取和写入。如果 JAXB v2 库在类路径下，将进行注册 MappingJackson2HttpMessageConverter 在 JSON 和类型化的对象或非类型化的 HashMap 间互相读取和写入。如果 Jackson 2 JSON 库字类路径下，将进行注册 MarshallingHttpMessageConverter 使用注入的编排器和解排器（marshaller 和 unmarshaller）来读取和写入 XML。支持的编排器和解排器包括 Castor、JAXB2、JIBX、XMLBeans 以及 Xstream ResourceHttpMessageConverter 读取或写入 Resource RssChannelHttpMessageConverter 在 RSS feed 和 Rome Channel 对象间互相读取或写入。如果 Rome 库在类路径下，将进行注册 SourceHttpMessageConverter 在 XML 和 javax.xml.transform.Source 对象间互相读取和写入。默认注册 StringHttpMessageConverter 将所有媒体类型(*/*)读取为 String。将 String 写入为 text/plain XmlAwareFormHttpMessageConverter FormHttpMessageConverter 的扩展，使用 SourceHttpMessageConverter 来支持基于 XML 的部分 表中的 HTTP 信息转换器除了其中的五个以外都是自动注册的，所以要使用它们的话，不需要 Spring 配置。但是为了支持它们，需要添加一些库到应用程序的类路径下。 5. 异常Spring 的一些异常会默认映射为 HTTP 状态码。 Spring 异常 HTTP 状态码 BindException 400 - Bad Request ConversionNotSupportedException 500 - Internal Server Error HttpMediaTypeNotAcceptableExceptio 406 - Not Acceptable HttpMediaTypeNotSupportedException 415 - Unsupported Media Type HttpMessageNotReadableException 400 - Bad Request MissingServletRequestParameterException 400 - Bad Request MissingServletRequestPartException 400 - Bad Requestn NoSuchRequestHandlingMethodExceptio 404 - Not Found TypeMismatchException 400 - Bad Request HttpMessageNotWritableException 500 - Internal Server Error HttpRequestMethodNotSupportedException 405 - Method Not Allowed 异常一般会由 Spring 自身抛出，作为 DispatcherServlet 处理过程中或执行校验时出现问题的结果。 Spring 提供了一种机制，能够通过 @ResponseStatus 注解将异常映射为 HTTP 状态码。（作用于自定义异常类上）]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring Boot 实战》: @Enable* 注解的工作原理]]></title>
    <url>%2F2017%2F05%2F19%2F%E3%80%8ASpring%20Boot%20%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9A%40Enable*%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[通过观察 @Enable* 注解的源码，可以发现所有的注解都有一个 @Import 注解。 @Import 注解是用来导入配置类的，这也就是说这些自动开启的实现其实是导入了一些自动配置的 Bean。 @Import 注解导入配置方式的三种类型1. 直接导入配置类123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;SchedulingConfiguration.class&#125;)@Documentedpublic @interface EnableScheduling &#123;&#125; 直接导入配置类 SchedulingConfiguration，这个类注解了 @Configuration，且注册了一个 scheduledAnnotationProcessor 的 Bean。 2. 依据条件选择配置类1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123; Class&lt;? extends Annotation&gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; AsyncConfigurationSelector 通过条件来选择需要导入的配置类，AsyncConfigurationSelector 的根接口为 ImportSelector，这个接口需要重写 selectImports 方法，在此方法内进行事先条件判断。若 adviceMode 为 PORXY，则返回 ProxyAsyncConfiguration 这个配置类；若 activeMode 为 ASPECTJ，则返回 AspectJAsyncConfiguration 配置类，源码如下： 12345678910111213141516171819202122public class AsyncConfigurationSelector extends AdviceModeImportSelector&lt;EnableAsync&gt; &#123; private static final String ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME = "org.springframework.scheduling.aspectj.AspectJAsyncConfiguration"; /** * &#123;@inheritDoc&#125; * @return &#123;@link ProxyAsyncConfiguration&#125; or &#123;@code AspectJAsyncConfiguration&#125; for * &#123;@code PROXY&#125; and &#123;@code ASPECTJ&#125; values of &#123;@link EnableAsync#mode()&#125;, respectively */ @Override public String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123; ProxyAsyncConfiguration.class.getName() &#125;; case ASPECTJ: return new String[] &#123; ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME &#125;; default: return null; &#125; &#125;&#125; 3. 动态注册 Bean1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; boolean proxyTargetClass() default false;&#125; AspectJAutoProxyRegistrar 实现了 ImportBeanDefinitionRegistrar 接口，ImportBeanDefinitionRegistrar 的作用是在运行时自动添加 Bean 到已有的配置类，通过重写方法： 1public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) 其中，AnnotationMetadata 参数用来获得当前配置类上的注解；BeanDefinittionRegistry 参数用来注册 Bean。源码如下： 1234567891011121314151617181920class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * Register, escalate, and configure the AspectJ auto proxy creator based on the value * of the @&#123;@link EnableAspectJAutoProxy#proxyTargetClass()&#125; attribute on the importing * &#123;@code @Configuration&#125; class. */ @Override public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAJAutoProxy.getBoolean("proxyTargetClass")) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; &#125;&#125;]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring Boot 实战》: Spring Boot 自动配置原理]]></title>
    <url>%2F2017%2F05%2F11%2F%E3%80%8ASpring%20Boot%20%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9ASpring%20Boot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[SpringBoot 框架可用于创建可执行的 Spring 应用程序，采用了习惯优于配置的方法。其中奥秘在于 @EnableAutoConfiguration 注释，此注释自动载入应用程序所需的所有 Bean——这依赖于 SpringBoot 在类路径中的查找。 1. @SpringBootApplication首先来看 @SpringBootApplication 注解: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package org.springframework.boot.autoconfigure;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.boot.SpringBootConfiguration;import org.springframework.boot.context.TypeExcludeFilter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;import org.springframework.core.annotation.AliasFor;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ @AliasFor(annotation = EnableAutoConfiguration.class, attribute = "exclude") Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ @AliasFor(annotation = EnableAutoConfiguration.class, attribute = "excludeName") String[] excludeName() default &#123;&#125;; /** * Base packages to scan for annotated components. Use &#123;@link #scanBasePackageClasses&#125; * for a type-safe alternative to String-based package names. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = "basePackages") String[] scanBasePackages() default &#123;&#125;; /** * Type-safe alternative to &#123;@link #scanBasePackages&#125; for specifying the packages to * scan for annotated components. The package of each class specified will be scanned. * &lt;p&gt; * Consider creating a special no-op marker class or interface in each package that * serves no purpose other than being referenced by this attribute. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = "basePackageClasses") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 该注解上存在元注解@EnableAutoConfiguration，这就是 Spring Boot 自动配置实现的核心入口，其定义为： 1234567891011121314151617181920212223242526@SuppressWarnings("deprecation")@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; 可见通过@Import注解，引入了EnableAutoConfigurationImportSelector。 2. @EnableAutoConfigurationImportSelector1234567891011121314public class EnableAutoConfigurationImportSelector extends AutoConfigurationImportSelector &#123; @Override protected boolean isEnabled(AnnotationMetadata metadata) &#123; if (getClass().equals(EnableAutoConfigurationImportSelector.class)) &#123; return getEnvironment().getProperty( EnableAutoConfiguration.ENABLED_OVERRIDE_PROPERTY, Boolean.class, true); &#125; return true; &#125;&#125; 父类 AutoConfigurationImportSelector 的 selectImports 方法如下： 12345678910111213141516171819202122232425262728public String[] selectImports(AnnotationMetadata metadata) &#123; try &#123; AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata .getAnnotationAttributes(EnableAutoConfiguration.class.getName(), true)); Assert.notNull(attributes, "No auto-configuration attributes found. Is " + metadata.getClassName() + " annotated with @EnableAutoConfiguration?"); // Find all possible auto configuration classes, filtering duplicates List&lt;String&gt; factories = new ArrayList&lt;String&gt;(new LinkedHashSet&lt;String&gt;( SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader))); // Remove those specifically disabled factories.removeAll(Arrays.asList(attributes.getStringArray("exclude"))); // Sort factories = new AutoConfigurationSorter(this.resourceLoader) .getInPriorityOrder(factories); return factories.toArray(new String[factories.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; &#125; 该方法使用了 Spring Core 包的 SpringFactoriesLoader 类的 loadFactoryNamesof() 方法，查询 META-INF/spring.factories 文件下以 EnableAutoConfiguration 的全限定名（org.springframework.boot.autoconfigure.EnableAutoConfiguration）为 key 的对应值，其结果为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\ org.springframework.boot.autoconfigure.MessageSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.PropertyPlaceholderAutoConfiguration,\ org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\ org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\ org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\ org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\ org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\ org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\ org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\ org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\ org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\ org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\ org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\ org.springframework.boot.autoconfigure.jms.hornetq.HornetQAutoConfiguration,\ org.springframework.boot.autoconfigure.jta.JtaAutoConfiguration,\ org.springframework.boot.autoconfigure.elasticsearch.ElasticsearchAutoConfiguration,\ org.springframework.boot.autoconfigure.elasticsearch.ElasticsearchDataAutoConfiguration,\ org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\ org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\ org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\ org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\ org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\ org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\ org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\ org.springframework.boot.autoconfigure.mongo.MongoDataAutoConfiguration,\ org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\ org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\ org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\ org.springframework.boot.autoconfigure.redis.RedisAutoConfiguration,\ org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\ org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\ org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\ org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\ org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\ org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\ org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\ org.springframework.boot.autoconfigure.velocity.VelocityAutoConfiguration,\ org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\ org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\ org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\ org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.web.GzipFilterAutoConfiguration,\ org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\ org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\ org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\ org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\ org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\ org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration 在这个文件中，可以看到一系列 Spring Boot 自动配置的列表。 3. MongoAutoConfiguration以 MongoAutoConfiguration 为例： 12345678910111213141516171819202122232425@Configuration@ConditionalOnClass(Mongo.class)@EnableConfigurationProperties(MongoProperties.class)public class MongoAutoConfiguration &#123; @Autowired private MongoProperties properties; private Mongo mongo; @PreDestroy public void close() throws UnknownHostException &#123; if (this.mongo != null) &#123; this.mongo.close(); &#125; &#125; @Bean @ConditionalOnMissingBean public Mongo mongo() throws UnknownHostException &#123; this.mongo = this.properties.createMongoClient(); return this.mongo; &#125;&#125; 这个类进行了简单的 Spring 配置，声明了 MongoDB 所需典型 Bean，并且和其他很多自动配置类一样，重度依赖于 Spring Boot 的注解（@Condition*）。 4. 调试以 DEBUG 级 log 启动 Springboot 项目，Spring Boot 会产生一个报告，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243Positive matches:----------------- MessageSourceAutoConfiguration - @ConditionalOnMissingBean (types: org.springframework.context.MessageSource; SearchStrategy: all) found no beans (OnBeanCondition) JmxAutoConfiguration - @ConditionalOnClass classes found: org.springframework.jmx.export.MBeanExporter (OnClassCondition) - SpEL expression on org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration: $&#123;spring.jmx.enabled:true&#125; (OnExpressionCondition) - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: all) found no beans (OnBeanCondition) DispatcherServletAutoConfiguration - found web application StandardServletEnvironment (OnWebApplicationCondition) - @ConditionalOnClass classes found: org.springframework.web.servlet.DispatcherServlet (OnClassCondition)Negative matches:----------------- DataSourceAutoConfiguration - required @ConditionalOnClass classes not found: org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType (OnClassCondition) DataSourceTransactionManagerAutoConfiguration - required @ConditionalOnClass classes not found: org.springframework.jdbc.core.JdbcTemplate,org.springframework.transaction.PlatformTransactionManager (OnClassCondition) MongoAutoConfiguration - required @ConditionalOnClass classes not found: com.mongodb.Mongo (OnClassCondition) FallbackWebSecurityAutoConfiguration - SpEL expression on org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration: !$&#123;security.basic.enabled:true&#125; (OnExpressionCondition) SecurityAutoConfiguration - required @ConditionalOnClass classes not found: org.springframework.security.authentication.AuthenticationManager (OnClassCondition) EmbeddedServletContainerAutoConfiguration.EmbeddedJetty - required @ConditionalOnClass classes not found: org.eclipse.jetty.server.Server,org.eclipse.jetty.util.Loader (OnClassCondition) WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#localeResolver - @ConditionalOnMissingBean (types: org.springframework.web.servlet.LocaleResolver; SearchStrategy: all) found no beans (OnBeanCondition) - SpEL expression: '$&#123;spring.mvc.locale:&#125;' != '' (OnExpressionCondition) WebSocketAutoConfiguration - required @ConditionalOnClass classes not found: org.springframework.web.socket.WebSocketHandler,org.apache.tomcat.websocket.server.WsSci (OnClassCondition) 对于每个自动配置，可以看到它启动或失败的原因。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring Boot 实战》: Spring EL 和资源调用]]></title>
    <url>%2F2017%2F05%2F04%2F%E3%80%8ASpring%20Boot%20%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9ASpring%20EL%E5%92%8C%E8%B5%84%E6%BA%90%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Spring EL 也就是 Spring 表达式语言，支持在 xml 和注解中使用表达式，类似于 JSP 的 EL 表达式语言。 Spring 开发中我们可能经常涉及到调用各种资源的情况，包含普通文件、网址、配置文件、系统环境变量等，我们可以使用 Spring 的表达式语言实现资源的注入。 因为需要将 file 转换成字符串，我们增加 commons-io 可以简化文件的相关操作。build.gradle 中增加 1compile group: 'commons-io', name: 'commons-io', version: '2.5' resource 目录下新建 test.txt，内容随意。 resource 目录下新建新建 test.properties 文件，内容如下： 1project.name=SpringEL 需要被注入的 bean 12345678910111213141516package com.springel;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;@Servicepublic class DemoService &#123; @Value("DemoService类的属性")//注入字符串 private String another; public String getAnother() &#123; return another; &#125; public void setAnother(String another) &#123; this.another = another; &#125;&#125; 配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.springel;import org.apache.commons.io.IOUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.env.Environment;import org.springframework.core.io.Resource;import java.io.IOException;@Configuration@ComponentScan("com.springel")@PropertySource("classpath:test.properties")public class ElConfig &#123; @Value("I LOVE YOU!")//注入字符串 private String normal; @Value("#&#123;systemProperties['os.name']&#125;")//获取操作系统名 private String osName; @Value("#&#123; T(java.lang.Math).random() * 100.0 &#125;")//注入表达式结果 private double randomNumber; @Value("#&#123;demoService.another&#125;")//注入其他Bean的属性 private String fromAnother; @Value("$&#123;project.name&#125;")//注入配置文件 private String projectName; @Value("classpath:cn/hncu/p2_2_2SpringEL/test.txt") private Resource testFile;//注意这个Resource是:org.springframework.core.io.Resource; @Autowired //注入配置文件 private Environment environment; @Value("http://www.baidu.com")//注入网址资源 private Resource testUrl; @Bean //注入配置文件 public static PropertySourcesPlaceholderConfigurer propertyConfigurer()&#123; return new PropertySourcesPlaceholderConfigurer(); &#125; public void outputResource()&#123; try &#123; System.out.println("normal:"+normal); System.out.println("osName:"+osName); System.out.println("randomNumber:"+randomNumber); System.out.println("fromAnother:"+fromAnother); System.out.println("projectName:"+projectName); System.out.println("测试文件:"+IOUtils.toString(testFile.getInputStream())); System.out.println("配置文件project.author:"+environment.getProperty("project.author")); System.out.println("网址资源:"+IOUtils.toString(testUrl.getInputStream())); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注入配置配件需要使用 @PropertySource 指定文件地址，若使用 @Value 注入，则要配置一个 PropertySourcesPlaceholderConfigurer 的 Bean。 注意，@Value(&quot;${project.name}&quot;) 使用的是 “$” 而不是 “#”。 运行类 12345678910111213package com.springel;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class Main &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ElConfig.class); ElConfig resourceService = context.getBean(ElConfig.class); resourceService.outputResource(); context.close(); &#125;&#125;]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入分析 Java Web 技术内幕》：JVM 内存管理]]></title>
    <url>%2F2017%2F04%2F28%2F%E3%80%8A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%20Java%20Web%20%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B%EF%BC%9AJVM%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. JVM 内存结构在 Java 虚拟机规范中将 Java 运行时数据划分为 6 种，分别为： PC 寄存器数据； Java 栈； 堆； 方法区； 本地方法区； 运行时常量池。 1.1 Java 栈Java 栈总是和线程关联在一起，每当创建一个线程时，JVM 就会为这个线程创建一个对应的 Java 栈，在这个 Java 栈中又会含有多个栈帧（Frames），这些栈帧是与每个方法关联起来的，每运行一个方法就创建一个栈帧，每个栈帧会含有一些内部变量（在方法内定义的变量）、操作栈和方法返回值等信息。 每当一个方法执行完成时，这个栈帧就会弹出栈帧的元素作为这个方法的返回值，并清除这个栈帧，Java 栈的栈顶的栈帧就是当前正在执行的活动栈，也就是当前正在执行的方法，PC 寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作栈使用，当在这个栈帧中调用另外一个方法时，与之对应的一个新的栈帧又被创建，这个新创建的栈帧又被放到 Java 栈的顶部，变为当前的活动栈帧。同样现在只有这个栈帧的本地变量才能被使用，当在这个栈帧中所有指令执行完成时这个栈帧移出 Java 栈，刚才的那个栈帧又变为活动栈帧，前面的栈帧的返回值又变为这个栈帧的操作栈中的一个操作数。如果前面的栈帧没有返回值，那么当前的栈帧的操作栈的操作数没有变化。 由于 Java 栈是与 Java 线程对应起来的，这个数据不是线程共享的，所以我们不用关心它的数据一致性问题，也不会存在同步锁的问题。 1.2 方法区JVM 方法区是用于存储类结构信息的地方，class 文件会被 JVM 解析成几个部分，这些不同的部分在这个 class 被加载到 JVM 时，会被存储在不同的数据结构中，其中的常量池、域、方法数据、方法体、构造函数，包括类中的专用方法、实例初始化、接口初始化都存储在这个区域。 方法区这个存储区域也属于后面介绍的 Java 堆中的一部分，也就是我们通常所说的 Java 堆中的永久区。这个区域可以被所有的线程共享，并且它的大小可以通过参数来设置。 这个方法区存储区域的大小一般在程序启动后的一段时间内就是固定的了，JVM 运行一段时间后，需要加载的类通常都已经加载到 JVM 中了。但是有一种情况是需要注意的，那就是在项目中如果存在对类的动态编译，而且是同样一个类的多次编译，那么需要观察方法区的大小是否能满足类存储。 1.3 运行时常量池在 JVM 规范中是这样定义运行时常量池这个数据结构的：Runtime Constant Pool 代表运行时每个 class 文件中的常量表。它包括几种常量：编译期的数字常量、方法或者域的引用（在运行时解析）。Runtime Constant Pool 的功能类似于传统编程语言的符号表，尽管它包含的数据比典型的符号表要丰富得多。每个Runtime Constant pool 都是在 JVM 的 Method area 中分配的，每个 Class 或者 Interface 的 Constant Pool 都是在 JVM 创建 class 或接口时创建的。 运行时常量池是方法区的一部分，所以它的存储也受方法区的规范约束，如果常量池无法分配，同样会 抛出 OutOfMemoryError。 1.4 本地方法栈本地方法栈是为 JVM 运行 Native 方法准备的空间，它和前面介绍的 Java 栈的作用是类似的，由于很多 Native 方法都是用 C 语言实现的，所以它通常又叫 C 栈，除了在我们的代码中包含的常规的 Native 方法会使用这个存储空间，在 JVM 利用 JIT 技术时会将一些 Java 方法重新编译为 Native Code 代码，这些编译后的本地代码通常也是利用这个栈来跟踪方法的执行状态的。 2. 垃圾回收2.1 如何检测垃圾只要是某个对象不再被其他活动对象引用，那么这个对象就可以被回收了。这里的活动对象指的是能够被一个根对象集合到达的对象。根对象集合大都会包含如下一些元素： 在方法中局部变量区的元素的引用； 在 Java 操作栈中的对象的引用； 在常量池中的对象引用； 在本地方法中持有的对象的引用； 类的 Class 对象。 2.2 基于分代的垃圾回收算法该算法的设计思路是：把对象按照寿命长短来分组，分为年轻代和年老代，新创建的对象被分在年轻代，如果对象经过几次回收后仍然存活，那么再把这个对象划分到年老代。年老代的收集频度不像年轻代那么频繁，这样就减少了每次垃圾收集时所要扫描的对象的数量，从而提高了垃圾回收效率。 这种设计的思路是把堆划分成若干个子堆，每个子堆对应一个年龄代。 JVM 将整个堆划分为 Young 区、Old 区和 Perm 区，分别存放不同年龄的对象，这三个区存放的对象有如下区别。 Young 区又分为 Eden 区和两个 Survivor 区，其中所有新创建的对象都在 Eden 区，当 Eden 区满后会触发 minor GC 将 Eden 区仍然存活的对象复制到其中一个Survivor 区中，另外一个 Survivor 区中的存活对象也复制到这个 Survivor 中，以保证始终有一个 Survivor 区是空的。 Old 区存放的是 Young 区的 Survivor 满后触发 minor GC 后仍然存活的对象，当 Eden 区满后会将对象存放到 Survivor 区中，如果 Survivor 区仍然存不下这些对象，GC 收集器会将这些对象直接存放到 Old 区。如果在 Survivor 区中的对象足够老，也直接存放到 Old 区。如果 Old 区也满了，将会触发 Full GC，回收整个堆内存。 Perm 区存放的主要是类的 Class 对象，如果一个类被频繁地加载，也可能会导致 Perm 区满，Perm 区的垃圾回收也是由 Full GC 触发的。 Sun 对堆中的不同代的大小也给出了建议，一般建议 Young 区的大小为整个堆的 1/4，而 Young 区中 Survivor 区一般设置为整个 Young 区的 1/8。 2.3 Serial CollectorSerial Collector 是 JVM 在client 模式下默认的 GC 方式。可以通过 JVM 配置参数 -XX:+UseSerialGC 来指定 GC 使用该收集算法。我们指定所有的对象都在 Young 区的 Eden中创建，但是如果创建的对象超过 Eden 区的总大小，或者超过了 PretenureSizeThreshold 配置参数配置的大小，就只能在 Old 区分配了。 当 Eden 空间不足时就触发了 Minor GC，触发 Minor GC 时首先会检查之前每次 Minor GC 时晋升到 Old 区的平均对象大小是否大于 Old 区的剩余空间，如果大于，则将直接触发 Full GC，如果小于，则要看 HandlePromotionFailure 参数（-XX:-HandlePromotionFailure）的值。如果为 true，仅触发 Minor GC，否则再触发一次 Full GC。其实这个规则很好理解，如果每次晋升的对象大小都超过了 Old 区的剩余空间，那么说明当前的 Old 区的空间已经不能满足新对象所占空间的大小，只有触发 Full GC 才能获得更多的内存空间。 当 Minor GC时，除了将 Eden 区的非活动对象回收以外，还会把一些老对象也复制到 Old 区中。这个老对象的定义是通过配置参数 MaxTenuringThreshold 来控制的，如 -XX:MaxTenuringThreshold=10，则如果这个对象已经被 Minor GC 回收过 10 次后仍然存活，那么这个对象在这次 Minor GC 后直接放入 Old 区。还有一种情况，当这次 Minor GC 时 Survivor 区中的 To Space 放不下这些对象时，这些对象也将直接放入 Old 区。如果 Old 区或者 Perm 区空间不足，将会触发 Full GC，Full GC 会检查 Heap 堆中的所有对象，清除所有垃圾对象，如果是 Perm 区，会清除已经被卸载的 classloader 中加载的类的信息。 2.4 Parallel CollectorParallel GC 根据 Minor GC 和 Full GC 的不同分为三种，分别是 ParNewGC、ParallelGC 和 ParallelOldGC。 ParNewGC 可以通过 -XX:+UseParNewGC 参数来指定， 它的对象分配和回收策略与 SerialCollector 类似，只是回收的线程不是单线程的，而是多线程并行回收。在 Parallel Collector 中还有一个 UseAdaptiveSizePolicy 配置参数，这个参数是用来动态控制 Eden、From Space 和 To Space 的 TenuringThreshold 大小的，以便于控制哪些对象经过多少次回收后可以直接放入 Old 区。 ParallelGC 在 Server 下默认的 GC 方式，可以通过 -XX:+UseParallelGC 参数来强制指定，并行回收的线程数可以通过 -XX:ParallelGCThreads 来指定，这个值有个计算公式，如果 CPU 和核数小于 8，线程数可以和核数一样，如果大于 8，值为 $3+(cpu core*5)/8$。 可以通过 -Xmn 来控制 Young 区的大小，如 -Xman10m，即设置 Young 区的大小为 10MB。在 Young 区内的 Eden、From Space 和 To Space 的大小控制可以通过 SurvivorRatio 参数来完成，如设置成 -XX:SurvivorRatio=8，表示 Eden 区与 From Space 的大小为 8:1，如果 Young 区的总大小为 10 MB，那么 Eden、s0 和 s1 的大小分别为 8 MB、1 MB 和 1 MB。但在默认情况下以 -XX:InitialSurivivorRatio 设置的为准，这个值默认也为 8，表示的是 Young:s0 为 8:1。当在 Eden 区中申请内存空间时，如果 Eden 区不够，那么看当前申请的空间是否大于等于 Eden 的一半，如果大于则这次申请的空间直接在 Old 中分配，如果小于则触发 Minor GC。在触发 GC 之前首先会检查每次晋升到 Old 区的平均大小是否大于 Old 区的剩余空间，如大于则再触发 Full GC。在这次触发 GC 后仍然会按照这个规则重新检查一次。也就是如果满足上面这个规则，Full GC 会执行两次。 在 Young 区的对象经过多次 GC 后有可能仍然存活，那么它们晋升到 Old 区的规则可以通过如下参数来控制：AlwaysTenure，默认为false，表示只要 Minor GC 时存活就晋升到 old；NeverTenure，默认为 false，表示永远不晋升到old 区。如果在上面两个都没设置的情况下设置 UseAdaptiveSizePolicy，启动时以 InitialTenuringThreshold 值作为存活次数的阈值，在每次 GC 后会动态调整，如果不想使用 UseAdaptiveSizePolicy，则以 MaxTenuringThreshold为准，不使用 UseAdaptiveSizePolicy 可以设置为 -XX:-UseAdaptiveSizePolicy。如果 Minor GC 时 To Space 不够，对象也将会直接放到 Old 区。当 Old 或者 Perm 区空间不足时会触发 Full GC，如果配置了参数 ScavengeBeforeFullGC，在 Full GC 之前会先触发Minor GC。 ParallelOldGC可以通过 -XX:+UseParallelOldGC 参数来强制指定， 并行回收的线程数可以通过-XX:ParallelGCThreads 来指定，这个数字的值有个计算公式，如果 CPU 和核数小于 8，线程数可以和核数一样，如果大于 8，值为 $3+(cpu core*5)/8$。 它与 ParallelGC 有何不同呢？其实不同之处在 Full GC 上，前者 Full GC 进行的动作为清空整个 Heap 堆中的垃圾对象，清除 Perm 区中已经被卸载的类信息，并进行压缩。而后者是清除 Heap 堆中的部分垃圾对象，并进行部分的空间压缩。GC 垃圾回收都是以多线程方式进行的，同样也将暂停所有的应用程序。 2.5 CMS Collector可通过 -XX:+UseConcMarkSweepGC 来指定，并发的线程数默认为 4（并行GC 线程数 +3），也可通过 ParallelCMSThreads 来指定。 CMS GC 与上面讨论的 GC 不太一样，它既不是上面所说的 Minor GC，也不是 Full GC，它是基于这两种 GC 之间的一种 GC。它的触发规则是检查 Old 区或者 Perm 区的使用率，当达到一定比例时就会触发 CMS GC，触发时会回收 Old 区中的内存空间。这个比例可以通过 CMSInitiatingOccupancyFraction 参数来指定， 默认是 92%， 这个默认值是通过 $$ ((100-MinHeapFreeRatio)+(double)(CMSTriggerRatio*MinHeapFreeRatio)/100.0)/100.0$$ 计算出来的，其中的 MinHeapFreeRatio 为 40、CMSTriggerRatio 为 80。如果让 Perm 区也使用 CMS GC 可以通过 -XX:+CMSClassUnloadingEnabled 来设定，Perm 区的比例默认值也是 92%，这个值可以通过 CMSInitiatingPermOccupancyFraction 设定。这个默认值也是通过一个公式计算出来的： $$((100-MinHeapFreeRatio)+(double)(CMSTriggerPermRatio*MinHeapFreeRatio)/ 100.0)/100.0$$其中 MinHeapFreeRatio 为 40，CMSTriggerPermRatio 为 80。 触发 CMS GC 时回收的只是 Old 区或者 Perm 区的垃圾对象，在回收时和前面所说的Minor GC 和 Full GC 基本没有关系。在这个模式下的 Minor GC 触发规则和回收规则与 Serial Collector 基本一致，不同之处只是GC 回收的线程是多线程而已。 触发 Full GC 是在这两种情况下发生的：一种是 Eden 分配失败，Minor GC 后分配到 ToSpace，To Space 不够再分配到 Old 区，Old 区不够则触发 Full GC；另外一种情况是，当CMS GC 正在进行时向Old 申请内存失败则会直接触发 Full GC。 这里还需要特别提醒一下，在Hotspot 1.6 中使用这种 GC 方式时在程序中显式地调用了 System.gc，且设置了 ExplicitGCInvokesConcurrent 参数，那么使用 NIO 时可能会引发内存泄漏。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入分析 Java Web 技术内幕》：Java I/O]]></title>
    <url>%2F2017%2F04%2F23%2F%E3%80%8A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%20Java%20Web%20%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B%EF%BC%9AJava-I-O%2F</url>
    <content type="text"><![CDATA[1. 建立通信链路当客户端要与服务端通信，客户端首先要创建一个 Socket 实例，操作系统将为这个 Socket 实例分配一个没有被使用的本地端口号，并创建一个包含本地和远程地址和端口号的套接字数据结构，这个数据结构将一直保存在系统中直到这个连接关闭。在创建 Socket 实例的构造函数正确返回之前，将要进行 TCP 的三次握手协议，TCP 握手协议完成后，Socket 实例对象将创建完成，否则将抛出 IOException 错误。 与之对应的服务端将创建一个 ServerSocket 实例，ServerSocket 创建比较简单只要指定的端口号没有被占用，一般实例创建都会成功，同时操作系统也会为 ServerSocket 实例创建一个底层数据结构，这个数据结构中包含指定监听的端口号和包含监听地址的通配符，通常情况下都是“*”即监听所有地址。之后当调用 accept() 方法时，将进入阻塞状态，等待客户端的请求。当一个新的请求到来时，将为这个连接创建一个新的套接字数据结构，该套接字数据的信息包含的地址和端口信息正是请求源地址和端口。这个新创建的数据结构将会关联到 ServerSocket 实例的一个未完成的连接数据结构列表中，注意这时服务端与之对应的 Socket 实例并没有完成创建，而要等到与客户端的三次握手完成后，这个服务端的 Socket 实例才会返回，并将这个 Socket 实例对应的数据结构从未完成列表中移到已完成列表中。所以 ServerSocket 所关联的列表中每个数据结构，都代表与一个客户端的建立的 TCP 连接。 2. 数据传输当连接已经建立成功，服务端和客户端都会拥有一个 Socket 实例，每个 Socket 实例都有一个 InputStream 和 OutputStream，正是通过这两个对象来交换数据。同时我们也知道网络 I/O 都是以字节流传输的。当 Socket 对象创建时，操作系统将会为 InputStream 和 OutputStream 分别分配一定大小的缓冲区，数据的写入和读取都是通过这个缓存区完成的。写入端将数据写到 OutputStream 对应的 SendQ 队列中，当队列填满时，数据将被发送到另一端 InputStream 的 RecvQ 队列中，如果这时 RecvQ 已经满了，那么 OutputStream 的 write 方法将会阻塞直到 RecvQ 队列有足够的空间容纳 SendQ 发送的数据。值得特别注意的是，这个缓存区的大小以及写入端的速度和读取端的速度非常影响这个连接的数据传输效率。 3. NIO典型的 NIO 代码： 12345678910111213141516171819202122232425262728293031323334public void selector() throws IOException &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); Selector selector = Selector.open(); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false);//设置为非阻塞方式 ssc.socket().bind(new InetSocketAddress(8080)); ssc.register(selector, SelectionKey.OP_ACCEPT);//注册监听的事件 while (true) &#123; Set selectedKeys = selector.selectedKeys();//取得所有key集合 Iterator it = selectedKeys.iterator(); while (it.hasNext()) &#123; SelectionKey key = (SelectionKey) it.next(); if ((key.readyOps() &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT) &#123; ServerSocketChannel ssChannel = (ServerSocketChannel) key.channel(); SocketChannel sc = ssChannel.accept();//接受到服务端的请求 sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_READ); it.remove(); &#125; else if ((key.readyOps() &amp; SelectionKey.OP_READ) == SelectionKey.OP_READ) &#123; SocketChannel sc = (SocketChannel) key.channel(); while (true) &#123; buffer.clear(); int n = sc.read(buffer);//读取数据 if (n &lt;= 0) &#123; break; &#125; buffer.flip(); &#125; it.remove(); &#125; &#125; &#125; &#125; 调用 Selector 的静态工厂创建一个选择器，创建一个服务端的 Channel 绑定到一个 Socket 对象，并把这个通信信道注册到选择器上，把这个通信信道设置为非阻塞模式。然后就可以调用 Selector 的 selectedKeys 方法来检查已经注册在这个选择器上的所有通信信道是否有需要的事件发生，如果有某个事件发生时，将会返回所有的 SelectionKey，通过这个对象 Channel 方法就可以取得这个通信信道对象从而可以读取通信的数据，而这里读取的数据是 Buffer，这个 Buffer 是我们可以控制的缓冲器。 在上面的这段程序中，是将 Server 端的监听连接请求的事件和处理请求的事件放在一个线程中，但是在实际应用中，我们通常会把它们放在两个线程中，一个线程专门负责监听客户端的连接请求，而且是阻塞方式执行的；另外一个线程专门来处理请求，这个专门处理请求的线程才会真正采用 NIO 的方式，像 Web 服务器 Tomcat 和 Jetty 都是这个处理方式。 通过 Channel 获取的 I/O 数据首先要经过操作系统的 Socket 缓冲区再将数据复制到 Buffer 中，这个的操作系统缓冲区就是底层的 TCP 协议关联的 RecvQ 或者 SendQ 队列，从操作系统缓冲区到用户缓冲区复制数据比较耗性能，Buffer 提供了另外一种直接操作操作系统缓冲区的的方式即 ByteBuffer.allocateDirector(size)，这个方法返回的 byteBuffer 就是与底层存储空间关联的缓冲区，它通过 Native 代码操作非 JVM 堆的内存空间。每次创建或者释放的时候都调用一次 System.gc()。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis: 持久化]]></title>
    <url>%2F2017%2F03%2F25%2FRedis-%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1. 持久化选项Redis提供了两种不同的持久化方法来将数据存储到硬盘里面。一种方法叫快照(snapshotting)，它可以将存在于某一时刻的所有数据都写入硬盘里；另一种方法叫只追加文件(append-only file, AOF)，它会在执行命令时，将被执行的写命令复制到硬盘里面。这两种持久化方法既可以同时使用，又可以单独使用。 2. RDB方式Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。如果在新的快照文件创建完毕之前，Redis、系统或者硬件这三者之中的任意一个崩溃了，那么Redis将丢失最近一次创建快照之后写入的所有数据。 2.1 快照时机创建快照的办法有以下几种。 客户端可以通过想Redis发送BGSAVE命令来创建一个快照，对于支持BGSAVE命令的平台来说，Redis会调用fork来创建一个子进程，然后子进程负责将快照写入硬盘，而父进程则继续处理命令请求。执行BGSAVE后Redis会立即返回OK表示开始执行快照操作，如果想知道快照是否完成，可以通过LASTSAVE命令获取最近一次执行快照的时间，返回结果是一个UNIX时间戳。 客户端还可以通过向Redis发送SAVE命令来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前将不再响应任何额其他命令。SAVE命令并不常用，我们通常只会在没有足够内存去执行BGSAVE命令的情况下，又或者即使等待持久化操作执行完毕也无所谓的情况下，才会使用这个命令。 如果用户设置了save配置选项，那么当任意一个save配置选项所设置的条件被满足时，Redis就会触发一次BGSAVE命令。save选项的格式为save M N：每当时间M内被更改的键的个数大于N时，即符合自动快照条件。 当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是，不论清空数据库的操作是否出发了自动快照条件，只要自动快照条件不为空，Redis就会执行一次快照操作。当没有定义自动快照条件时，执行FLUSHALL则不会进行快照。 当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令，阻塞所有客户端，不在执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器。 当一个Redis服务器连接另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有在执行BGSAVE操作，或者从服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令。 2.2 快照原理RDB是Redis默认采用的持久化方式，配置信息在配置文件redis.conf中。默认会将快照文件存储在Redis当前进程的工作目录中的dump.rdb文件中,可以通过配置dir和dbfilename两个参数分别配置指定快照文件的存储路径和文件名。快照的过程如下。 redis使用fork函数复制一份当前进程的副本(子进程)； 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件； 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 在执行fork的时候操作系统会使用写时复制（copy-on-write）策略，即fork()函数发生的那一刻父子进程共享同一内存空间，当父进程要更改某一片的数据时（如执行写命令），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是fork()一刻的内存数据。 Redis在执行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的RDB文件替换成新的，也就是说任何时候RDB文件都是完整的。这时我们就可以通过备份RDB文件来实现Redis数据库备份。 RDB文件是经过压缩的二进制格式，所以占用的空间小于内存中的数据大小，更加利于传输。可以通过设置redcompression参数以禁用压缩节省CPU占用。 在只使用快照持久化来保存数据时，一定要记住：如果系统真的发送崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于那些即使丢失一部分数据也不会造成问题的应用程序。 如果Redis的内存占用量达到数十个GB，并且剩余的空闲内存并不多，或者Redis运行在虚拟机上面，那么执行BGSAVE可能会导致系统长时间地停顿，也可能引发系统大量地使用虚拟内存，从而导致Redis的性能降低至无法使用的程度。 3. AOF持久化简单来说，AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾从新执行一次AOF文件包含的所有写命令，就可以回复AOF文件所记录的数据集。AOF持久化可以通过设置appendonly yes选项打开。 AOF文件的同步频率通过appendfsync选项设置。 选项 同步频率 always 每个Redis写命令都要同步写入硬盘，这样做会严重降低Redis的速度 everysec 秒执行一次同步，显示地将多个写命令同步到硬盘 no 让操作系统来决定何时进行同步 在向硬盘写入文件时，至少会发生3件事。当调用file.write()方法对文件进行写入时，写入的内容首先会被存储到缓冲区，然后操作系统会在将来的某个时候将缓冲区存储的内容写入硬盘，而数据只有在被写入硬盘之后，才算是真正地保存到了硬盘里面。用户可以通过file.flush()方法来请求操作系统尽快地将缓冲区存储的数据写入硬盘里，但具体何时执行写入操作仍然由操作系统决定。 为了解决AOF文件体积不断增大的问题，用户可以向Redis发送BGREWRITEAOF命令，这个命令会移除AOF文件中冗余命令来重写AOF文件，使AOF文件的体积变得尽可能地小。BGREWRITEAOF的工作原理和BGSAVE创建快照的工作原理非常相似：Redis会创建一个子进程，然后由子进程负责对AOF文件进行重写。 AOF持久化也可以通过设置auto-aof-rewrite-percentage和auto-aof-rewrite-min-size来自动执行BGREWRITEAOF。 4. 验证快照文件和AOF文件无论是快照持久化还是AOF持久化，都提供了在需要系统故障时进行数据恢复的工具，Redis提供了两个命令行程序redis-check-aof和redis-check-dump,她们可以在系统故障发生之后检查AOF和快照的状态。并在有需要的时候对文件进行修复在不给定任何参数的情况下运行这两个程序，就可以看见他们的基本使用方法： 12345$redis-check-aofUsage:redis-check-aof [--fix]&lt;file.aof&gt;$redis-check-dumpUsage:redis-check-dump &lt;dump.rdb&gt;$ 如果用户在运行redis-check-aof程序给定了–fix参数那么程序将对AOF文件进行修复。程序修复AOF文件的方法非常简单：他会扫描指定的AOF文件，寻找不正确或者不完整的命令，当发现第一个出错命令的时候，程序会删除出错命令已经出错命令后面的所有命令，只保留出错命令之前的正确命令，在大多数情况下，被删除的都是AOF文件末尾的不完整的写命令。 遗憾的是目前没有办法修复出错的快照文件。 参考资料 《Redis入门指南(第2版)》 《Redis实战》]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis: 复制]]></title>
    <url>%2F2017%2F03%2F24%2FRedis-%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis复制的启动过程 步骤 主服务器操作 从服务器操作 1 等待命令进入 连接（或者重连接）主服务器，发送 SYNC 命令 2 开始执行 BGSAVE，并使用缓冲区记录 BGSAVE 之后执行的所有写命令 根据配置选项来决定是继续使用现有的数据（如果有的话）来处理客户端的命令请求，还是向发送请求的客户端返回错误 3 BGSAVE 执行完毕，向从服务器发送快照文件并在发送期间继续使用缓冲区记录被执行的写命令 丢弃所有的旧数据（如果有的话），开始载入主服务器发来的快照文件 4 快照文件发送完毕，开始向服务器发送存储在缓冲区里的写命令 完成对快照文件的解释操作，像往常一样开始接受命令请求 5 缓冲区存储的写命令发送完毕；现在开始每执行一个写命令，就向从服务器发送相同的写命令 执行主服务发来的所有存储在缓冲区里面的写命令；并从现在开始，接收并执行主服务器传来的每一个写命令 如果用户使用的是SLAVEOF配置选项，那么Redis在启动时首先会载入当前可用的任何快照文件或者AOF文件，然后执行上面表中的复制过程，如果如果用户使用的是SLAVEOF命令，那么Redis会立即尝试连接主服务器，并在连接成功之后，开始上表所示的复制过程。 当多个从服务器连接主服务器的时候，就会出现下表两种情况中的其中一种。 当新的从服务器连接主服务器时 主服务器的操作 上表中的步骤 3 尚未执行 所有的从服务器都会接收到相同的快照文件或者相同的缓冲区写命令 上表中的步骤 3 正在执行或者已经执行完毕 当主服务器与较早的进行的连接的从服务器执行完复制所需的 5 个步骤之后，主服务器会与新连接的从服务器执行一次新的步骤 1 至步骤 5 主从链创建多个从服务器可能造成网络不可用——当复制需要通过互联网进行或者需要在不同数据中心之间进行时，尤为如此。因为Redis的主服务器和从服务器并没有什么特别不同的地方，所有从服务器可以拥有自己的从服务器，从而形成主从链(master/slave chaining)。 从服务器对从服务器进行复制的操作上和从服务器对主服务器进行复制的唯一区别在于，如果从服务器X拥有从服务器Y,那么当从服务器X在执行复制过程中的步骤4的时候,他将断开与从服务器Y的连接，导致从服务器Y需要重新连接并重新同步。 当读请求的重要性明显高于写请求的重要性，并且当读请求的数量远远超出一台Redis服务器可以处理的范围时，用户就可以添加新的从服务器来处理读请求。随着负载的不断上升，主服务器可能会无法快速的更新所有从服务器，或者因为重新连接或者重新同步从服务器而导致系统超载。为了解决这个问题，用户可以创建一个由Redis主从节点(master/slave node)组成的中间层来分担主服务器的复制工作。 AOF持久化的同步选项可以控制数据丢失的时间长度：通过将每个写命令同步到硬盘里面，用户几乎可以不损失任何数据(除非系统崩溃或者硬盘驱动器损坏)，但这种做法会对服务器的性能造成影响；另一方面，如果用户将同步的频率设置为每秒一次，那么服务器的性能将会回到正常水平，但故障可能会造成1秒的数据丢失，通过同时使用复制和AOF持久化，我们可以将数据持久化到多台服务器上面。 为了将数据保存到多台机器上面，用户需要为主服务器设置多个从服务器，然后对每个从服务器设置appendonly yes选项和appendfsync everysecz选项(如果有需要的话，也可以对主服务器进行相同的设置)这样的话，用户就可以让多台服务器以每秒一次的频率将数据同步到硬盘上，但只是第一步：因为用户还必须等待主服务器发送的写命令到达从服务器，并且在执行后续操作之前，检查 数据是否被同步到了硬盘里面。 更换故障主服务器假设A、B两台服务器都运行着Redis,其中A为主服务器，B为从服务器，如果此时机器A因为某个暂时无法修复的故障断开了网络连接，决定使用安装了Redis的机器C作为新的主服务器。 更换主服务器的计划很简单： 在机器B上执行SAVE命令，在机器B上生成快照文件； 将快照文件发送到机器C上，并启动机器C； 将机器B设置为机器C的从服务器。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卡特兰数与算法]]></title>
    <url>%2F2017%2F01%2F15%2F%E5%8D%A1%E7%89%B9%E5%85%B0%E6%95%B0%E4%B8%8E%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[hexo的latex语法比较难搞，可以参见https://segmentfault.com/a/1190000011267196 1. 来源：LeetCode 96 - Unique Binary Search Trees Given n, how many structurally unique BST’s (binary search trees) that store values 1…n? For example,Given n = 3, there are a total of 5 unique BST’s. 123456&gt; 1 3 3 2 1&gt; \ / / / \ \&gt; 3 2 1 1 3 2&gt; / / \ \&gt; 2 1 2 3&gt; 2. 分析假设有 $n$ 个 node，排序后的序列为 ($x_1, x_2, \dots, x_n$)。假设其可构造成 $f(n)$ 个不同的 BST。 若 $n=0$，唯一解为空树，即 $f(0)=1$。 若 $n&gt;0$，一共有 n 种情况： 选 $x_1$ 做 root，使其左子树为空，右子树为剩下 $n-1$ 个 node 的构造 BST，问题转换为 $n-1$ 个 node 的构造 BST 有多少个解，即 $f(1)=f(0) f(n-1)$； 选 $x_2$ 做 root，使其左子树为 $x_1$，右子树为剩下 $n-2$ 个 node 的构造 BST，问题转换为 $n-1$ 个 node 的构造 BST 有多少个解，即 $f(2)=f(1)f(n-2)$； 选 $x_k(1\leq k \leq n)$ 做 root，其左子树共有 $f(k-1)$ 种可能，右子树有 $f(n-k)$ 种可能，即 $f(k)=f(k-1)f(n-k)，(k &gt; 0)$。 由此得到 $$f(n) =\begin{cases}1, &amp; n=0 \f(0)f(n-1) + \dots + f(n-1)f(0) = \sum_{k=1}^n f(k-1)f(n-k), &amp; n&gt;0\end{cases}\tag{1}$$ 3. 递推公式令生成函数 $$\begin{equation}\begin{split}g(x)&amp;= \sum_{k=1}^{\infty}f(k-1)x^k\&amp;=f(0)x + f(1)x^2 + f(2)x^3 + \dots + f(n-1)x^n + \dots\end{split}\tag{2}\end{equation}$$ 则 $$\begin{split}[g(x)]^2 &amp;= f^2(0)x^2 \&amp;+ [f(0)f(1) + f(1)f(0)]x^3 \&amp;+ [f(0)f(2) + f^2(1) + f(2)f(0)]x^4 \&amp;+ \dots \&amp;+ [f(0)f(n-1) + f(1)f(n-2) + … + f(n-1)f(0)]x^n \&amp;+ \dots\end{split}$$ 代入 $f(0) = 1$，$f(1) = 1$ 和 $f(n)$ 的递推公式，得到 $$\begin{equation}\begin{split}[g(x)]^2 &amp;= x^2 + f_2x^3 + f_3x^4 + … + f_{n-1}x^n \ &amp;= g(x) - x\end{split}\tag{3}\end{equation}$$ 解这个方程，其两个根为 $$g_1(x)=\frac{1 + \sqrt{1-4x}}{2}, g_2(x)=\frac{1 - \sqrt{1-4x}}{2}$$ 由于 $g(0)=0$，验证得仅 $g_2(x)$ 成立，所以 $$g(x)=g_2(x)=\frac{1}{2} - \frac{1}{2}(1-4x)^{\frac{1}{2}}\tag{4}$$ 4. 牛顿二项式展开根据牛顿二项式定理 $$(x+y)^n = \sum_{k=0}^{n}\binom{n}{k}x^{n-k}y^{k}，其中\binom{n}{k}=\frac{n!}{k!(n-k)!}\tag{5}$$ 当 $n$ 不是正整数时，$k$ 无法正好求和到 $n$，因此将一直求和至正无穷，这样形式上就得到了广义二项式定理: $$(x+y)^{\alpha} = \sum_{k=0}^{\infty}\binom{\alpha}{k}x^{\alpha-k}y^k\tag{6}$$ 其中 $$\binom{\alpha}{k}=\frac{\alpha(\alpha-1)\dots(\alpha-k+1)}{k!} \tag{7}$$ 是形式上的组合数。实际上广义二项式定理并非总是成立，因为等式右边不一定收敛。 其常见形式为 $$\begin{equation}\begin{split}(1+z)^{\alpha} &amp;= \sum_{k=0}^{\infty}\binom{\alpha}{k}z^{k} \&amp; = 1+ \sum_{k=1}^{\infty}\binom{\alpha}{k}z^{k}, (|z|&lt;1)\end{split}\tag{8}\end{equation}$$ 现考察 $\alpha=\frac{1}{2}$ 的情况，有 $$\begin{equation}\begin{split}\binom{\alpha}{k}&amp;=\frac{\frac{1}{2}(\frac{1}{2}-1)(\frac{1}{2}-2)\dots(\frac{1}{2}-k+1)}{k!} \&amp; = \frac{(-1)^{k-1}}{2^k}\frac{1 \times 3 \times 5 \times \dots \times (2k-3)}{k!} \&amp; = \frac{(-1)^{k-1}}{2^k}\frac{1 \times 2 \times 3 \times \dots \times(2k-3) \times (2k-2)}{2 \times 4 \times \dots \times (2k-2) \times k! } \&amp; = \frac{(-1)^{k-1}}{2^k}\frac{(2k-2)!}{2^{k-1}(k-1)!k!} \&amp; = \frac{(-1)^{k-1}}{k \times 2^{2k-1}} \frac{(2k-2)!}{[(k-1)!]^2} \&amp; = \frac{(-1)^{k-1}}{k \times 2^{2k-1}} \binom{2k-2}{k-1}, (k &gt; 0)\end{split}\tag{9}\end{equation}$$ 因此， $$(1+z)^{\alpha} = 1+\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k \times 2^{2k-1}} \binom{2k-2}{k-1}z^{k}, (|z|&lt;1)\tag{10}$$ 5. 回到 $g(x)$令上式中的 $z=-4x$，即得到 $$\begin{equation}\begin{split}g(x)&amp;=\frac{1}{2} - \frac{1}{2}(1-4x)^{1/2} \&amp;=\frac{1}{2}-\frac{1}{2}[1+\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k \times 2^{2k-1}} \binom{2k-2}{k-1}(-4x)^{k}] \&amp;=\sum_{k=1}^{\infty}\frac{1}{k}\binom{2k-2}{k-1}x^k, (|x|&lt;\frac{1}{4})\end{split}\tag{11}\end{equation}$$ 又因为按照定义 $g(x)= \sum_{k=1}^{\infty}f(k-1)x^k$，所以 $$\begin{equation}\begin{split}f(n-1)&amp;=\frac{1}{n}\binom{2n-2}{n-1}, n&gt;1\end{split}\end{equation}$$ 或写为 $$\begin{equation}\begin{split}f(n)&amp;=\frac{1}{n+1}\binom{2n}{n}, n&gt;0\end{split}\tag{12}\end{equation}$$ 此即卡特兰数（Catalan Number）的通项公式。递归计算时可采用 $$f(n+1) = \frac{2(2n+1)}{n+2}f(n)\tag{13}$$ 6. 卡特兰数的应用 括号化问题。矩阵链乘： $P=A1×A2×A3×\dots×An$，依据乘法结合律，不改变其顺序，只用括号表示成对的乘积，试问有几种括号化的方案？ 将多边行划分为三角形问题。将一个凸多边形区域分成三角形区域（划分线不交叉）的方法数？类似：在圆上选择 2n 个点，将这些点成对连接起来使得所得到的 n 条线段不相交的方法数？ 出栈次序问题。 一个栈（无穷大）的进栈序列为 1,2,3,…,n，有多少个不同的出栈序列？ 有 2n 个人排成一行进入剧场。入场费 5 元。其中只有 n 个人有一张 5 元钞票，另外 n 人只有 10 元钞票，剧院无其它钞票，问有多少中方法使得只要有 10 元的人买票，售票处就有 5 元的钞票找零？(将持 5 元者到达视作将 5 元入栈，持 10 元者到达视作使栈中某 5 元出栈) 一位大城市的律师在他住所以北 n 个街区和以东 n 个街区处工作。每天她走 2n 个街区去上班。如果他从不穿越（但可以碰到）从家到办公室的对角线，那么有多少条可能的道路？]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表中的环问题]]></title>
    <url>%2F2017%2F01%2F08%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E7%8E%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 来源 LeetCode 141 - Linked List Cycle Given a linked list, determine if it has a cycle in it. Follow up:Can you solve it without using extra space? LeeCode 142 - Linked List Cycle II Given a linked list, return the node where the cycle begins. If there is no cycle, return null. Note: Do not modify the linked list. Follow up:Can you solve it without using extra space? 2. 判断是否有环双指针问题，设置两个指针 fast 和 slow，初始均指向 head 节点。fast 指针每次走两步，slow 指针每次走一步。若 fast 指针或 fast.next 指针为 null，则无环；当 fast == slow 则有环。 3. 计算环的位置假设环的连接点为 joint，head 到 joint 的步长为 $x$，环长为 $L$， fast 和 slow 指针在交汇时经过了 $t$ 个步骤，交汇点 intersection 沿链表方向距离 joint 的步长为 $y$。则$$t=x+(L-y)\2t=x+(L-y)+nL$$其中 $n$ 为交汇时 fast 指针已经在环上走过的圈数。可得：$$x=(n-1)L+y$$这个式子的含义是，head 到 joint 的距离，等于 intersection 到 joint 的距离加上环长的整数倍。 那么，让两个指针一个从 head 出发，一个从 intersection 出发，经过相同的步数（即 $x$）之后，他们应当在 joint 相汇。 LeetCode 142 Solution： 1234567891011121314public ListNode detectCycle(ListNode head) &#123; ListNode fast = head, slow = head; while(true) &#123; if(fast == null || fast.next == null) return null; fast = fast.next.next; slow = slow.next; if(fast == slow) break; &#125; while(head != slow) &#123; head = head.next; slow = slow.next; &#125; return head;&#125; 4. 其他问题 怎么求环长？ fast 和 slow 交汇后，让 slow 再走一圈即得到环长。 或者先得到环的连接点，再从连接点开始走一圈环。 怎么得到单链表总长？ 在计算环的连接点时，可以计算出 $x$，再加上环长。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper Java Api]]></title>
    <url>%2F2017%2F01%2F01%2FZooKeeper%20Java%20Api%2F</url>
    <content type="text"><![CDATA[Api 测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package ZooKeeperApi;import com.alibaba.fastjson.JSON;import org.apache.zookeeper.AsyncCallback;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import java.util.List;/** * Created by xyq on 2017/12/28. */public class ZooKeeperApi &#123; private static final String addr = "localhost:2181"; private static final int timeout = 5000; public static void main(String[] args) &#123; try &#123; // 创建 ZooKeeper 实例 ZooKeeper zooKeeper = new ZooKeeper(addr, timeout, new MyWatcher()); while(zooKeeper.getState() != ZooKeeper.States.CONNECTED) &#123;&#125; long sessionId = zooKeeper.getSessionId(); byte[] passwd = zooKeeper.getSessionPasswd(); System.out.println("ZooKeeper connected, sessionId=" + sessionId); // 同步创建临时顺序节点 String syncCreateRes = zooKeeper.create("/sync-ephemeral-sequential-znode-", "sync_create".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); System.out.println("sync create znode, path=" + syncCreateRes); // 异步检测临时顺序节点是否存在, 并注册 Watcher zooKeeper.exists(syncCreateRes, true, new MyStatCallback(), "ctx"); // 异步删除临时顺序节点 zooKeeper.delete(syncCreateRes, -1, new MyVoidCallback(), "ctx"); // 同步创建持久顺序节点 String persistentNode = zooKeeper.create("/async-persistent-sequential-znode-", "async_create".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL); // 异步获取持久顺序节点数据，并注册 Watcher zooKeeper.getData(persistentNode, true, new MyDataCallback(), "ctx"); // 异步更新持久顺序节点数据 zooKeeper.setData(persistentNode, "new_data".getBytes(), -1, new MyStatCallback(), "ctx"); // 异步获取持久顺序节点子节点, 并注册 Watcher zooKeeper.getChildren(persistentNode, true, new MyChildren2Callback(), "ctx"); // 异步在持久顺序节点下创建临时子节点 zooKeeper.create(persistentNode + "/child", "child".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL, new MyStringCallback(), "ctx"); Thread.sleep(2000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; static class MyWatcher implements Watcher &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println("receive an event, keeperState=" + watchedEvent.getState() + ", type=" + watchedEvent.getType()); &#125; &#125; static class MyStringCallback implements AsyncCallback.StringCallback &#123; @Override public void processResult(int i, String s, Object o, String s1) &#123; System.out.println("async create znode result, resultCode=" + i + ", path=" + s + ", ctx=" + o + ", realPath=" + s1); &#125; &#125; static class MyVoidCallback implements AsyncCallback.VoidCallback &#123; @Override public void processResult(int i, String s, Object o) &#123; System.out.println("async delete znode result, resultCode=" + i + ", path=" + s + ", ctx=" + o); &#125; &#125; static class MyChildren2Callback implements AsyncCallback.Children2Callback &#123; @Override public void processResult(int i, String s, Object o, List&lt;String&gt; list, Stat stat) &#123; System.out.println("async get znode children result, resultCode=" + i + ", path=" + s + ", ctx=" + o + ", childrenList=" + JSON.toJSONString(list) + ", stat=" + JSON.toJSONString(stat)); &#125; &#125; static class MyStatCallback implements AsyncCallback.StatCallback &#123; @Override public void processResult(int i, String s, Object o, Stat stat) &#123; System.out.println("async judge znode existence result, resultCode=" + i + ", path=" + s + ", ctx=" + o + ", stat=" + JSON.toJSONString(stat)); &#125; &#125; static class MyDataCallback implements AsyncCallback.DataCallback &#123; @Override public void processResult(int i, String s, Object o, byte[] bytes, Stat stat) &#123; System.out.println("async get znode data result, resultCode=" + i + ", path=" + s + ", ctx=" + o + ", stat=" + JSON.toJSONString(stat)); &#125; &#125;&#125; 运行结果： 123456789101112ZooKeeper connected, sessionId=99251216681467907receive an event, keeperState=SyncConnected, type=Nonesync create znode, path=/sync-ephemeral-sequential-znode-0000000064async judge znode existence result, resultCode=0, path=/sync-ephemeral-sequential-znode-0000000064, ctx=ctx, stat=&#123;&quot;aversion&quot;:0,&quot;ctime&quot;:1514453932664,&quot;cversion&quot;:0,&quot;czxid&quot;:1320,&quot;dataLength&quot;:11,&quot;ephemeralOwner&quot;:99251216681467907,&quot;mtime&quot;:1514453932664,&quot;mzxid&quot;:1320,&quot;numChildren&quot;:0,&quot;pzxid&quot;:1320,&quot;version&quot;:0&#125;receive an event, keeperState=SyncConnected, type=NodeDeletedasync delete znode result, resultCode=0, path=/sync-ephemeral-sequential-znode-0000000064, ctx=ctxasync get znode data result, resultCode=0, path=/async-persistent-sequential-znode-0000000065, ctx=ctx, stat=&#123;&quot;aversion&quot;:0,&quot;ctime&quot;:1514453932674,&quot;cversion&quot;:0,&quot;czxid&quot;:1322,&quot;dataLength&quot;:12,&quot;ephemeralOwner&quot;:0,&quot;mtime&quot;:1514453932674,&quot;mzxid&quot;:1322,&quot;numChildren&quot;:0,&quot;pzxid&quot;:1322,&quot;version&quot;:0&#125;receive an event, keeperState=SyncConnected, type=NodeDataChangedasync judge znode existence result, resultCode=0, path=/async-persistent-sequential-znode-0000000065, ctx=ctx, stat=&#123;&quot;aversion&quot;:0,&quot;ctime&quot;:1514453932674,&quot;cversion&quot;:0,&quot;czxid&quot;:1322,&quot;dataLength&quot;:8,&quot;ephemeralOwner&quot;:0,&quot;mtime&quot;:1514453932680,&quot;mzxid&quot;:1323,&quot;numChildren&quot;:0,&quot;pzxid&quot;:1322,&quot;version&quot;:1&#125;async get znode children result, resultCode=0, path=/async-persistent-sequential-znode-0000000065, ctx=ctx, childrenList=[], stat=&#123;&quot;aversion&quot;:0,&quot;ctime&quot;:1514453932674,&quot;cversion&quot;:0,&quot;czxid&quot;:1322,&quot;dataLength&quot;:8,&quot;ephemeralOwner&quot;:0,&quot;mtime&quot;:1514453932680,&quot;mzxid&quot;:1323,&quot;numChildren&quot;:0,&quot;pzxid&quot;:1322,&quot;version&quot;:1&#125;receive an event, keeperState=SyncConnected, type=NodeChildrenChangedasync create znode result, resultCode=0, path=/async-persistent-sequential-znode-0000000065/child, ctx=ctx, realPath=/async-persistent-sequential-znode-0000000065/child 小结 ZooKeeper 不支持递归创建，即无法在父节点不存在的情况下创建一个子节点。另外，如果一个节点已经存在了，那么创建同名节点的时候会抛出 NodeExistsException 异常。 目前，ZooKeeper 的节点内容只支持字节数组（byte[]）类型。 在同步接口调用中，我们需要关注接口抛出异常的可能，但是在异步接口中，所有的异常再回调函数中通过 Result Code 来体现。 org.apache.zookeeper.KeeperException.Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public static enum Code implements CodeDeprecated &#123; /** Everything is OK */ OK (Ok), /** System and server-side errors. * This is never thrown by the server, it shouldn't be used other than * to indicate a range. Specifically error codes greater than this * value, but lesser than &#123;@link #APIERROR&#125;, are system errors. */ SYSTEMERROR (SystemError), /** A runtime inconsistency was found */ RUNTIMEINCONSISTENCY (RuntimeInconsistency), /** A data inconsistency was found */ DATAINCONSISTENCY (DataInconsistency), /** Connection to the server has been lost */ CONNECTIONLOSS (ConnectionLoss), /** Error while marshalling or unmarshalling data */ MARSHALLINGERROR (MarshallingError), /** Operation is unimplemented */ UNIMPLEMENTED (Unimplemented), /** Operation timeout */ OPERATIONTIMEOUT (OperationTimeout), /** Invalid arguments */ BADARGUMENTS (BadArguments), /** API errors. * This is never thrown by the server, it shouldn't be used other than * to indicate a range. Specifically error codes greater than this * value are API errors (while values less than this indicate a * &#123;@link #SYSTEMERROR&#125;). */ APIERROR (APIError), /** Node does not exist */ NONODE (NoNode), /** Not authenticated */ NOAUTH (NoAuth), /** Version conflict */ BADVERSION (BadVersion), /** Ephemeral nodes may not have children */ NOCHILDRENFOREPHEMERALS (NoChildrenForEphemerals), /** The node already exists */ NODEEXISTS (NodeExists), /** The node has children */ NOTEMPTY (NotEmpty), /** The session has been expired by the server */ SESSIONEXPIRED (SessionExpired), /** Invalid callback specified */ INVALIDCALLBACK (InvalidCallback), /** Invalid ACL specified */ INVALIDACL (InvalidACL), /** Client authentication failed */ AUTHFAILED (AuthFailed), /** Session moved to another server, so operation is ignored */ SESSIONMOVED (-118), /** State-changing request is passed to read-only server */ NOTREADONLY (-119);&#125; 在更新数据时，version 参数使用 -1 表示针对最新版本进行更新。 无论节点是否存在，通过调用 exists 接口都可以注册 Watcher，能够对节点创建、节点删除和节点数据更新事件进行监听，但不监听子节点的各种变化。]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode]]></title>
    <url>%2F2017%2F01%2F01%2FLeetCode%2F</url>
    <content type="text"><![CDATA[https://github.com/xyq000/LeetCode.git]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：Web 页面请求的历程]]></title>
    <url>%2F2016%2F11%2F24%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9AWeb-%E9%A1%B5%E9%9D%A2%E8%AF%B7%E6%B1%82%E7%9A%84%E5%8E%86%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1. 场景一名学生 Bob 启动他的计算机，将其用一根网线连接到学校的以太网交换机，然后通过浏览器访问 Google 主页。 网络环境： Bob 的计算机与交换机相连 交换机与学校路由器相连 路由器与一个 ISP 相连，本例中 ISP 为 comcast.net 本例中 comcast.net 为学校提供了 DNS 服务，所以 DNS 服务器驻留在 Comcast 网络中而不是学校网络中 2. 准备：DHCP、UDP、IP 和以太网Bob 的计算机目前还没有 IP 地址，如何动态获取 IP 地址？ 运行 DHCP，以从本地的 DHCP 服务器获取一个 IP 地址以及其他信息。 Bob 计算机上的操作系统生成一个 DHCP 请求报文，并将这个报文放入目的地端口 67（DHCP 服务器）和源端口 68（DHCP 客户）的 UDP 报文段。该 UDP 报文段则被放置在一个具有广播 IP 目的地地址（255.255.255.255）和源 IP 地址 0.0.0.0 的 IP 数据报中，因为此时 Bob 的计算机还不具有一个 IP 地址。 该 IP 数据报则被放置在以太网帧中，目的 MAC 地址 FF:FF:FF:FF:FF:FF，使该帧将广播到与交换机连接的所有设备，源 MAC 地址为 Bob 计算机的网卡 MAC 地址 00:16:D3:23:68:8A。 | 协议层 | 数据 || —- | —————————————- || 应用层 | DHCP 请求报文 || 传输层 | UDP 源端口 68 目的端口 67 || 网络层 | 源 IP 0.0.0.0 目的 IP 255.255.255.255 || 链路层 | 源 MAC 00:16:D3:23:68:8A 目的 MAC FF:FF:FF:FF:FF:FF | 包含 DHCP 请求的广播以太网帧是第一个有 Bob 计算机发送到以太网交换机的帧。该交换机在所有的出端口广播帧，包括连接到路由器的端口。同时交换机会在交换机表（switch table）中新添加一条记录，内容包括 MAC 地址，通往该 MAC 地址的交换机接口，该记录放置在表中的时间。 | 地址 | 端口 | 时间 || —————– | —- | —- || 00-16-D3-23-68-8A | 1 | 9:30 | 路由器在它的具有 MAC 地址 00:22:6B:45:1F:1B 接口接收到该广播以太网帧，该帧中包含 DHCP 请求，并且从该以太网帧中抽取出 IP 数据报。该数据报的广播 IP 目的地址指示了这个 IP 数据报应当由在该结点的高层协议处理，因此该数据报的载荷（一个 UDP 报文段）被分解向上到达 UDP，从此 UDP 报文段中抽取出 DHCP 请求报文。 我们假设运行在路由器中的 DHCP 服务器能够以 CIDR 块 68.85.2.0/24 分配 IP 地址，然后分配地址 68.85.2.101 给 Bob 计算机。DHCP 服务器生成一个 DHCP ACK 报文，包含内容 | DHCP ACK 报文 | 值 || ————– | ————— || IP 地址 | 68.85.2.101 || DNS 服务器 IP 地址 | 68.87.71.226 || 默认网关路由器（第一跳路由） | IP 地址 68.85.2.1 || 子网块（网络掩码） | 68.85.2.0/24 | 该 DHCP 报文被放入一个 UDP 报文段中，UDP 报文段被放入一个 IP 数据报中，IP 数据报再被放入一个以太网帧中。这个以太网帧的源 MAC 地址是路由器连到归属网络时接口的 MAC 地址（00:22:6B:45:1F:1B），目的 MAC 地址是 Bob 计算机的 MAC 地址（00-16-D3-23-68-8A）。 包含 DHCP ACK 报文的以太网帧由路由器发送给交换机。因为交换机是自学习的，并且先前从 Bob 计算机收到（包含 DHCP 请求的）以太网帧，所以该交换机从交换机表中查询到通往 Bob 计算机 MAC 地址 00:22:6B:45:1F:1B 的相应接口。 Bob 计算机接收到包含 DHCP ACK 的以太网帧，从该以太网帧中抽取 IP 数据报，从 IP 数据报中抽取 UDP 报文段，从 UDP 报文段中抽取 DHCP ACK 报文。Bob的 DHCP 客户则记录下它的 IP 地址和它的 DNS 服务器的 IP 地址。它还在其 IP 转发表中安装默认网关的地址。 3. 仍在准备：DNS 和 ARP当 Bob 将 www.google.com 的 URL 键入其 Web 浏览器时，他开启了一长串事件，这导致 Google 主页最终显示在其 Web 浏览器上。Bob 的 Web 浏览器通过生成一个 TCP 套接字开始了该过程，套接字用于向 www.google.com 发送 HTTP 请求。为了生成套接字，Bob 的计算机机需要知道 www.google.com 的 IP 地址。这就需要 DNS 协议提供这种域名到 IP 地址的转换服务。 但如果Bob计算机想向子网 68.85.2.0/24 之外的目的地址发送数据报，则先要经过默认网关。 Bob 计算机上的操作系统生成一个 DNS 查询报文，将字符串 www.google.com 放入 DNS 报文的问题段中。该 DNS 报文则放置在一个具有 53 号（DNS 服务器）目的端口的 UDP 报文段中。该 UDP 报文段则被放入具有 IP 目的地址 68.87.71.226（在 DHCP ACK 返回的 DNS 服务器地址）和源地址 68.85.2.101 的 IP 数据报中。 Bob 的计算机则将包含 DNS 请求报文的数据报放入一个以太网帧中。该帧将发送到（在链路层寻址）Bob 学校网络中的网关路由器。目前仅从 DHCP ACK 报文知道学校网关路由器的 IP 地址 65.85.2.1，但不知道网关路由器的 MAC 地址。此时就需要 ARP 协议提供IP地址到 MAC 地址的转换服务。 Bob 的计算机生成一个具有目的 IP 地址 68.85.2.1（默认网关）的 ARP 查询报文，将该 ARP 报文放置在一个具有广播目的地址 FF:FF:FF:FF:FF:FF 的以太网帧中，并向交换机发送该以太网帧，交换机将该帧交付给所有连接的设备，包括网关路由器。封装 ARP 报文的以太网帧： | 域 | 值 || ———- | ———————————- || 硬件类型 | 1 表示以太网 || 协议类型 | 发送者所提供/请求的高级协议地址类型，0x0800 代表 IP 协议 || 发送者 IP 地址 | 68.85.2.101 || 发送者 MAC 地址 | 00:16:D3:23:68:8A || 目的 IP 地址 | 68.85.2.1 || 目的 MAC 地址 | FF:FF:FF:FF:FF:FF | 网关路由器在通往学校网络的接口上接收到包含该 ARP 查询报文的帧，发现在 ARP 报文中的目标地址 68.85.2.1 匹配其接口地址。网关路由器因此准备一个 ARP 回答，指示 IP 地址 68.85.2.1 对应的 MAC 地址为 00:22:6B:45:1F:1B。它将 ARP 回答放在一个以太网帧中，其目的地址为 00:16:D3:23:68:8A（Bob 的计算机），并向交换机发送该帧，再由交换机将帧交付给 Bob 的计算机。 Bob 计算机收到包含 ARP 回到报文的帧，并从 ARP 回答报文中抽取网关路由器的 MAC 地址（00:22:6B:45:1F:1B），在本地 ARP 表中创建一条新的记录。 | IP 地址 | MAC 地址 | TTL (Time to Live) || ——— | —————– | —————— || 68.85.2.1 | 00-22-6B-45-1F-1B | 09:30:00 | 现在，Bob 的计算机能够使包含 DNS 查询报文的以太网帧寻址到网关路由器的 MAC 地址了。 4. 仍在准备：域内路由选择到 DNS 服务器 网关路由器接收该帧并抽取包含 DNS 查询的 IP 数据报。路由器查找该数据报的目的地址（68.87.71.226），并根据其转发表决定该数据报应道发送到 Comcast 网络中最左边的路由器。IP 数据报放置在链路层帧中，该链路适合将学校路由器连接到最左边 Comcast 路由器，并且该帧经过这条链路发送。 Comcast 最左边的路由器接到该帧，抽取 IP 数据报，检查该数据报的目的地址（68.87.71.226），并根据其转发表确定接口，经过该接口朝着 DNS 服务器转发数据报，而转发表已根据 Comcast 的域内协议（如 RIP、OSPF 或 IS-IS）以及因特网的域间协议 BGP 所填写。 最终包含 DNS 查询的 IP 数据报到达了 DNS 服务器。DNS 服务器抽取出 DNS 查询报文，在它的 DNS 数据库中查找域名 www.google.com，找到包含对应 www.google.com 的 IP 地址（64.233.169.105）的 DNS 源记录。该 DNS 服务器形成了一个包含这种主机名到 IP 地址映射的 DNS 回答报文，将该 DNS 回答报文放入 UDP 报文段中，该报文段放入寻址到 Bob 计算机的 IP 数据报中。该数据报将通过 Comcast 网络反向转发到学校的路由器，并从这里经过以太网交换机到 Bob 计算机。 Bob 计算机从 DNS 报文抽取出服务器 www.google.com 的 IP 地址，并添加到浏览器的 DNS 缓存中。 经过大量的工作后，Bob 的计算机终于可以与 www.google.com 服务器通信了。 5. Web 客户 - 服务器交互：TCP 和 HTTP Bob 计算机有了 www.google.com 的 IP 地址，它就能够生成 TCP 套接字，该套接字将用于向 www.google.com 发送 HTTP GET 报文。当 Bob 生成 TCP 套接字时，在 Bob 计算机中的 TCP 必须首先与 www.google.com 中的 TCP 执行三次握手。Bob 计算机首先生成一个具有目的端口 80（针对 HTTP）的 TCP SYN 报文段，将该 TCP 报文段放置在具有目的 IP 地址 64.233.169.105（www.google.com）的 IP 数据报中，将该数据报放置在 MAC 地址为 00:22:6B:45:1F:1B（网关路由器）的帧中，并向交换机发送该帧。 在学校网络、Comcast 网络和 Google 网络中的路由器朝着 www.google.com 转发包含 TCP SYN 的数据报，使用每台路由器中的转发表。 最终，包含 TCP SYN 的数据报到达 www.google.com。Google 服务器从数据报抽取出 TCP SYN 报文并分解到与端口 80 相联系的套接字。对于 Google HTTP 服务器和 Bob 计算机之间的 TCP 连接生成一个连接套接字。产生一个 TCP SYNACK 报文段（SYNACK segment），将其放入一个向 Bob 计算机寻址的数据报中。包含 TCP SYNACK 报文段的数据报经过 Google、Comcast 和学校网络，最终到达 Bob 计算机的以太网卡。 Bob 的 Web 浏览器生成 HTTP GET 报文。HTTP GET 报文则写入套接字，其中 GET 报文成为一个 TCP 报文段的载荷，该 TCP 报文段则被放进一个数据报中，并交付到 www.google.com。 注意到该 TCP 报文同时也对来自 Google 的 SYNACK 报文段进行 ACK。 在 www.google.com 的 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将请求的 Web 页面内容放入 HTTP 响应体中，并将报文发送进 TCP 套接字中。包含 HTTP 响应报文的数据报经过 Google、Comcast 和学校网络转发，到达 Bob 计算机。Bob 的 Web 浏览器从套接字读取 HTTP 响应，从 HTTP 响应体中抽取 Web 网页的 HTML，最终渲染出页面效果。]]></content>
      <categories>
        <category>Network</category>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：DNS]]></title>
    <url>%2F2016%2F09%2F24%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9ADNS%2F</url>
    <content type="text"><![CDATA[1. DNS 是什么DNS（Domain Name System）是 一个由分层的 DNS 服务器实现的分布式数据库 一个使得主机能够查询分布式数据库的应用层协议 运行在 UDP 上，使用 53 号端口 2. DNS 提供的服务 域名解析：将主机名（Host）解析为 IP 地址。 主机别名：有着复杂主机名的主机能够拥有一个或者多个别名，应用程序可以调用 DNS 来获得主机别名对应的规范主机名以及主机的 IP 地址。 邮件服务器别名：电子邮件应用程序可以调用 DNS，对提供的邮件服务器别名进行解析，以获得该主机的规范主机名机器 IP 地址。 负载分配：DNS 也用于在冗余的服务器之间进行负载分配。一些繁忙的站点被冗余分布在多台服务器上，每台服务器均运行在不同的端系统上，有着不同的 IP 地址。所以在这种情况下，一个 IP 地址集合与一个规范主机名关联。DNS 数据库存储着这些 IP 地址集合。当客户对该主机名进行 DNS 请求时，服务器用 IP 地址的整个集合进行响应，但在每个回答中循环这些地址次序。因为客户通常总是与 IP 地址排在最前面的服务器建立连接，所以 DNS 就在所有这些冗余服务器之间循环分配了负载。 3. 简要工作流程用浏览器描述 DNS 工作过程： 同一台主机运行着 DNS 应用的客户端。 浏览器从 URL 中抽取出主机名，传给 DNS 应用的客户端。 DNS 客户机端向 DNS 服务器发送一个包含主机名的 DNS 请求。 DNS 服务器最终将返回一个（或一个集合）该主机名对应的主机 IP 地址。 浏览器向位于该 IP 地址 80 端口的 HTTP 服务器进程发起一个 TCP 连接。 4. DNS 服务器的层次结构DNS 使用了大量的 DNS 服务器，它们以层次方式组织，并分布在全世界范围内。大致来说，有 3 种类型的 DNS 服务器：根 DNS 服务器、顶级域（Top-Level Domain，TLD）DNS 服务器和权威 DNS 服务器。它们以下图的层次结构组织： 根 DNS 服务器。在因特网上有 13 个根 DNS 服务器（编号为 A 到 M），它们中的大部分位于北美洲。每台“服务器”实际上是一个冗余服务器的网络，以提供安全性和可靠性。根 DNS 服务器用来返回 TLD 服务器的 IP 地址。 顶级域名服务器（top level domain，简称 TLD)。这些服务器负责顶级域名如 com、org、net、edu 和 gov，以及所有国家的顶级域名如 uk、fr 等。TLD 服务器返回权威服务器的 IP 地址。 权威 DNS 服务器。每一个在 internet 中的有公共可访问主机的组织或机构，必须提供公共可访问的 DNS 记录，并将之存放在权威 DNS 服务器中。权威 DNS 服务器可以是本组织的服务器也可以租用其他组织的服务器。它用来返回主机的 IP 地址。权威 DNS 存在的理由：每一个机构都有很多的主机，这些主机可能位于不同的地理位置，有不同的 IP 地址，但他们可能有相同的域名，如果这些信息全部由顶级域名服务器进行管理，工作量太大。 本地 DNS 服务器：根、TLD和权威 DNS 服务器都处在 DNS 服务器的层次结构中，还有一类重要的 DNS，称为本地 DNS 服务器。一个本地 DNS 服务器严格来说不属于该层次结构，但它却是很重要的。每个 ISP 都有一台本地 DNS 服务器。本地 DNS 服务器起着代理的作用，本地主机将 DNS 请求发向本地 DNS 服务器，本地 DNS 服务器将该请求转发到 DNS 服务器层次结构中。 5. DNS 解析流程5.1 浏览器访问域名时的前置步骤若用户通过浏览器访问某站点，此时存在两个步骤： 浏览器检查缓存中是否有该域名对应的解析过的 IP 地址，若命中则解析过程结束；否则进行步骤 2。 浏览器检查操作系统缓存中是否有该域名对应的 DNS 解析结果，若命中则解析过程结束；否则进行后续步骤。 5.2 DNS 在服务器之间的解析步骤下图例子假设主机 cs.ustc.edu 想知道主机 cs.csu.edu 的 IP 地址，假设 USTC 大学的本地 DNS 服务器为 dns.ustc.edu，同时假设 CSU 大学的权威 DNS 服务器为 dns.csu.edu。 主机 cs.ustc.edu 首先向它的本地 DNS 服务器 dns.ustc.edu 发送一个 DNS 查询报文。该查询报文含有被转换的主机名 cs.csu.edu。 本地 DNS 服务器将该查询报文发送到根 DNS 服务器，根 DNS 服务器注意到 edu 的前缀，所以将负责 edu 的 TLD 的 IP 地址列表返回给本地 DNS 服务器。 本地 DNS 服务器再次向这些 TLD 服务器之一发送 DNS 查询报文，该 TLD 服务器注意到 csu.edu 的前缀，所以将权威服务器 dns.cs.edu 的 IP 地址返回给本地 DNS 服务器。 本地 DNS 服务器向权威服务器 dns.cs.edu 发送查询报文，权威服务器用 cs.csu.edu 的 IP 地址进行响应。 最后，本地 DNS 服务器将查询得到的 IP 地址返回给主机 cs.ustc.edu。 DNS 查询也可以一种递归的方式进行： 5.3 DNS 缓存如果每次 DNS 解析都要走完上面介绍的整个流程，就会带来网络带宽的消耗和时延，这对于用户和 DNS 解析系统都是不友好的。所以当本地 DNS 服务器在完成一次查询后就会将得到的主机名到 IP 地址的映射缓存到本地，从而加快 DNS 的解析速度。实际上，解析大多数都是在本地服务器上完成的。由于主机名和 IP 地址之间的映射不是永久的，DNS 服务器在一段时间后，通常是两天，就会丢弃缓存信息。 大部分的 DNS 洪泛攻击可以由本地 DNS 缓存缓解。 在 Linux 下可以通过/etc/init.d/nscd restart来清除缓存。 5.4 JVM 中的 DNS 缓存Java 应用中的 JVM 也会缓存 DNS 的解析结果，这个缓存是在 InetAddress 类中，缓存时间较特殊，两种缓存策略： 缓存正确结果 缓存失败的结果 两个缓存时间由两个配置项来控制，配置项是在 %JAVA_HOME%\lib\security\java.security 文件中配置的。 两个配置项分别是 networkaddress.cache.ttl 和 networkaddress.cache.negtive.ttl ，其默认值分别是 -1（永不失效）和 10（保留 10 秒钟）。 修改方式： 直接修改 java.secury 文件的默认值 在 JAVA 启动时加启动参数 -Dsun.NET.inetaddress.ttl=XXX 来修改默认值。 如果要用 InetAddress 类来解析域名时，一定要采用单例模式，否则会有严重的性能问题，每次都要创建新的类，都要进行完整的域名解析过程。 6. DNS 记录共同实现 DNS 分布式数据库的所有 DNS 服务器存储了资源记录（Resource Record，RR），资源记录提供了主机名到 IP 地址的映射。每个 DNS 回答报文包含了一条或多条资源记录。资源记录是一个包含了下列字段的四元组： 1（Name，Value，Type，TTL） TTL 是该记录的生存时间，它决定了资源记录应当从缓存中删除的时间。如果域名解析改动较频繁，比如使用动态 IP 等，就应该把 TTL 尽量设小； 如果域名解析不是经常改动，一般可将 TTL 适当设置得大一点，以加快主机的访问速度。Name 和 Value 的值取决于 Type。 如果 Type=A，则 Name 是主机名，Value 是该主机对应的 IP 地址。即，一条 A 记录提供了标准的主机名到 IP 地址的映射。 如果 TYpe=NS，则 Name 是个域，比如 csu.edu，而 Value 是知道如何获得该域中主机 IP 地址的权威 DNS 服务器的主机名，比如 dns.csu.edu。这个记录用于沿着查询链来路由 DNS 查询。 如果 Type=CNAME，则 Value 是别名为 Name 的主机对应的规范主机名。该记录能够向查询的主机提供一个主机名对应的规范主机名。 如果 Type=MX，则 Value 是别名为 Name 的邮件服务器的规范主机名。MX 记录允许邮件服务器主机名具有简单的别名。事实上，MX 记录允许一个公司的邮件服务器和 Web 服务器使用相同（别名化）的主机名。为了获得邮件服务器的规范主机名，DNS 客户端应当请求一条 MX 记录；而为了获得其他服务器的规范主机名，DNS 客户应当请求 CNAME 记录。 如果一台 DNS 服务器是用于某特定主机名的权威 DNS 服务器，那么该 DNS 服务器会有一条包含该主机名的类型 A 记录（即使该 DNS 服务器不是其权威 DNS 服务器，它也可能在缓存中包含有一条类型 A 记录）。如果服务器不是用于某主机名的权威服务器，那么该服务器将包含一条类型 NS 记录，该记录对应于包含主机名的域；它还将包括一条类型 A 记录，该记录提供了在 NS 记录的 Value 字段中的 DNS 服务器的 IP 地址。举例来说，假设一台 edu TLD 服务器不是主机 gaia.cs.umass.edu 的权威 DNS 服务器，则该服务器将包含一条包括主机 cs.umass.edu 的域记录，如（umass.edu，dns.umass.edu，NS）；该 edu TLD 服务器还将包含一条类型 A 记录，如（dns.umass.edu，128.119.40.111，A），该记录将名字 dns.umass.edu 映射为一个 IP 地址。 注册一个全新的域名最少要向对应的 TLD 注入 A 型与 NS 型两种记录。 7. DNS 报文 DNS 报文格式前 12 个字节是首部区域，其中有几个字段。第一个字段（标识符）是一个 16 比特的数，用于标识该查询。这个标识符会被复制到对查询的回答报文中，以便让客户用它来匹配发送的请求和接收到的回答。标志字段中含有若干标志。1 比特的“查询/回答”标志位指出报文是查询报文（0）还是回答报文（1）。当某 DNS 服务器是所请求名字的权威 DNS 服务器时，1 比特的“权威的”标志位被置在回答报文中。如果客户（主机或者DNS 服务器）在该 DNS 服务器没有某记录时希望它执行递归查询，将设置 1 比特的“希望递归”标志位。如果该 DNS 服务器支持递归查询，在它的回答报文中会对 1 比特的“递归可用”标志位置位。在该首部中，还有 4 个有关数量的字段，这些字段指出了在首部后的 4 类数据区域出现的数量。 问题区域包含着正在进行的查询信息。该区域包括：①名字字段，指出正在被查询的主机名字；②类型字段，它指出有关该名字的正被询问的问题类型，例如主机地址是与一个名字相关联（类型 A）还是与某个名字的邮件服务器相关联（类型 MX）。 在来自 DNS 服务器的回答中，回答区域包含了对最初请求的名字的资源记录。前面讲过每个资源记录中有 Type（如 A、NS、CNAME 和 MX）字段、Value 字段和 TTL 字段。在回答报文的回答区域中可以包含多条 RR，因此一个主机名能够有多个 IP 地址（例如，就像本节前面讨论的冗余 Web 服务器）。 权威区域包含了其他权威服务器的记录。 附加区域包含了其他有帮助的记录。例如，对于一个 MX 请求的回答报文的回答区域包含了一条资源记录，该记录提供了邮件服务器的规范主机名。该附加区域包含一个类型 A 记录，该记录提供了用于该邮件服务器的规范主机名的 IP 地址。 8. DNS 轮询8.1 原理大多数域名注册商都支持在 DNS 服务器中为同一个域名配置多个 IP 地址（即为一个主机名设置多条A资源记录）。在应答 DNS 查询时，DNS 服务器对每个查询返回所有轮询主机服务器 IP，其顺序取决于 DNS 服务器配置，以此将客户端的访问引导到不同的 IP 上去，从而达到负载均衡的目的。 DNS 服务器一般基于 BIND（Berkeley Internet Name Domain）实现。BIND 将根据 rrset-order 语句定义的次序把配置中设定的所有A记录都发送给客户端，客户端可以使用自己规定的算法从记录中挑选一条。rrset-order 语句是主配置文件中 options 主语句的一条子语句，可以定义固定、随机和轮询的次序。order_spec 定义： 1[ class class_name ][ type type_name ][ name &quot;domain_name&quot;] order ordering 如果没有设定类，默认值为 ANY。如果没有设定类型，默认值为 ANY。如果没有设定名称，默认值为 “*”。合法的排序参数包括： fixed：记录以它们在域文件中的顺序 random：记录以随机顺序被返回 cyclic：记录以环顺序被返回 8.2 实验dig 三次 note.youdao.com： 123456789101112131415161718192021$ dig note.youdao.com; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; note.youdao.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 38905;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;note.youdao.com. IN A;; ANSWER SECTION:note.youdao.com. 1069 IN A 59.111.179.138note.youdao.com. 1069 IN A 59.111.179.135note.youdao.com. 1069 IN A 59.111.179.136note.youdao.com. 1069 IN A 59.111.179.137;; Query time: 23 msec;; SERVER: 10.238.14.2#53(10.238.14.2);; WHEN: Fri Aug 18 16:17:26 2017;; MSG SIZE rcvd: 97 123456789101112131415161718192021$ dig note.youdao.com; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; note.youdao.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33819;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;note.youdao.com. IN A;; ANSWER SECTION:note.youdao.com. 1023 IN A 59.111.179.135note.youdao.com. 1023 IN A 59.111.179.136note.youdao.com. 1023 IN A 59.111.179.137note.youdao.com. 1023 IN A 59.111.179.138;; Query time: 2 msec;; SERVER: 10.238.14.2#53(10.238.14.2);; WHEN: Fri Aug 18 16:18:11 2017;; MSG SIZE rcvd: 97 123456789101112131415161718192021$ dig note.youdao.com; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; note.youdao.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 3771;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;note.youdao.com. IN A;; ANSWER SECTION:note.youdao.com. 1112 IN A 59.111.179.136note.youdao.com. 1112 IN A 59.111.179.137note.youdao.com. 1112 IN A 59.111.179.138note.youdao.com. 1112 IN A 59.111.179.135;; Query time: 2 msec;; SERVER: 10.238.14.2#53(10.238.14.2);; WHEN: Fri Aug 18 16:36:44 2017;; MSG SIZE rcvd: 97 可以看到 ANSWER SECTION 中 IP 的顺序是不同的，并且可以猜测这里使用了 cyclic 的轮询方式。假定客户端（如浏览器）总是选择第一条记录，则每次对 note.youdao.com 的 HTTP 请求会被映射到不同IP上。 8.3 DNS 轮询的用处 负载均衡。如果采用 DNS 轮询技术，将一个域名解析到多台服务器的各自的 IP 地址上，利用浏览器的随机访问对流量进行分摊，则会降低每台服务器的压力，实现均衡负载。故障时保证访问是它的另一个重要应用。从之前的原理的简述我们可以看出，轮询时 DNS 服务器会将所有的 IP 返回给浏览器，浏览器自身的机制会使其在连接出错时继续连接下一个 IP，直到所有 IP 都无法连接或者连接成功为止。这样，只要两台服务器不同时宕机，那么我们几乎可以让网站在线率达到将近百分之百。类似地，在更换服务器地址时，使用另一台服务器做 DNS 轮询进行过渡是一个很好的方法。 CDN 加速。DNS 轮询是 CDN 的基础，通过对于不同访问线路的不同解析，达到最快的访问速度。 内外网的不同访问内容与内容的加速访问。 8.4 DNS 负载均衡的优点 将负载均衡的工作交给 DNS，省去了网站管理维护负载均衡服务器的麻烦。 技术实现比较灵活、方便，简单易行，成本低，使用于大多数 TCP/IP 应用。 对于部署在服务器上的应用来说不需要进行任何的代码修改即可实现不同机器上的应用访问。 服务器可以位于互联网的任意位置。 同时许多 DNS 还支持基于地理位置的域名解析，即会将域名解析成距离用户地理最近的一个服务器地址，这样就可以加速用户访问，改善性能。 8.5 DNS 负载均衡的缺点 目前的 DNS 是多级解析的，每一级 DNS 都可能缓存 A 记录，当某台服务器下线之后，即使修改了 A 记录，要使其生效也需要较长的时间，这段时间，DNS 仍然会将域名解析到已下线的服务器上，最终导致用户访问失败。 不能够按服务器的处理能力来分配负载。DNS 负载均衡采用的是简单的轮询算法，不能区分服务器之间的差异，不能反映服务器当前运行状态，所以其的负载均衡效果并不是太好。 可能会造成额外的网络问题。为了使本 DNS 服务器和其他 DNS 服务器及时交互，保证 DNS 数据及时更新，使地址能随机分配，一般都要将 DNS 的刷新时间设置的较小，但太小将会使 DNS 流量大增造成额外的网络问题。 9. 为什么只有 13 台根服务器？准确说是 “There are 12 organisations maintaining root servers and 13 root server IPs being used”。 Why There Are Only 13 DNS Root Name Servers Because DNS operation relies on potentially millions of other internet servers finding the root servers at any time, the addresses for root servers must be distributable over IP as efficiently as possible. Ideally, all of these IP addresses should fit into a single packet (datagram) to avoid the overhead of sending multiple messages between servers. In IPv4 in widespread use today, the DNS data that can fit inside a single packet is as small as 512 bytes after subtracting all the other protocol supporting information contained in packets. Each IPv4 address requires 32 bytes. Accordingly, the designers of DNS chose 13 as the number of root servers for IPv4, taking 416 bytes of a packet and leaving up to 96 bytes for other supporting data and the flexibility to add a few more DNS root servers in the future if needed.​ 10. 跟踪 DNS 解析过程10.1 nslookup12345678910111213$ nslookup note.youdao.comServer: 10.238.14.2Address: 10.238.14.2#53Non-authoritative answer:Name: note.youdao.comAddress: 59.111.179.135Name: note.youdao.comAddress: 59.111.179.136Name: note.youdao.comAddress: 59.111.179.137Name: note.youdao.comAddress: 59.111.179.138 10.2 dig略 10.3 dig +trace12345678910111213141516171819202122232425262728293031323334353637383940414243$ dig note.youdao.com +trace; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; note.youdao.com +trace;; global options: +cmd. 79850 IN NS m.root-servers.net.. 79850 IN NS a.root-servers.net.. 79850 IN NS g.root-servers.net.. 79850 IN NS l.root-servers.net.. 79850 IN NS e.root-servers.net.. 79850 IN NS c.root-servers.net.. 79850 IN NS b.root-servers.net.. 79850 IN NS d.root-servers.net.. 79850 IN NS h.root-servers.net.. 79850 IN NS j.root-servers.net.. 79850 IN NS i.root-servers.net.. 79850 IN NS k.root-servers.net.. 79850 IN NS f.root-servers.net.;; Received 505 bytes from 10.238.14.2#53(10.238.14.2) in 26 mscom. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.;; Received 493 bytes from 192.203.230.10#53(192.203.230.10) in 184 msyoudao.com. 172800 IN NS ns1.yodao.com.youdao.com. 172800 IN NS ns2.yodao.com.;; Received 107 bytes from 192.43.172.30#53(192.43.172.30) in 367 msnote.youdao.com. 1200 IN A 59.111.179.137note.youdao.com. 1200 IN A 59.111.179.138note.youdao.com. 1200 IN A 59.111.179.135note.youdao.com. 1200 IN A 59.111.179.136;; Received 108 bytes from 61.135.216.245#53(61.135.216.245) in 9 ms]]></content>
      <categories>
        <category>Network，读书笔记</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：TCP]]></title>
    <url>%2F2016%2F09%2F23%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9ATCP%2F</url>
    <content type="text"><![CDATA[1. TCP 连接TCP 被称为面向连接的（connection-oriented），这是因为在一个应用程序可以开始向另一个应用程序发送数据之前，这两个进程必须先相互 “握手”，相互发送某些预备报文段，以建立确保数据传输的参数。作为 TCP 连接建立的一部分，连接的双方都将初始化与 TCP 连接相关的许多 TCP 状态变量。 这种连接状态完全保留在两个端系统中。由于 TCP 协议只在端系统中运行，而不在中间的网络元素中运行，所以中间的网络元素不会维持 TCP 连接状态。事实上，中间路由器对 TCP 连接完全视而不见，它们看到的是数据报，而不是链接。 TCP 连接提供的是全双工服务（full－duplex service）：如果一台主机上的进程 A 与另一台主机上的进程 B 存在一条 TCP 连接，那么应用层数据就可以在从进程 B 流向进程 A 的同时，也可以从进程 A 流向进程 B。TCP 连接也总是点到点（point－to－point）的，即在单个发送方与单个接收方之间的连接。 一旦建立起一条 TCP 连接，两个应用进程之间就可以相互发送数据了。客户进程通过套接字传递数据流。数据一旦到达套接字，它就由客户中运行的 TCP 控制了。TCP 将这些数据引导到该连接的发送缓存（send buffer）里，发送缓存是在三次握手初期设置的缓存之一。接下来 TCP 就会不时从发送缓存里取出一块数据。TCP 可以从缓存中取出并放入报文段中的数据受限于 “最大报文段长度”（Maximum Segment Size，MSS）。MSS 通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即所谓的最大传输单元（Maximum Transmission Unit，MTU））来设置。设置该 MSS 要保证一个 TCP 报文段加上 TCP／IP 首部长度（通常 40 个字节）将适合单个链路层帧。以太网和 PPP 链路层协议都具有 1500 字节的 MTU，因此 MSS 的典型值为 1460 字节。注意到 MSS 是指在报文段里应用层数据的最大长度，而不是指包括 TCP 首部的 TCP 报文段的最大长度。 TCP 为每块客户数据配上一个 TCP 首部，从而形成多个 TCP 报文段（TCP segment）。这些报文段被下传给网络层，网络层将其分别封装在网络层 IP 数据报中。然后这些 IP 数据报被发送到网络中。当 TCP 在另一端接收到一个报文段后，该报文段的数据就被放入该 TCP 连接的接收缓存中。应用程序从此缓存中读取数据流。TCP 连接的每一端都有各自的发送缓存和接收缓存。 可以看出，TCP 连接的组成包括：一台主机上的缓存、变量和与进程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。在这两台主机之间的网络元素（如路由器、交换机和中继器）中，没有为该连接分配任何缓存和变量。 2. TCP 报文段结构 TCP 把数据看成一个无结构的、有序的字节流。一个报文段的序号（sequence number for a segment）是该报文段首字节的字节流编号。确认号是希望从目标主机收到的下一字节的序号。 假定主机 A 已收到一个来自主机 B 的包含字节0-535的报文段，以及另一个包含字节900-1000的报文段。由于某种原因，A 还没有收到字节536-899的报文段。在这个例子中，主机 A 为了重新构建主机 B 的数据流，仍在等待字节536（和其后的字节）。因此，A 到 B 的下一个报文段将在确认号字段中包含536。因为 TCP 只确认该流中至第一个丢失字节为止的字节，所以TCP被称为提供累积确认（cumulative acknowledgment）。实践中，主机 A 将保留失序的字节900~1000，并等待缺少的字节以填补该间隔。 3. 可靠数据传输TCP 在 IP 不可靠的尽力而为服务之上创建了一种可靠数据传输服务（reliable data transfer service）。TCP 的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是无损坏、无间隔、非冗余和按序的数据流；即该字节流与连接的另一方端系统发送出的字节流是完全相同。 TCP 发送方有三个与发送和重传有关的事件： 从上层应用程序接收数据。TCP 从上层应用程序接受数据，将数据封装在一个报文段中，并把该报文段交给 IP。注意到每一个报文段都包含一个序号，这个序号就是该报文段第一个数据字节流编号。还要注意到如果定时器还没有为某些其他报文段而运行，则当报文段被传给 IP 时，TCP 就要启动该定时器。 定时器超时。TCP 通过重传引起超时的报文段（具有最小序号的还未被确认的报文段）来响应超时事件。然后 TCP 重启定时器。 收到 ACK。当该事件发生时，TCP 将 ACK 的值 y 与它的变量 SendBase 进行比较。TCP 状态变量 SendBase是最早未被确认的字节的序号。（因此 SendBase - 1 是指接收方已正确接收到的数据的最后一个字节的序号。）TCP 采用累积确认，所以 y 确认了字节编号在 y 之前的所有字节都已经收到。如果 y &gt; SendBase，则该 ACK 是在确认一个或多个先前未被确认的报文段。因此发送方更新它的 SendBase 变量；如果当前有未被确认的报文段，TCP 还要重新启动定时器。 发送方伪代码： 1234567891011121314151617181920212223242526272829303132333435/* 假设发送方不受 TCP 流量和拥塞控制的限制，来自上层的数据长度小于 MSS，且数据传送只在一个方向进行 */NextSeqNum = InitialSeqNumber SendBase = InitiSeqNumber loop(forever)&#123; switch(event)&#123; event: 接收来自应用程序产生的数据data放入到发送缓存中 if(定时器没有开启) start_timer 将包装后的报文段交付给网络层形成IP数据报 NextSeqNum = NextSeqNum + length（data） break; event:如果定时器超时 发送那个没有确认的序号最小的分组 start_timer break; event:接收到ACK，将ACK中的确认号赋给y if（y &gt; SendBase）&#123; SendBase = y; if(目前还有尚未确认的部分)&#123; start_timer &#125; &#125;else &#123; 开始对y进行计数 if(发送ACK的确认号为y的个数为3个的时候)&#123; 重新发送序号为y的哪一个分组 &#125; &#125; break； &#125; &#125; 超时时间加倍我们现在讨论一下在大多数 TCP 实现中所做的一些修改。首先关注的是在定时器时限过期后超时间隔的长度。在这种修改中，每当超时事件发生时，TCP 重传具有最小序号的还未被确认的报文段。只是每次 TCP 重传时都会将下一次的超时间隔设置为先前值的两倍，而不是用从 EstimatedRTT 和 DevRTT 推算出的值。因此，超时间隔在每次重传后会呈指数型增长。然而，每当定时器在另两个事件（即收到上层应用的数据和收到 ACK）中的任意一个启动时，TimeoutInterval 由最近的 EstimatedRTT 值与 DevRTT 值推算得到。 这种修改提供了一个形式受限的拥塞控制。定时器过期很可能是由网络拥塞引起的，即太多的分组到达源与目的地之间的路径上的一台（或多台）路由器的队列中，造成分组丢失或长时间的排队时延。在拥塞的时候，如果源持续重传分组，会使拥塞更加严重。相反，TCP 采用更文雅的方式，每个发送方的重传都是经过越来越长的时间间隔后进行的。 快速重传超时触发重传存在的问题之一是超时周期可能相对较长。当一个报文段丢失时，这种长超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端的时延。幸运的是，发送方通常可在超时事件发生之前通过注意所谓冗余 ACK 来较好地检测到丢包情况。冗余 ACK（duplicate ACK）就是再次确认某个报文段的 ACK，而发送方先前已经收到对该报文段的确认。下表总结了 TCP 接收方的 ACK 生成策略 [RFC 5681]。当 TCP 接收方收到一个具有这样序号的报文段时，即其序号大于下一个所期望的、按序的报文段，它检测到了数据流中的一个间隔，这就是说有报文段丢失。这个间隔可能是由于在网络中报文段丢失或重新排序造成的。因为 TCP 不使用否定确认，所以接收方不能向发送方发回一个显式的否定确认。相反，它只是对已经接收到的最后一个按序字节数据进行重复数据（即产生一个冗余 ACK）即可。（注意到表中允许接收方不丢弃失序报文段。） 产生 TCP ACK 的建议 [RFC 5681] 事件 TCP 接收方动作 具有所期望序号的按序报文段到达。所有在期望序号及以前的数据都已经被确认 延迟的 ACK。对另一个按序报文段的到达最多等待500ms。如果下一个按序报文段在这个时间间隔内没有到达，则发送一个 ACK 具有所期望序号的按序报文段到达。另一个按序报文段等待 ACK 传输 立即发送单个累积 ACK，以确认两个按序报文段 比期望序号大的失序报文段到达。检测出间隔 立即发送冗余 ACK，指示下一个期待字节的序号（其为间隔的低端序号） 能部分或完全填充接受数据间隔的报文段到达 倘若该报文段起始于间隔的低端，则立即发送 ACK 因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余 ACK。如果 TCP 发送方接收到对相同数据的3个冗余 ACK，它把这当作一种指示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。一旦收到3个冗余 ACK，TCP 就执行快速重传（fast retransmit）[RFC 5681]，即在该报文段的定时器过期之前重传丢失的报文段。 是回退 N 步还是选择重传TCP是GBN协议和SR协议的混合体： TCP 发送方仅需要维持已发送过但未被确认的最小序号和下一个要发送的字节的序号就可以了，这一点和 GBN 一致。 GBN 定时器过期之后发送方会重传未被确认的最小序号之后的数据段，这样很可能会造成重发大量分组，导致占用带宽，分组冗余。TCP 和 SR 相似，用的是选择重发，只发未被确认的最小序号的分组。 4. 流量控制一条 TCP 连接每一侧主机都为该连接设置了接收缓存。当该 TCP 连接收到正确、按序的字节后，它就将数据放入接收缓存。相关联的应用进程会从该缓存中读取数据，但不必是数据刚已到达就立即读取。事实上，接收方应用也许正忙于其他业务，甚至要过很长时间后采取读取数据。如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。 TCP 为它的应用程序提供了流量控制服务（flow-control service）以消除发送方使接收方缓存溢出的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。 TCP 通过让发送方维护一个称为接收窗口（receive window）的变量来提供流量控制。通俗地说，接收窗口用于给发送方一个指示——该接收方还有多少可用的缓存空间。因为 TCP 是全双工通信，在连接两端的发送方都各自维护一个接收窗口。现假设主机 A 通过一条 TCP 连接向主机 B 发送一个大文件。主机 B 为该连接分配了一个接收缓存，并用 RevBuffer 来表示其大小，主机 B 上的应用进程不时地从该缓存中读取数据。定义以下变量： LastByteRead：主机 B 上的应用进程从缓存读出的数据流的最后一个字节的编号。 LastByteRcvd：从网络中到达的并且已放入主机 B 接收缓存中的数据流的最后一个字节的编号。 由于 TCP 不允许已分配的缓存溢出，下式必须成立 $$LastByteRcvd - LastByteRead \leq RcvBuffer$$ 接收窗口用 rwnd 表示，根据缓存可用空间的数量来设置： $$rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]$$ 由于该空间是随着时间变化的，所以 rwnd 是动态的。主机 B 通过把当前的 rwnd 值放入它发给主机 A 的报文段接口窗口字段中，通知主机 A 它在该连接的缓存中海有多少可用空间。开始时，主机 B 设定 rwnd = RcvBuffer。注意到为了实现这一点，主机 B 必须跟踪几个与连接有关的变量。 主机 A 轮流跟踪两个变量，LastByteSent 和 LastByteAcked，这两个变量的意义很明显。注意到这两个变量之间的差 LastByteSent - LastByteAcked，就是主机 A 发送到连接中但未被确认的数据量。通过将未被确认的数据量控制在 rwnd 以内，就可以保证主机 A 不会使主机 B 的接收缓存溢出。因此，主机 A 在该连接的整个生命周期须保证： $$LastByteSent - LastByteAcked \leq rwnd$$ TCP 规范中要求：当主机 B 的接收窗口为 0 时，主机 A 继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文段里将包含一个非 0 的 rwnd 值，以此通知主机 A 接收缓存有新的空间了。 UDP 并不提供流量控制。进程每次从缓存中读取一个完整的报文段。如果进程从缓存中读取报文段的速度不够快，那么缓存将会溢出，并且将丢失报文段。 5. TCP 连接管理建立连接 第一步：客户端的 TCP 首先向服务端的 TCP 发送一个特殊的 TCP 报文段。报文段中不包含应用层数据。但是在报文段的首部中的一个标志位（即 SYN 比特）被值为 1。因此，这个特殊报文段通常被称为 SYN 报文段。另外，客户端会随机地选择一个初始序号（client_isn），并将此编号放置于该起始的 TCP SYN 报文段的序号字段中。该报文段会被封装在一个 IP 数据报中，并发送给服务器。 第二步：一旦包含 TCP SYN 报文段的 IP 数据报到达服务器主机，服务器会从该数据报中提取出 TCP SYN 报文段，为该 TCP 连接分配 TCP 缓存和变量，并向客户 TCP 发送允许连接的报文段。这个允许连接的报文段也不包含应用层数据。但是，在报文段的首部却包含 3 个重要的信息。首先，SYN 比特被置为 1。其次，该 TCP 报文段首部的确认号字段被置为 client_isn + 1。最后，服务器选择自己的初始序号（server_isn），并将其放置到 TCP 报文段首部的序号字段中。这个允许连接的报文段实际上表明了：“我收到了你发起建立连接的 SYN 分组，该分组带有初始序号 client_isn，我同意建立该连接。我自己的初始序号是server_isn。”该允许连接的报文段有时被称为 SYNACK 报文段（SYNACK segment）。 第三步：在接收到 SYNACK 报文段后，客户端也要给该连接分配缓存和变量。客户主机向服务器发送另一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认（该客户通过将值 server_isn + 1 放置到 TCP 报文段首部的确认字段中来完成此项工作）。因为连接已经建立了，所以该 SYN 比特被置为0。该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据。 一旦完成这个 3 个步骤，客户和服务器主机就可以相互发送包括数据的报文段了。在以后每一个报文段中，SYN 比特都将被置为 0。 关闭连接参与一条 TCP 连接的两个进程中的任何一个都能终止该连接。当连接结束后，主机中的资源（缓存和变量）都将被释放。 第一步：客户应用进程发出一个关闭连接命令。这会引起客户 TCP 向服务器进程发送一个特殊的 TCP 报文段，其首部中的一个标志位即 FIN 比特被置为 1。 第二步：当服务器接收到该报文段后，就向发送方回送一个确认报文段。 第三步：服务器发送它自己的终止报文段，其 FIN 比特被置为 1。 第四步：该客户对这个服务器的终止报文段进行确认。 状态机客户 TCP 开始时处于 CLOSED（关闭）状态。客户的应用程序发起一个新的 TCP 连接。这引起客户中的 TCP 向服务器中的 TCP 发送一个 SYN 报文段。在发送 SYN 报文段后，客户TCP进入了 SYN_SENT 状态。 当客户 TCP 处在 SYN_SENT状态时，它等待来自服务器 TCP 的对客户所发报文段进行确认且 SYN 比特被置为1的一个报文段。收到这样一个报文段之后，客户 TCP 进入 ESTABLISHED（已建立）状态。当处在 ESTABLISHED 状态时，TCP 客户就能发送和接收包含有效载荷数据的 TCP 报文段了。 假设客户应用程序决定要关闭该连接。（注意服务器也能选择关闭该连接。）这引起客户 TCP 发送一个带有 FIN 比特被置为1的 TCP 报文段，并进入 FIN_WAIT_1 状态。当处在 FIN_WAIT_1 状态时，客户TCP等待一个来自服务器的带有确认的 TCP 报文段。当它收该报文段时，客户 TCP 进入 FIN_WAIT_2 状态。当处在 FIN_WAIT_2 状态时，客户等待来自服务器的 FIN 比特被置为1的另一个报文段；当接收到该报文段后，客户 TCP 对服务器的报文段进行确认，并进入 TIME_WAIT 状态。假定 ACK 丢失，TIME_WAIT 状态使 TCP 客户重传最后的确认报文。TIME_WAIT 状态持续 2MSL（Maximum Segment Lifetime） 后，连接就正式关闭，客户端所有资源（包括端口号）将被释放。 客户 TCP 经历的典型的 TCP 状态序列 服务器端 TCP 经历的典型的 TCP 状态序列 向运行在本地8888端口的一个应用程序发送 HTTP 请求的 TCP 连接过程： 6. SYN 洪泛攻击在 TCP 三次握手中，服务器为了响应一个收到的 SYN，分配并初始化连续变量和缓存。然后服务器发送一个 SYNACK 进行响应，并等待来自客户的 ACK 报文段。如果某客户不发送 ACK 来完成该三次握手的第三步，最终（通常在一分多钟之后）服务器将终止该半连接并回收资源。 这种 TCP 连接管理协议为经典的 DoS（deny of service）攻击即 SYN 洪泛攻击（SYN flood attack）提供了环境。在这种攻击中，攻击者发送大量的 TCP SYN 报文段，而不完成第三次握手的步骤。随着这种 SYN 报文段纷至踏来，服务器不断为这些半开连接分配资源（但从未使用），导致服务器的连接资源被消耗殆尽。 现在有一种有效的防御系统，称为 SYN cookie，它们被部署在大多数主流操作系统中。SYN cookie 以下列方式工作： 当服务器接收到一个 SYN 报文段时，它并不知道该报文段是来自一个合法的用户，还是一个 SYN 洪泛攻击的一部分。因此服务器不会为该报文段生成一个半开连接。相反，服务器生成一个初始 TCP 序列号，该序列号是 SYN 报文段的源和目的 IP 地址与端口号以及仅有该服务器知道的秘密数的一个复杂函数（散列函数）。这种精心制作的初始序列号被称为 “cookie”，服务器则发送具有这种特殊初始序列号的 SYNACK 分组。重要的是，服务器并不记忆该 cookie 或任何对应于 SYN 的其他状态信息。 如果客户是合法的，则它将返回一个 ACK 报文段。当服务器收到该 ACK，需要验证该 ACK 是与前面发送的某些 SYN 相对应的。服务器将使用在 SYNACK 报文段中的源和目的地 IP 地址与端口号（它们与初始的 SYN 中的相同）以及秘密数运行相同的散列函数。如果该函数的结果加 1 与在客户的 SYNACK 中的确认（cookie）值相同的话，服务器认为该 ACK 对应于较早的 SYN 报文段，因此它是合法的。服务器则生成一个具有套接字的全开的连接。 如果客户没有返回一个 ACK 报文段，则初始的 SYN 并没有对服务器产生危害，因为服务器没有为它分配任何资源。 7. TCP 拥塞控制TCP 必须使用端到端拥塞控制而不是使用网络辅助的拥塞控制，因为 IP 层不向端系统提供显式的网络拥塞反馈。TCP 采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。 TCP 连接的每一端都是由一个接收缓存、一个发送缓存和几个变量组成。运行在发送方的 TCP 拥塞控制机制跟踪一个额外的变量，即拥塞窗口（congestion window），拥塞窗口表示为 cwnd，它对一个 TCP 发送方能向网络中发送流量的速率进行了限制：在一个发送方中未被确认的数据量不会超过cwnd和rwnd中的最小值。特别是，在一个发送方中未被确认的数据量不会超过 cwnd 与 rwnd 中的最小值，即 $$LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}$$ 通过约束发送方中未被确认的数据量，间接限制了发送方的发送速率。考虑一个丢包和发送时延均可以忽略不计的连接。在每个往返时间 (RTT)的起始点，上面的限制条件允许发送方向该连接发送 cwnd 个字节的数据，在该 RTT 结束时发送方接收对数据的确认报文。因此，该发送方的发送速率大概为 cwnd/RTT 字节/秒。通过 调节 cwnd 的值，发送方因此能调整它向连接发送数据的速率。 TCP 拥塞控制算法包括 3 个主要部分：（1）慢启动（slow-start）；（2）拥塞避免；（3）快速恢复。慢启动和拥塞避免是 TCP 的强制部分，两者的差异在于对收到的 ACK 做出反应时增加 cwnd 长度的方式。 7.1 慢启动在慢启动状态，cwnd 的值以 1 个 MSS 开始并且每当传输的报文段首次被确认就增加一倍 MSS。这个过程每过一个 RTT，发送速率就翻番。因此，TCP 发送速率起始慢，但在慢启动阶段以指数增长。 指数增长的结束：首先，如果存在一个由超时指示的丢包事件（即拥塞），TCP 发送方将 cwnd 设置为 1 并重新开始慢启动过程。它还将第二个状态变量的值 ssthread（慢启动阈值）设置为 cwnd/2，即当检测到拥塞时将 ssthread 置为拥塞窗口值的一半。其次，当达到或超过 ssthread 的值时，进入拥塞避免模式。最后，如果检测到 3 个冗余 ACK，执行快速重传并进入快速恢复状态。 7.2 拥塞避免一旦进入拥塞避免模式，cwnd 的值大约是上次遇到拥塞时的值的一半。此后，每个 RTT 只将 cwnd 的值增加一个 MSS。 7.3 快速恢复对于引起进入快速恢复的每个冗余 ACK，cwnd 增加一个MSS。当最后一个 ACK 到达时，进入拥塞避免。如果出现超时事件，快速恢复在执行如同在慢启动和拥塞避免中相同的动作后，迁移到慢启动状态：当丢包事件发生后，cwnd 被设置为一个MSS，并且 ssthread 的值被设置为 cwnd 的一半。]]></content>
      <categories>
        <category>Network</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：网络层]]></title>
    <url>%2F2016%2F08%2F23%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9A%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[1. 转发和路由选择网络层需要有两种功能： 转发。当一个分组到达路由器的一条输入链路时，路由器必须将该分组移到适当的输出链路。 路由选择。当分组从发送方流向接收方时，网络层必须决定这些分组所采用的路由或路径。计算这些路径的算法被称为路由选择算法（routing algorithm）。 每台路由器都有一张转发表（forwarding table）。路由器通过检查到达分组首部字段的值来转发分组，然后使用该值在该路由器的转发表中国索引查询。存储在转发表项中的该首部的值指出了该分组将被转发的路由器的输出链路接口。分组首部中的该值可能是该分组的目的地址或该分组所属连接的指示，这取决于网络层协议。 2. 路由器结构 输入端口：它要执行将一条输入的物理链路端接到路由器的物理层功能。它也要执行需要与位于入链路远端的数据链路层功能交互的数据链路层功能。还要完成查找与转发功能，以便转发到路由器交换结构部分的分组能出现在适当的输出端口。控制分组从输入端口转发到选路处理器。在路由器中，多个端口经常被集中到路由器中的一块线路卡（line card）上。 交换结构：交换结构将路由器的输入端口连接到它的输出端口。交换结构完全包容在路由器中。 输出端口：输出端口存储经过交换结构转发给它的分组，并将这些分组传输到输出链路。因此，输出端口执行与输入端口顺序相反的数据链路层和物理层功能。当一条链路时是双向（承载两个方向的流量）链路时，与链路相连的输出端口通常与输入端口在同一线路卡上成对出现。 路由选择处理器：路由选择处理器执行路由选择协议，维护路由选择表以及连接的链路状态信息，并执行网络管理功能。 3. 数据报网络在数据报网络中，每当一个端系统要发送分组，它就为该分组加上目的端系统的地址，然后将分组推进网络中。 当分组从源到目的地传输，它通过一系列路由器传递。这些路由器中的每台都使用分组的目的地址来转发该分组。特别是，每台路由器有一个将目的地址映射到链路接口的转发表；当分组到达路由器时，路由器使用该分组的目的地址在转发表中查找适当的输出链路接口。然后路由器有意将该分组向该输出链路接口转发。 路由器的输入端口和输出端口处都能够形成分组队列，当无内存可用于存储到达的分组时将会出现丢包（packet loss）。 4. 数据报格式 版本号：这 4 比特规定了数据报的 IP 协议版本。通过查看版本号，路由器可确定如何解释 IP 数据报的剩余部分。不同的 IP 版本使用不同的数据报格式。目前使用的 IP 版本为 IPv4。 首部长度：因为一个 IPv4 数据报可包含一些可选项（包含在 IPv4 数据报首部中），故需要用这 4 比特来确定 IP 数据报中的数据部分实际从哪里开始。大多数 IP 数据报不包含可选项，所以一般的 IP 数据报都有 20 字节的首部。 服务类型：服务类型（TOS）比特用来使不同类型的 IP 数据报能相互区别开来。 数据报长度：这是 IP 数据报的总长度，（首部加上数据），以字节计。因为该字段长为 16 比特，所以 IP 数据报的理论最大长度为 65535 字节。然而，数据报很少有超过 1500 字节的。 标识、标志、片偏移：该三个字节与所谓 IP 分片有关，（IPv6不允许在路由器上分片） TTL：TTL 字段用来确保数据报不会永远在网络中循环。每当数据报经过一台路由器时，该字段的值减1。若 TTL 字段减为 0，则该数据报必须丢弃。 协议：该字段仅在一个 IP 数据报到达其最终目的时才会用到。该字段值指明了 IP 数据报的数据分部应交给哪个运输层协议。 值为 6 表明数据部分要交给 TCP，而值为 17 表明数据要交给 UDP。 首部检验和：首部检验和用于帮助路由器检测收到的 IP 数据报中的比特错误。首部检验和是这样计算的：将首部中的每两个字节当作一个数，用反码运算对这些数求和。该和的反码（被称为因特网检验和）存放在检验和字段中。路由器要对每个收到的 IP 数据报计算其首部检验和，并根据数据报首部中携带的检验和与计算得到的检验和是否一致，来检查是否出错。路由器一般会丢弃检测出错误的数据报。注意到在每台路由器上必须重新计算检验和并存放到原处，因为 TTL 字段以及可能的选项字段会改变。注意到在 IP 层只对 IP 首部计算了检验和，而 TCP/UDP 检验和是对整个 TCP/UDP 报文段进行的。其次，TCP/UDP 与 IP 不一定都必须属于同一个协议栈。 源和目的 IP 地址：当源主机产生一个数据报时，它在源 IP 字段中插入它的 IP 地址，在目的 IP 地址字段中插入其最终目的地的地址。通常源主机通过 DNS 查找来决定目的地址。 选项：选项字段允许IP首部被扩展。首部选项意味着很少使用，因此决定对每个数据报首部不包括选项字段中的信息，这样能够节约开销。 数据（有效载荷）：在大多数情况下，IP 数据报中的数据字段包含要交付给目的地的运输层报文段（TCP 或 UDP）。然而，该数据字段也可承载其他类型的数据，如 ICMP 报文。 5. IP 数据报分片一个链路层帧能承载的最大数据量叫做最大传输单元（Maximum Transmission Unit，MTU）。因为每个 IP 数据报封装在链路层帧中从一台路由器传输到下一台路由器，故链路层协议的 MTU 严格地限制着 IP 数据报的长度。对 IP 数据报长度具有严格限制并不是主要问题。问题在于在发送方与目的地路径上的每段链路可能使用不同的链路层协议，且每种协议可能具有不同的 MTU。 当一台目的主机从相同源收到一系列数据报时，它需要确定这些数据报中的某些是否是一些原来较大的数据报分片。如果某些数据报是片的话，则它必须进一步确定何时收到了最后一片，并且如何将这些接收到的片拼接到一起以形成初始的数据报。为了让目的主机执行这些重新组装任务，IPv4 的设计者将标识、标志和片位移字段放在 IP 数据报首部中。当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时再贴上标识号。发送主机通常将为它发送给的每个数据报的标识号加 1。当某路由器需要对一个数据报分片时，形成的每个数据报（即片）具有初始数据报的源地址、目的地址与标识号。当目的地从同一发送主机收到一系列数据报时，它能够检查数据报的标识号以确定哪些数据报实际上是同一较大数据报的片。由于 IP 是一种不可靠的服务，一个或多个片可能永远到达不了目的地。因为这种原因，为了让目的主机绝对地相信它已收到了初始数据报的最后一个片，最后一个片的标志比特被设为 0，而所以其他片的标志比特被设为 1。另外，为了让目的主机确定是否丢失了一个片（且能按正确的顺序重新组装片），使用偏移字段指定该片应该放在初始 IP 数据报的哪个位置。 除了最后一片的所有初始有效载荷数据的数量应当是 8 字节的倍数，并且偏移值应当被规定以 8 字节块为单位。 6. IPv4编址因特网的地址分配策略被称为无类别域间路由选择（Classless Interdomain Routing， CIDR）。CIDR 将子网寻址的概念一般化了。因为对于子网寻址，32 比特的 IP 地址被划分为两部分，并且也具有点分十进制数形式 a.b.c.d/x，其中 x 指示了地址的第一部分中的比特数。形式为 a.b.c.d/x 的地址的 x 最高比特构成了 IP 地址的网络部分，并且经常被称为该地址的前缀。 在 CIDR 被采用之前，IP 地址的网络部分被限制为长度为8、16 或 24 比特，这是一种称为分类编址的编址方案，这是因为具有 8、16、24 比特子网地址的子网分别被称为 A、B 和 C 类网络。 当一台主机发出一个目的地址为 255.255.255.255 的数据报时，该报文会交付给同一个网络中的所有主机。 7. DHCP动态主机配置协议（Dynamic Host Configuration）DHCP 允许主机自动获取（被分配）一个 IP 地址。网络管理员能够配置 DHCP，以使某给定主机每次与网络连接时能够得到一个相同的 IP 地址，或者某主机将被分配一个临时的 IP 地址，该地址在每次与网络连接时也许是不同的。除了主机 IP 地址分配外，DHCP 还允许一台主机得知其他信息，例如它的子网掩码、它的第一跳路由器地址（常称为默认网关）与它的本地 DNS 服务器的地址。 DHCP 协议是一个 4 个步骤的过程： DHCP 服务器发现。一台新到的主机的首要任务是发现一个要与其交互的 DHCP 服务器。这可通过一个 DHCP 发现报文来完成，客户在 UDP 分组中向端口 67 发送该发现报文。DHCP 客户生成包含 DHCP 发现报文的 IP 数据报，其中使用广播目的地址 255.255.255.255 并且使用“本主机”源地址0.0.0.0。DHCP客户将该数据报传递给链路层，链路层然后将该帧广播到所有与该子网连接的子网。 DHCP 服务器提供。DHCP 服务器收到一个 DHCP 发现报文时，用一个 DHCP 提供报文对客户做出响应，仍然使用 IP 广播地址 255.255.255。每台服务器提供的报文包含有收到的发现报文的事务 ID、向客户推荐的 IP 地址、网络掩码以及 IP 地址租用期，即 IP 地址有效的时间量。 DHCP 请求。新到达的客户从一个或多个服务器提供中选择一个，并向选中的服务器提供一个 DHCP 请求报文进行响应，回显配置参数。 DHCP ACK。服务器用 DHCP ACK 报文对 DHCP 请求报文进行响应，证实所要求的参数。 仅最后两步是必要的。 8. NATNAT 能使路由器对于外界来说甚至不像一台路由器。NAT 路由器对外界的行为反过来就如同一个具有单一 IP 地址的单一设备。技巧就是使用在 NAT 路由器上的一张 NAT 转换表，并且在表项中包含了端口号及其 IP 地址。 假设一个用户坐在家庭网络主机 10.0.0.1 旁，请求 IP 地址为128.119.40.186 的某台 Web 服务器（端口 80）上的一个 Web 页面。主机 10.0.0.1 为其指派了（任意）源端口号 3345 并将该数据包发送到 LAN 中。NAT 路由器收到该数据报，为该数据包生成一个新的源端口号 5001，将源 IP 替代为其广域网一侧接口的 IP 地址 138.76.29.7，且将源端口 3345 更换为新端口 5001。当生成一个新的源端口号时，NAT 路由器可选择任意一个当前未在 NAT 转换表中的源端口号。（注意到因为端口号字段为 16 比特长，NAT 协议可支持超过 60000 个并行使用路由器广域网一侧 IP 地址的连接！）路由器中的 NAT 也在它的 NAT 转换表中增加一表项。Web 服务器并不知道刚到达的包含 HTTP 请求的数据报已被 NAT 路由器进行了改装，它会发回一个响应报文，其目的地址是 NAT 路由器的 IP 地址，其目的端口是 5001。当该报文到达 NAT 路由器时，路由器使用目的 IP 地址与目的端口号从 NAT 转换表中检索出家庭浏览器使用的适当 IP 地址（10.0.0.1）和目的端口号（3345）。于是，路由器改写该数据报的目的 IP 地址与目的端口号，并向家庭网络转发该数据报。 9. ICMPICMP 由 [RFC 792] 定义，被主机和路由器用来彼此沟通网络层的信息。ICMP 最电影的用途是差错报告。例如，当运行一个 Telnet、FTP 或 HTTP 会话时，“目的网络不可达”之类的错误报文就是在 ICMP 中产生的。在某个位置，IP 路由器不能找到一条路径，以通往 Telnet、FTP 或 HTTP 应用所指定的主机。该路由器就会向源主机创建和发出一个类型为 3 的 ICMP 报文以指示该错误。 ICMP 通常被认为是 IP 的一部分，但从体系结构上讲它是位于 IP 之上的，因为 ICMP 报文是承载在 IP 分组中的。 ping 程序发送一个 ICMP 类型 8 编码 0 的报文到指定主机。看到该回显（echo）请求，目的主机发回一个类型 0 编码 0 的 ICMP 回显回答。 为了判断源和目的地之间所有路由器的名字和地址，源主机中的 Traceroute 向目的主机发送一系列普通的 IP 数据报。这些数据报携带了具有一个不可达 UDP 端口号的 UDP 报文段。第一个数据报的 TTL 为 1，第二个的 TTL 为 2，以此类推。该源主机也为每个数据报启动定时器。当第 n 个数据报到达第 n 台路由器时，第 n 台路由器观察到这个数据报的 TTL 正好过期。根据 IP 协议规则，路由器丢弃该数据报并发送一个 ICMP 告警报文给源主机（类型 11 编码 0）。该告警报文包含了路由器的名字与它的 IP 地址。当该 ICMP 报文返回源主机时，源主机从定时器得到往返时延，从 ICMP 报文中得到第 n 台路由器的名字与 IP 地址。这些数据报之一将最终沿着这条路到达目的主机。因为该数据报包含了一个具有不可达端口号的 UDP 报文段，该目的主机将向源主机发送一个端口不可达的 ICMP 报文。当源主机收到这个特别的 ICMP 报文时，知道它不需要再发送另外的探测分组。（标准的 Traceroute 程序实际上使用相同的 TTL 发送 3 个一组的分组；因此 Traceroute 输出对每个 TTL 提供了 3 个结果。）]]></content>
      <categories>
        <category>Network</category>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：数据链路层]]></title>
    <url>%2F2016%2F08%2F15%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[1. ARP 工作原理每台主机或路由器在其内存中具有一个 ARP 表，这张表包含 IP 地址到 MAC 地址的映射关系。该 ARP 表也包含一个 TTL 值，它指示了从表中删除每个映射的时间。这张表不必为该子网上的每台主机和路由器都包含一个表项；某些可能从来没有进入到该表中，某些可能已经过期。 假设同一个子网下的 222.222.222.220 要向 222.222.222.222 发送数据报。在这种情况下，发送方用 ARP 协议来解析这个地址。首先，发送方构造一个称为 ARP 分组的特殊分组。一个 ARP 分组有几个字段，包括发送和接收 IP 地址以及 MAC 地址。ARP 查询和响应分组都具有相同的格式。ARP 查询分组的目的是询问子网上其他所有主机和路由器，以确定对应于要解析的 IP 地址的那个 MAC 地址。 222.222.222.220 向它的适配器传递一个 ARP 查询分组，并且指示适配器应该用 MAC 广播地址（即 FF:FF:FF:FF:FF:FF）来发送这个分组。适配器在链路层帧中封装这个 ARP 分组，用广播地址作为帧的目的地址，并将该帧传输进子网中。包含该 ARP 查询的帧能被子网上的所有其他适配器收到（交换器转发到所有非来源端口），并且（由于广播地址）每个适配器都把在该帧中的 ARP 分组向上传输到 ARP 模块。这些 ARP 模块中的每个都检查它的 IP 地址是否与 ARP 分组中的目的 IP 地址相匹配。与之匹配的一个给查询主机发送回一个带有所希望映射的响应 ARP 分组。然后查询主机222.222.222.220能够更新它的 ARP 表，并发送它的 IP 数据报，该数据报封装在一个链路层帧中，并且该帧的目的 MAC 就是对先前 ARP 请求进行响应的主机或路由器的 MAC 地址。 关于 ARP 协议有两件事情需要注意。首先，查询 ARP 报文是在广播帧中发送的，而响应 ARP 报文是在一个标准帧中发送。其次，ARP 是即插即用的，这就是说，一个 ARP 表是自动建立的。并且如果某主机与子网断开连接，它的表项最终会从留在子网中的结点的表中删除掉。 最好把 ARP 看成是跨越链路层和网络层边界两边的协议。 链路层帧在路由器之间转发时，源路由器会用自己的 MAC 地址替换帧的 源 MAC 地址，用下一跳路由器的 MAC 地址替换帧的目的 MAC 地址。 2. 交换机转发和过滤过滤（filtering）是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能，转发（forwarding）是决定一个帧应该被导向哪个接口，并把该帧接口移动到那些接口的交换机功能。交换机的过滤和转发借助于交换机表完成。交换机表中的一个表项包含： 一个MAC地址； 通向该地址的交换机接口； 表项放置在表中的时间； 为了理解交换机过滤和转发的工作过程，假定目的地址为 DD-DD-DD-DD-DD-DD 的帧从交换机接口 x 口到达，交换机用 MAC 地址 DD-DD-DD-DD-DD-DD 索引它的表。有 3 种可能的情况： 表中没有对于 DD-DD-DD-DD-DD-DD 的表项。在这种情况下，交换机向除接口 x 外的所有接口前面的输出缓存转发该帧的副本。换言之，如果没有对于目的地址的表项，交换机广播该帧。 表中有一个表项将 DD-DD-DD-DD-DD-DD 与接口 x 联系起来。在这种情况下，该帧从包括适配器 DD-DD-DD-DD-DD-DD 的局域网网段到来。无需将该帧转发到任何其他接口，交换机通过丢弃该帧执行过滤功能即可。 表中有一个表项将 DD-DD-DD-DD-DD-DD 与接口 $ y \neq x$ 联系起来。在这种情况下，该帧需要被转发到与接口 y 相连的局域网网段。交换机通过将该帧放到接口 y 前面的输出缓存完成转发功能。 3. RARP反向地址转换协议（RARP）允许局域网的物理机器从网关服务器的 ARP 表或者缓存上请求其 IP 地址。网络管理员在局域网网关路由器里创建一个表以映射物理地址（MAC）和与其对应的 IP 地址。当设置一台新的机器时，其 RARP 客户机程序需要向路由器上的 RARP 服务器请求相应的 IP 地址。假设在路由表中已经设置了一个记录，RARP 服务器将会返回 IP 地址给机器，此机器就会存储起来以便日后使用。RARP 可以使用于以太网、光纤分布式数据接口及令牌环 LAN。 4. DHCP 和 RARP 的区别RARP 在功能上有点类似于 DHCP 协议，确切的说 DHCP 是 BOOTP 协议的升级，而 BOOTP 在某种意义上又是 RARP 协议的升级。BOOTP 和 RARP 的区别在于 RARP 是在数据链路层实现的，而 BOOTP 是在应用层实现的，作为 BOOTP 的升级版 DHCP 也是在应用层实现的。这种实现层面的差别也从 RARP 和 BOOTP/DHCP 的报文封装格式的差别上体现出来了，RARP 直接封装在以太网帧中，协议类型置为0x0800以标识这个报文是 ARP/RARP 报文，BOOTP/DHCP 报文是直接封装在 UDP 报文中，作为 UDP 的数据段出现的。 从功能上说，RARP 只能实现简单的从 MAC 地址到 IP 地址的查询工作，RARP server 上的 MAC 地址和 IP 地址是必须事先静态配置好的。但 DHCP 却可以实现除静态分配外的动态IP地址分配以及IP地址租期管理等等相对复杂的功能。 RARP 是早期提供的通过硬件地址获取 IP 的解决方案，但它有自己的局限性，比如 RARP 客户与 RARP 服务器不在同一网段，中间有路由器等设备连接，这时候利用 RARP 就显得无能为力，因为 RARP 请求报文不能通过路由器，BOOTP/DHCP 提供了很好的解决方法。 RARP、BOOT 和 DHCP 都是动态学习 IP 地址的协议。起初，客户端主机要发送一个广播以启动发现进程，有一台专门的服务器负责监听这些请求并提供 IP 地址给客户端主机。 RARP 使用的是和 ARP 相同的消息，只不过它的消息中列出的目标 MAC 地址是其自己的 MAC 地址，而目标 IP 地址是 0.0.0.0。预先配置好的 RARP 服务器（必须处于客户端同一子网中）接收请求并进行查询。如果目标 MAC 地址匹配到，RARP 服务器就发送 ARP 响应（包含配置的 IP 地址在其源 IP 地址字段中）。]]></content>
      <categories>
        <category>Network</category>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《计算机网络：自顶向下方法》：流水线可靠数据传输]]></title>
    <url>%2F2016%2F08%2F11%2F%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95%E3%80%8B%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[1. 流水线技术流水线可靠数据传输协议允许发送方发送多个分组而无需等待确认。流水线技术对可靠数据传输协议带来如下影响： 必须增加序号范围，因为每个输送中的分组（不计算重传的）必须有一个唯一的序号，而且也许有多个在输送中未确认的报文。 协议的发送方和接受端也许必须缓存多个分组。发送方最低限度应当能缓存那些已发送但没有确认的分组。接收方也需要缓存那些已正确接受的分组。 所需序号范围和对缓存的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。解决流水线差错恢复有两种基本方法是：回退N步（Go－Back－N，GBN）和选择重传（Selective Repeat，SR）。 2. 回退N步在回退 N 步协议中，允许发送方发送多个数组（当有多个分组可用时）而不需要等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。 上图显示了发送方看到的 GBN 协议的序号范围。如果我们将基序号（base）定义为最早的未确认分组的序号，将下一个序号（nextseqnum）定义为最小的未使用序号（即下一个待发分组的序号），则可将序号范围分割成 4 段。在 [0, base-1] 段内的序号对应于已经发送并确认的分组。[base, nextseqnum-1] 段对应已经发送但未被确认的分组。[nextseqnum, base+N-1] 段内的序号能用于那些要立即发送的分组，如果有数据来自于上层的话。最后，大于或等于 base+N 的序号是不能使用的，直到当前流水线中未确认的分组（特别是序号为 base 的分组）已得到确认为止。 在上图中，我们可以把 [base, base + N-1] 看做一个长度为 N 的窗口。随着协议的运行，该窗口在序号空间向前滑动。因此，N 常被称为窗口长度（window size），GBN 协议也常被称为滑动窗口协议（sliding-window protocol）。至于为什么需要限制 N 的范围，是因为这是流量控制的方法之一。 在实践中，一个分组的序号承载在分组首部的一个固定长度的字段中。如果分组序号字段的比特数是 k，则该序号范围是 [0, 2^k - 1]。在一个有限的序号范围内，所有涉及序号的运算必须使用模 2^k 运算。 下图是GBN 协议发送方扩展 FSM 描述： 如上描述，GBN 协议发送方必须响应三种类型的事件： 上层的调用。当上层调用 rdt_send() 时，发送方首先检查发送窗口是否已满，即是否有 N 个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送，并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。然后上层可能会过一会儿再试。在实际实现中，发送方更可能缓存这些数据，或者使用同步机制（如一个信号量或标志）允许上层在仅当窗口不满时才调用 rdt_send()。 收到一个ACK。在 GBN 协议中，对序号为 n 的分组的确认采取累积确认（cumulative acknowledgment）的方式，表明接收方已正确接收到序号为 n 的以前且包括 n 在内的所有分组。 超时事件。协议的名字“回退 N 步”来源于出现丢失和时延过长分组时发送方的行为。就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。如果出现超时，发送方重传所有已发送但未被确认过的分组。上图中发送方仅使用一个定时器，如果收到了一个 ACK，但仍有已发送但未被确认的分组，则定时器被重新启动。如果没有已发送但未被确认的分组，该定时器被终止。 下图是 GBN 协议接收方扩展 FSM 描述： 在 GBN 中，接收方的动作也很简单。如果一个序号为 n 的分组被正确接收到，并且按序（即上次交付给上层的数据是序号为 n - 1 的分组），则接收方为分组 n 发送一个 ACK，并将该分组中的数据部分交付到上层。在所有其他情况下，接收方将丢弃该分组，并为最近按序接收的分组重新发送 ACK。注意到因为一次交付给上层一个分组，如果分组 k 为已接受并交付，则所有序号比 k 小的分组也已经交付。因此，使用累积确认是 GBN 的一个自然的选择。 尽管丢弃一个正确接收（但失序）的分组。但这样做是有道理的。因为接收方必须将数据按序交付给上层，假设现在期望接收分组 n，而分组 n + 1 却到了，因为数据必须按序交付，所以接收方可能缓存分组 n + 1，然后，在它收到并交付分组 n 后，再将该分组交付到上层。但是，如果分组 n 丢失，则该分组及分组 n + 1 最终将在发送方根据 GBN 重传规则而被重传，所以，接收方只需要直接丢弃分组 n + 1 即可。这种方法的优点是接受缓存简单，即接收方不需要缓存任何失序分组。因此，虽然发送方必须维护窗口的上下边界及 nextseqnum 在该窗口中的位置，但是接收方需要维护的唯一信息就是下一个按序接收的分组的序号。该值保存在 expectedseqnum 变量中。当然，丢弃一个正确接收的分组的缺点是随后对该分组的重传也许会丢失或出错，因此甚至需要更多的重传。 一个示例如下： 3. 选择重传顾名思义，选择重传（SR）协议通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免了不必要的重传。这种个别的、按需的重传要求接收方逐个地确认正确接收的分组。再次用窗口长度 N 来限制流水线中未完成、未被确认的分组数。然而，与 GBN 不同的是，发送方已经收到了对窗口中某些分组的 ACK。 下图描述了发送方与接收方的序号空间： SR 发送方的事件与动作： 从上层收到数据。当从上层接收到数据后，SR 发送方检查下一个可用于该分组的序号。如果序号位于发送方的窗口内，则将数据打包并发送；否则就像在 GBN 中一样，要么将数据缓存，要么将其返回给上层以便以后传输。 超时。定时器再次被用来防止丢失分组。然而，现在每个分组必须拥有其自己的逻辑定时器，因为超时发生后只能发送一个分组。可以使用单个硬件定时器模拟多个逻辑定时器的操作。 收到ACK。如果收到 ACK，倘若该分组序号在窗口内，则 SR 发送方将那个被确认的分组标记为已接收。如果该分组的序号等于 send_base，则窗口基序号向前移动到具有最小序号的未确认分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。 SR 接收方将确认一个正确接收的分组而不管其是否按序。失序的分组将被缓存直到所有丢失分组（即序号更小的分组）皆被收到为止，这时才可以将一批分组按序交付给上层。 SR 接收方的事件与动作： 序号在 [rcv_base, rcv_base+N-1] 内的分组被正确接收。在此情况下，收到的分组落在接收方的窗口内，一个选择 ACK 被回送给发送方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收端的基序号（rcv_base），则该分组以及以前缓存的序号连续的（起始于 rcv_base 的）分组交付给上层。然后，接收窗口按向前移动分组的编号向上交付这些分组。 序号在 [rcv_base-N, rcv_base-1] 内的分组被正确收到。在此情况下，必须产生一个 ACK，即使该分组是接收方以前确认过的分组。 其他情况。忽略该分组。 注意上面的第二步，接收方需要重新确认（而不是忽略）已收到过的那些序号小于当前窗口基序号的分组。如果分组 send_base 的 ACK 没有从接收方传播回发送方，则发送方最终将重传分组 send_base，即使显然接收方已经收了该分组。如果接收方不确认该分组，则发送方窗口将永远不能向前滑动！ 上面的例子说明了对于 SR 协议（和很多其他协议一样） 对于哪些分组已经被正确接收，哪些没有，发送方和接收方并不总能看到相同的结果。对 SR 协议而言，这就意味着发送方和接收方的窗口并不总是一致。 一个示例如下： 当我们面对有限序号范围的现实时，发送方和接收方窗口间缺乏同步会产生严重的后果。考虑下面的例子： 在这个例子中，有四个分组序号 0、1、2、3 且窗口长度为 3。假定发送了分组 0 至 2，并且接收方被正确接收且确认了。此时，接收方窗口落在 4、5、6 个分组上，其序号分别为 3、0、1.现在考虑两种情况。 在第一种情况下，如上图中的 a 图所示，对前 3 个分组的 ACK 丢失，因此发送方重传这些分组。因此，接收方下一步要接收序号为 0 的分组，即第一个发送分组的副本。 在第二种情况下，如上图中的 b 图所示，对前 3 个分组的 ACK 都被正确交付。因此发送方向前移动窗口并发送第 4、5、6 个分组，其序号分别为 3、0、1.序号为 3 的分组丢失，但序号为 0 的分组到达（一个包含新数据的分组）。 显然，接收方并不知道发送方那边出现了什么问题，对于接收方自己来说，上面两种情况是等价的。没有办法区分是第一个分组的重传还是第 5 个分组的初次传输。所以，窗口长度比序号空间小 1 时协议无法正常工作。但窗口应该有多小呢？ 答案是：窗口长度必须小于或等于序号空间大小的一半。 4. 可靠数据传输过程中的分组重新排序问题在前面的所有假设中，我们都是假定分组在发送方与接收方之间的信道中不能被重新排序。但是当连接两端的信道是一个网络时，分组重新排序是可能会发生的。 分组重新排序的一个表现就是一个具有序号或确认号 x 的分组的旧副本可能会出现，即使发送方或接收方的窗口中都包含 x。 对于分组重新排序，信道可被看成基本上是在缓存分组，并在将来任意时刻自然地释放出这些分组。由于序号可以被重新使用，那么必须小心，以免出现这样的冗余分组。 实际应用中采用的方法是：确保一个序号不被重新使用，直到发送方“确信”任何先前发送的序号为 x 的分组都不再在网络中为止。通过假定一个分组在网络中的“存活”时间不会超过某个固定最大时间量来做到这一点。在高速网络的 TCP 扩展中，最长的分组寿命被假定为大约 3 分钟 [RFC 1323]。 5. 可靠数据传输机制及其用途总结 机制 用途和说明 检验和 用于监测在一个传输分组中的比特错误 定时器 用于超时/重传一个分组，可能因为该分组（或其ACK）在信道中丢失了。由于当一个分组延时但未丢失，或当一个分组已被接收方接收但从接收方到发送方的 ACK 丢失时，可能产生超时事件，所以接收方可能会收到一个分组的多个冗余副本 序号 用于为从发送方流向接收方的数据分组按序号编号。所接受分组的序号的空隙可使接收方检测出丢失的分组。具有相同序号的分组可使接收方检测出一个分组的冗余副本 确认 接收方用于告诉发送方一个分组或一组分组已经被正确地接收到了。确认报文通常携带着被确认的分组或多个分组的序号。确认可以是逐个的或积累的，这取决于协议 否定确认 接收方用于告诉发送方某个分组未被正确的接收。否定确定报文通常携带着未被正确接收的分组的序号 窗口、流水线 发送方也许被限制仅发送那些序号落在一个指定范围内的分组。通过允许一次发送多个分组但未被确认，发送方的利用率可以在停等操作模式上得到增加。窗口长度可根据接收方接收和缓存报文的能力、网络中的拥塞程度或两者的情况来进行设置]]></content>
      <categories>
        <category>Network</category>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《HTTP权威指南》: HTTPS]]></title>
    <url>%2F2016%2F07%2F28%2F%E3%80%8AHTTP%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B%EF%BC%9AHTTPS%2F</url>
    <content type="text"><![CDATA[1. X.509证书1.1 证书格式： 证书版本号(Version)版本号指明 X.509 证书的格式版本，现在的值可以为: v1 v2 v3 证书序列号(Serial Number)序列号指定由CA分配给证书的唯一的”数字型标识符”。当证书被取消时，实际上是将此证书的序列号放入由CA签发的CRL中，这也是序列号唯一的原因。 签名算法标识符(Signature Algorithm)签名算法标识用来指定由CA签发证书时所使用的”签名算法”。算法标识符用来指定CA签发证书时所使用的: 公开密钥算法 hash算法example: sha256WithRSAEncryption须向国际知名标准组织(如ISO)注册 签发机构名(Issuer)此域用来标识签发证书的CA的X.500 DN(DN-Distinguished Name)名字。包括: 国家(C) 省市(ST) 地区(L) 组织机构(O) 单位部门(OU) 通用名(CN) 邮箱地址 有效期(Validity)指定证书的有效期，包括: 证书开始生效的日期时间 证书失效的日期和时间每次使用证书时，需要检查证书是否在有效期内。 证书用户名(Subject)指定证书持有者的X.500唯一名字。包括: 国家(C) 省市(ST) 地区(L) 组织机构(O) 单位部门(OU) 通用名(CN) 邮箱地址 证书持有者公开密钥信息(Subject Public Key Info)证书持有者公开密钥信息域包含两个重要信息: 证书持有者的公开密钥的值 公开密钥使用的算法标识符。此标识符包含公开密钥算法和hash算法。 扩展项(extension)X.509 V3证书是在v2的基础上一标准形式或普通形式增加了扩展项，以使证书能够附带额外信息。标准扩展是指由X.509 V3版本定义的对V2版本增加的具有广泛应用前景的扩展项，任何人都可以向一些权威机构，如ISO，来注册一些其他扩展，如果这些扩展项应用广泛，也许以后会成为标准扩展项。 签发者唯一标识符(Issuer Unique Identifier)签发者唯一标识符在第2版加入证书定义中。此域用在当同一个X.500名字用于多个认证机构时，用一比特字符串来唯一标识签发者的X.500名字。可选。 证书持有者唯一标识符(Subject Unique Identifier)持有证书者唯一标识符在第2版的标准中加入X.509证书定义。此域用在当同一个X.500名字用于多个证书持有者时，用一比特字符串来唯一标识证书持有者的X.500名字。可选。 签名算法(Signature Algorithm)证书签发机构对证书上述内容的签名算法。example:sha256WithRSAEncryption 签名值(Issuer’s Signature)证书签发机构对证书上述内容的签名值 1.2 证书样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Data: Version: v3 Serial Number: 0x1 Signature Algorithm: SHA1withRSA - 1.2.840.113549.1.1.5 Issuer: CN=Certificate Manager,OU=netscape,O=ExampleCorp,L=MV,ST=CA,C=US Validity: Not Before: Friday, February 21, 2005 12:00:00 AM PST America/Los_Angeles Not After: Monday, February 21, 2007 12:00:00 AM PST America/Los_Angeles Subject: CN=Certificate Manager,OU=netscape,O=ExampleCorp,L=MV,ST=CA,C=US Subject Public Key Info: Algorithm: RSA - 1.2.840.113549.1.1.1 Public Key: Exponent: 65537 Public Key Modulus: (2048 bits) : E4:71:2A:CE:E4:24:DC:C4:AB:DF:A3:2E:80:42:0B:D9: CF:90:BE:88:4A:5C:C5:B3:73:BF:49:4D:77:31:8A:88: 15:A7:56:5F:E4:93:68:83:00:BB:4F:C0:47:03:67:F1: 30:79:43:08:1C:28:A8:97:70:40:CA:64:FA:9E:42:DF: 35:3D:0E:75:C6:B9:F2:47:0B:D5:CE:24:DD:0A:F7:84: 4E:FA:16:29:3B:91:D3:EE:24:E9:AF:F6:A1:49:E1:96: 70:DE:6F:B2:BE:3A:07:1A:0B:FD:FE:2F:75:FD:F9:FC: 63:69:36:B6:5B:09:C6:84:92:17:9C:3E:64:C3:C4:C9 Extensions: Identifier: Netscape Certificate Type - 2.16.840.1.113730.1.1 Critical: no Certificate Usage: SSL CA Secure Email CA ObjectSigning CA Identifier: Basic Constraints - 2.5.29.19 Critical: yes Is CA: yes Path Length Constraint: UNLIMITED Identifier: Subject Key Identifier - 2.5.29.14 Critical: no Key Identifier: 3B:46:83:85:27:BC:F5:9D:8E:63:E3:BE:79:EF:AF:79: 9C:37:85:84 Identifier: Authority Key Identifier - 2.5.29.35 Critical: no Key Identifier: 3B:46:83:85:27:BC:F5:9D:8E:63:E3:BE:79:EF:AF:79: 9C:37:85:84 Identifier: Key Usage: - 2.5.29.15 Critical: yes Key Usage: Digital Signature Key CertSign Crl Sign Signature: Algorithm: SHA1withRSA - 1.2.840.113549.1.1.5 Signature: AA:96:65:3D:10:FA:C7:0B:74:38:2D:93:54:32:C0:5B: 2F:18:93:E9:7C:32:E6:A4:4F:4E:38:93:61:83:3A:6A: A2:11:91:C2:D2:A3:48:07:6C:07:54:A8:B8:42:0E:B4: E4:AE:42:B4:B5:36:24:46:4F:83:61:64:13:69:03:DF: 41:88:0B:CB:39:57:8C:6B:9F:52:7E:26:F9:24:5E:E7: BC:FB:FD:93:13:AF:24:3A:8F:DB:E3:DC:C9:F9:1F:67: A8:BD:0B:95:84:9D:EB:FC:02:95:A0:49:2C:05:D4:B0: 35:EA:A6:80:30:20:FF:B1:85:C8:4B:74:D9:DC:BB:50 浏览器收到证书时会对签名颁发机构进行检查。若该机构是权威的公共签名机构，浏览器可能已经知道其公开密钥（浏览器会预装很多签名颁发机构的证书），这样就可以验证签名了。 如果对签名颁发机构一无所知，浏览器就无法确定是否应该信任它，这时通常会向用户显示一个对话框，看看他是否相信这个签名发布者（可能是本地的IT部门或软件厂商）。 2. HTTPS 连接的建立在未加密 HTTP 中，客户端会打开一条到 Web 服务器端口 80 的 TCP 连接，发送一条请求报文，接收一条响应报文，关闭连接。 由于 SSL 安全层的存在，HTTPS 中这个过程会略微复杂一些。在 HTTPS 中，客户端首先打开一条到 Web 服务器端口 443（安全 HTTP 的默认端口）的连接。一旦建立了 TCP 连接，客户端和服务器就会初始化 SSL 层，对加密参数进行沟通，并交换密钥。握手完成之后，SSL 初始化就完成了，客户端就可以将请求报文发送给安全层了。在将这些报文发送给 TCP 之前，要先对其进行加密。 在发送已加密的 HTTP 报文之前,客户端和服务器要进行一次 SSL 握手，在这个握手过程中，它们要完成以下工作： 交换协议版本号; 选择一个两端都了解的密码; 对两端的身份进行认证; 生成临时的会话密钥，以便加密信道。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《HTTP权威指南》: 连接管理]]></title>
    <url>%2F2016%2F07%2F22%2F%E3%80%8AHTTP%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B%EF%BC%9A%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. HTTP 事务的时延HTTP位于TCP上层，所以HTTP事务的性能在很大程度上取决于底层TCP通道的性能。TCP时延取决于硬件速度、网络和服务器负载，请求和响应报文的尺寸，以及客户端和服务器之间的距离。HTTP事务的时延有以下几种主要原因： 客户端首先需要根据URI确定Web服务器的IP地址和端口号。如果最近没有对URI中的主机名进行访问，通过DNS解析系统将URI中的主机名转换成一个IP地址需要花费数十秒时间。 接下来，客户端会向服务器发送一条TCP连接请求，并等待服务器回送一个请求接受应答。每条新的TCP连接都会有连接建立时延。这个值通常最多只有一两秒种，但如果有数百个HTTP事务的话，这个值会快速地叠加上去。 一旦连接建立起来了，客户端就会通过新建立的TCP管道来发送HTTP请求。数据到达时，Web服务器会从TCP连接中读取请求报文，并对请求进行处理。因特网传输请求报文，以及服务器处理请求报文都需要时间。 然后，Web服务器会回送HTTP响应，这也需要花费时间。 2. HTTP性能TCP相关时延包括： TCP连接建立握手 TCP慢启动拥塞控制 数据聚集的Nagle算法 用于捎带确认的TCP延迟确认算法 TIME_WAIT时延和端口耗尽。 2.1 TCP连接的握手时延TCP连接握手需要经过以下几个步骤： 请求新的TCP连接时，客户端要向服务器发送一个小的TCP分组（通常是40~60个字节）。这个分组中设置了一个特殊的SYN标记，说明这是一个连接请求。 如果服务器接受了连接，就会对一些连接参数进行计算，并向客户端回送一个TCP分组，这个分组中SYN和ACK标记都被置位，说明连接请求已被接受。 最后，客户端向服务器回送一条确认信息，通知它连接已成功建立。现代的TCP栈都允许客户端在这个确认分组中发送数据。 2.2 延迟确认由于因特网自身无法确保可靠分组传输（因特网路由器超负荷的话，可以随意丢弃分组），所以TCP实现了自己的确认机制来确保数据的成功传输。 每个TCP段都有一个序列号和数据完整性校验和。每个段的接受着收到完好的段时，都会想发送者回答小的确认分组。如果发送者没有在指定的窗口时间内收到确认信息，发送者就认为分组已被破坏或损毁，并重发数据。 由于确认报文很小，所以TCP允许发往相同方向的输出数据分组中对其进行捎带。TCP将返回的去人信息于输出的数据分组结合在一起，可以更有效地利用网络。为了增加确认报文找到 同向传输数据分组的可能性，很多TCP栈都实现了一种“延迟确认”算法。延迟确认算法会在一个特定的窗口时间（通常是100ms到200ms）内将输出确认存在缓冲区中，以寻找能够捎带它的输出数据分组。如果在哪个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送。 但是，HTTP具有双峰特征的请求-应答行为降低了捎带信息的可能。当希望有相反方向回传分组的时候,偏偏没有那么多。通常，延迟确认算法会引入相当大的时延。根据所使用操作系统的不同，可以调整或禁止延迟确认算法。 2.3 TCP慢启动TCP数据传输的性能还取决于TCP连接的使用期（age）。TCP连接会随着时间进行自我“调谐”，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐被称为TCP慢启动（slow start），用于防止因特网的突然过载和拥塞。 TCP慢启动限制了一个TCP端点在任意时刻可以传输的分组数。简单来说，每成功接收一个分组，发送端就有了发送另外两个分组的权限。如果某个HTTP事务有大量数据要发送，是不能一次将所有分组都发送出去的。必须发送一个分组，等待确认；然后可以发送两个分组，每个分组都必须被确认，这样就可以发送四个分组了，以此类推。这种方式被称为“打开拥塞窗口”。 由于存在这种拥塞控制特性，所以新连接的传输速度会比已经交换过一定量数据的、“已调谐”连接慢一些。 2.4 Nagle算法与TCP_NODELAYTCP有一个数据流接口，应用程序可以通过它将任意尺寸的数据放入TCP栈中——即使一次只放一个字节也可以！但是，每个TCP段中都至少装载了40个字节的标记和首部，所以如果TCP发送了大量包含少量数据的分组，网络的性能就会严重下降。 Nagle算法（根据其发明者John Nagle命名）试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。 Nagle算法鼓励发送全尺寸（LAN上最大尺寸的分组大约是1500字节，在因特网上是几百字节）的段。只有当所有其他分组都被确认之后，Nagle算法才允许发送非全尺寸的分组。如果其他分组仍然在传输过程中，就将那部分数据缓存起来。只有当挂起分组被确认，或者缓存中积累了足够发送一个全尺寸分组的数据时，才会将缓存的数据发送出去。 Nagle算法会引发几种HTTP性能问题。首先，小的HTTP报文可能无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。其次，Nagle算法与延迟确认之间的交互存在问题——Nagle算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100~200毫秒。 HTTP应用程序常常会在自己的栈中设置参数TCP_NODELAY，禁用Nagle算法，提高性能。如果要这么做的话，一定要确保会向TCP写入大块的数据，这样就不会产生一堆小分组了。 2.5 TIME_WAIT累积与端口耗尽当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。这类信息只会维持一小段时间，通常是所估计的最大分段试用期的两倍（称为2MSL，通常为2分钟）左右，以确保在这段时间内不会创建具有相同地址和端口号的新连接。实际上，这个算法可以防止在2分钟内创建、关闭并重新创建2个相同IP地址和端口号的连接。 现在高速路由器的使用，使得重复分组几乎不可能在连接关闭的几分钟之后，出现在服务器上。有些操作系统会将2MSL设置为一个较小的值，但修改此值时要特别小心。分组确实会被复制，如果来自之前连接的复制分组插入具有相同连接值的新TCP流，会破坏TCP数据。 2MSL的连接关闭延迟通常不是什么问题，但在性能基准环境下就可能会成为一个问题。进行性能基准测试时，通常只有一台或几台用来产生流量的计算机连接到某系统中去，这样就限制了连接到服务器的客户端IP地址数。而且，服务器通常会在HTTP默认端口80上进行监听。用TIME_WAIT防止端口号重用时，这些情况也限制了可用的连接值组合。 在只有一个客户端和一台Web服务器的异常情况下，构建一条TCP连接的4个值： 1&lt;source-IP-address，source-port，destination-IP-address，destination-port&gt; 其中的3个都是固定的——只有源端口号可以随意改变： 1&lt;client-IP, source-port, server-IP,80&gt; 客户端每次连接到服务器上去时，都会获得一个新的源端口，以实现连接的唯一性。但由于可用源端口的数量有限（比如60000个），而且在2MSL（比如，120s）内连接是无法重用的，连接率就被限制在了60000/120 = 500次/s。如果再不断进行优化，并且服务器的连接率不超过500次/s, 就可以确保不会遇到TIME_WAIT端口耗尽的问题。要修正这个问题，可以增加客户端负载生成器的数量，或者确保客户端和服务器在循环使用几个虚拟IP地址以增加更多的连接组合。 3. HTTP连接的处理3.1 常被误解的Connection首部HTTP允许客户端和最终的源服务器之间存在一串HTTP中间实体（代理，高速缓存等）。可以从客户端开始，逐跳地将HTTP报文经过这些中间设备，转发到源端服务器上（或者进行反向传输）。 某些情况下，两个相邻的HTTP应用会为它们共享的连接应用一组选项。HTTP的Connection首部字段中有一个有逗号分隔的连接标签列表，这些标签为此连接必定了一些不会传播到其它连接中去的选项。 Connection首部可以承载三种不同类型的标签： HTTP首部字段名，列出了只与此连接有关的首部； 任意标签值，用于描述此连接的非标准选项； 值close，说明操作完成之后需关闭这条持久连接。 如果连接标签中包含了一个HTTP首部字段的名称，那么这个首部字段就包含了一些与连接有关的信息，不能将其转发出去。在将报文转发之前，必须删除Connection首部列出的所有首部字段。 HTTP应用程序收到一条带有Connection首部的报文肘，接收端会解析发送端请求的所有选项，并将其应用。然后会在将此报文转发给下一跳地址之前，删除Connection首部以及Connection中列出的所有首部。而且，可能还会有少量没有作为Connection首部值列出，但一定不能被代理转发的逐跳首部。其中包括Prxoy-Authenticate、Proxy-Connection、Transfer-Encoding和Upgrade. 4. 持久连接Web客户端经常会打开到同一个站点的连接。这种性质被称为站点局部性（site locality）。 因此，HTTP/1.1（以及 HTTP/1.0的各种增强版本）允许HTTP设备在事务处理结束之后将TCP连接保持在打开状态，以便为未来的HTTP请求重用现存的连接。在事务处理结束之后仍然保持在打开状态的TCP连接被称为持久连接。非持久连接会在每个事务结束之后关闭。持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为止。 重用已对目标服务器打开的空闲持久连接，就可以避开缓慢的连接建立阶段。而且，已经打开的连接还可以避免慢启动的拥塞适应阶段，以便更快速地进行数据的传输。 4.1 持久以及并行连接并行连接的缺点： 每个事务都会打开/关闭一条新的连接，会耗费时间和带宽。 由于tcp慢启动特性的存在，每个新连接的性能都会下降。 可打开的并行连接数量实际上有限。 持久连接有一些比并行连接更好的地方。持久连接降低了时延和连接建立的开销，将连接保持在已协调状态，而且减少了打开连接的潜在数量。但是，管理持久连接一定要特别小心，不然就会出现积累大量的空闲连接。 4.2 HTTP/1.0+keep-alive连接很多HTTP/1.0的浏览器和服务器都进行了扩展，以支持keep-alive型持久连接。 4.3 Keep-Alive操作实现HTTP/1.0 keep-alive的客户端可以通过包含Connection: Keep-Alive首部请求将一条连接保持在打开状态。 如果服务器允许，就在响应中包含同样的头部。如果响应中没有Connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。 4.4 Keep-Alive选项可以用Keep-Alive通用首部中指定的、由逗号分隔的选项来调节keep-alive的行为。 参数timeout是在Keep-Alive响应首部发送的。它估计了服务器希望将连接保持在活跃状态的时间。这并不是一个承诺值。 参数max是在Keep-Alive响应首部发送的，它估计了服务器还希望为多少个事务保持此连接的活跃状态。这并不是一个承诺值。 Keep-Alive还可支持任意未经处理的属性，这些属性主要用于诊断和调试。语法为name [=value]。 Keep-Alive首部完全是可选的，但只有在提供Connection: Keep-Alive时才能使用它。这里有个Keep-Alive响应首部的例子，这个例子说明服务器最多还会为另外5个事务保持连接的打开状态，或者将打开状态保持到连接空闲了2分钟之后。 1Connection: Keep-AliveKeep-Alive: max=5, timeout=120 4.5 Keep-Alive连接的限制和规则使用keep-alive连接时有一些限制和一些需要澄清的地方。 在HTTP/1.0中，keep-alive并不是默认使用的。客户端必须发送一个Connection: Keep-Alive请求首部来激活keep-alive连接。 Connection: Keep-Alive首部必须随所有希望保持持久连接的报文一起发送。如果客户端没有发送Connection: Keep-Alive首部，服务器就会在那条请求之后关闭连接。 通过检测响应中是否包含Connection: Keep-Alive响应首部，客户端可以判断服务器是否会在发出响应之后关闭连接。 只有在无需检测到连接的关闭即可确定报文实体主体部分长度的情况下，才能将连接保持在打开状态——也就是说实体的主体部分必须有正确的Content-Length，有多部件媒体类型，或者用分块传输编码的方式进行了编码。在一条keep-alive信道中回送错误的Content-Length是很糟糕的事，这样的话，事务处理的另一端就无法精确地检测出一条报文的结束和另一条报文的开始了。 代理和网关必须执行Connection首部的规则。代理或网关必须在将报文转发出去或将其高速缓存之前，删除在Connection首部中命名的所有首部字段以及Connection首部自身。 严格来说，不应该与无法确认是否支持Connection首部的代理服务器建立keep-alive连接，以防出现哑代理问题。在实际中不是总能做到这一点。 从技术上来讲，应该忽略所有来自HTTP/1.0设备的Connection首部字段(包括Connection: Keep-Alive)，因为它们可能是由比较老的代理服务器误转发的。但实际上，尽管可能会有在老代理上挂起的危险，有些客户端和服务器还是会违反这条规则。 除非重复发送请求会发生其他一些副作用，否则如果在客户端收到完整的响应之前连接就关闭了，客户端就一定要做好重试请求的准备。 4.6 Keep-Alive和哑代理Web客户端的Connection: Keep-Alive首部应该只会对这条离开客户端的TCP链路产生影响，这就是将其称作“连接”首部的原因。如果客户端正在与一台Web服务器对话，客户端可以发送一个Connection: Keep-Alive首部来告知服务器它希望保持连接的活跃状态。如果服务器支持keep-alive，就回送一个Connection: Keep-Alive首部，否则就不回送。 问题出在代理上——尤其是那些不理解Connection首部，而且不知道在沿着转发链路将其发送出去之前，应该将该首部删除的代理。很多老的或简单的代理都是盲中继(blind relay)，它们只是将字节从一个连接转发到另一个连接中去，不对Connection首部进行特殊的处理。 假设有一个Web客户端正通过一个作为盲中继使用的哑代理与Web服务器进行对话，下图显示的就是这种情形。 Web客户端向代理发送了一条报文，其中包含了Connection: Keep-Alive首部，如果可能的话请求建立一条keep-alive连接。客户端等待响应，以确定对方是否认可它对keep-alive信道的请求。 哑代理收到了这条HTTP请求，但它并不理解connection首部（只是将其作为一个扩展首部对待）。代理不知道keep-alive是什么意思，因此只是沿着转发链路将报文一字不漏地发送给服务器。但Connection首部是个逐跳首部，只适用于单条传输链路，不应该沿着传输链路向下传输。接下来，就要发生一些很糟糕的事情了。 经过中继的HTTP请求抵达了Web服务器。当Web服务器收到经过代理转发的Connection: Keep-Alive首部时，会误以为代理（对服务器来说，这个代理看起来就和所有其他客户端一样）希望进行keep-alive对话。Web服务器同意进行keep-alive对话，并回送了一个Connection: Keep-Alive响应首部。所以，此时Web服务器认为它在与代理进行keep-alive对话，会遵循keep-alive的规则。但代理却对keep-alive一无所知。 哑代理将Web服务器的响应报文回送给客户端，并将来自Web服务器的Connection: Keep-Alive首部一起传送过去。客户端看到这个首部，就会认为代理同意进行keep-alive对话。所以，此时客户端和服务器都认为它们在进行keep-alive对话，但与它们进行对话的代理却对keep-alive一无所知。 由于代理对keep-alive一无所知，所以会将收到的所有数据都回送给客户端，然后等待源端服务器关闭连接。但源端服务器会认为代理已经显式地请求它将连接保持在打开状态了，所以不会去关闭连接。这样，代理就会挂在那里等待连接的关闭。 客户端收到了回送的响应报文时，会立即转向下一条请求，在keep-alive连接上向代理发送另一条请求。而代理并不认为同一条连接上会有其他请求到来，请求被忽略，浏览器就在这里转圈，不会有任何进展了。 这种错误的通信方式会使浏览器一直处于挂起状态，直到客户端或服务器将连接超时，并将其关闭为止。 为避免此类代理通信问题的发生，现代的代理都绝不能转发Connection首部和所有名字出现在Connection值中的首部。因此,如果一个代理收到了一个Connection: Keep-Alive首部，是不应该转发Connection首部，或所有名为Keep-Alive的首部的。 4.7 插入Proxy-Connection在网景的变通做法是，浏览器会向代理发送非标准的Proxy-Connection扩展首部，而不是官方支持的著名的Connection首部。如果代理是盲中继，它会将无意义的Proxy-Connection首部转发给Web服务器，服务器会忽略此首部，不会带来任何问题。但如果代理是个聪明的代理（能够理解持久连接的握手动作），就用一个Connection首部取代无意义的Proxy-Connection首部，然后将其发送给服务器，以收到预期的效果。 在客户端和服务器之间只有一个代理时可以用这种方案来解决问题。但如果在哑代理的任意一侧还有一个聪明的代理，这个问题就会再次露头了。 4.8 HTTP/1.1持久连接HTTP/1.1逐渐停止了对keep-alive连接的支持，用一种名为持久连接（persistent connection）的改进型设计取代了它。持久连接的目的与keep-alive连接的目的相同，但工作机制更优一些。 与HTTP/1.0+的keep-alive连接不同，HTTP/1.1持久连接在默认情况下是激活的。除非特别指明，否则HTTP/1.1假定所有连接都是持久的。要在事务处理结束之后将连接关闭，HTTP/1.1应用程序必须向报文中显式地添加一个Connection: close首部。这是与以前的HTTP协议版本很重要的区别，在以前的版本中，keep-alive连接要么是可选的，要么根本就不支持。 HTTP/1.1客户端假定在收到响应后，除非响应中包含了Connection: close首部，不然HTTP/1.1连接就仍维持在打开状态。但是，客户端和服务器仍然可以随时关闭空闲的连接。不发送Connection: close并不意味着服务器承诺永远将连接保持在打开状态。 只有当连接上所有的报文都有正确的、自定义报文长度时——也就是说,实体主体部分的长度都和相应的Content-Length一致,或者是用分块传输编码方式编码的——连接才能持久保持。 (因为是持久连接，无法通过连接的关闭来判断报文发送结束) 4.9 持久连接的限制和规则在持久连接的使用中有以下限制和需要澄清的问题： 发送了Connection: close请求首部之后，客户端就无法在那条连接上发送更多的请求了。 如果客户端不想在连接上发送其他请求了，就应该在最后一条请求中发送一个Connection: close请求首部。 只有当连接上所有的报文都有正确的、自定义报文长度时——也就是说，实体主体部分的长度都和相应的Content—Length一致，或者是用分块传输编码方式编码的——连接才能持久保持。 HTTP/1.1的代理必须能够分别管理与客户端和服务器的持久连接——每个持久连接都只适用于一跳传输。 由于较老的代理会转发Connection首部，所以HTTP/1.1的代理服务器不应该与HTTP/1.0客户端建立持久连接，除非它们了解客户端的处理能力。实际上，这一点是很难做到的，很多厂商都违背了这一原则。 尽管服务器不应该试图在传输报文的过程中关闭连接，而且在关闭连接之前至少应该响应一条请求，但不管Connection首部取了什么值，HTTP/1.1设备都可以在任意时刻关闭连接。 HTTP/1.1应用程序必须能够从异步的关闭中恢复出来。只要不存在可能会累积起来的副作用，客户端都应该重试这条请求。 除非重复发起请求会产生副作用，否则如果在客户端收到整条响应之前连接关闭了，客户端就必须要重新发起请求。 一个用户客户端对任何服务器或代理最多只能维护两条持久连接，以防服务器过载。代理可能需要更多到服务器的连接来支持并发用户的通信，所以，如果有N个用户试图访问服务器的话，代理最多要维持2N条到任意服务器或父代理的连接。 5. 管道化连接HTTP/1.1允许在持久连接上可选地使用请求管道。这是在keep-alive连接上的进一步性能优化。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向服务器时，第二条和第三条请求也可以开始发送了。在髙时延网络条件下，这样做可以降低网络的环回时间，提高性能。 对管道化连接有如下几条限制： 如果HTTP客户端无法确认连接是持久的，就不应该使用管道。 必须按照与请求相同的顺序回送HTTP响应。HTTP报文中没有序列号标签，因此如果收到的响应失序了，就没办法将其与请求匹配起来了。 HTTP客户端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化清求。如果客户端打开了一条持久连接，并立即发出了10条请求，服务器可能在只处理了5条请求之后关闭连接。剩下的5条请求会失败，客户端必须能够应对这些过早关闭连接的情况，重新发出这些请求。 HTTP客户端不应该用管道化的方式发送会产生副作用的请求（比如POST）。总之，出错的时候，管道化方式会阻碍客户端了解服务器执行的是一系列管道化请求中的哪一些。由于无法安全地重试POST这样的非幂等请求（幂等是指多个请求返回相同的结果），所以出错时，就存在某些方法永远不会被执行的风险。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《HTTP权威指南》: 缓存]]></title>
    <url>%2F2016%2F07%2F12%2F%E3%80%8AHTTP%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B%EF%BC%9A%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[1. 缓存的处理步骤现代的商业化代理缓存相当地复杂。这些缓存构建得非常高效，可以支持HTTP和其他一些技术的各种高级特性。但除了一些微妙的细节之外，Web缓存的基本工作原理大多很简单。对一条HTTP GET报文的基本缓存处理过程包括7个步骤： 接收—缓存从网络中读取抵达的请求报文； 解析—缓存对报文进行解析，提取出URL和各种首部； 查询—缓存查看是否有本地副本可用，如果没有，就获取一份副本(并将其保存在本地)； 新鲜度检测—缓存查看已缓存副本是否足够新鲜，如果不是，就询问服务器是否有任何更新； 创建响应—缓存会用新的首部和已缓存的主体来构建一条响应报文； 发送—缓存通过网络将响应发回给客户端； 日志—缓存可选地创建一个日志文件条目来描述这个事务。 1.1 接收在第一步中，缓存检测到一条网络连接上的活动，读取输入数据。高性能的缓存会同时从多条输入连接上读取数据，在整条报文抵达之前开始对事务进行处理。 1.2 解析接下来，缓存将请求报文解析为片断，将首部的各个部分放入易于操作的数据结构中。这样，缓存软件就更容易处理首部字段并修改它们了。 1.3 查询在第三步中，缓存获取了URL，查找本地副本。本地副本可能存储在内存、本地磁盘，甚至附近的另一台计算机中。专业级的缓存会使用快速算法来确定本地缓存中是否有某个对象。如果本地没有这个文档，它可以根据情形和配置，到原始服务器或父代理中去取，或者返回一条错误信息。已缓存对象中包含了服务器响应主体和原始服务器响应首部，这样就会在缓存命中时返回正确的服务器首部。已缓存对象中还包含了一些元数据（metadata），用来记录对象在缓存中停留了多长时间，以及它被用过多少次等。 1.4 新鲜度检测HTTP通过缓存将服务器文档的副本保留一段时间。在这段时间里，都认为文档是”新鲜的”，缓存可以在不联系服务器的情况下，直接提供该文档。但一旦已缓存副本停留的时间太长，超过了文档的新鲜度限值（freshness limit），就认为对象“过时”了，在提供该文档之前，缓存要再次与服务器进行确认，以查看文档是否发生了变化。客户端发送给缓存的所有请求首部自身都可以强制缓存进行再验证，或者完全避免验证，这使得事情变得更加复杂了。HTTP有一组非常复杂的新鲜度检测规则，缓存产品支持的大量配置选项，以及与非HTTP新鲜度标准进行互通的需要则使问题变得更加严重了。本章其余的大部分篇幅都用于解释新鲜度的计算问题。 1.5 创建响应我们希望缓存的响应看起来就像来自原始服务器的一样，缓存将已缓存的服务器响应首部作为响应首部的起点。然后缓存对这些基础首部进行了修改和扩充。缓存负责对这些首部进行改造，以便与客户端的要求相匹配。比如，服务器返回的可能是一条HTTP/1.0响应（甚至是HTTP/0.9响应），而客户端期待的是一条HTTP/1.1响应，在这种情况下，缓存必须对首部进行相应的转换。缓存还会向其中插入新鲜度信息（Cache-Control、Age以及Expires首部），而且通常会包含一个Via首部来说明请求是由一个代理缓存提供的。注意，缓存不应该调整Date首部。Date首部表示的是原始服务器最初产生这个对象的日期。 1.6 发送一旦响应首部准备好了，缓存就将响应回送给客户端。和所有代理服务器一样，代理缓存要管理与客户端之间的连接。高性能的缓存会尽力高效地发送数据，通常可以避免在本地缓存和网络I/O缓冲区之间进行文档内容的复制。 1.7 日志大多数缓存都会保存日志文件以及与缓存的使用有关的一些统计数据。每个缓存事务结束之后，缓存都会更新缓存命中和未命中数目的统计数据（以及其他相关的度量值），并将条目插入一个用来显示请求类型、URL和所发生事件的日志文件。 2. 保持副本的新鲜可能不是所有的已缓存副本都与服务器上的文档一致。毕竟，这些文档会随着时间发生变化。报告可能每个月都会变化。在线报纸每天都会发生变化。财经数据可能每过几秒钟就会发生变化。如果缓存提供的总是老的数据，就会变得毫无用处。已缓存数据要与服务器数据保持一致。HTTP有一些简单的机制可以在不要求服务器记住有哪些缓存拥有其文档副本的情况下，保持已缓存数据与服务器数据之间充分一致。HTTP将这些简单的机制称为文档过期（document expiration）和服务器再验证（server revalidation）。 2.1 文档过期通过特殊的HTTP Cache-Control首部和Expires首部，HTTP让原始服务器向每个文档附加了一个“过期日期”。这些首部说明了在多长时间内可以将这些内容视为新鲜的。在缓存文档过期之前，缓存可以以任意频率使用这些副本，而无需与服务器联系——当然，除非客户端请求中包含有阻止提供已缓存或未验证资源的首部。但一旦已缓存文档过期，缓存就必须与服务器进行核对，询问文档是否被修改过，如果被修改过，就要获取一份新鲜（带有新的过期日期）的副本。 2.2 过期日期和使用期服务器用HTTP/1.0+的Expires首部或HTTP/1.1的Cache-Control: max-age响应首部来指定过期日期，同时还会带有响应主体。Expires首部和Cache-Control: max-age首部所做的事情本质上是一样的，但由于Cache-Control首部使用的是相对时间而不是绝对日期，所以我们更倾向于使用比较新的Cache-Control首部。绝对日期依赖于计算机时钟的正确设置。 首部 描述 Cache-Control: max-age max-age值定义了文档的最大使用期——从第一次生成文档到文档不再新鲜、无法使用为止，最大的合法生存时间(以秒为单位) Expires 指定一个绝对的过期日期。如果过期日期已经过了，就说明文档不再新鲜了 2.3 服务器再验证仅仅是已缓存文档过期了并不意味着它和原始服务器上目前处于活跃状态的文档有实际的区别；这只是意味着到了要进行核对的时间了。这种情况被称为“服务器再验证”，说明缓存需要询问原始服务器文档是否发生了变化。缓存并不一定要为每条请求验证文档的有效性——只有在文档过期时它才需要与服务器进行再验证。这样不会提供陈旧的内容，还可以节省服务器的流量，并拥有更好的用户响应时间。 如果再验证显示内容发生了变化，缓存会获取一份新的文档副本，并将其存储在旧文档的位置上，然后将文档发送给客户端。 如果再验证显示内容没有发生变化，缓存只需要获取新的首部，包括一个新的过期日期，并对缓存中的首部进行更新就行了。 HTTP协议要求行为正确的缓存返回下列内容之一： “足够新鲜”的已缓存副本； 与服务器进行过再验证，确认其仍然新鲜的已缓存副本； 如果需要与之进行再验证的原始服务器出故障了，就返回一条错误报文 ； 附有警告信息说明内容可能不正确的已缓存副本。 2.4 用条件方法进行再验证HTTP的条件方法可以高效地实现再验证。HTTP允许缓存向原始服务器发送一个“条件GET”，请求服务器只有在文档与缓存中现有的副本不同时，才回送对象主体。通过这种方式，将新鲜度检测和对象获取结合成了单个条件GET。向GET请求报文中添加一些特殊的条件首部，就可以发起条件GET。只有条件为真时，Web服务器才会返回对象。HTTP定义了5个条件请求首部。对缓存再验证来说最有用的2个首部是If-Modified-Since和If-None-Match。所有的条件首部都以前缀“If-”开头。 首部 描述 If-Modified-Since: 如果从指定日期之后文档被修改过了，就执行请求的方法。可以与Last-Modified服务器响应首部配合使用，只有在内容被修改后与已缓存版本有所不同的时候才去获取内容 If-None-Match: 服务器可以为文档提供特殊的标签，而不是将其与最近修改日期相匹配，这些标签就像序列号一样。如果已缓存标签与服务器文档中的标签有所不同，If-None-Match首部就会执行所请求的方法 2.5 If-Modified-Since:Date再验证最常见的缓存再验证首部是If-Modified-Since。If-Modified-Since再验证请求通常被称为IMS请求。只有自某个日期之后资源发生了变化的时候，IMS请求才会指示服务器执行请求： 如果自指定日期后，文档被修改了，If-Modified-Since条件就为真，通常GET就会成功执行。携带新首部的新文档会被返回给缓存，新首部除了其他信息之外，还包含了一个新的过期日期。 如果自指定日期后，文档没被修改过，条件就为假，会向客户端返回一个小的304 Not Modified响应报文，为了提高有效性，不会返回文档的主体。这 些首部是放在响应中返回的，但只会返回那些需要在源端更新的首部。比如，Content-Type首部通常不会被修改，所以通常不需要发送。一般会发送一个新的过期日期。 If-Modified-Since首部可以与Last-Modified服务器响应首部配合工作。原始服务器会将最后的修改日期附加到所提供的文档上去。当缓存要对已缓存文档进行再验证时，就会包含一个If-Modified-Since首部，其中携带有最后修改已缓存副本的日期： 1If-Modified-Since: &lt;cached last-modified date&gt; 如果在此期间内容被修改了，最后的修改日期就会有所不同，原始服务器就会回送新的文档。否则，服务器会注意到缓存的最后修改日期与服务器文档当前的最后修改日期相符，会返回一个304 Not Modified响应。 注意，有些Web服务器并没有将If-Modified-Since作为真正的日期来进行比对。相反，它们在IMS日期和最后修改日期之间进行了字符串匹配。这样得到的语义就是“如果最后的修改不是在这个确定的日期进行的”，而不是“如果在这个日期之后没有被修改过”。将最后修改日期作为某种序列号使用时，这种替代语义能够很好地识别出缓存是否过期，但这会妨碍客户端将If-Modified-Since首部用于真正基于时间的一些目的。 2.6 If-None-Match：实体标签再验证有些情况下仅使用最后修改日期进行再验证是不够的。 有些文档可能会被周期性地重写（比如，从一个后台进程中写入），但实际包含的数据常常是一样的。尽管内容没有变化，但修改日期会发生变化。 有些文档可能被修改了，但所做修改并不重要，不需要让世界范围内的缓存都重装数据(比如对拼写或注释的修改)。 有些服务器无法准确地判定其页面的最后修改日期。 有些服务器提供的文档会在亚秒间隙发生变化(比如，实时监视器)，对这些服务器来说，以一秒为粒度的修改日期可能就不够用了。 为了解决这些问题，HTTP允许用户对被称为实体标签（ETag）的“版本标识符”进行比较。实体标签是附加到文档上的任意标签（引用字符串）。它们可能包含了文档的序列号或版本名，或者是文档内容的校验和及其他指纹信息。 当发布者对文档进行修改时，可以修改文档的实体标签来说明这个新的版本。这样，如果实体标签被修改了，缓存就可以用If-None-Match条件首部来GET文档的新副本了。 2.7 强弱验证器缓存可以用实体标签来判断，与服务器相比，已缓存版本是不是最新的(与使用最近修改日期的方式很像)。从这个角度来看，实体标签和最近修改日期都是缓存验证器（cache validator）。 HTTP把验证码分为两类：弱验证码（weak validators）和强验证码（strong validators）。弱验证码不一定能唯一标识资源的一个实例，而强验证码必须如此。弱验证码的一个例子是对象的大小字节数。有可能资源的内容改变了，而大小还保持不变，因此假想的字节计数验证码与改变是弱相关的。而资源内容的加密校验和（比如MD5）就是强验证码，当文档改变时它总是会改变 最后修改时间被当作弱验证码，因为尽管它说明了资源最后被修改的时间，但它的描述精度最大就是1秒。因为资源在1秒内可以改变很多次，而且服务器每秒可以处理数千个请求，最后修改日期时间并不总能反应变化情况。ETag首部被当作强验证码，因为每当资源内容改变时，服务器都可以在ETag首部放置不同的值。版本号和摘要校验和也是很好的ETag首部候选，但它们不能带有任意的文本。ETag首部很灵活，它可以带上任意的文本值（以标记的形式），这样就可以用来设计出各种各样的客户端和服务器验证策略。 有时候，客户端和服务器可能需要采用不那么精确的实体标记验证方法。例如，某服务器可能想对一个很大、被广泛缓存的文档进行一些美化修饰，但不想在缓存服务器再验证时产生很大的传输流量。在这种情况下，该服务器可以在标记前面加上“W/”前缀来广播一个“弱”实体标记。对于弱实体标记来说，只有当关联的实体在语义上发生了重大改变时，标记才会变化。而强实体标记则不管关联的实体发生了什么性质的变化，标记都一定会改变。 12ETag: W/&quot;v2.6&quot;If-None-Match: W/&quot;v2.6&quot; 不管相关的实体值以何种方式发生了变化，强实体标签都要发生变化。而相关实体在语义上发生了比较重要的变化时，弱实体标签也应该发生变化。 注意，原始服务器一定不能为两个不同的实体重用一个特定的强实体标签值，或者为两个语义不同的实体重用一个特定的弱实体标签值。缓存条目可能会留存任意长的时间，与其过期时间无关，有人可能希望当缓存验证条目时，绝对不会再次使用在过去某一时刻获得的验证器，这种愿望可能不太现实。 2.8 实体标签和最近修改日期如果服务器回送了一个实体标签，HTTP/1.1客户端就必须使用实体标签验证器。如果服务器只回送了一个Last-Modified值，客户端就可以使用If-Modified-Since验证。如果实体标签和最后修改日期都提供了，客户端就应该使用这两种再验证方案，这样HTTP/1.0和HTTP/1.1缓存就都可以正确响应了。 除非HTTP/1.1原始服务器无法生成实体标签验证器，否则就应该发送一个出去，如果使用弱实体标签有优势的话，发送的可能就是个弱实体标签，而不是强实体标签。而且，最好同时发送一个最近修改值。如果HTTP/1.1缓存或服务器收到的请求既带有If-Modified-Since，又带有实体标签条件首部，那么只有这两个条件都满足时，才能返回304 Not Modified响应。 3. 控制缓存的能力服务器可以通过HTTP定义的几种方式来指定在文档过期之前可以将其缓存多长时间。按照优先级递减的顺序，服务器可以： 附加一个”Cache-Control: no-store”首部到响应中去； 附加一个”Cache-Control: no-cache”首部到响应中去； 附加一个”Cache-Control: must-revalidate”首部到响应中去； 附加一个”Cache-Control: max-age”首部到响应中去； 附加一个”Expires”日期首部到响应中去； 不附加过期信息，让缓存确定自己的过期日期。 3.1 no-Store 与 no-Cache 响应首部HTTP/1.1提供了几种限制对象缓存，或限制提供已缓存对象的方式，以维持对象的新鲜度。no-store首部和no-cache首部可以防止缓存提供未经证实的已缓存对象： 123Pragma: no-cacheCache-Control: no-storeCache-Control: no-cache 标识为no-store的响应会禁止缓存对响应进行复制。缓存通常会像非缓存代理服务器一样，向客户端转发一条no-store响应，然后删除对象。 标识为no-cache的响应实际上是可以存储在本地缓存区中的。只是在与原始服务器进行新鲜度再验证之前，缓存不能将其提供给客户端使用。这个首部使用do-not-serve-from-cache-without-revalidation这个名字会更恰当一些。 HTTP/1.1中提供Pragma: no-cache首部是为了兼容于HTTP/1.0+。除了与只理解Pragma: no-cache”的HTTP/1.0应用程序进行交互时，HTTP 1.1应用程序都应该使用Cache-Control: no-cache。 3.2 max-age响应首部Cache-Control: max-age首部表示的是从服务器将文档传来之时起，可以认为此文档处于新鲜状态的秒数（Cache-Control: max-age=3600）。还有一个s-maxage首部（注意maxage的中间没有连字符），其行为与max-age类似，但仅适用于共享（公有）缓存（Cache-Control: s-maxage=3600）。服务器可以请求缓存不要缓存文档，或者将最大使用期设置为零，从而在每次访问的时候都进行刷新（Cache-Control: max-age=0）。 3.3 Expires响应首部不推荐使用Expires首部，它指定的是实际的过期日期而不是秒数。HTTP设计者后来认为，由于很多服务器的时钟都不同步，或者不正确，所以最好还是用剩余秒数，而不是绝对时间来表示过期时间。可以通过计算过期值和日期值之间的秒数差来计算类似的新鲜生存期 1Expires: Fri, 05 Jul 2002, 05:00:00 GMT 有些服务器还会回送一个Expires:0响应首部，试图将文档置于永远过期的状态，但这种语法是非法的，可能给某些软件带来问题。应该试着支持这种结构的输入，但不应该产生这种结构的输出。 3.4 must-revalidate 响应首部可以配置缓存，使其提供一些陈旧(过期)的对象，以提高性能。如果原始服务器希望缓存严格遵守过期信息，可以在原始响应中附加一个Cache-Control: must-revalidate首部。 Cache-Control: must-revalidate响应首部告诉缓存，在事先没有跟原始服务器进行再验证的情况下，不能提供这个对象的陈旧副本。缓存仍然可以随意提供新鲜的副本。如果在缓存进行must-revalidate新鲜度检查时，原始服务器不可用，缓存就必须返回一条504 Gateway Timeout错误。 3.5试探性过期如果响应中没有Cache-Control: max-age首部，也没有Expires首部，缓存可以计算出一个试探性最大使用期。可以使用任意算法，但如果得到的最大使用期大于24小时，就应该向响应首部添加一个Heuristic Expiration Warning（试探性过期警告，警告13）首部。 3.6 客户端的新鲜度限制Web 浏览器都有刷新（Refresh）或 重载（Reload）按钮，可以强制对浏览器或代理缓存中可能过期的内容进行刷新。刷新按钮会发布一个附加了Cache-Control请求首部的GET请求，这个请求会强制进行再验证，或者无条件地从服务器获取文档。刷新的确切行为取决于特定的浏览器、文档以及拦截缓存的配置。 客户端可以用Cache-Control请求首部来强化或放松对过期时间的限制。有些应用程序对文档的新鲜度要求很高（比如人工刷新按钮），对这些应用程序来说，客户端可以用Cache-Control首部使过期时间更严格。另一方面，作为提高性能、可靠性或开支的一种折衷方式，客户端可能会放松新鲜度要求。 Cache-Control请求指令： 指令 目的 Cache-Control: max-stale 缓存可以随意提供过期的文件。如果指定了参数(s)，在这段时间内，文档就不能过期。这条指令放松了缓存的规则 Cache-Control: min-fresh=(s) 至少在未来(s)秒内文档要保持新鲜。这就使缓存规则更加严格了 Cache-Control: max-age = (s) 缓存无法返回缓存时间长于(s)秒的文档。这条指令会使缓存规则更加严格，除非同时还发送max-stale指令，在这种情况下，使用期可能会超过其过期时间 Cache-Control: no-cache 除非资源进行了再验证，否则这个客户端不会接受已缓存的资源 Cache-Control: no-store 缓存应该尽快从存储器中删除文档的所有痕迹，因为其中可能会包含敏感信息 Cache-Control: only-if-cached 只有当缓存中有副本存在时，客户端才会获取一份副本]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《HTTP 权威指南》: 实体和编码]]></title>
    <url>%2F2016%2F07%2F01%2F%E3%80%8AHTTP%20%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B%EF%BC%9A%E5%AE%9E%E4%BD%93%E5%92%8C%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1. 报文是箱子，实体是货物HTTP 实体首部描述了 HTTP 报文的内容，HTTP/1.1 版定义了以下 10 个基本字体首部字段： Content-Type：实体中所承载的对象类型； Content-Length：所传送实体主体的长度或大小； Content-Language：与所传送对象最相配的人类语言； Content-Encoding：对象数据所做的任意变换； Content-Location：一个备用位置，请求时可通过它获得对象； Content-Range：如果这是部分实体，这个首部说明它是整体的哪个部分； Content-MD5：实体主体内容的校验和； Content-Modified：所传输内容在服务器上创建或最后修改的日期时间； Expires：实体数据将要失效的日期时间； Allow：该资源所允许的各种请求方法； ETag：这份文档特定实例的唯一验证码； Cache-Control：指出应该如何缓存该文档。 2. Content-Length：实体的大小Content-Length 首部指示出报文中实体主体的字节大小。这个大小是包含了所有内容编码的。比如，对文本文件进行了 gzip 压缩的话，Content-Length 首部就是压缩后的大小，而不是原始大小。 除非使用了分块编码，否则 Content-Length 首部就是带有实体主体的报文必须使用的。使用 Content-Length 首部是为了能够检测出服务器崩溃而导致的报文截尾，并对共享持久连接的多个报文进行正确分段。 HTTP 的早期版本采用关闭连接的办法来划定报文的结束。但是，没有 Content-Length 的话，客户端无法区分到底是报文结束时正常的连接关闭，还是报文传输中由于服务器崩溃而导致的连接关闭。客户端需要通过 Content-Length 来检测报文截尾。 Content-Length 首部对于持久连接是必不可少的。如果响应通过持久连接传送，就可能有另一条HTTP响应紧随其后。客户端通过 Content-Length 首部就可以知道报文在何处结束，下一条报文从何处开始。因为连接是持久的，客户端无法依赖连接关闭来判别报文的结束。如果没有 Content-Length 首部，HTTP 应用程序就不知道某个实体主体在哪里结束，下一条报文从哪里开始。 HTTP 允许对实体主体的内容进行编码，比如可以使之更安全或进行压缩以节省空间。如果主体进行了内容编码，Content-Length 首部说明的就是编码后（encoded）的主体的字节长度，而不是未编码的原始主体的长度。 下面列出的规则说明了在若干不同的情况下如何正确计算主体的长度和结束位置。这些规则应当按顺序应用，谁先匹配就用谁。 如果特定的 HTTP 报文类型中不允许带有主体，就忽略 Content-Length 首部，它是对没有实际发送出来的主体进行计算的。这种情况下，Content-Length 首部是提示性的，并不说明实际的主体长度。 如果报文中含有描述传输编码的 Transfer-Encoding 首部（不采用默认的 HTTP “恒等” 编码），那实体就应由一个称为 “零字节块”（zero-byte chunk）的特殊模式结束，除非报文已经因连接关闭而结束。 如果报文中含有 Content-Length 首部（并且报文类型允许有实体主体），而且没有非恒等的 Transfer-Encoding 首部字段，那么 Content-Length 的值就是主体的长度。如果收到的报文中既有 Content-Length 首部字段又有非恒等的 Transfer-Encoding 首部字段，那就必须忽略 Content-Length，因为传输编码会改变实体主体的表示和传输方式（因此可能就会改变传输的字节数）。 如果报文使用了 multipart/byteranges（多部分/字节范围）媒体类型，并且没有用 Content-Length 首部指出实体主体的长度，那么多部分报文中的每个部分都要说明它自己的大小。这种多部分类型是唯一的一种自定界的实体主体类型，因此除非发送方知道接收方可以解析它，否则就不能发送这种媒体类型。 如果上面的规则都不匹配，实体就在连接关闭的时候结束。实际上，只有服务器可以使用连接关闭来指示报文的结束。客户端不能用关闭连接来指示客户端报文的结束，因为这样会使服务器无法发回响应。 3. 内容编码内容编码的过程如下所述 网站服务器生成原始响应报文，其中有原始的 Content-Type 和 Content- Length 首部。 内容编码服务器（也可能就是原始的服务器或下行的代理）创建编码后的报文。编码后的报文有同样的 Content-Type 但 Content-Length 可能不同（比如主体被压缩了）。内容编码服务器在编码后的报文中增加 Content-Encoding 首部，这样接收的应用程序就可以进行解码了。 接收程序得到编码后的报文，进行解码，获得原始报文。 为了避免服务器使用客户端不支持的编码方式，客户端就把自己支持的内容编码方式列表放在请求的 Accept-Encoding 首部里发出去。如果 HTTP 请求中没有包含 Accept-Encoding 首部，服务器就可以假设客户端能够接受任何编码方式（等价于发送 Accept-Encoding:*）。 4. 传输编码和分块编码4.1 Transfer-Encoding 首部HTTP 协议中只定义了下面两个首部来描述和控制传输编码 Transfer-Encoding：告知接收方为了可靠地传输报文，已经对其进行了何种编码。 TE：用在请求首部中，告知服务器可以使用哪些传输编码扩展。 4.2 分块编码分块编码把报文分割为若干个大小已知的块。块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了。要注意的是，分块编码是一种传输编码，因此是报文的属性，而不是主体的属性。 若客户端和服务器之间不是持久连接，客户端就不需要知道它正在读取的主体的长度，而只需要读到服务器关闭主体连接为止。当使用持久连接时，在服务器写主体之前，必须知道它的大小并在 Content-Length 首部中发送。如果服务器动态创建内容，就可能在发送之前无法知道主体的长度。 分块编码为这种困难提供了解决方案，只要允许服务器把主体逐块发送，说明每块的大小就可以了。因为主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后在主体发送完之前重复这个过程。服务器可以用大小为 0 的块作为主体结束的信号，这样就可以继续保持连接，为下一个响应做准备。 分块编码是相当简单的。它由起始的 HTTP 响应首部块开始，随后就是一系列分块。每个分块包含一个长度值和该分块的数据。长度值是十六进制形式并将 CRLF 与数据分隔开。分块中数据的大小以字节计算，不包括长度值与数据之间的 CRLF 序列以及分块结尾的 CRLF 序列。最后一个块有点特别，它的长度值为 0，表示 “主体结束”。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术文章 Backup]]></title>
    <url>%2F2016%2F05%2F29%2F%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0%20Backup%2F</url>
    <content type="text"><![CDATA[分布式一致性Raft http://thesecretlivesofdata.com/raft/ https://raft.github.io/ https://raft.github.io/raft.pdf]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>技术文章</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术文档 Backup]]></title>
    <url>%2F2016%2F05%2F29%2F%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3%20Backup%2F</url>
    <content type="text"><![CDATA[Mysql Mysql 5.7 官方文档：https://dev.mysql.com/doc/refman/5.7/en/ Redis Redis 中文网：http://www.redis.cn/ Redis 命令参考：http://doc.redisfans.com/index.html 《Redis 设计与实现》：http://redisbook.com/ Spring Boot 官方文档：https://docs.spring.io/spring-boot/docs/current/reference/html/ Spring Cloud Spring Cloud Config: http://cloud.spring.io/spring-cloud-config/single/spring-cloud-config.html Spring Cloud Netflix: https://cloud.spring.io/spring-cloud-netflix/single/spring-cloud-netflix.html Spring Boot Admin: http://codecentric.github.io/spring-boot-admin/1.5.3/ Spring Cloud Sleuth: http://cloud.spring.io/spring-cloud-static/spring-cloud-sleuth/1.2.4.RELEASE/ Spring Cloud Stream: https://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/ Spring Cloud Stream Kafka Binder: https://docs.spring.io/autorepo/docs/spring-cloud-stream-binder-kafka-docs/1.1.0.M1/reference/htmlsingle/ Spring Cloud Bus: http://cloud.spring.io/spring-cloud-static/spring-cloud-bus/1.3.1.RELEASE/]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>技术文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis原理]]></title>
    <url>%2F2016%2F04%2F01%2FMybatis%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[0. 官方文档mybatis 1. 完整配置文件示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!-- 自定义属性字段 --&gt; &lt;properties resource="resource.properties"&gt; &lt;property name="propKey" value="propValue"&gt;&lt;/property&gt; &lt;/properties&gt; &lt;!-- 参数设置 --&gt; &lt;settings&gt; &lt;setting name="settingKey" value="settingValue"/&gt; &lt;/settings&gt; &lt;!-- 自定义别名 --&gt; &lt;typeAliases&gt; &lt;typeAlias type="type" alias="alias"/&gt; &lt;package name="typeAliaPackage" /&gt; &lt;/typeAliases&gt; &lt;!-- 自定义类型处理器 --&gt; &lt;typeHandlers&gt; &lt;typeHandler jdbcType="VARCHAR" javaType="string" handler="MyStringTypeHandler"/&gt; &lt;!--扫描整个包下的自定义类型处理器--&gt; &lt;package name="typeHandlerPackage" /&gt; &lt;/typeHandlers&gt; &lt;!-- 自定义对象工厂 --&gt; &lt;objectFactory type="MyObjectFactory"&gt; &lt;property name="objectFactoryPropKey" value="objectFactoryPropValue"&gt;&lt;/property&gt; &lt;/objectFactory&gt; &lt;!-- 自定义插件 --&gt; &lt;plugins&gt; &lt;!-- 分页拦截器 --&gt; &lt;plugin interceptor="com.xhm.util.PageInterceptor"&gt;&lt;/plugin&gt; &lt;/plugins&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"&gt; &lt;property name="autoCommit" value="false"&gt;&lt;/property&gt; &lt;/transactionManager&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="$&#123;driver&#125;"&gt;&lt;/property&gt; &lt;property name="url" value="$&#123;url&#125;"&gt;&lt;/property&gt; &lt;property name="username" value="$&#123;username&#125;"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;password&#125;"&gt;&lt;/property&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 数据库厂商标识 --&gt; &lt;databaseIdProvider type="DB_VENDOR"&gt; &lt;property name="SQL Server" value="sqlserver" /&gt; &lt;property name="MySQL" value="mysql" /&gt; &lt;property name="DB2" value="db2" /&gt; &lt;property name="Oracle" value="oracle" /&gt; &lt;/databaseIdProvider&gt; &lt;!-- 引入映射器 --&gt; &lt;mappers&gt; &lt;!-- 通过项目文件路径 --&gt; &lt;mapper resource="mapper/MyMapper.xml"/&gt; &lt;!-- 通过类路径 --&gt; &lt;mapper class="mapper/MyMapper"/&gt; &lt;!-- 通过文件url路径 --&gt; &lt;mapper url="classpath:///mapper/MyMapper.xml"/&gt; &lt;!-- 通过包扫描 --&gt; &lt;package name="mapperPackage" /&gt; &lt;/mappers&gt;&lt;/configuration&gt; 2. 构建SqlSessionFactory2.1 Mybatis的核心组件 类 功能 生命周期 SqlSessionFactoryBuilder 根据配置生成SqlSessionFactory 方法内 SqlSessionFactory 生成SqlSession Mybatis应用整个生命周期 SqlSession 获取Mapper接口，执行SQL语句 一个事务 SQL Mapper 配置SQL语句和对象映射规则 方法内 2.2 时序图 2.3 核心代码 SqlSessionFactoryBuilder 12345678910111213141516171819public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error building SqlSession.", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125;&#125; public SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config);&#125; DefaultSqlSessionFactory 123456789101112131415161718192021222324252627282930public class DefaultSqlSessionFactory implements SqlSessionFactory &#123; private final Configuration configuration; public DefaultSqlSessionFactory(Configuration configuration) &#123; this.configuration = configuration; &#125; @Override public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); &#125; private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; //通过Confuguration对象去获取Mybatis相关配置信息, Environment对象包含了数据源和事务的配置 final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException("Error opening session. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125;&#125; XMLConfigBuilder 1234567891011121314151617181920212223242526272829public Configuration parse() &#123; if (parsed) &#123; throw new BuilderException("Each XMLConfigBuilder can only be used once."); &#125; parsed = true; parseConfiguration(parser.evalNode("/configuration")); return configuration;&#125;private void parseConfiguration(XNode root) &#123; try &#123; //和配置文件里的顺序一致 propertiesElement(root.evalNode("properties")); Properties settings = settingsAsProperties(root.evalNode("settings")); loadCustomVfs(settings); typeAliasesElement(root.evalNode("typeAliases")); pluginElement(root.evalNode("plugins")); objectFactoryElement(root.evalNode("objectFactory")); objectWrapperFactoryElement(root.evalNode("objectWrapperFactory")); reflectionFactoryElement(root.evalNode("reflectionFactory")); settingsElement(settings); environmentsElement(root.evalNode("environments")); databaseIdProviderElement(root.evalNode("databaseIdProvider")); typeHandlerElement(root.evalNode("typeHandlers")); mapperElement(root.evalNode("mappers")); &#125; catch (Exception e) &#123; throw new BuilderException("Error parsing SQL Mapper Configuration. Cause: " + e, e); &#125;&#125; 3. 映射器的内部组成3.1 映射器的三个组成部分 MappedStatement：保存映射器的一个节点 SqlSource：提供BoundSql，它是MappedStatement的一个属性 BoundSql：建立SQL和参数 3.2 BoundSqlBoundSql提供三个主要的属性：parameterMappings，parameterObject和sql parameterObject为参数本身 如果传递的是POJO或Map，那么这个parameterObject就是传入的POJO或Map 如果传递多个参数且没有使用@Param注解，那么Mybatis就会把parameterObject变为一个Map&lt;String, Object&gt;对象，其键值关系按顺序规划，形如：{“1”: param1, “2”: param2} 如果使用了@Param注解，Mybatis会按注解参数建立Map&lt;String, Object&gt;对象 parameterMappings是一个List，每一个元素都是ParameterMapping的对象，用于描述参数 sql属性保存映射器SQL 4. Mapper代理4.1 时序图 4.2 核心代码 MapperRegistry 1234567891011public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException("Type " + type + " is not known to the MapperRegistry."); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException("Error getting mapper instance. Cause: " + e, e); &#125;&#125; MapperProxyFactory 12345678protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125;public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);&#125; 5. SQL执行5.1 SqlSession下的四大对象 Executor：由它来调度StatementHandler，ParameterHandler和ResultHandler来执行对应的SQL StatementHandler：使数据库的Statement执行操作，在四大对象中处于核心地位，起到承上启下的作用 ParameterHandler：处理SQL参数 ResultHandler：进行最后数据集（ResultSet）的封装 5.2 Executor Mybatis中有三种Executor，由setting元素的defaultExecutorType设置 SIMPLE：默认 REUSE：执行器重用预处理语句 BATCH：重用语句和批量更新 org.apache.ibatis.session.Configuration#newExecutor(org.apache.ibatis.transaction.Transaction, org.apache.ibatis.session.ExecutorType) 1234567891011121314151617public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; interceptorChain.pluginAll(executor)通过配置的插件生成Executor的代理，改变Executor的行为。 5.3 StatementHandlerStatementHandler处理数据库会话 org.apache.ibatis.session.Configuration#newStatementHandler 12345public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125; RoutingStatementHandler通过适配模式找到对应的StatementHandler org.apache.ibatis.executor.statement.RoutingStatementHandler#RoutingStatementHandler 1234567891011121314151617public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; switch (ms.getStatementType()) &#123; case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException("Unknown statement type: " + ms.getStatementType()); &#125;&#125; 5.4 时序图（以一次多记录查询为例） 5.5 核心代码 MapperProxy 123456789101112131415161718192021@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args);&#125;private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) &#123; mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); &#125; return mapperMethod;&#125; MapperMethod 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; if (SqlCommandType.INSERT == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); &#125; else if (SqlCommandType.UPDATE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); &#125; else if (SqlCommandType.DELETE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); &#125; else if (SqlCommandType.SELECT == command.getType()) &#123; if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; &#125; else if (SqlCommandType.FLUSH == command.getType()) &#123; result = sqlSession.flushStatements(); &#125; else &#123; throw new BindingException("Unknown execution method for: " + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException("Mapper method '" + command.getName() + " attempted to return null from a method with a primitive return type (" + method.getReturnType() + ")."); &#125; return result;&#125;private &lt;E&gt; Object executeForMany(SqlSession sqlSession, Object[] args) &#123; List&lt;E&gt; result; Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) &#123; RowBounds rowBounds = method.extractRowBounds(args); result = sqlSession.&lt;E&gt;selectList(command.getName(), param, rowBounds); &#125; else &#123; result = sqlSession.&lt;E&gt;selectList(command.getName(), param); &#125; // issue #510 Collections &amp; arrays support if (!method.getReturnType().isAssignableFrom(result.getClass())) &#123; if (method.getReturnType().isArray()) &#123; return convertToArray(result); &#125; else &#123; return convertToDeclaredCollection(sqlSession.getConfiguration(), result); &#125; &#125; return result;&#125; DefaultSqlSession 1234567891011@Overridepublic &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error querying database. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; BaseExecutor 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql);&#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if (closed) &#123; throw new ExecutorException("Executor was closed."); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list; &#125; private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list; &#125; protected Connection getConnection(Log statementLog) throws SQLException &#123; Connection connection = transaction.getConnection(); if (statementLog.isDebugEnabled()) &#123; return ConnectionLogger.newInstance(connection, statementLog, queryStack); &#125; else &#123; return connection; &#125; &#125; SimpleExecutor 1234567891011121314151617181920@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125;private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); stmt = handler.prepare(connection); handler.parameterize(stmt); return stmt;&#125; BaseStatementHandler 1234567891011121314151617@Overridepublic Statement prepare(Connection connection) throws SQLException &#123; ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try &#123; statement = instantiateStatement(connection); setStatementTimeout(statement); setFetchSize(statement); return statement; &#125; catch (SQLException e) &#123; closeStatement(statement); throw e; &#125; catch (Exception e) &#123; closeStatement(statement); throw new ExecutorException("Error preparing statement. Cause: " + e, e); &#125;&#125; PreparedStatementHandler 12345678910111213141516171819202122232425262728@Overridepublic &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.&lt;E&gt; handleResultSets(ps);&#125;@Overrideprotected Statement instantiateStatement(Connection connection) throws SQLException &#123; String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) &#123; String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) &#123; return connection.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS); &#125; else &#123; return connection.prepareStatement(sql, keyColumnNames); &#125; &#125; else if (mappedStatement.getResultSetType() != null) &#123; return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); &#125; else &#123; return connection.prepareStatement(sql); &#125;&#125;@Overridepublic void parameterize(Statement statement) throws SQLException &#123; parameterHandler.setParameters((PreparedStatement) statement);&#125; DefaultParameterHandler 123456789101112131415161718192021222324252627282930313233343536@Overridepublic void setParameters(PreparedStatement ps) &#123; ErrorContext.instance().activity("setting parameters").object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; jdbcType = configuration.getJdbcTypeForNull(); &#125; try &#123; typeHandler.setParameter(ps, i + 1, value, jdbcType); &#125; catch (TypeException e) &#123; throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e); &#125; catch (SQLException e) &#123; throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e); &#125; &#125; &#125; &#125;&#125; DefaultResultSetHandler 12345678910111213141516171819202122232425262728293031323334353637@Overridepublic List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity("handling results").object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; String[] resultSets = mappedStatement.getResulSets(); if (resultSets != null) &#123; while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); &#125; rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; &#125; return collapseSingleResultList(multipleResults);&#125; 6. 示例代码 github - LearnMybatis 目录结构 TestMybatis 1234567891011121314151617181920212223242526272829303132333435363738394041424344import data.User;import mapper.UserMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Assert;import org.junit.Test;import java.io.IOException;import java.io.InputStream;/** * Created by xyq on 17/3/31. */public class TestMybatis extends Assert &#123; @Test public void test() &#123; String resource = "mybatis-config.xml"; SqlSessionFactory sqlSessionFactory = initSqlSessionFactory(resource); SqlSession sqlSession = sqlSessionFactory.openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = new User(); user.setUserId("id"); user.setUserName("name"); assertEquals(userMapper.insertUser(user), 1); User res = userMapper.getUser("id"); assertEquals(res.getUserId(), "id"); assertEquals(res.getUserName(), "name"); user.setUserName("NAME"); assertEquals(userMapper.updateUser(user), 1); assertEquals(userMapper.deleteUser("id"), 1); &#125; public static SqlSessionFactory initSqlSessionFactory(String resource) &#123; InputStream is = null; try &#123; is = Resources.getResourceAsStream(resource); &#125; catch (IOException e) &#123; System.out.println("can not load resource " + resource); &#125; return new SqlSessionFactoryBuilder().build(is); &#125;&#125; User 1234567891011121314151617181920212223242526package data;/** * Created by xyq on 17/3/31. */public class User &#123; private String userId; private String userName; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125;&#125; UserMapper 123456789101112131415161718package mapper;import data.User;import org.apache.ibatis.annotations.Param;/** * Created by xyq on 17/3/31. */public interface UserMapper &#123; public int insertUser(User user); public int updateUser(User user); public User getUser(@Param("userId") String userId); public int deleteUser(@Param("userId") String userId);&#125; UserMapper.xml 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="mapper.UserMapper"&gt; &lt;resultMap id="userType" type="User"&gt; &lt;result property="userId" column="user_id" /&gt; &lt;result property="userName" column="user_name" /&gt; &lt;/resultMap&gt; &lt;sql id="columns"&gt; user_id, user_name &lt;/sql&gt; &lt;select id="getUser" resultMap="userType"&gt; SELECT &lt;include refid="columns" /&gt; from t_user &lt;/select&gt; &lt;insert id="insertUser" parameterType="User"&gt; INSERT INTO t_user (&lt;include refid="columns" /&gt;) VALUES (#&#123;userId&#125;, #&#123;userName&#125;) &lt;/insert&gt; &lt;update id="updateUser" parameterType="User"&gt; update t_user set user_name = #&#123;userName&#125; where user_id = #&#123;userId&#125; &lt;/update&gt; &lt;delete id="deleteUser"&gt; delete from t_user where user_id = #&#123;userId&#125; &lt;/delete&gt;&lt;/mapper&gt; mybatis-config.xml 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias type="data.User" alias="User"/&gt; &lt;/typeAliases&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"&gt; &lt;property name="autoCommit" value="false"&gt;&lt;/property&gt; &lt;/transactionManager&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/sampledb"&gt;&lt;/property&gt; &lt;property name="username" value="root"&gt;&lt;/property&gt; &lt;property name="password" value="password"&gt;&lt;/property&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="mapper/UserMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>Mybatis</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring 3.x 企业应用开发实战》：MVC]]></title>
    <url>%2F2016%2F03%2F26%2F%E3%80%8ASpring%203.x%20%E4%BC%81%E4%B8%9A%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9AMVC%2F</url>
    <content type="text"><![CDATA[1. 处理流程 请求提交给 DispatchServlet 查找 HandlerMapping 调用由 HandlerAdapter 封装后的 Handler 返回 ModelAndView 到 DispatcherServlet 借由 ViewResolver 完成逻辑视图到真实视图的转换 返回响应 2. 配置 DispatcherServlet web.xml 1234567891011121314151617181920212223242526272829&lt;web-app&gt; &lt;!-- 父容器配置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/applicationServlet.xml, &lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 子容器配置 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;logLevel&lt;/param-name&gt; &lt;param-value&gt;FINE&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- url映射 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;url-pattern&gt;/api/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 子容器可以访问父容器的 bean，父容器不能访问子容器的 bean 默认采用 org.springframework.web.context.ContextLoaderListener 默认使用 /WEB-INF/{servlet-name}-*.xml 加载子容器 3. DispatcherServlet 的初始化 DispatcherServlet 初始化 1234567891011protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context);&#125; 默认配置： DispatcherServlet.properties 123456789101112131415161718192021222324# Default implementation classes for DispatcherServlet's strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 4. Controller 注解4.1 类注解 @Controller （由 Spring 识别 Handler 实例） @RequestMapping(value=, method=, params=) 4.2 方法注解 @RequestMapping(value=, method=, params=) @PathVariable，配合占位符 {parameter} @RequestParam(value=, required=, defaultValue=) @CookieValue(value=, required=, defaultValue=) @RequestHeader(value=, required=, defaultValue=) 5. 封装入参 HttpServletRequest，WebRequest，ServletRequest 的 InputStream / Reader HttpServeltResponse，ServletResponse的OutputStream / Writer 6. 请求信息和对象的转换6.1 基本 HttpMessageConverter&lt;T&gt; 使用 @RequestBody / @ResponseBody；使用 HttpEntity&lt;T&gt; / ResponseEntity&lt;T&gt; Spring 根据 HTTP 报文头部的 Accept 指定的 MIME 类型，查找匹配的 HttpMessageConverter Spring MVC 默认装配 AnnotationMethodHandlerAdapter，调用 HttpMessageConverter MVC 命名空间的 &lt;mvc:annotation-driven/&gt; 标签会创建并注册一个默认的 DefaultAnnotationHandlerMapping 和一个 AnnotationMethodHandlerAdapter 实例，如果上下文中存在自定义的对应组件 bean，则覆盖默认配置 6.2 样例 app-servlet.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;bean id="handlerMapping" class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping"&gt; &lt;property name="alwaysUseFullPath" value="true"/&gt; &lt;property name="interceptors"&gt; &lt;list&gt; &lt;ref bean="monitorInterceptor"/&gt; &lt;ref bean="commonOutLogInterceptor"/&gt; &lt;ref bean="serverTraceInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="handlerAdapter" class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"&gt; &lt;property name="messageConverters"&gt; &lt;list&gt; &lt;bean class="org.springframework.http.converter.ByteArrayHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"&gt; &lt;property name="writeAcceptCharset" value="false"/&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.xml.SourceHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.xml.XmlAwareFormHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;bean class="org.springframework.http.MediaType"&gt; &lt;constructor-arg value="text"/&gt; &lt;constructor-arg value="json"/&gt; &lt;constructor-arg&gt; &lt;map&gt; &lt;entry key="charset" value="UTF-8" /&gt; &lt;/map&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 7. 处理模型数据 Spring MVC 在调用方法前会创建一个隐含的模型对象 ModelAndView：返回值类型为 ModelAndView 时，方法体通过该对象添加模型数据 @ModelAttribute：入参对象添加到数据模型中 Map 和 Model：入参为 org.springframework.ui.Model、org.springframework.ui.ModelMap或 java.util.Map 时，处理方法返回时，Map 中的数据会自动添加到模型中 @SessionAttributes：将模型中的某个属性暂存到 HttpSession 中，以便多个请求共享 8. 数据绑定8.1 基本 Spring MVC 将 ServletRequest 对象及处理方法的入参实例传递给 DataBinder； DataBinder调用 ConversionService 组件进行数据类型转换、数据格式化等工作，将 ServletRequest 中的消息填充到入参对象中； 然后再调用 Validator 组件对已经绑定了请求消息数据的入参对象进行数据合法性校验，并最终生成绑定结果 BindingResult 对象，其中还包含相应的校验错误对象 抽取 BindingResult 中的入参对象及校验错误对象，赋给处理方法的相应入参 8.2 数据转换 例如：将请求信息中A类型参数转换并绑定到 Controller 对应的处理方法的 B 类型入参中 基于 ConversionService 接口，Spring 将自动识别其实现类，用于入参类型转换，类似于 C++ 中的自定义类型转换。例如，将 HTTP 请求信息中的字符串格式参数转换为 Controller 对应方法中的类类型入参 可通过 ConversionServiceFactoryBean 的 converters 属性注册自定义转换器。可接受 Converter，ConverterFacotory，GenericConverter或 ConditionalConverterFactory 的实现类，并统一封装到一个 ConversionService 的实例（即 GenericConversionService）中 1234567&lt;bean id="conversionService" class="org.springframework.context.support.ConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;list&gt; &lt;bean class="MyConverters" /&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; &lt;mvc:annotation-driven/&gt;标签还会注册一个默认的 ConversionService，即 FormattingConversionServiceFactoryBean 8.3 数据格式化 例如：将请求信息中字符串类型参数转换并绑定到 Controller 对应的处理方法入参中的 Date 类型属性中 格式化框架定义了 Formatter&lt;T&gt; 接口，扩展于 Printer&lt;T&gt; 和 Parser&lt;T&gt; 接口 Srping 提供 AnnotationFormatterFactory&lt;A extends Annotation&gt; 接口及两个实现类：NumberFormatAnnotationFormatterFactory和 JodaDateTimeFormatAnnotationFormatterFactory 在入参类属性上使用注解：@DateTimeFormat，@NumberFormat Spring 通过 &lt;mvc:annotation-driven/&gt; 标签创建 FormattingConversionServiceFactoryBean 作为 FormattingConversionService 的实例，自动装配 NumberFormatAnnotationFormatterFactory 和 JodaDateTimeFormatAnnotationFormatterFactory 8.4 数据验证 &lt;mvc:annotation-driven/&gt;标签会默认装配 LocalValidatorFactoryBean，实现了 Spring 的Validator 接口，通过在入参上标注 @Valid 注解即可让 Spring 在完成数据绑定后执行数据校验 @Valid注解标注的入参和其后的 BindingResult 或 Errors 入参成对出现，后者保存前者的校验结果 校验结果也保存在 MVC 的隐含模型中 样例 123456789101112131415161718192021222324public Class User &#123; private String userId; @Pattern(regexp="w&#123;4,30&#125;") private String userName; @Length(min=2, max=100) private String nickName; @Past @DateTimeFormat(pattern = "yyyy-MM-dd") private Date birthday; @DecimalMin(value = "1000.00") @DecimalMax(value = "10000.00") @NumberFormat(pattern = "#,###.##") pirvate Long salary;&#125;@RequestMapping(value = "/handle")public void handle(@Valid User uer, BindingResult bindingResult) &#123; //do something&#125; 9. 视图解析9.1 基本 视图对象是一个 bean，由视图解析器负责实例化。 不同的视图实现技术对应于不同的 View 实现类 所有的视图解析器都实现了 ViewResolver 接口 9.2 样例 app-servlet.xml 12345678910111213141516171819202122232425262728293031&lt;!-- For multipart encoding support --&gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSize" value="209715200"/&gt;&lt;/bean&gt;&lt;bean id="beanNameResolver" class="org.springframework.web.servlet.view.BeanNameViewResolver"/&gt;&lt;!--VM 模板文件解析 --&gt;&lt;bean id="viewResolver" class="org.springframework.web.servlet.view.velocity.VelocityViewResolver"&gt; &lt;property name="cache" value="true" /&gt; &lt;property name="prefix" value="" /&gt; &lt;property name="suffix" value=".vm" /&gt; &lt;property name="contentType"&gt; &lt;value&gt;text/html; charset=UTF-8&lt;/value&gt; &lt;/property&gt; &lt;property name="toolboxConfigLocation" value="/WEB-INF/toolbox.xml"/&gt;&lt;/bean&gt;&lt;bean id="velocityConfig" class="org.springframework.web.servlet.view.velocity.VelocityConfigurer"&gt; &lt;property name="resourceLoaderPath" value="/WEB-INF/vm/" /&gt; &lt;property name="velocityPropertiesMap"&gt; &lt;props&gt; &lt;prop key="input.encoding"&gt;UTF-8&lt;/prop&gt; &lt;prop key="output.encoding"&gt;UTF-8&lt;/prop&gt; &lt;prop key="velocimacro.library"&gt;&lt;/prop&gt; &lt;prop key="velocimacro.library.autoreload"&gt;true&lt;/prop&gt; &lt;prop key="directive.foreach.counter.name"&gt;loopCursor&lt;/prop&gt; &lt;prop key="directive.foreach.counter.initial.value"&gt;0&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 10. 静态资源处理 需要对项目中的图片、html 静态资源等单独处理 配置 &lt;mvc:default-servlet-handler&gt; 后，会装配一个 DefaultServletHttpRequestHandler，对静态资源做检查 配置 &lt;mvc:resources/&gt;，允许对静态资源文件路径作映射，并提供文件在浏览器端的缓存控制，例如 1&lt;mvc:resources mapping="/resources/**" location="/,classpath:/META-INF/publicResources" /&gt; 11. 拦截器11.1 基本 DispatcherServlet将请求交给处理器映射（HandlerMapping），找到对应的 HandlerExecutionChain 找到对应的 HandlerExecutionChain 包含若干 HandlerInterceptor，和一个 Handler HandlerInterceptor 接口： 12345678public interface HandlerInterceptor &#123; boolean preHandle (HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; void postHandle (HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; void afterCompletion (HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception;&#125; 11.2 样例 app-servlet.xml: 123456&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/api/**" /&gt; &lt;bean class="outfox.ynote.webserver.web.HttpsInterceptor" /&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 12. 异常处理12.1 基本 Spring MVC 通过 HandlerExceptionResolver 处理异常 HandlerExceptionResolver 接口： 123public interface HandlerExceptionResolver &#123; ModelAndView resolveException (HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex);&#125; Spring MVC 默认装配了 DefaultHandlerExceptionResolver Spring MVC 默认注册了 AnnotationMethodHandlerExceptionResolver，允许通过 @ExceptionHandler 指定处理特定异常 12.2 样例 web.xml 123456789101112131415&lt;web-app&gt; &lt;!-- 对各种异常和错误，交由 ErrorController 处理 --&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;403&lt;/error-code&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;exception-type&gt;java.lang.Throwable&lt;/exception-type&gt; &lt;location&gt;/error&lt;/location&gt; &lt;/error-page&gt;&lt;/web-app&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring 3.x 企业应用开发实战》：DAO]]></title>
    <url>%2F2016%2F03%2F17%2F%E3%80%8ASpring%203.x%20%E4%BC%81%E4%B8%9A%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%9ADAO%2F</url>
    <content type="text"><![CDATA[1. 概念 Spring 的 DAO 异常体系建立在运行期异常的基础上，封装了源异常 JDBC 数据访问流程： 准备资源 启动事务 在事务中执行具体数据访问操作 提交/回滚事务 关闭资源，处理异常 Spring 将相同的数据访问流程固化到模板类中，把数据访问中固定和变化的部分分开，同时保证模板类是线程安全的。Spring 为不同的持久化技术都提供了简化操作的模板和回调。 数据库事务：原子性，一致性，隔离性和持久性（ACID） 5 类数据库并发问题： 脏读：A 事务读取到 B 事务尚未提交的数据 不可重复读：A 事务中读取到 B 事务已经提交的更新数据，即连续两次读取结果不同 幻读：A 事务读取 B 事务的==新增==数据 第一类更新丢失：A 事务撤销时覆盖了 B 事务的提交 第二类更新丢失：A 事务覆盖 B 事务已经提交的数据 JDBC 默认情况下自动提交，即每条执行的 SQL 语句都对应一个事务，AutoCommit = TRUE Spring基于 ThreadLocal 解决有状态的 Connetion 的并发问题，事务同步管理器 org.springframework.transaction.support.TransactionSynchronizationManager 使用 ThreadLocal 为不同事务线程提供独立的资源副本 Spring 事务管理基于 3 个接口：TransactionDefinition，TransactionStatus 和 PlatformTransactionManager Spring 为不同持久化技术提供了从 TransactionSynchronizationManager 获取对应线程绑定资源的工具类，如 DataSourceUtils.getConnection(DataSource dataSource)。模板类在内部通过工具类访问 TransactionSynchronizationManager中的线程绑定资源 Spring 通过事务传播行为控制当前的事务如何传播到被嵌套调用的目标服务接口方法中 使用 &lt;tx:annotation-driven transaction-manager=&quot;txManager&quot;&gt; 对标注 @Transactional 注解的 bean 进行加工处理，织入事务管理切面 @Transactional 注解的属性 事务传播行为：propagation，默认 PROPAGATION_REQUIRED，即如果当前没有事务，就新建一个事务；否则加入到当前事务 事务隔离级别：isolation，默认 ISOLATION_DEFAULT 读写事务属性：readOnly 超时时间：timeout 回滚设置：rollbackFor，rollbackForClassName，noRollbackFor，noRollbackForClassName 在相同线程中进行相互嵌套调用的事务方法工作于相同的事务中；如果在不同线程中，则工作在独立的事务中 特殊方法： 注解不能被继承，所以业务接口中的 @Transactional 注解不会被业务实现类继承；方法处的注解会覆盖类定义处的注解 对于基于接口动态代理的 AOP 事务，由于接口方法都是 public 的，实现类的实现方法必须是 public的，同时不能使用 static 修饰符。因此，可以通过接口动态代理实施 AOP 增强、实现 Spring 事务的方法只能是 public 或 public final 的 基于 CGLib 动态代理实施 AOP 的时候，由于使用 final、static、private 的方法不能被子类覆盖，相应的，这些方法不能实施 AOP 增强，实现事务 不能被 Spring 进行 AOP 事务增强的方法不能启动事务，但是外层方法的事务上下文仍然可以传播到这些方法中 2. Spring 中使用 JDBC 编程示例 本地 mysql 建表 12345CREATE TABLE `t_user` ( `user_id` varchar(256) NOT NULL, `user_name` varchar(256) DEFAULT NULL, PRIMARY KEY (`user_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 springDAO.xml 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd "&gt; &lt;context:component-scan base-package="com.dao" /&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close" p:driverClassName="com.mysql.jdbc.Driver" p:url="jdbc:mysql://localhost:3306/sampledb" p:username="root" p:password="123123" /&gt; &lt;bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate" p:dataSource-ref="dataSource" /&gt; &lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager" p:dataSource-ref="dataSource" /&gt;&lt;/beans&gt; User 12345678910111213141516171819202122232425package com.data;public class User &#123; private String userId; private String userName; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125;&#125; BaseDAO 12345678910package com.dao;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;public class BaseDAO &#123; @Autowired protected JdbcTemplate jdbcTemplate;&#125; UserDAO 1234567891011121314151617181920212223242526272829303132package com.dao;import org.springframework.stereotype.Repository;import org.springframework.transaction.annotation.Transactional;import com.data.User;import com.mapper.UserRowMapper;@Repositorypublic class UserDAO extends BaseDAO &#123; private static final String SQL_GET_USER = "select * from t_user where " + "user_id = ?;"; private static final String SQL_INSERT_USER = "insert into t_user values(?, ?);"; private static final String SQL_CLEAN_USER = "delete from t_user where 1=1;"; @Transactional public User getUserById(String userId) &#123; return jdbcTemplate.queryForObject(SQL_GET_USER, new Object[]&#123;userId&#125;, new UserRowMapper()); &#125; @Transactional public int insertUser(User user) &#123; return jdbcTemplate.update(SQL_INSERT_USER, user.getUserId(), user.getUserName()); &#125; @Transactional public int cleanUser() &#123; return jdbcTemplate.update(SQL_CLEAN_USER); &#125;&#125; UserRowMapper 123456789101112131415161718package com.dao;import java.sql.ResultSet;import java.sql.SQLException;import org.springframework.jdbc.core.RowMapper;import com.data.User;public class UserRowMapper implements RowMapper&lt;User&gt;&#123; public User mapRow(ResultSet rs, int rowNumber) throws SQLException &#123; User user = new User(); user.setUserId(rs.getString("user_id")); user.setUserName(rs.getString("user_name")); return user; &#125;&#125; BaseTestCase 123456789101112package com;import org.junit.Assert;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=&#123;"/springDAO.xml"&#125;)public class BaseTestCase extends Assert &#123;&#125; TestUserDAO 1234567891011121314151617181920212223242526272829303132333435package com.dao;import org.junit.After;import org.junit.Before;import org.junit.Test;import org.springframework.beans.factory.annotation.Autowired;import com.BaseTestCase;import com.data.User;public class TestUserDAO extends BaseTestCase&#123; @Before @After public void clean() &#123; dao.cleanUser(); &#125; @Autowired private UserDAO dao; @Test public void getUserById() &#123; User user = new User(); String id = "id"; String name = "name"; user.setUserId(id); user.setUserName(name); assertEquals(dao.insertUser(user), 1); user = dao.getUserById(id); assertEquals(user.getUserId(), id); assertEquals(user.getUserName(), name); &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle实战-2]]></title>
    <url>%2F2016%2F02%2F18%2FGradle%E5%AE%9E%E6%88%98-2%2F</url>
    <content type="text"><![CDATA[1. Java和eclipse插件 初始化时创建java项目目录结构 1234567$ gradle init --type java-library:wrapper:initBUILD SUCCESSFULTotal time: 0.666 secs 默认的build.gradle的内容，默认已添加java插件。Java插件可以引入源代码约定，默认情况下到src/main/java下查找代码；并提供build，compileJava等task 12345678910111213141516171819202122232425// build.gradle/* * This build file was generated by the Gradle 'init' task. * * This generated file contains a sample Java project to get you started. * For more details take a look at the Java Quickstart chapter in the Gradle * user guide available at https://docs.gradle.org/3.3/userguide/tutorial_java_projects.html */// Apply the java plugin to add support for Javaapply plugin: 'java'// In this section you declare where to find the dependencies of your projectrepositories &#123; // Use jcenter for resolving your dependencies. // You can declare any Maven/Ivy/file repository here. jcenter()&#125;dependencies &#123; // The production code uses Guava compile 'com.google.guava:guava:20.0' // Use JUnit test framework testCompile 'junit:junit:4.12'&#125; 查看当前.classpath 12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;classpath&gt; &lt;classpathentry path="bin" kind="output"/&gt; &lt;classpathentry kind="src" path="src/main/java"/&gt; &lt;classpathentry kind="src" path="src/test/java"/&gt; &lt;classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-1.8/"/&gt; &lt;classpathentry sourcepath="/Users/xyq/.gradle/caches/modules-2/files-2.1/com.google.guava/guava/20.0/9c8493c7991464839b612d7547d6c263adf08f75/guava-20.0-sources.jar" kind="lib" path="/Users/xyq/.gradle/caches/modules-2/files-2.1/com.google.guava/guava/20.0/89507701249388e1ed5ddcf8c41f4ce1be7831ef/guava-20.0.jar"/&gt; &lt;classpathentry sourcepath="/Users/xyq/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/a6c32b40bf3d76eca54e3c601e5d1470c86fcdfa/junit-4.12-sources.jar" kind="lib" path="/Users/xyq/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/2973d150c0dc1fefe998f834810d68f278ea58ec/junit-4.12.jar"/&gt; &lt;classpathentry sourcepath="/Users/xyq/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/1dc37250fbc78e23a65a67fbbaf71d2e9cbc3c0b/hamcrest-core-1.3-sources.jar" kind="lib" path="/Users/xyq/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar"/&gt;&lt;/classpath&gt; 添加eclipse插件 1apply plugin: 'eclipse' 执行IDE支持，如关联Referenced Libraries等 123456789$ gradle eclipse:eclipseClasspath:eclipseJdt:eclipseProject:eclipseBUILD SUCCESSFULTotal time: 0.664 secs 2. 构建项目 新建入口类 1234567package com;public class Main &#123; public static void main(String[] args) &#123; System.out.println("hello gradle"); &#125;&#125; 项目根目录下运行 12345678910111213141516$ gradle build:compileJava UP-TO-DATE:processResources UP-TO-DATE:classes UP-TO-DATE:jar UP-TO-DATE:assemble UP-TO-DATE:compileTestJava UP-TO-DATE:processTestResources UP-TO-DATE:testClasses UP-TO-DATE:test UP-TO-DATE:check UP-TO-DATE:build UP-TO-DATEBUILD SUCCESSFULTotal time: 0.692 secs UP-TO-DATE标记了被跳过的任务。Gradle的增量式构建支持自动鉴别不需要被执行的任务，如compileTestJava，因为当前项目里没有添加单元测试类。构建生成的class、jar包、单测结果等文件在build/目录下。 3. 运行项目12$ java -cp build/classes/main/ com.Mainhello gradle 4. 修改项目和插件属性build.gradle中添加 12345678910//定义项目版本，version = 0.1//定义java兼容版本sourceCompatibility = 1.8//Jar包main方法位置jar &#123; manifest &#123; attributes 'Main-class': 'com.Main' &#125;&#125; 运行gradle build后，build/lib/下生成LearnGradle-0.1.jar，接着 12$ java -jar build/libs/LearnGradle-0.1.jarhello gradle 5. 可自定义源代码目录结构 示例 12345678910111213sourceSets &#123; main &#123; java &#123; srcDirs = ['src'] &#125; &#125; test &#123; java &#123; srcDirs = ['test'] &#125; &#125;&#125;buildDir = 'out' 6. 定义中央仓库123repositories &#123; mavenCentral()&#125; 7. 引入外部依赖gradle中，依赖由configuration分组 12345dependencies &#123; compile group: 'org.apache.commons', name: 'common3-lang3', version: '3.5' compile 'com.google.guava:guava:20.0' testCompile 'junit:junit:4.12'&#125; 默认依赖的jar包在用户目录的.gradle/cache/下。可以通过如下的task将项目依赖的jar包复制到项目目录中 123456task downloadLib(type: Copy) &#123; delete fileTree(dir: 'lib') from configurations.compile from configurations.testCompile into "lib"&#125; 8. 构建简单的Java Web项目 build.gradle添加gretty插件 1234567apply plugin: 'war'apply from: 'https://raw.github.com/akhikhl/gretty/master/pluginScripts/gretty.plugin'//grtty configgretty &#123; httpPort = 8080&#125; 构建web项目目录结构 1$ mkdir -p src/main/webapp/WEB-INF web页面 在webapp/创建一个静态HTML页面index.html，这个页面是之后访问的目标页面 12345678&lt;html&gt;&lt;head&gt; &lt;title&gt;Gradle Java Web Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;Hello Gradle Java Web!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 编译 运行gradle build，build/libs/目录下生成了LearnGradle-0.1.war文件，查看该war包内容 1234567891011$ jar -tf build/libs/LearnGradle-0.1.warMETA-INF/META-INF/MANIFEST.MFWEB-INF/WEB-INF/classes/WEB-INF/classes/com/WEB-INF/classes/com/Main.classWEB-INF/lib/WEB-INF/lib/commons-lang3-3.5.jarWEB-INF/lib/guava-20.0.jarindex.html 运行 12345678910111213$ gradle jettyStart:prepareInplaceWebAppFolder UP-TO-DATE:createInplaceWebAppFolder UP-TO-DATE:compileJava UP-TO-DATE:processResources UP-TO-DATE:classes UP-TO-DATE:prepareInplaceWebAppClasses UP-TO-DATE:prepareInplaceWebApp UP-TO-DATE:jettyStart00:35:12 INFO Jetty 9.2.15.v20160210 started and listening on port 808000:35:12 INFO LearnGradle runs at:00:35:12 INFO http://localhost:8080/LearnGradleRun 'gradle appStop' to stop the server. 在浏览器中打开http://localhost:8080/LearnGradle/index.html即可看到Hello Gradle Java Web! Gretty相关链接 https://github.com/akhikhl/gretty http://akhikhl.github.io/gretty-doc/Getting-started.html http://akhikhl.github.io/gretty-doc/Gretty-tasks http://akhikhl.github.io/gretty-doc/Gretty-configuration.html 9. 包装器wrapper和跨平台 自动创建 通过gradle init --type java-library初始化的项目已包含以下文件：gradlew，gradlew.bat，gradle/wrapper/gradle-wrapper.jar，gradle/wrapper/gradle-wrapper.properties。Linix / Windows平台可以在下载代码后通过gradlew / gradlew.bat在命令行操作项目 手动创建 在build.gradle添加任务 123task wrapper (type: Wrapper) &#123; gradleVersion = '3.3'&#125; 123456$ gradle wrapper:wrapperBUILD SUCCESSFULTotal time: 0.66 secs]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle实战-1]]></title>
    <url>%2F2016%2F02%2F16%2FGradle%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[1. 使用Gradle创建Java项目目录结构创建目录LearnGradle，并执行1234567$ gradle init:wrapper:initBUILD SUCCESSFULTotal time: 0.707 secs 2. Gradle中的task在build.gradle中添加 123456/*hellow gradle*/task helloGradle &#123; doLast&#123; println 'Hello Gradle' &#125;&#125; 在项目根目录下运行 1234567$ gradle helloGradle:helloGradleHello GradleBUILD SUCCESSFULTotal time: 0.667 secs 3. 高级特性示例123456789101112131415161718192021222324252627/*task chain sample*/task startChain &#123; doLast &#123; chainMessage() &#125;&#125;//隐含对Ant任务的使用def chainMessage() &#123; ant.echo(message: 'Repeat from here...')&#125;//循环定义任务，使用隐式变量it3.times &#123; task "repeatTasks$it" &#123; doLast &#123; println "do repeatTask$it" &#125; &#125;&#125;//定义任务依赖repeatTasks0.dependsOn startChainrepeatTasks1.dependsOn repeatTasks0repeatTasks2.dependsOn repeatTasks1task taskChainSample (dependsOn: repeatTasks2) 在项目根目录下运行 1234567891011121314$ gradle taskChainSample:startChain[ant:echo] Repeat from here...:repeatTasks0do repeatTasktask ':repeatTasks0':repeatTasks1do repeatTasktask ':repeatTasks1':repeatTasks2do repeatTasktask ':repeatTasks2':taskChainSampleBUILD SUCCESSFULTotal time: 0.752 secs 4. Gradle Help1234567891011121314151617181920212223242526272829303132333435363738394041$ gradle --helpUSAGE: gradle [option...] [task...]-?, -h, --help Shows this help message.-a, --no-rebuild Do not rebuild project dependencies.-b, --build-file Specifies the build file.-c, --settings-file Specifies the settings file.--configure-on-demand Only relevant projects are configured in this build run. This means faster build for large multi-project builds. [incubating]--console Specifies which type of console output to generate. Values are 'plain', 'auto' (default) or 'rich'.--continue Continues task execution after a task failure.-D, --system-prop Set system property of the JVM (e.g. -Dmyprop=myvalue).-d, --debug Log in debug mode (includes normal stacktrace).--daemon Uses the Gradle Daemon to run the build. Starts the Daemon if not running.--foreground Starts the Gradle Daemon in the foreground. [incubating]-g, --gradle-user-home Specifies the gradle user home directory.--gui Launches the Gradle GUI.-I, --init-script Specifies an initialization script.-i, --info Set log level to info.--include-build Includes the specified build in the composite. [incubating]-m, --dry-run Runs the builds with all task actions disabled.--max-workers Configure the number of concurrent workers Gradle is allowed to use. [incubating]--no-daemon Do not use the Gradle Daemon to run the build.--offline The build should operate without accessing network resources.-P, --project-prop Set project property for the build script (e.g. -Pmyprop=myvalue).-p, --project-dir Specifies the start directory for Gradle. Defaults to current directory.--parallel Build projects in parallel. Gradle will attempt to determine the optimal number of executor threads to use. [incubating]--profile Profiles build execution time and generates a report in the &lt;build_dir&gt;/reports/profile directory.--project-cache-dir Specifies the project-specific cache directory. Defaults to .gradle in the root project directory.-q, --quiet Log errors only.--recompile-scripts Force build script recompiling.--refresh-dependencies Refresh the state of dependencies.--rerun-tasks Ignore previously cached task results.-S, --full-stacktrace Print out the full (very verbose) stacktrace for all exceptions.-s, --stacktrace Print out the stacktrace for all exceptions.--status Shows status of running and recently stopped Gradle Daemon(s).--stop Stops the Gradle Daemon if it is running.-t, --continuous Enables continuous build. Gradle does not exit and will re-execute tasks when task file inputs change. [incubating]-u, --no-search-upward Don't search in parent folders for a settings.gradle file.-v, --version Print version info.-x, --exclude-task Specify a task to be excluded from execution. 5. 列出项目所有tasks12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273$ gradle -q tasks --all------------------------------------------------------------All tasks runnable from root project------------------------------------------------------------Build tasks-----------assemble - Assembles the outputs of this project.build - Assembles and tests this project.buildDependents - Assembles and tests this project and all projects that depend on it.buildNeeded - Assembles and tests this project and all projects it depends on.classes - Assembles main classes.clean - Deletes the build directory.jar - Assembles a jar archive containing the main classes.testClasses - Assembles test classes.Build Setup tasks-----------------init - Initializes a new Gradle build. [incubating]wrapper - Generates Gradle wrapper files. [incubating]Documentation tasks-------------------javadoc - Generates Javadoc API documentation for the main source code.Help tasks----------buildEnvironment - Displays all buildscript dependencies declared in root project 'LearnGradle'.components - Displays the components produced by root project 'LearnGradle'. [incubating]dependencies - Displays all dependencies declared in root project 'LearnGradle'.dependencyInsight - Displays the insight into a specific dependency in root project 'LearnGradle'.dependentComponents - Displays the dependent components of components in root project 'LearnGradle'. [incubating]help - Displays a help message.model - Displays the configuration model of root project 'LearnGradle'. [incubating]projects - Displays the sub-projects of root project 'LearnGradle'.properties - Displays the properties of root project 'LearnGradle'.tasks - Displays the tasks runnable from root project 'LearnGradle'.IDE tasks---------cleanEclipse - Cleans all Eclipse files.eclipse - Generates all Eclipse files.Verification tasks------------------check - Runs all checks.test - Runs the unit tests.Other tasks-----------cleanEclipseClasspathcleanEclipseJdtcleanEclipseProjectcompileJava - Compiles main Java source.compileTestJava - Compiles test Java source.eclipseClasspath - Generates the Eclipse classpath file.eclipseJdt - Generates the Eclipse JDT settings file.eclipseProject - Generates the Eclipse project file.helloGradleprocessResources - Processes main resources.processTestResources - Processes test resources.repeatTasks0repeatTasks1repeatTasks2startChaintaskChainSampleRules-----Pattern: clean&lt;TaskName&gt;: Cleans the output files of a task.Pattern: build&lt;ConfigurationName&gt;: Assembles the artifacts of a configuration.Pattern: upload&lt;ConfigurationName&gt;: Assembles and uploads the artifacts belonging to a configuration. 6. 查看某个task的详细信息1234567891011121314$ gradle -q help --task buildDetailed task information for buildPath :buildType Task (org.gradle.api.Task)Description Assembles and tests this project.Group build 7. 列出项目所有properties123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118$ gradle -q properties------------------------------------------------------------Root project------------------------------------------------------------allprojects: [root project 'LearnGradle']ant: org.gradle.api.internal.project.DefaultAntBuilder@1f8f3840antBuilderFactory: org.gradle.api.internal.project.DefaultAntBuilderFactory@1fbffe05archivesBaseName: LearnGradleartifacts: org.gradle.api.internal.artifacts.dsl.DefaultArtifactHandler_Decorated@4c645666asDynamicObject: DynamicObject for root project 'LearnGradle'assemble: task ':assemble'attributesSchema: org.gradle.api.internal.attributes.DefaultAttributesSchema_Decorated@2170586ebaseClassLoaderScope: org.gradle.api.internal.initialization.DefaultClassLoaderScope@475b3938buildDependents: task ':buildDependents'buildDir: /Users/xyq/workspace/LearnGradle/buildbuildFile: /Users/xyq/workspace/LearnGradle/build.gradlebuildNeeded: task ':buildNeeded'buildScriptSource: org.gradle.groovy.scripts.UriScriptSource@2774b800buildscript: org.gradle.api.internal.initialization.DefaultScriptHandler@494d1deecheck: task ':check'childProjects: &#123;&#125;class: class org.gradle.api.internal.project.DefaultProject_DecoratedclassLoaderScope: org.gradle.api.internal.initialization.DefaultClassLoaderScope@6add8f81classes: task ':classes'cleanEclipse: task ':cleanEclipse'cleanEclipseClasspath: task ':cleanEclipseClasspath'cleanEclipseJdt: task ':cleanEclipseJdt'cleanEclipseProject: task ':cleanEclipseProject'compileJava: task ':compileJava'compileTestJava: task ':compileTestJava'components: [org.gradle.api.internal.java.JavaLibrary@7451e91b]configurationActions: org.gradle.configuration.project.DefaultProjectConfigurationActionContainer@76e7eb29configurations: [configuration ':archives', configuration ':compile', configuration ':compileClasspath', configuration ':compileOnly', configuration ':default', configuration ':runtime', configuration ':testCompile', configuration ':testCompileClasspath', configuration ':testCompileOnly', configuration ':testRuntime']convention: org.gradle.api.internal.plugins.DefaultConvention@57642a76defaultArtifacts: org.gradle.api.internal.plugins.DefaultArtifactPublicationSet_Decorated@5143069cdefaultTasks: []deferredProjectConfiguration: org.gradle.api.internal.project.DeferredProjectConfiguration@2aa1349edependencies: org.gradle.api.internal.artifacts.dsl.dependencies.DefaultDependencyHandler_Decorated@63562c40dependencyCacheDir: /Users/xyq/workspace/LearnGradle/build/dependency-cachedependencyCacheDirName: dependency-cachedepth: 0description: nulldisplayName: root project 'LearnGradle'distsDir: /Users/xyq/workspace/LearnGradle/build/distributionsdistsDirName: distributionsdocsDir: /Users/xyq/workspace/LearnGradle/build/docsdocsDirName: docseclipse: org.gradle.plugins.ide.eclipse.model.EclipseModel_Decorated@15178dc6eclipseClasspath: task ':eclipseClasspath'eclipseJdt: task ':eclipseJdt'eclipseProject: task ':eclipseProject'ext: org.gradle.api.internal.plugins.DefaultExtraPropertiesExtension@5ca91e1eextensions: org.gradle.api.internal.plugins.DefaultConvention@57642a76fileOperations: org.gradle.api.internal.file.DefaultFileOperations@7f8fc4d1fileResolver: org.gradle.api.internal.file.BaseDirFileResolver@2d69c34cgradle: build 'LearnGradle'group:helloGradle: task ':helloGradle'identityPath: :inheritedScope: org.gradle.api.internal.ExtensibleDynamicObject$InheritedDynamicObject@4b9029ajar: task ':jar'javadoc: task ':javadoc'libsDir: /Users/xyq/workspace/LearnGradle/build/libslibsDirName: libslogger: org.gradle.internal.logging.slf4j.OutputEventListenerBackedLogger@5dd205dflogging: org.gradle.internal.logging.services.DefaultLoggingManager@1074a5fdmodelRegistry: org.gradle.model.internal.registry.DefaultModelRegistry@115c426emodelSchemaStore: org.gradle.model.internal.manage.schema.extract.DefaultModelSchemaStore@2dfbc134module: org.gradle.api.internal.artifacts.ProjectBackedModule@44f77247name: LearnGradleorg.gradle.eclipse.postprocess.applied: trueparent: nullparentIdentifier: nullpath: :pluginManager: org.gradle.api.internal.plugins.DefaultPluginManager_Decorated@724c80aaplugins: [org.gradle.api.plugins.HelpTasksPlugin@42a20621, org.gradle.language.base.plugins.LifecycleBasePlugin@482e65be, org.gradle.api.plugins.BasePlugin@4590f8ff, org.gradle.api.plugins.ReportingBasePlugin@33edb140, org.gradle.platform.base.plugins.ComponentBasePlugin@2d705ad3, org.gradle.language.base.plugins.LanguageBasePlugin@73c9898c, org.gradle.platform.base.plugins.BinaryBasePlugin@338c4dea, org.gradle.api.plugins.JavaBasePlugin@3a1924a5, org.gradle.api.plugins.JavaPlugin@759dc13f, org.gradle.plugins.ide.eclipse.EclipsePlugin@7673da29]processOperations: org.gradle.api.internal.file.DefaultFileOperations@7f8fc4d1processResources: task ':processResources'processTestResources: task ':processTestResources'project: root project 'LearnGradle'projectDir: /Users/xyq/workspace/LearnGradleprojectEvaluationBroadcaster: ProjectEvaluationListener broadcastprojectEvaluator: org.gradle.configuration.project.LifecycleProjectEvaluator@3eade1abprojectPath: :projectRegistry: org.gradle.api.internal.project.DefaultProjectRegistry@b43e0ceproperties: &#123;...&#125;repeatTasks0: task ':repeatTasks0'repeatTasks1: task ':repeatTasks1'repeatTasks2: task ':repeatTasks2'reporting: org.gradle.api.reporting.ReportingExtension_Decorated@787f9cfareportsDir: /Users/xyq/workspace/LearnGradle/build/reportsrepositories: [org.gradle.api.internal.artifacts.repositories.DefaultMavenArtifactRepository_Decorated@6ea00a8f]resources: org.gradle.api.internal.resources.DefaultResourceHandler@3fd10e49rootDir: /Users/xyq/workspace/LearnGradlerootProject: root project 'LearnGradle'scriptHandlerFactory: org.gradle.api.internal.initialization.DefaultScriptHandlerFactory@2b80dcedscriptPluginFactory: org.gradle.configuration.ScriptPluginFactorySelector@2f9c0d2bserviceRegistryFactory: org.gradle.internal.service.scopes.ProjectScopeServices$4@41869e25services: ProjectScopeServicessourceCompatibility: 1.8sourceSets: [source set 'main', source set 'test']standardOutputCapture: org.gradle.internal.logging.services.DefaultLoggingManager@1074a5fdstartChain: task ':startChain'state: project state 'EXECUTED'status: integrationsubprojects: []targetCompatibility: 1.8taskChainSample: task ':taskChainSample'tasks: [task ':assemble', task ':buildDependents', task ':buildNeeded', task ':check', task ':classes', task ':cleanEclipse', task ':cleanEclipseClasspath', task ':cleanEclipseJdt', task ':cleanEclipseProject', task ':compileJava', task ':compileTestJava', task ':eclipse', task ':eclipseClasspath', task ':eclipseJdt', task ':eclipseProject', task ':helloGradle', task ':jar', task ':javadoc', task ':processResources', task ':processTestResources', task ':properties', task ':repeatTasks0', task ':repeatTasks1', task ':repeatTasks2', task ':startChain', task ':taskChainSample', task ':test', task ':testClasses']test: task ':test'testClasses: task ':testClasses'testReportDir: /Users/xyq/workspace/LearnGradle/build/reports/teststestReportDirName: teststestResultsDir: /Users/xyq/workspace/LearnGradle/build/test-resultstestResultsDirName: test-resultsversion: unspecified 8. Gradle守护进程 开启守护进程 1234567891011121314$ gradle taskChainSample --daemon:startChain[ant:echo] Repeat from here...:repeatTasks0do repeatTasktask ':repeatTasks0':repeatTasks1do repeatTasktask ':repeatTasks1':repeatTasks2do repeatTasktask ':repeatTasks2':taskChainSampleBUILD SUCCESSFULTotal time: 0.735 secs 后续触发的gradle &lt;task&gt; --daemon会重用gradle守护进程使用gradle &lt;task&gt; --no-daemon选择不重用守护进程 查看守护进程 12$ ps | grep gradle69403 ttys002 0:00.00 grep gradle 关闭守护进程 123$ gradle --stopStopping Daemon(s)1 Daemon stopped 守护进程会在3小时候自动过期]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP]]></title>
    <url>%2F2016%2F02%2F13%2FSpring%20AOP%2F</url>
    <content type="text"><![CDATA[1. 术语 连接点（JointPoint）：代码中具有边界性质特定点；Spring仅支持方法的连接点，包含方法和方位两方面信息 切点（Pointcut）：定位到某个方法 增强（Advice）：织入到目标连接点上的代码 目标对象（Target）：增强逻辑的目标织入类 引介（Introduction）：特殊的增强，为类添加一些属性和方法 织入（Weaving）：将增强添加到目标连接点上的过程：编译期织入、类装载期织入、动态代理织入（Spring的方案） 代理（Proxy）：被AOP织入增强后的结果类 切面（Aspect）：切点+增强 2. 动态代理的两种实现：JDK和CGLib JDK动态代理动态创建一个符合某一接口的实力，生成目标类的代理对象，缺点是需要提供接口；方法必须是public或public final的 CGLib采用底层的字节码技术，在子类中对父类的方法进行拦截，织入横切逻辑；不能为final和private方法代理 样例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package test;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;public class ProxyTest &#123; public static void main(String[] args) &#123; ServiceImpl jdkTarget = new ServiceImpl(); ProxyHandler handler = new ProxyHandler(jdkTarget); Service jdkProxy = (Service)Proxy.newProxyInstance( jdkTarget.getClass().getClassLoader(), jdkTarget.getClass().getInterfaces(), handler); jdkProxy.process("jdk proxy"); System.out.println(); CglibProxy cglibProxy = new CglibProxy(); ServiceImpl cglibTarget = (ServiceImpl)cglibProxy.getProxy(ServiceImpl.class); cglibTarget.process("cglib proxy"); &#125; public interface Service &#123; public void process(String arg); &#125; public static class ServiceImpl implements Service &#123; @Override public void process(String arg) &#123; System.out.println("do something with " + arg); &#125; &#125; //jdk proxy public static class ProxyHandler implements InvocationHandler &#123; private Object target; public ProxyHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("before process jdk proxy"); Object obj = method.invoke(target, args); System.out.println("after process jdk proxy"); return obj; &#125; &#125; //cglib proxy public static class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); public Object getProxy(Class clazz) &#123; enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println("before process cglib proxy"); Object result = proxy.invokeSuper(obj, args); System.out.println("after process cglib proxy"); return result; &#125; &#125;&#125; 结果 1234567before process jdk proxydo something with jdk proxyafter process jdk proxybefore process cglib proxydo something with cglib proxyafter process cglib proxy 性能：CGLib所创建的动态代理对象性能比JDK方式高（约10倍），但CGLib在创建代理对象时所花费的时间比JDK方式多（约8倍）；CGLib适合Spring里singleton模式的bean管理 3. ProxyFactory Spring定义了org.springframework.aop.framework.AopProxy接口及Cglib2AopProxy和JdkDynamicAopProxy两个final实现类 如果通过ProxyFactory的setInterfaces(Class[] interfaces)指定针对接口代理，则使用JdkDynamicAopProxy；如果使用setOptimize(true)，使用Cglib2AopProxy ProxyFacotry通过addAdvice(Advice)形成增强链 4. 增强类型4.1 前置增强 接口：org.springframework.aop.BeforeAdvice 样例 123456789101112package com.aop;import java.lang.reflect.Method;import org.springframework.aop.MethodBeforeAdvice;public class BeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method arg0, Object[] arg1, Object arg2) throws Throwable &#123; String arg = (String)arg1[0]; System.out.println("before advice " + arg); &#125;&#125; 4.2 后置增强 接口：org.springframework.aop.AfterReturninigAdvice 样例 1234567891011package com.aop;import java.lang.reflect.Method;import org.springframework.aop.AfterReturningAdvice;public class AfterAdvice implements AfterReturningAdvice &#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; String arg = (String)args[0]; System.out.println("after advice " + arg); &#125;&#125; 4.3 环绕增强 接口：org.aopalliance.intercept.MethodInterceptor 样例 123456789101112131415package com.aop;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;public class AroundAdvice implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; Object[] args = invocation.getArguments(); String arg = (String)args[0]; System.out.println("around advice: before " + arg); Object obj = invocation.proceed(); System.out.println("around advice: after " + arg); return obj; &#125;&#125; 4.4 异常抛出增强 接口：org.springframework.aop.ThrowsAdvice 样例 123456789101112package com.aop;import java.lang.reflect.Method;import org.springframework.aop.ThrowsAdvice;public class ExceptionAdvice implements ThrowsAdvice &#123; public void afterThrowing(Method method, Object[] args, Object target, Exception ex) throws Throwable &#123; System.out.println("------"); System.out.println("throws exception, method=" + method.getName()); System.out.println("throws exception, message=" + ex.getMessage()); &#125;&#125; 4.5 测试4.5.1 基于代码的测试 TestAopAdvice 1234567891011121314151617181920212223242526272829package com.aop;import org.springframework.aop.ThrowsAdvice;import org.springframework.aop.framework.ProxyFactory;public class TestAopAdvice &#123; public static void main(String[] args) &#123; AopExample example = new AopExample(); BeforeAdvice beforeAdvice = new BeforeAdvice(); AfterAdvice afterAdvice = new AfterAdvice(); AroundAdvice aroundAdvice = new AroundAdvice(); ThrowsAdvice throwsAdvice = new ExceptionAdvice(); ProxyFactory pf = new ProxyFactory(); pf.setTarget(example); pf.addAdvice(beforeAdvice); pf.addAdvice(afterAdvice); pf.addAdvice(aroundAdvice); pf.addAdvice(throwsAdvice); AopExample proxy = (AopExample)pf.getProxy(); proxy.handle("blabla"); System.out.println(); try&#123; proxy.throwExp("blabla"); &#125; catch(Exception e) &#123; &#125; &#125;&#125; 输出 1234567891011before advice blablaaround advice: before blablaaop example blablaaround advice: after blablaafter advice blablabefore advice blablaaround advice: before blabla----after throwing----throws exception, method=throwExpthrows exception, message=try throws advice 4.5.2 基于Spring配置的测试 springAop.xml 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;bean id="aopExample" class="com.aop.AopExample" /&gt; &lt;bean id="beforeAdvice" class="com.aop.BeforeAdvice" /&gt; &lt;bean id="afterAdvice" class="com.aop.AfterAdvice" /&gt; &lt;bean id="aroundAdvice" class="com.aop.AroundAdvice" /&gt; &lt;bean id="exceptionAdvice" class="com.aop.ExceptionAdvice" /&gt; &lt;bean id="aopTest" class="org.springframework.aop.framework.ProxyFactoryBean" p:proxyTargetClass="true" p:interceptorNames="beforeAdvice,afterAdvice,aroundAdvice,exceptionAdvice" p:target-ref="aopExample" /&gt;&lt;/beans&gt; TestAopAdvice2 123456789101112131415161718package com.aop;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestAopAdvice2 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ctx = new ClassPathXmlApplicationContext("/springAop.xml"); AopExample aopExample = (AopExample)ctx.getBean("aopTest"); aopExample.handle("blabla"); System.out.println(); try&#123; aopExample.throwExp("blabla"); &#125; catch(Exception e) &#123; &#125; ctx.close(); &#125;&#125; 输出 1234567891011121314151617二月 09, 2017 9:54:11 下午 org.springframework.context.support.ClassPathXmlApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:54:11 CST 2017]; root of context hierarchy二月 09, 2017 9:54:11 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [springAop.xml]before advice blablaaround advice: before blablaaop example blablaaround advice: after blablaafter advice blablabefore advice blablaaround advice: before blabla----after throwing----throws exception, method=throwExpthrows exception, message=try throws advice二月 09, 2017 9:54:11 下午 org.springframework.context.support.ClassPathXmlApplicationContext doClose信息: Closing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:54:11 CST 2017]; root of context hierarchy 4.6 引介增强 接口：org.springframework.aop.IntroductionInterceptor 4.6.1 基于Spring配置的测试代码 IntroductionAdvice 12345package com.aop;public interface IntroductionAdvice &#123; public void setIntroductionActive(boolean active);&#125; ConfigurableIntroduction 1234567891011121314151617181920212223242526package com.aop;import org.aopalliance.intercept.MethodInvocation;import org.springframework.aop.support.DelegatingIntroductionInterceptor;public class ConfigurableIntroduction extends DelegatingIntroductionInterceptor implements IntroductionAdvice &#123; private ThreadLocal&lt;Boolean&gt; map = new ThreadLocal&lt;Boolean&gt;(); @Override public void setIntroductionActive(boolean active) &#123; map.set(active); &#125; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; Object obj = null; if(map.get() != null &amp;&amp; map.get()) &#123; System.out.println("before monitor operation"); obj = super.invoke(invocation); System.out.println("after monitor operation"); &#125; else &#123; obj = super.invoke(invocation); &#125; return obj; &#125;&#125; TestIntroductionAdvice 12345678910111213141516package com.aop;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestIntroductionAdvice &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ctx = new ClassPathXmlApplicationContext("/springAop.xml"); AopExample introductionAop = (AopExample)ctx.getBean("introductionAop"); introductionAop.handle("introduction advice"); IntroductionAdvice ci = (IntroductionAdvice)introductionAop; ci.setIntroductionActive(true); introductionAop.handle("introduction advice"); ctx.close(); &#125;&#125; springAop.xml添加 123456&lt;bean id="configurableIntroduction" class="com.aop.ConfigurableIntroduction" /&gt;&lt;bean id="introductionAop" class="org.springframework.aop.framework.ProxyFactoryBean" p:interfaces="com.aop.IntroductionAdvice" p:target-ref="aopExample" p:interceptorNames="configurableIntroduction" p:proxyTargetClass="true" /&gt; 输出 1234567891011二月 09, 2017 9:56:10 下午 org.springframework.context.support.ClassPathXmlApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:56:10 CST 2017]; root of context hierarchy二月 09, 2017 9:56:10 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [springAop.xml]aop example introduction advice----before monitor operationaop example introduction adviceafter monitor operation二月 09, 2017 9:56:11 下午 org.springframework.context.support.ClassPathXmlApplicationContext doClose信息: Closing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:56:10 CST 2017]; root of context hierarchy 4.6.2 与其他增强在配置上的区别 须指定引介增强所实现的接口 只能通过为目标类创建子类的方式生成引介增强的代理，因此proxyTargeClass必须为true 5. Spring中的配置参数说明 target：代理的对象 proxyInterfaces：代理所要实现的接口 interceptorNames：需要织入目标对象的bean列表，这些bean必须是实现了org.aopalliance.intercept.MethodInterceptor或org.springframework.aop.Advisor的bean，配置中的顺序对应调用的顺序 singleton：返回的代理是否为单例，默认为true optimize：为true时使用CGLib代理 proxyTargetClass：为true时使用CGLib代理，并覆盖proxyInterfaces设置 6. Java注解 一个例子 1234567891011package com.aspectj;import java.lang.annotation.Retention;import java.lang.annotation.Target;import java.lang.annotation.ElementType;import java.lang.annotation.RetentionPolicy;@Target(ElementType.METHOD) //声明可以使用该注解的目标类型@Retention(RetentionPolicy.RUNTIME)//声明注解的保留期限public @interface Authority &#123; boolean value() default true;//声明注解成员&#125; 成员以无入参无抛出异常的方式声明 可以通过default为成员指定一个默认值 在方法上使用注解：@Authority(value=true) 如果注解只有一个成员，需命名为value()，使用时可以忽略成员名和赋值号(=)，如@Authority(true) 注解类拥有多个成员时，如果仅对value成员赋值，可以不适用赋值号；如果同时对多个成员赋值，则必须使用赋值号 注解类可以没有成员，称为标识注解 所有注解类隐式继承于java.lang.annotation.Annotation，注解不允许显式继承于其他接口 如果成员是数组类型，可以通过{}赋值 7. 基于AspectJ的AOP7.1 一个例子 定义切面 1234567891011package com.aspectj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;@Aspectpublic class PreAspect &#123; @Before("execution(*handle(..))") public void before() &#123; System.out.println("aspect: before processing"); &#125;&#125; 测试 1234567891011121314package com.aspectj;import org.springframework.aop.aspectj.annotation.AspectJProxyFactory;import com.aop.AopExample;public class AspectJTest &#123; public static void main(String[] args) &#123; AspectJProxyFactory factory = new AspectJProxyFactory(); AopExample example = new AopExample(); factory.setTarget(example); factory.addAspect(PreAspect.class); AopExample proxy = factory.getProxy(); proxy.handle("pre aspect"); &#125;&#125; 结果 12aspect: before processingaop example pre aspect 7.2 通过配置使用切面7.2.1 典型配置 springAspectj.xml 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;bean id="aopExample" class="com.aop.AopExample" /&gt; &lt;bean id="preAspect" class="com.aspectj.PreAspect" /&gt; &lt;bean class="org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator" /&gt;&lt;/beans&gt; 7.2.2 基于Schema的配置 springAspectj.xml 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;aop:aspectj-autoproxy /&gt; &lt;bean id="aopExample" class="com.aop.AopExample" /&gt; &lt;bean id="preAspect" class="com.aspectj.PreAspect" /&gt;&lt;/beans&gt; AspectJTest2 123456789101112131415package com.aspectj;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.aop.AopExample;public class AspectJTest2 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ctx = new ClassPathXmlApplicationContext("/springAspectj.xml"); AopExample aopExample = (AopExample)ctx.getBean("aopExample"); aopExample.handle("blabla"); ctx.close(); &#125;&#125; 输出 12345678二月 09, 2017 10:13:56 下午 org.springframework.context.support.ClassPathXmlApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 22:13:56 CST 2017]; root of context hierarchy二月 09, 2017 10:13:56 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [springAspectj.xml]aspect: before processingaop example blabla二月 09, 2017 10:13:57 下午 org.springframework.context.support.ClassPathXmlApplicationContext doClose信息: Closing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 22:13:56 CST 2017]; root of context hierarchy 通过&lt;aop:aspectj-autoproxy /&gt;引入aop命名空间，自动为Spring容器中匹配@AspectJ切面的bean创建代理，完成切面织入，其内部实现仍为AnnotationAwareAspectJAutoProxyCreator &lt;aop:aspectj-autoproxy /&gt;的proxy-target-class属性为false时，采用JDK动态代理；为true时使用CGLib 8. AspectJ语法8.1 切点表达式函数 分类 类型 说明 举例 方法切点函数 通过描述目标类方法信息定义连接点 execution()，@annotation() 方法入参切点函数 通过描述目标类方法入参的信息定义连接点 args()，@args() 目标类切点函数 通过描述目标类类型信息定义连接点 within()，target()，@within()，@target() 代理类切点函数 通过描述目标类的代理类的信息定义连接点 this() 函数说明 函数 入参 说明 execution() 方法匹配模式串 表示满足某一匹配模式的所有目标类方法连接点，如execution(* handle(..))表示所有目标类中的handle()方法 @annotation() 方法注解类名 表示标注了特定注解的目标方法连接点，如@annotation(com.aspectj.Authority)表示任何标注了@Authority注解的目标类方法 args() 类名 通过判别目标类方法运行时入参对象的类型定义指定连接点，如args(com.data.Car)表示所有有且仅有一个按类型匹配于Car（含子类）入参的方法 @args() 类型注解类名 通过判别目标方法运行时入参对象的类是否标注特定注解来制定连接点，如@args(com.aspectj.Authority)表示任何这样的一个目标方法：它有一个入参且入参对象的类标注@Authority注解。要使@args()生效，类继承树中，标注注解的类类型需要不高于入参类类型 within 类名匹配串 表示特定域下的所有连接点，如within(com.service.*)，within(com.service.*Service)和within(com.service..*) target() 类名 假如目标按类型匹配于指定类，则目标类的所有连接点匹配这个切点。如通过target(com.data.Car)定义的切点，Car及Car的子类中的所有连接点都匹配该切点，包括子类中扩展的方法 @within() 类型注解类名 假如目标类按类型匹配于某个类A，且类A标注了特定注解，则目标类的所有连接点都匹配于这个切点。如@within(com.aspectj.Authority)定义的切点，假如Car类标注了@Authority注解，则Car以及Car的子类的所有连接点都匹配。@within标注接口类无效 @target() 类型注解类名 目标类标注了特定注解，则目标类（不包括子类）所有连接点都匹配该切点。如通过@target(com.aspectj.Authority)定义的切点，若BMWCar标注了@Authority，则BMWCar所有连接点匹配该切点 this() 类名 代理类按类型匹配于指定类，则被代理的目标类所有连接点匹配切点 8.2 通配符8.2.1 通配符类型 类型 说明 * 匹配任意字符，但只能匹配上下文中的一个元素 .. 匹配任意字符，可以匹配上下文中的多个元素。表示类时，和*联合使用；表示入参时单独使用 + 按类型匹配指定类的所有类（包括实现类和继承类），必须跟在类名后面 8.2.1 函数按通配符支持分类 支持所有通配符：execution()，within() 仅支持+通配符：args()，this()，target() 不支持通配符：@args，@within，@target，@annotation 8.3 增强类型 @Before：前置增强，相当于BeforeAdvice @AfterReturning：后置增强，相当于AfterReturningAdvice @Around：环绕增强，相当于MethodInterceptor @AfterThrowing：相当于ThrowsAdvice @After：Final增强，抛出异常或正常退出都会执行的增强 @DeclareParents：引介增强，相当于IntroductionInterceptor 8.4 Execution() 语法：execution(&lt;修饰符模式&gt;? &lt;返回类型模式&gt; &lt;方法名模式&gt; (&lt;参数模式&gt;) &lt;异常模式&gt;?) 8.4.1 通过方法签名定义切点 execution(pulic * *(..))：匹配目标类的public方法，第一个*代表返回类型，第二个*代表方法名，..代表任意入参 execution(* *To(..))：匹配目标类所有以To结尾的方法，第一个*代表返回类型，*To代表任意以To结尾的方法 8.4.2 通过类定义切点 execution(* com.data.User.*(..))：匹配User接口的所有方法 execution(* com.data.User+.*(..))：匹配User接口的所有方法，包括其实现类中不在User接口中定义的方法 8.4.3 通过类包定义切点 execution(* com.data.*(..))：匹配data包下所有类的所有方法 execution(* com.data.User..*(..))：匹配data包及其子孙包中的所有类的所有方法 execution(* com..*Manager.get*(..))：匹配com包及其子孙包中后缀为Manager的类里以get开头的方法 8.4.4 通过方法入参定义切点 execution(* get(String, int))：匹配get(String, int)方法 execution(* get(String, *))：匹配名为get且第一个入参类型为String、第二个入参类型任意的方法 execution(* get(String, ..))：匹配名为get且第一个入参为String类型的方法 execution(* get(Object+))：匹配名为get且唯一入参是Object或其子类的方法 8.5 进阶8.5.1 逻辑运算符 与&amp;&amp;，或||，非! 8.5.2 切点复合运算 例如：@After(&quot;within(com.data.*) &amp;&amp; execution(* handle(..))&quot;) 8.5.3 命名切点 使用@Pointcut命名切点 使用方法名作为切点的名称，方法的访问控制符控制切点的可用性 12@Pointcut("within(com.data.*)")public void inPackage()&#123;&#125; //别名为inPackage 8.5.4 增强织入的顺序 如果增强在同一个切面类中声明，则依照增强在切面类中定义的顺序织入 如果增强位于不同的增强类中，且都实现了org.springframework.core.Ordered接口，则由接口方法的顺序号决定（顺序号小的先织入） 如果增强位于不同的增强类中，且没有实现org.springframework.core.Ordered接口，织入顺序不确定 8.5.5 访问连接点信息 AspectJ使用org.aspectj.lang.JointPoint接口表示目标类连接点对象。如果是环绕增强时，使用org.aspectj.lang.ProceedingJointPoint表示连接点对象，该类是JointPoint接口的子接口。任何一个增强方法都可以通过将第一个入参声明为JointPoint访问到连接点上下文的信息 8.5.6 绑定连接点方法入参 args()用于绑定连接点方法的入参，@annotation()用于绑定连接点方法的注解对象，@args()用于绑定连接点方法的入参注解。下例表示方法入参为(String, int, ..)的方法匹配该切点，并将name和age两个参数绑定到切面方法的入参中 1234@Before("args(name, age, ..)")public void bindJointPointValues(String name, int age) &#123; //do something&#125; 8.5.7 绑定代理对象 使用this()或target()可以绑定被代理对象的实例。下例表示代理对象为User类的所有方法匹配该切点，且代理对象绑定到user入参中 1234@Before("this(user)")public void bindProxy(User user) &#123; //do something&#125; 8.5.8 绑定类注解对象 @within()和@target()函数可以将目标类的注解对象绑定到增强方法中 1234@Before("@within(a)")public void bindAnnotation(Authority a) &#123; //do something&#125; 8.5.9 绑定返回值 通过returning绑定连接点方法的返回值 1234@AfterReturning(value="target(com.data.Car)", returning="rvl")public void bindReturningValue(int rvl) &#123; //do something&#125; rvl的类型必须和连接点方法的返回值类型匹配 8.5.10 绑定抛出的异常 使用AfterThrowing注解的throwing成员绑定 1234@AfterThrowing(value="target(com.data.Car)", throwing="iae")public void bindException(IllegalArgumentException iae) &#123; //do something&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IoC]]></title>
    <url>%2F2016%2F02%2F10%2FSpring%20IOC%2F</url>
    <content type="text"><![CDATA[1. Spring的资源抽象接口假如有一个文件位于Web应用的类路径下，用户可以通过以下方式对这个文件资源进行访问： 通过FileSystemResource以文件系统绝对路径的方式进行访问； 通过ClassPathResource以类路径的方式进行访问； 通过ServletContextResource以相对于Web应用根目录的方式进行访问。 2. BeanFactory的类体系结构 BeanFactory：位于类结构树的顶端，最主要的方法是getBean(String beanName)，从容器中返回特定类型的bean ListableBeanFactory：该接口定义了访问容器中Bean基本信息的若干方法 HierarchicalBeanFactory：父子级联IoC容器的接口，子容器可以通过接口方法访问父容器 ConfigurableBeanFactory：增强了IoC容器的可定制性 AutowireCapableBeanFactory：定义了将容器中的bean按照某种规则进行自动装配的方法 SingletonBeanRegistry：定义了允许在运行期向容器注册单实例bean的方法 BeanDefinitionRegistry：每一个bean在容器中通过BeanDefinition对象表示，BeanDefinitionRegistry定义了向容器手工注册bean的方法 Spring在DefaultSingletonBeanRegistry类中提供了一个用于缓存单实例bean的缓存器，以HashMap实现，单实例的bean以beanName为key保存在这个HashMap中 3. ApplicationContext的类体系结构 ApplicationEventPublisher：让容器拥有发布应用上下文事件的功能，包括容器启动事件、关闭事件等。实现了ApplicationListener事件监听接口的Bean 可以接收到容器事件，并对事件进行响应处理。在ApplicationContext抽象实现类AbstractApplicationContext中，我们可以发现存在一个ApplicationEventMulticaster，它负责保存所有监听器，以便在容器产生上下文事件时通知这些事件监听者。 MessageSource：为应用提供i18n国际化消息访问的功能； ResourcePatternResolver：所有ApplicationContext实现类都实现了类似于PathMatchingResourcePatternResolver的功能，可以通过带前缀的Ant风格的资源文件路径装载Spring的配置文件。 LifeCycle：该接口是Spring 2.0加入的，该接口提供了start()和stop()两个方法，主要用于控制异步处理过程。在具体使用时，该接口同时被ApplicationContext实现及具体Bean实现，ApplicationContext会将start/stop的信息传递给容器中所有实现了该接口的Bean，以达到管理和控制JMX、任务调度等目的。 ConfigurableApplicationContext扩展于ApplicationContext，它新增加了两个主要的方法：refresh()和close()，让ApplicationContext具有启动、刷新和关闭应用上下文的能力。在应用上下文关闭的情况下调用refresh()即可启动应用上下文，在已经启动的状态下，调用refresh()则清除缓存并重新装载配置信息，而调用close()则可关闭应用上下文。 4. WebApplicantContext体系结构 它允许从相对于Web根目录的路径中加载配置文件完成初始化工作。从WebApplicationContext中可以获取ServletContext引用，整个Web应用上下文对象将作为属性放置在ServletContext中，以便Web应用环境可以访问spring上下文。 WebApplicationContext扩展了ApplicationContext，WebApplicationContext定义了一个常量ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE，在上下文启动时，我们可以直接通过下面的语句从web容器中获取WebApplicationContext: 1WebApplicationContext wac=(WebApplicationContext)servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE); 5. BeanFactory中Bean的生命周期5.1 Bean生命周期 如果容器注册InstantiationAwareBeanPostProcessor接口，调用postProcessBeforeInstantiation方法 Bean的实例化(调用默认构造器) 如果容器注册InstantiationAwareBeanPostProcessor接口，调用postProcessAfterInstantiation方法 如果容器注册InstantiationAwareBeanPostProcessor接口，调用postProcessPropertyValues方法 根据配置设置属性值 如果Bean实现了BeanNameAware接口，调用BeanNameAware接口的setBeanName方法 如果Bean实现了BeanFactoryAware接口，调用BeanFactoryAware接口的setBeanFactory方法 如果容器注册了BeanPostProcessor接口，调用BeanPostProcessor接口的postProcessBeforeInitialization方法 如果Bean实现了InitializingBean接口，调用InitializingBean接口的afterPropertiesSet方法 通过init-method属性配置的初始方法 如果容器注册了BeanPostProcessor接口，调用BeanPostProcessor接口的postProcessAfterInitialization方法 如果是单例模式，将Bean放入缓存池中；容器销毁时，调用DisposableBean的destroy方法；最后调用destroy-method方法 如果是多例模式，将Bean交给调用者。 5.2 初始化过程中的方法分类 bean自身的方法：如调用bean构造函数实例化bean，调用Setter设置bean的属性值，以及通过&lt;bean&gt;的init-method和destory-method所指定的方法； bean级生命周期接口方法：如BeanNameAware、BeanFactoryAware、InitializingBean和DisposableBean，这些接口方法由bean类直接实现； 容器级生命周期接口方法：如InstantiationAwareBeanPostProcessor和 BeanPostProcessor这两个接口实现，一般称它们的实现类为“后处理器”。 5.3 说明 Spring的AOP等功能即通过BeanPostProcessor实现 如果&lt;bean&gt;通过init-method属性定义了初始化方法，将执行这个方法 如果bean的作用范围为scope=&quot;prototype&quot;，将bean返回给调用者之后，调用者负责bean的后续生命的管理，Spring不再管理这个bean的生命周期；如果scope=&quot;singleton&quot;，则将bean放入到Spring IoC容器的缓存池中，并将bean的引用返回给调用者，Spring继续管理这些bean的后续生命周期 对于单例的bean，当容器关闭时，将触发Spring对bean的后续生命周期的管理工作。如果bean实现了DisposableBean接口，则将调用接口的destroy()方法 对于单例的bean，如果通过destroy-method指定了bean的销毁方法，Spring将执行这个方法 后处理器的实际调用顺序和注册顺序无关，在具有多个后处理器的情况下，必须通过实现org.springframework.core.Ordered接口确定调用顺序 5.4 测试 applicationContext.xml 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="car" class="com.data.Car" p:color="color" init-method="init" destroy-method="destroy2" /&gt;&lt;/beans&gt; Car 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.data;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.beans.factory.BeanNameAware;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.InitializingBean;public class Car implements BeanNameAware, BeanFactoryAware, InitializingBean, DisposableBean &#123; public Car() &#123; System.out.println("construct car"); &#125; private String name; private String color; private BeanFactory beanFactory; private String beanName; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getColor() &#123; return color; &#125; public void setColor(String color) &#123; this.color = color; System.out.println("set color=" + color); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("after properties set method"); &#125; public void init() &#123; System.out.println("init method"); &#125; @Override public void destroy() &#123; System.out.println("destroy method"); &#125; public void destroy2() &#123; System.out.println("my destroy method"); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println("set bean factory"); this.beanFactory = beanFactory; &#125; @Override public void setBeanName(String name) &#123; System.out.println("set bean name"); this.beanName = name; &#125; public BeanFactory getBeanFactory() &#123; return beanFactory; &#125; public String getBeanName() &#123; return beanName; &#125;&#125; MyBeanPostProcessor 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.beanfactory;import java.beans.PropertyDescriptor;import org.springframework.beans.BeansException;import org.springframework.beans.PropertyValues;import org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessorAdapter;public class MyBeanPostProcessor extends InstantiationAwareBeanPostProcessorAdapter&#123; public MyBeanPostProcessor() &#123; System.out.println("construct MyBeanPostProcessor"); &#125; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println("post process before instantiation"); return null; &#125; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; System.out.println("post process after instantiation"); return true; &#125; @Override public PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; System.out.println("post process property values"); return pvs; &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("post process before initialization"); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("post process after initialization"); return bean; &#125;&#125; TestBeanFactory 12345678910111213141516171819202122232425package config;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.core.io.ClassPathResource;import org.springframework.core.io.Resource;import com.beanfactory.MyBeanPostProcessor;import com.data.Car;@SuppressWarnings("deprecation")public class TestBeanFactory &#123; public static void main(String[] args) &#123; Resource res = new ClassPathResource( "/applicationContext.xml"); XmlBeanFactory bf = new XmlBeanFactory(res); bf.addBeanPostProcessor(new MyBeanPostProcessor()); System.out.println("bean factory initialization done"); Car car1 = bf.getBean("car", Car.class); Car car2 = bf.getBean("car", Car.class); System.out.println("(car1 == car2) = " + (car1 == car2)); System.out.println("get color=" + car1.getColor()); bf.destroySingletons(); &#125;&#125; 结果 12345678910111213141516171819二月 09, 2017 10:58:59 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [applicationContext.xml]construct MyBeanPostProcessorbean factory initialization donepost process before instantiationconstruct carpost process after instantiationpost process property valuesset color=colorset bean nameset bean factorypost process before initializationafter properties set methodinit methodpost process after initialization(car1 == car2) = trueget color=colordestroy methodmy destroy method 6. ApplicationContext中的Bean生命周期6.1 流程图 6.2 说明 如果bean实现了org.springframework.context.ApplicationContextAware接口，会增加一个调用该接口方法setApplicationContext()的步骤 如果配置文件中声明了工厂后处理器接口BeanFactoryPostProcessor的实现类，则应用上下文在加载配置文件之后、初始化bean实例之前将调用这些BeanFactoryPostProcessor对配置信息进行加工处理 ApplicationContext和BeanFactory的不同之处在于：前者会利用Java反射机制自动识别出配置文件中定义的BeanPostProcessor、InstantiationAwareBeanPostProcessor和BeanFactoryPostProcessor，并自动将它们注册到应用上下文中；而后者需要在代码中通过手工调用addBeanPostProcessor()方法进行注册 对bean的初始化，BeanFactory发生在第一次调用bean时，而ApplicationContext发生在初始化容器时 6.3 测试 MyBeanPostProcessor同上 Car增加对ApplicationContextAware接口的实现，并添加@PostConstruct和@PreDestroy的注解方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package com.data;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.beans.factory.BeanNameAware;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.InitializingBean;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;public class Car implements BeanNameAware, BeanFactoryAware, InitializingBean, DisposableBean, ApplicationContextAware &#123; public Car() &#123; System.out.println("construct car"); &#125; private String name; private String color; private BeanFactory beanFactory; private String beanName; private ApplicationContext ctx; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getColor() &#123; return color; &#125; public void setColor(String color) &#123; this.color = color; &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("after properties set method"); &#125; public void init() &#123; System.out.println("init method"); &#125; @Override public void destroy() &#123; System.out.println("destroy method"); &#125; public void destroy2() &#123; System.out.println("my destroy method"); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println("set bean factory"); this.beanFactory = beanFactory; &#125; @Override public void setBeanName(String name) &#123; System.out.println("set bean name"); this.beanName = name; &#125; public BeanFactory getBeanFactory() &#123; return beanFactory; &#125; public String getBeanName() &#123; return beanName; &#125; @PostConstruct public void postConstruct() &#123; System.out.println("post construct"); &#125; @PreDestroy public void preDestroy() &#123; System.out.println("pre destroy"); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; System.out.println("set application context"); this.ctx = applicationContext; &#125; public ApplicationContext getApplicationContext() &#123; return ctx; &#125;&#125; MyBeanFactoryPostProcessor 123456789101112131415package com.beanfactory;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanFactoryPostProcessor;import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; public MyBeanFactoryPostProcessor() &#123; System.out.println("construct MyBeanFactoryPostProcessor"); &#125; public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println("post process bean factory"); &#125;&#125; 基于Java类的Spring配置：AnnotationBeans 123456789101112131415161718192021222324252627package config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.beanfactory.MyBeanFactoryPostProcessor;import com.beanfactory.MyBeanPostProcessor;import com.data.Car;@Configurationpublic class AnnotationBeans &#123; @Bean(name = "car", initMethod = "init", destroyMethod = "destroy2") public Car getCar() &#123; Car car = new Car(); car.setColor("color"); return car; &#125; @Bean(name = "myBeanPostProcessor") public MyBeanPostProcessor getMyBeanPostProcessor() &#123; return new MyBeanPostProcessor(); &#125; @Bean(name = "myBeanFactoryPostProcessor") public MyBeanFactoryPostProcessor getMyBeanFactoryPostProcessor() &#123; return new MyBeanFactoryPostProcessor(); &#125;&#125; TestApplicationContext 123456789101112131415161718package config;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import com.data.Car;public class TestApplicationContext &#123; public static void main(String[] args) &#123; /*对于以xml形式初始化的ctx，也可以用ClassPathXmlApplicationContext 或者FileSystemXmlApplicationContext*/ AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext( AnnotationBeans.class); System.out.println("application context done"); Car car = ctx.getBean("car", Car.class); System.out.println("get color=" + car.getColor()); ctx.close(); &#125;&#125; 结果 123456789101112131415161718192021222324252627282930313233343536二月 09, 2017 11:55:25 下午 org.springframework.context.annotation.AnnotationConfigApplicationContext prepareRefresh信息: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@306a30c7: startup date [Thu Feb 09 23:55:25 CST 2017]; root of context hierarchy二月 09, 2017 11:55:25 下午 org.springframework.context.annotation.ConfigurationClassEnhancer intercept警告: @Bean method AnnotationBeans.getMyBeanFactoryPostProcessor is non-static and returns an object assignable to Spring&apos;s BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method&apos;s declaring @Configuration class. Add the &apos;static&apos; modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.construct MyBeanFactoryPostProcessorpost process bean factoryconstruct MyBeanPostProcessorpost process before instantiationpost process after instantiationpost process property valuespost process before initializationpost process after initializationpost process before instantiationpost process after instantiationpost process property valuespost process before initializationpost process after initializationpost process before instantiationconstruct carpost process after instantiationpost process property valuesset bean nameset bean factoryset application contextpost process before initializationpost constructafter properties set methodinit methodpost process after initializationapplication context doneget color=color二月 09, 2017 11:55:25 下午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@306a30c7: startup date [Thu Feb 09 23:55:25 CST 2017]; root of context hierarchypre destroydestroy methodmy destroy method 7. 容器内部工作机制7.1 启动源码Spring的AbstractApplicationContext的refresh()方法定义了Spring容器在加载配置文件后的各项处理工作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 7.2 容器启动流程ContextLoaderListener通过调用继承自ContextLoader的initWebApplicationContext方法实例化SpringIoC容器。在实例化Spring IoC容器的过程中，最主要的两个方法是createWebApplicationContext和configureAndRefreshWebApplicationContext方法。createWebApplicationContext方法用于返回XmlWebApplicationContext实例，即Web环境下的SpringIoC容器。configureAndRefreshWebApplicationContext用于配XmlWebApplicationContext，读取web.xml中通过contextConfigLocation标签指定的XML文件，通过调用refresh来调用AbstractApplicationContext中的refresh初始化。 BeanFactory实例化XML文件中配置的bean，Spring将配置文件的bean的信息解析成为一个个的BeanDefinition对象并装入到容器的Bean定义注册表，但此时Bean还未初始化；obtainFreshBeanFactory()会调用自身的refreshBeanFactory()，而refreshBeanFactory()方法由子类AbstractRefreshableApplicationContext实现，该方法返回了一个创建的DefaultListableBeanFactory对象，这个对象就是由ApplicationContext管理的BeanFactory容器对象； 调用工厂后处理器：根据反射机制从BeanDefinitionRegistry中找出所有BeanFactoryPostProcessor类型的Bean，并调用其postProcessBeanFactory()接口方法。经过第一步加载配置文件，已经把配置文件中定义的所有bean装载到BeanDefinitionRegistry这个Beanfactory中，对于ApplicationContext应用来说这个BeanDefinitionRegistry类型的BeanFactory就是Spring默认的DefaultListableBeanFactory 注册Bean后处理器：根据反射机制从BeanDefinitionRegistry中找出所有BeanPostProcessor类型的Bean，并将它们注册到容器Bean后处理器的注册表中； 初始化消息源：初始化容器的国际化信息资源； 初始化应用上下文事件广播器； 初始化其他特殊的Bean； 注册事件监听器； 初始化singleton的Bean：实例化所有singleton的Bean，并将它们放入Spring容器的缓存中； 发布上下文刷新事件：在此处时容器已经启动完成，发布容器refresh事件创建上下文刷新事件，事件广播器负责将些事件广播到每个注册的事件监听器中。 7.3 Bean加载流程 ResourceLoader从存储介质中加载Spring配置文件，并使用Resource表示这个配置文件的资源； BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个&lt;bean&gt;解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中； 容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作： 对使用到占位符的&lt;bean&gt;元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象； 对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）； Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作； 在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作； 利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。 8. Spring事件Spring事件体系包括三个组件：事件，事件监听器，事件广播器。 事件：ApplicationEvent 事件监听器：ApplicationListener，对监听到的事件进行处理。 事件广播器：ApplicationEventMulticaster，将Spring publish的事件广播给所有的监听器。Spring在ApplicationContext接口的抽象实现类AbstractApplicationContext中完成了事件体系的搭建。 AbstractApplicationContext拥有一个applicationEventMulticaster成员变量，applicationEventMulticaster提供了容器监听器的注册表。 8.1 事件广播器的初始化12345678910111213141516private void initApplicationEventMulticaster() throws BeansException &#123; if (containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME )) &#123; this.applicationEventMulticaster = (ApplicationEventMulticaster) getBean( APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class ); if (logger.isInfoEnabled()) &#123; logger.info("Using ApplicationEventMulticaster [" + this. applicationEventMulticaster + "]" ); &#125; &#125; else &#123; this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(); if (logger.isInfoEnabled()) &#123; logger.info("Unable to locate ApplicationEventMulticaster with name '"+ APPLICATION_EVENT_MULTICASTER_BEAN_NAME + "': using default [" + this .applicationEventMulticaster + "]"); &#125; &#125; &#125; 用户可以在配置文件中为容器定义一个自定义的事件广播器，只要实现ApplicationEventMulticaster就可以了，Spring会通过反射的机制将其注册成容器的事件广播器，如果没有找到配置的外部事件广播器，Spring自动使用 SimpleApplicationEventMulticaster作为事件广播器。 8.2 注册事件监听器1234567891011private void registerListeners () throws BeansException &#123; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! Collection listeners = getBeansOfType(ApplicationListener.class,true,false).values(); for (Iterator it = listeners.iterator(); it.hasNext();) &#123; addListener((ApplicationListener) it.next()); &#125;&#125;protected void addListener(ApplicationListener listener) &#123; getApplicationEventMulticaster().addApplicationListener(listener);&#125; Spring根据反射机制，使用ListableBeanFactory的getBeansOfType方法，从BeanDefinitionRegistry中找出所有实现 org.springframework.context.ApplicationListener的Bean，将它们注册为容器的事件监听器，实际的操作就是将其添加到事件广播器所提供的监听器注册表中。 8.3 发布事件1234567891011public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, "Event must not be null"); if (logger.isDebugEnabled()) &#123; logger.debug("Publishing event in context [" + getDisplayName() + "]: " + event); &#125; getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; 在AbstractApplicationContext的publishEvent方法中， Spring委托ApplicationEventMulticaster将事件通知给所有的事件监听器 8.4 Spring默认的事件广播器SimpleApplicationEventMulticaster12345678910public void multicastEvent( final ApplicationEvent event) &#123; for (Iterator it = getApplicationListeners().iterator(); it.hasNext();) &#123; final ApplicationListener listener = (ApplicationListener) it.next(); getTaskExecutor().execute(new Runnable() &#123; public void run() &#123; listener.onApplicationEvent(event); &#125; &#125;); &#125; &#125; 遍历注册的每个监听器，并启动来调用每个监听器的onApplicationEvent方法。由于SimpleApplicationEventMulticaster的taskExecutor的实现类是SyncTaskExecutor，因此，事件监听器对事件的处理，是同步进行的。 8.5 举例 springEvent.xml 123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.event" /&gt;&lt;/beans&gt; MockEvent 12345678910package com.event;import org.springframework.context.ApplicationContext;import org.springframework.context.event.ApplicationContextEvent;public class MockEvent extends ApplicationContextEvent &#123; public MockEvent(ApplicationContext source) &#123; super(source); &#125;&#125; MockEventListener 1234567891011package com.event;import org.springframework.context.ApplicationListener;import org.springframework.stereotype.Component;@Componentpublic class MockEventListener implements ApplicationListener&lt;MockEvent&gt; &#123; public void onApplicationEvent(MockEvent event) &#123; System.out.println("mock event received"); &#125;&#125; MockEventPublisher 123456789101112131415161718192021package com.event;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;;@Componentpublic class MockEventPublisher implements ApplicationContextAware &#123; private ApplicationContext ctx; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.ctx = applicationContext; &#125; public void publishEvent() &#123; System.out.println("publish event"); MockEvent event = new MockEvent(this.ctx); ctx.publishEvent(event); &#125;&#125; MockEventTest 1234567891011121314package com.event;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MockEventTest &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ctx = new ClassPathXmlApplicationContext( "/springEvent.xml"); MockEventPublisher publisher = ctx.getBean(MockEventPublisher.class); publisher.publishEvent(); ctx.close(); &#125;&#125; 结果 12345678二月 09, 2017 9:57:43 下午 org.springframework.context.support.ClassPathXmlApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:57:43 CST 2017]; root of context hierarchy二月 09, 2017 9:57:43 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [springEvent.xml]publish eventmock event received二月 09, 2017 9:57:44 下午 org.springframework.context.support.ClassPathXmlApplicationContext doClose信息: Closing org.springframework.context.support.ClassPathXmlApplicationContext@69d0a921: startup date [Thu Feb 09 21:57:43 CST 2017]; root of context hierarchy]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
</search>
